<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2026-02-02</h1>
<h3>Title: Neural Signals Generate Clinical Notes in the Wild</h3>
<ul>
<li><strong>Authors: </strong>Jathurshan Pradeepkumar, Zheng Chen, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22197">https://arxiv.org/abs/2601.22197</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22197">https://arxiv.org/pdf/2601.22197</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22197]] Neural Signals Generate Clinical Notes in the Wild(https://arxiv.org/abs/2601.22197)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Generating clinical reports that summarize abnormal patterns, diagnostic findings, and clinical interpretations from long-term EEG recordings remains labor-intensive. We curate a large-scale clinical EEG dataset with $9{,}922$ reports paired with approximately $11{,}000$ hours of EEG recordings from $9{,}048$ patients. We therefore develop CELM, the first clinical EEG-to-Language foundation model capable of summarizing long-duration, variable-length EEG recordings and performing end-to-end clinical report generation at multiple scales, including recording description, background activity, epileptiform abnormalities, events/seizures, and impressions. Experimental results show that, with patient history supervision, our method achieves $70\%$--$95\%$ average relative improvements in standard generation metrics (e.g., ROUGE-1 and METEOR) from $0.2$--$0.3$ to $0.4$--$0.6$. In the zero-shot setting without patient history, CELM attains generation scores in the range of $0.43$--$0.52$, compared to baselines of $0.17$--$0.26$. CELM integrates pretrained EEG foundation models with language models to enable scalable multimodal learning. We release our model and benchmark construction pipeline at [URL].</li>
<li><strong>摘要：</strong>从长期脑电图记录中生成总结异常模式、诊断结果和临床解释的临床报告仍然是劳动密集型的。我们整理了一个大规模临床脑电图数据集，其中包含价值 9{,}922 美元的报告以及来自 9 美元{,}048 美元患者的约 11{,}000 小时的脑电图记录。因此，我们开发了 CELM，这是第一个临床脑电图到语言基础模型，能够总结长时间、可变长度的脑电图记录，并在多个尺度上生成端到端临床报告，包括记录描述、背景活动、癫痫样异常、事件/癫痫发作和印象。实验结果表明，通过患者病史监督，我们的方法在标准生成指标（例如 ROUGE-1 和 METEOR）方面实现了 $70\%$--$95\%$ 平均相对改进，从 $0.2$--$0.3$ 到 $0.4$--$0.6$。在没有患者病史的零样本设置中，CELM 获得的生成分数在 $0.43$-$0.52$ 范围内，而基线为 $0.17$-$0.26$。 CELM 将预训练的脑电图基础模型与语言模型相集成，以实现可扩展的多模式学习。我们在 [URL] 上发布了我们的模型和基准构建管道。</li>
</ul>

<h3>Title: Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions</h3>
<ul>
<li><strong>Authors: </strong>Lingkai Kong, Anagha Satish, Hezi Jiang, Akseli Kangaslahti, Andrew Ma, Wenbo Chen, Mingxiao Song, Lily Xu, Milind Tambe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22211">https://arxiv.org/abs/2601.22211</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22211">https://arxiv.org/pdf/2601.22211</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22211]] Latent Spherical Flow Policy for Reinforcement Learning with Combinatorial Actions(https://arxiv.org/abs/2601.22211)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) with combinatorial action spaces remains challenging because feasible action sets are exponentially large and governed by complex feasibility constraints, making direct policy parameterization impractical. Existing approaches embed task-specific value functions into constrained optimization programs or learn deterministic structured policies, sacrificing generality and policy expressiveness. We propose a solver-induced \emph{latent spherical flow policy} that brings the expressiveness of modern generative policies to combinatorial RL while guaranteeing feasibility by design. Our method, LSFlow, learns a \emph{stochastic} policy in a compact continuous latent space via spherical flow matching, and delegates feasibility to a combinatorial optimization solver that maps each latent sample to a valid structured action. To improve efficiency, we train the value network directly in the latent space, avoiding repeated solver calls during policy optimization. To address the piecewise-constant and discontinuous value landscape induced by solver-based action selection, we introduce a smoothed Bellman operator that yields stable, well-defined learning targets. Empirically, our approach outperforms state-of-the-art baselines by an average of 20.6\% across a range of challenging combinatorial RL tasks.</li>
<li><strong>摘要：</strong>具有组合动作空间的强化学习（RL）仍然具有挑战性，因为可行的动作集呈指数级增长，并且受到复杂的可行性约束的控制，使得直接策略参数化不切实际。现有方法将特定于任务的价值函数嵌入到受限优化程序中或学习确定性结构化策略，从而牺牲了通用性和策略表达性。我们提出了一种求解器诱导的 \emph{潜在球形流策略}，它将现代生成策略的表现力引入组合强化学习，同时保证设计的可行性。我们的方法 LSFlow 通过球形流匹配在紧凑连续潜在空间中学习 \emph{stochastic} 策略，并将可行性委托给组合优化求解器，将每个潜在样本映射到有效的结构化动作。为了提高效率，我们直接在潜在空间中训练价值网络，避免在策略优化期间重复调用求解器。为了解决由基于求解器的动作选择引起的分段常数和不连续的价值景观，我们引入了一个平滑的贝尔曼算子，它可以产生稳定、明确的学习目标。根据经验，我们的方法在一系列具有挑战性的组合 RL 任务中平均优于最先进的基线 20.6%。</li>
</ul>

<h3>Title: DAJ: Data-Reweighted LLM Judge for Test-Time Scaling in Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Peijia Qin, Ruiyi Zhang, Qi Cao, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22230">https://arxiv.org/abs/2601.22230</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22230">https://arxiv.org/pdf/2601.22230</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22230]] DAJ: Data-Reweighted LLM Judge for Test-Time Scaling in Code Generation(https://arxiv.org/abs/2601.22230)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Test-time scaling for code generation commonly relies on Best-of-N selection, in which multiple candidate solutions are sampled from a base model, and the best one is selected by an LLM judge. However, training reliable LLM judges is challenging due to severe distribution shifts, including imbalances between easy and hard problems, mismatches between training tasks and evaluation benchmarks, and trajectory mismatch arising from training data generated by cheaper models whose behavior differs from that of inference-time models. We propose DAJ, a reasoning-based LLM judge trained with verifiable rewards under a bi-level data-reweighted learning framework. The proposed framework learns data-importance weights (either domain-level or instance-level) to optimize generalization performance on a held-out meta set aligned with target benchmarks. To the best of our knowledge, this is the first application of data reweighting to LLM-as-a-Judge training for test-time scaling. Our approach automatically emphasizes hard problems, in-distribution samples, and trajectory-aligned data, without relying on hand-crafted heuristics. Empirically, DAJ achieves state-of-the-art performance on LiveCodeBench and BigCodeBench, outperforming strong test-time scaling baselines as well as leading proprietary models.</li>
<li><strong>摘要：</strong>代码生成的测试时间扩展通常依赖于 Best-of-N 选择，其中从基本模型中采样多个候选解决方案，并由 LLM 法官选择最佳解决方案。然而，由于严重的分布变化，训练可靠的LLM法官具有挑战性，包括简单问题和困难问题之间的不平衡、训练任务和评估基准之间的不匹配，以及由行为与推理时间模型不同的更便宜的模型生成的训练数据引起的轨迹不匹配。我们提出 DAJ，一种基于推理的法学硕士法官，在双层数据重新加权学习框架下接受可验证奖励的培训。所提出的框架学习数据重要性权重（域级或实例级），以优化与目标基准一致的保留元集的泛化性能。据我们所知，这是首次将数据重新加权应用于法学硕士法官培训以调整测试时间。我们的方法自动强调难题、分布内样本和轨迹对齐数据，而不依赖于手工设计的启发式方法。根据经验，DAJ 在 LiveCodeBench 和 BigCodeBench 上实现了最先进的性能，超越了强大的测试时间扩展基线以及领先的专有模型。</li>
</ul>

<h3>Title: Is Hierarchical Quantization Essential for Optimal Reconstruction?</h3>
<ul>
<li><strong>Authors: </strong>Shirin Reyhanian, Laurenz Wiskott</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22244">https://arxiv.org/abs/2601.22244</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22244">https://arxiv.org/pdf/2601.22244</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22244]] Is Hierarchical Quantization Essential for Optimal Reconstruction?(https://arxiv.org/abs/2601.22244)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vector-quantized variational autoencoders (VQ-VAEs) are central to models that rely on high reconstruction fidelity, from neural compression to generative pipelines. Hierarchical extensions, such as VQ-VAE2, are often credited with superior reconstruction performance because they split global and local features across multiple levels. However, since higher levels derive all their information from lower levels, they should not carry additional reconstructive content beyond what the lower-level already encodes. Combined with recent advances in training objectives and quantization mechanisms, this leads us to ask whether a single-level VQ-VAE, with matched representational budget and no codebook collapse, can equal the reconstruction fidelity of its hierarchical counterpart. Although the multi-scale structure of hierarchical models may improve perceptual quality in downstream tasks, the effect of hierarchy on reconstruction accuracy, isolated from codebook utilization and overall representational capacity, remains empirically underexamined. We revisit this question by comparing a two-level VQ-VAE and a capacity-matched single-level model on high-resolution ImageNet images. Consistent with prior observations, we confirm that inadequate codebook utilization limits single-level VQ-VAEs and that overly high-dimensional embeddings destabilize quantization and increase codebook collapse. We show that lightweight interventions such as initialization from data, periodic reset of inactive codebook vectors, and systematic tuning of codebook hyperparameters significantly reduce collapse. Our results demonstrate that when representational budgets are matched, and codebook collapse is mitigated, single-level VQ-VAEs can match the reconstruction fidelity of hierarchical variants, challenging the assumption that hierarchical quantization is inherently superior for high-quality reconstructions.</li>
<li><strong>摘要：</strong>矢量量化变分自动编码器 (VQ-VAE) 是依赖高重建保真度的模型的核心，从神经压缩到生成管道。分层扩展（例如 VQ-VAE2）通常被认为具有卓越的重建性能，因为它们将全局和局部特征分割到多个级别。然而，由于较高级别从较低级别获取所有信息，因此它们不应携带超出较低级别已编码内容的额外重构内容。结合训练目标和量化机制的最新进展，这让我们不禁要问，具有匹配的表征预算且没有码本崩溃的单级 VQ-VAE 是否可以与分层对应的重建保真度相媲美。尽管分层模型的多尺度结构可以提高下游任务的感知质量，但与码本利用率和整体表征能力无关的分层对重建精度的影响仍然没有得到充分的实证检验。我们通过在高分辨率 ImageNet 图像上比较两级 VQ-VAE 和容量匹配的单级模型来重新审视这个问题。与之前的观察一致，我们确认码本利用率不足限制了单级 VQ-VAE，并且过高维的嵌入会破坏量化的稳定性并增加码本崩溃。我们表明，轻量级干预（例如数据初始化、非活动码本向量的定期重置以及码本超参数的系统调整）可显着减少崩溃。我们的结果表明，当表征预算匹配并且码本崩溃得到缓解时，单级 VQ-VAE 可以匹配分层变体的重建保真度，从而挑战了分层量化本质上优于高质量重建的假设。</li>
</ul>

<h3>Title: FunPRM: Function-as-Step Process Reward Model with Meta Reward Correction for Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Ruiyi Zhang, Peijia Qin, Qi Cao, Eric Xue, Pengtao Xie</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22249">https://arxiv.org/abs/2601.22249</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22249">https://arxiv.org/pdf/2601.22249</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22249]] FunPRM: Function-as-Step Process Reward Model with Meta Reward Correction for Code Generation(https://arxiv.org/abs/2601.22249)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Code generation is a core application of large language models (LLMs), yet LLMs still frequently fail on complex programming tasks. Given its success in mathematical reasoning, test-time scaling approaches such as Process Reward Model (PRM)-based Best-of-N selection offer a promising way to improve performance. However, existing PRMs remain ineffective for code generation due to the lack of meaningful step decomposition in code and the noise of Monte Carlo-estimated partial-solution correctness scores (rewards). To address these challenges, we propose FunPRM. FunPRM prompts LLMs to encourage modular code generation organized into functions, with functions treated as PRM reasoning steps. Furthermore, FunPRM introduces a novel meta-learning-based reward correction mechanism that leverages clean final-solution rewards obtained via a unit-test-based evaluation system to purify noisy partial-solution rewards. Experiments on LiveCodeBench and BigCodeBench demonstrate that FunPRM consistently outperforms existing test-time scaling methods across five base LLMs, notably achieving state-of-the-art performance on LiveCodeBench when combined with O4-mini. Furthermore, FunPRM produces code that is more readable and reusable for developers.</li>
<li><strong>摘要：</strong>代码生成是大型语言模型 (LLM) 的核心应用，但 LLM 在执行复杂的编程任务时仍然经常失败。鉴于其在数学推理方面的成功，测试时间扩展方法（例如基于过程奖励模型 (PRM) 的 Best-of-N 选择）提供了一种有前途的提高性能的方法。然而，由于代码中缺乏有意义的步骤分解以及蒙特卡罗估计的部分解决方案正确性分数（奖励​​）的噪音，现有的 PRM 对于代码生成仍然无效。为了应对这些挑战，我们提出了 FunPRM。 FunPRM 提示法学硕士鼓励将模块化代码生成组织成函数，并将函数视为 PRM 推理步骤。此外，FunPRM 引入了一种新颖的基于元学习的奖励校正机制，该机制利用通过基于单元测试的评估系统获得的干净的最终解决方案奖励来净化嘈杂的部分解决方案奖励。 LiveCodeBench 和 BigCodeBench 上的实验表明，FunPRM 在五个基础 LLM 中始终优于现有的测试时间扩展方法，特别是与 O4-mini 结合使用时，在 LiveCodeBench 上实现了最先进的性能。此外，FunPRM 生成的代码对于开发人员来说更具可读性和可重用性。</li>
</ul>

<h3>Title: VMonarch: Efficient Video Diffusion Transformers with Structured Attention</h3>
<ul>
<li><strong>Authors: </strong>Cheng Liang, Haoxian Chen, Liang Hou, Qi Fan, Gangshan Wu, Xin Tao, Limin Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22275">https://arxiv.org/abs/2601.22275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22275">https://arxiv.org/pdf/2601.22275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22275]] VMonarch: Efficient Video Diffusion Transformers with Structured Attention(https://arxiv.org/abs/2601.22275)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>The quadratic complexity of the attention mechanism severely limits the context scalability of Video Diffusion Transformers (DiTs). We find that the highly sparse spatio-temporal attention patterns exhibited in Video DiTs can be naturally represented by the Monarch matrix. It is a class of structured matrices with flexible sparsity, enabling sub-quadratic attention via an alternating minimization algorithm. Accordingly, we propose VMonarch, a novel attention mechanism for Video DiTs that enables efficient computation over the dynamic sparse patterns with structured Monarch matrices. First, we adapt spatio-temporal Monarch factorization to explicitly capture the intra-frame and inter-frame correlations of the video data. Second, we introduce a recomputation strategy to mitigate artifacts arising from instabilities during alternating minimization of Monarch matrices. Third, we propose a novel online entropy algorithm fused into FlashAttention, enabling fast Monarch matrix updates for long sequences. Extensive experiments demonstrate that VMonarch achieves comparable or superior generation quality to full attention on VBench after minimal tuning. It overcomes the attention bottleneck in Video DiTs, reduces attention FLOPs by a factor of 17.5, and achieves a speedup of over 5x in attention computation for long videos, surpassing state-of-the-art sparse attention methods at 90% sparsity.</li>
<li><strong>摘要：</strong>注意力机制的二次复杂度严重限制了视频扩散变压器（DiT）的上下文可扩展性。我们发现视频 DiT 中表现出的高度稀疏的时空注意力模式可以自然地用 Monarch 矩阵表示。它是一类具有灵活稀疏性的结构化矩阵，通过交替最小化算法实现次二次关注。因此，我们提出了 VMonarch，这是一种针对视频 DiT 的新型注意机制，它能够利用结构化 Monarch 矩阵对动态稀疏模式进行有效计算。首先，我们采用时空 Monarch 分解来明确捕获视频数据的帧内和帧间相关性。其次，我们引入了一种重新计算策略，以减轻 Monarch 矩阵交替最小化过程中因不稳定性而产生的伪影。第三，我们提出了一种融合到 FlashAttention 中的新型在线熵算法，可以实现长序列的快速 Monarch 矩阵更新。大量实验表明，VMonarch 经过最少的调整后，在 VBench 上实现了可比或更高的生成质量，以充分关注。它克服了视频 DiT 中的注意力瓶颈，将注意力 FLOP 减少了 17.5 倍，并且在长视频的注意力计算中实现了超过 5 倍的加速，在稀疏度为 90% 的情况下超越了最先进的稀疏注意力方法。</li>
</ul>

<h3>Title: SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I) Models</h3>
<ul>
<li><strong>Authors: </strong>Mingyu Lu, Soham Gadgil, Chris Lin, Chanwoo Kim, Su-In Lee</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22276">https://arxiv.org/abs/2601.22276</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22276">https://arxiv.org/pdf/2601.22276</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22276]] SurrogateSHAP: Training-Free Contributor Attribution for Text-to-Image (T2I) Models(https://arxiv.org/abs/2601.22276)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As Text-to-Image (T2I) diffusion models are increasingly used in real-world creative workflows, a principled framework for valuing contributors who provide a collection of data is essential for fair compensation and sustainable data marketplaces. While the Shapley value offers a theoretically grounded approach to attribution, it faces a dual computational bottleneck: (i) the prohibitive cost of exhaustive model retraining for each sampled subset of players (i.e., data contributors) and (ii) the combinatorial number of subsets needed to estimate marginal contributions due to contributor interactions. To this end, we propose SurrogateSHAP, a retraining-free framework that approximates the expensive retraining game through inference from a pretrained model. To further improve efficiency, we employ a gradient-boosted tree to approximate the utility function and derive Shapley values analytically from the tree-based model. We evaluate SurrogateSHAP across three diverse attribution tasks: (i) image quality for DDPM-CFG on CIFAR-20, (ii) aesthetics for Stable Diffusion on Post-Impressionist artworks, and (iii) product diversity for FLUX.1 on Fashion-Product data. Across settings, SurrogateSHAP outperforms prior methods while substantially reducing computational overhead, consistently identifying influential contributors across multiple utility metrics. Finally, we demonstrate that SurrogateSHAP effectively localizes data sources responsible for spurious correlations in clinical images, providing a scalable path toward auditing safety-critical generative models.</li>
<li><strong>摘要：</strong>随着文本到图像 (T2I) 传播模型越来越多地在现实世界的创意工作流程中使用，用于评估提供数据集合的贡献者的原则性框架对于公平补偿和可持续数据市场至关重要。虽然沙普利值提供了一种理论上有依据的归因方法，但它面临着双重计算瓶颈：（i）对每个抽样的参与者子集（即数据贡献者）进行详尽的模型再训练的成本高昂，以及（ii）估计由于贡献者相互作用而产生的边际贡献所需的子集组合数量。为此，我们提出了 SurrogateSHAP，这是一种无需再训练的框架，通过预训练模型的推理来近似昂贵的再训练游戏。为了进一步提高效率，我们采用梯度增强树来近似效用函数，并从基于树的模型中分析得出 Shapley 值。我们通过三个不同的归因任务评估 SurrogateSHAP：(i) CIFAR-20 上 DDPM-CFG 的图像质量，(ii) 后印象派艺术品上稳定扩散的美学，以及 (iii) 时尚产品数据上 FLUX.1 的产品多样性。在各种设置中，SurrogateSHAP 的性能优于先前的方法，同时大大减少了计算开销，能够跨多个效用指标一致地识别有影响力的贡献者。最后，我们证明 SurrogateSHAP 可以有效地定位导致临床图像中虚假相关性的数据源，为审核安全关键生成模型提供可扩展的路径。</li>
</ul>

<h3>Title: Conformal Prediction for Generative Models via Adaptive Cluster-Based Density Estimation</h3>
<ul>
<li><strong>Authors: </strong>Qidong Yang, Qianyu Julie Zhu, Jonathan Giezendanner, Youssef Marzouk, Stephen Bates, Sherrie Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, physics.ao-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22298">https://arxiv.org/abs/2601.22298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22298">https://arxiv.org/pdf/2601.22298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22298]] Conformal Prediction for Generative Models via Adaptive Cluster-Based Density Estimation(https://arxiv.org/abs/2601.22298)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Conditional generative models map input variables to complex, high-dimensional distributions, enabling realistic sample generation in a diverse set of domains. A critical challenge with these models is the absence of calibrated uncertainty, which undermines trust in individual outputs for high-stakes applications. To address this issue, we propose a systematic conformal prediction approach tailored to conditional generative models, leveraging density estimation on model-generated samples. We introduce a novel method called CP4Gen, which utilizes clustering-based density estimation to construct prediction sets that are less sensitive to outliers, more interpretable, and of lower structural complexity than existing methods. Extensive experiments on synthetic datasets and real-world applications, including climate emulation tasks, demonstrate that CP4Gen consistently achieves superior performance in terms of prediction set volume and structural simplicity. Our approach offers practitioners a powerful tool for uncertainty estimation associated with conditional generative models, particularly in scenarios demanding rigorous and interpretable prediction sets.</li>
<li><strong>摘要：</strong>条件生成模型将输入变量映射到复杂的高维分布，从而能够在不同的领域中生成真实的样本。这些模型的一个关键挑战是缺乏校准的不确定性，这破坏了对高风险应用程序的单个输出的信任。为了解决这个问题，我们提出了一种针对条件生成模型的系统共形预测方法，利用模型生成样本的密度估计。我们引入了一种称为 CP4Gen 的新颖方法，它利用基于聚类的密度估计来构建预测集，与现有方法相比，该预测集对异常值不太敏感，更可解释，并且结构复杂性更低。对合成数据集和现实世界应用（包括气候模拟任务）的广泛实验表明，CP4Gen 在预测集数量和结构简单性方面始终实现卓越的性能。我们的方法为从业者提供了与条件生成模型相关的不确定性估计的强大工具，特别是在需要严格且可解释的预测集的场景中。</li>
</ul>

<h3>Title: Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes</h3>
<ul>
<li><strong>Authors: </strong>Gonzalo Gomez-Nogales, Yicong Hong, Chongjian Ge, Marc Comino-Trinidad, Dan Casas, Yi Zhou</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22301">https://arxiv.org/abs/2601.22301</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22301">https://arxiv.org/pdf/2601.22301</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22301]] Coarse-to-Real: Generative Rendering for Populated Dynamic Scenes(https://arxiv.org/abs/2601.22301)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Traditional rendering pipelines rely on complex assets, accurate materials and lighting, and substantial computational resources to produce realistic imagery, yet they still face challenges in scalability and realism for populated dynamic scenes. We present C2R (Coarse-to-Real), a generative rendering framework that synthesizes real-style urban crowd videos from coarse 3D simulations. Our approach uses coarse 3D renderings to explicitly control scene layout, camera motion, and human trajectories, while a learned neural renderer generates realistic appearance, lighting, and fine-scale dynamics guided by text prompts. To overcome the lack of paired training data between coarse simulations and real videos, we adopt a two-phase mixed CG-real training strategy that learns a strong generative prior from large-scale real footage and introduces controllability through shared implicit spatio-temporal features across domains. The resulting system supports coarse-to-fine control, generalizes across diverse CG and game inputs, and produces temporally consistent, controllable, and realistic urban scene videos from minimal 3D input. We will release the model and project webpage at this https URL.</li>
<li><strong>摘要：</strong>传统的渲染管道依赖复杂的资源、准确的材质和照明以及大量的计算资源来生成逼真的图像，但它们仍然面临着填充动态场景的可扩展性和真实性方面的挑战。我们提出了 C2R（Coarse-to-Real），这是一种生成渲染框架，可以从粗略的 3D 模拟中合成真实风格的城市人群视频。我们的方法使用粗略的 3D 渲染来显式控制场景布局、相机运动和人体轨迹，而学习的神经渲染器则在文本提示的指导下生成逼真的外观、照明和精细尺度动态。为了克服粗略模拟和真实视频之间缺乏配对训练数据的问题，我们采用了两阶段混合 CG-真实训练策略，该策略从大规模真实镜头中学习强大的生成先验，并通过跨域共享隐式时空特征引入可控性。由此产生的系统支持从粗到精的控制，可概括不同的 CG 和游戏输入，并从最少的 3D 输入生成时间一致、可控且逼真的城市场景视频。我们将在此 https URL 发布模型和项目网页。</li>
</ul>

<h3>Title: BayesFlow: A Probability Inference Framework for Meta-Agent Assisted Workflow Generation</h3>
<ul>
<li><strong>Authors: </strong>Bo Yuan, Yun Zhou, Zhichao Xu, Kiran Ramnath, Aosong Feng, Balasubramaniam Srinivasan</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22305">https://arxiv.org/abs/2601.22305</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22305">https://arxiv.org/pdf/2601.22305</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22305]] BayesFlow: A Probability Inference Framework for Meta-Agent Assisted Workflow Generation(https://arxiv.org/abs/2601.22305)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Automatic workflow generation is the process of automatically synthesizing sequences of LLM calls, tool invocations, and post-processing steps for complex end-to-end tasks. Most prior methods cast this task as an optimization problem with limited theoretical grounding. We propose to cast workflow generation as Bayesian inference over a posterior distribution on workflows, and introduce \textbf{Bayesian Workflow Generation (BWG)}, a sampling framework that builds workflows step-by-step using parallel look-ahead rollouts for importance weighting and a sequential in-loop refiner for pool-wide improvements. We prove that, without the refiner, the weighted empirical distribution converges to the target posterior. We instantiate BWG as \textbf{BayesFlow}, a training-free algorithm for workflow construction. Across six benchmark datasets, BayesFlow improves accuracy by up to 9 percentage points over SOTA workflow generation baselines and by up to 65 percentage points over zero-shot prompting, establishing BWG as a principled upgrade to search-based workflow design. Code will be available on this https URL.</li>
<li><strong>摘要：</strong>自动工作流程生成是自动合成复杂端到端任务的 LLM 调用、工具调用和后处理步骤序列的过程。大多数现有方法将此任务视为理论基础有限的优化问题。我们建议将工作流生成转换为工作流后验分布上的贝叶斯推理，并引入 \textbf{贝叶斯工作流生成（BWG）}，这是一个采样框架，它使用并行前瞻推出来逐步构建工作流以进行重要性加权，并使用顺序内循环细化器来进行池范围的改进。我们证明，在没有细化器的情况下，加权经验分布收敛到目标后验。我们将 BWG 实例化为 \textbf{BayesFlow}，这是一种用于工作流构建的免训练算法。在六个基准数据集上，BayesFlow 比 SOTA 工作流生成基线提高了高达 9 个百分点的准确度，比零样本提示提高了高达 65 个百分点，从而使 BWG 成为基于搜索的工作流设计的原则性升级。代码将在此 https URL 上提供。</li>
</ul>

<h3>Title: Gaussian Process Bandit Optimization with Machine Learning Predictions and Application to Hypothesis Generation</h3>
<ul>
<li><strong>Authors: </strong>Xin Jennifer Chen, Yunjin Tong</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22315">https://arxiv.org/abs/2601.22315</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22315">https://arxiv.org/pdf/2601.22315</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22315]] Gaussian Process Bandit Optimization with Machine Learning Predictions and Application to Hypothesis Generation(https://arxiv.org/abs/2601.22315)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Many real-world optimization problems involve an expensive ground-truth oracle (e.g., human evaluation, physical experiments) and a cheap, low-fidelity prediction oracle (e.g., machine learning models, simulations). Meanwhile, abundant offline data (e.g., past experiments and predictions) are often available and can be used to pretrain powerful predictive models, as well as to provide an informative prior. We propose Prediction-Augmented Gaussian Process Upper Confidence Bound (PA-GP-UCB), a novel Bayesian optimization algorithm that leverages both oracles and offline data to achieve provable gains in sample efficiency for the ground-truth oracle queries. PA-GP-UCB employs a control-variates estimator derived from a joint Gaussian process posterior to correct prediction bias and reduce uncertainty. We prove that PA-GP-UCB preserves the standard regret rate of GP-UCB while achieving a strictly smaller leading constant that is explicitly controlled by prediction quality and offline data coverage. Empirically, PA-GP-UCB converges faster than Vanilla GP-UCB and naive prediction-augmented GP-UCB baselines on synthetic benchmarks and on a real-world hypothesis evaluation task grounded in human behavioral data, where predictions are provided by large language models. These results establish PA-GP-UCB as a general and sample-efficient framework for hypothesis generation under expensive feedback.</li>
<li><strong>摘要：</strong>许多现实世界的优化问题涉及昂贵的真实预言（例如，人类评估、物理实验）和廉价、低保真度的预测预言（例如，机器学习模型、模拟）。与此同时，大量的离线数据（例如过去的实验和预测）通常是可用的，可用于预训练强大的预测模型，并提供信息丰富的先验信息。我们提出了预测增强高斯过程置信上限（PA-GP-UCB），这是一种新颖的贝叶斯优化算法，它利用预言机和离线数据来实现地面真实预言机查询的样本效率的可证明的增益。 PA-GP-UCB 采用从联合高斯过程后验导出的控制变量估计器，以纠正预测偏差并减少不确定性。我们证明 PA-GP-UCB 保留了 GP-UCB 的标准后悔率，同时实现了由预测质量和离线数据覆盖率明确控制的严格较小的领先常数。根据经验，PA-GP-UCB 在综合基准和基于人类行为数据的现实世界假设评估任务上比 Vanilla GP-UCB 和朴素预测增强 GP-UCB 基线收敛得更快，其中预测由大型语言模型提供。这些结果将 PA-GP-UCB 确立为在昂贵的反馈下生成假设的通用且样本有效的框架。</li>
</ul>

<h3>Title: AgentScore: Autoformulation of Deployable Clinical Scoring Systems</h3>
<ul>
<li><strong>Authors: </strong>Silas Ruhrberg Estévez, Christopher Chiu, Mihaela van der Schaar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22324">https://arxiv.org/abs/2601.22324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22324">https://arxiv.org/pdf/2601.22324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22324]] AgentScore: Autoformulation of Deployable Clinical Scoring Systems(https://arxiv.org/abs/2601.22324)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Modern clinical practice relies on evidence-based guidelines implemented as compact scoring systems composed of a small number of interpretable decision rules. While machine-learning models achieve strong performance, many fail to translate into routine clinical use due to misalignment with workflow constraints such as memorability, auditability, and bedside execution. We argue that this gap arises not from insufficient predictive power, but from optimizing over model classes that are incompatible with guideline deployment. Deployable guidelines often take the form of unit-weighted clinical checklists, formed by thresholding the sum of binary rules, but learning such scores requires searching an exponentially large discrete space of possible rule sets. We introduce AgentScore, which performs semantically guided optimization in this space by using LLMs to propose candidate rules and a deterministic, data-grounded verification-and-selection loop to enforce statistical validity and deployability constraints. Across eight clinical prediction tasks, AgentScore outperforms existing score-generation methods and achieves AUC comparable to more flexible interpretable models despite operating under stronger structural constraints. On two additional externally validated tasks, AgentScore achieves higher discrimination than established guideline-based scores.</li>
<li><strong>摘要：</strong>现代临床实践依赖于以证据为基础的指南，这些指南被实施为由少量可解释的决策规则组成的紧凑评分系统。虽然机器学习模型取得了强大的性能，但由于与可记忆性、可审计性和床边执行等工作流程限制不一致，许多机器学习模型未能转化为常规临床使用。我们认为，这种差距不是因为预测能力不足而产生的，而是因为对与指南部署不兼容的模型类进行了优化。可部署的指南通常采用单位加权临床检查表的形式，通过对二进制规则的总和进行阈值化而形成，但学习此类分数需要搜索可能规则集的指数级大离散空间。我们引入了 AgentScore，它通过使用 LLM 提出候选规则和确定性的、基于数据的验证和选择循环来执行统计有效性和可部署性约束，从而在该空间中执行语义引导优化。在八项临床预测任务中，AgentScore 的性能优于现有的评分生成方法，尽管在更强的结构约束下运行，但其 AUC 仍可与更灵活的可解释模型相媲美。在另外两项外部验证的任务中，AgentScore 比既定的基于指南的分数实现了更高的区分度。</li>
</ul>

<h3>Title: DP-$λ$CGD: Efficient Noise Correlation for Differentially Private Model Training</h3>
<ul>
<li><strong>Authors: </strong>Nikita P. Kalinin, Ryan McKenna, Rasmus Pagh, Christoph H. Lampert</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22334">https://arxiv.org/abs/2601.22334</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22334">https://arxiv.org/pdf/2601.22334</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22334]] DP-$λ$CGD: Efficient Noise Correlation for Differentially Private Model Training(https://arxiv.org/abs/2601.22334)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Differentially private stochastic gradient descent (DP-SGD) is the gold standard for training machine learning models with formal differential privacy guarantees. Several recent extensions improve its accuracy by introducing correlated noise across training iterations. Matrix factorization mechanisms are a prominent example, but they correlate noise across many iterations and require storing previously added noise vectors, leading to substantial memory overhead in some settings. In this work, we propose a new noise correlation strategy that correlates noise only with the immediately preceding iteration and cancels a controlled portion of it. Our method relies on noise regeneration using a pseudorandom noise generator, eliminating the need to store past noise. As a result, it requires no additional memory beyond standard DP-SGD. We show that the computational overhead is minimal and empirically demonstrate improved accuracy over DP-SGD.</li>
<li><strong>摘要：</strong>差分隐私随机梯度下降 (DP-SGD) 是训练具有正式差分隐私保证的机器学习模型的黄金标准。最近的几个扩展通过在训练迭代中引入相关噪声来提高其准确性。矩阵分解机制是一个突出的例子，但它们在多次迭代中关联噪声，并且需要存储先前添加的噪声向量，从而在某些设置中导致大量的内存开销。在这项工作中，我们提出了一种新的噪声相关策略，该策略仅将噪声与前一个迭代相关联，并取消其中的受控部分。我们的方法依赖于使用伪随机噪声发生器的噪声再生，从而无需存储过去的噪声。因此，除了标准 DP-SGD 之外，它不需要额外的内存。我们证明了计算开销是最小的，并且凭经验证明了比 DP-SGD 更高的精度。</li>
</ul>

<h3>Title: Learning Policy Representations for Steerable Behavior Synthesis</h3>
<ul>
<li><strong>Authors: </strong>Beiming Li, Sergio Rozada, Alejandro Ribeiro</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22350">https://arxiv.org/abs/2601.22350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22350">https://arxiv.org/pdf/2601.22350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22350]] Learning Policy Representations for Steerable Behavior Synthesis(https://arxiv.org/abs/2601.22350)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Given a Markov decision process (MDP), we seek to learn representations for a range of policies to facilitate behavior steering at test time. As policies of an MDP are uniquely determined by their occupancy measures, we propose modeling policy representations as expectations of state-action feature maps with respect to occupancy measures. We show that these representations can be approximated uniformly for a range of policies using a set-based architecture. Our model encodes a set of state-action samples into a latent embedding, from which we decode both the policy and its value functions corresponding to multiple rewards. We use variational generative approach to induce a smooth latent space, and further shape it with contrastive learning so that latent distances align with differences in value functions. This geometry permits gradient-based optimization directly in the latent space. Leveraging this capability, we solve a novel behavior synthesis task, where policies are steered to satisfy previously unseen value function constraints without additional training.</li>
<li><strong>摘要：</strong>给定马尔可夫决策过程（MDP），我们寻求学习一系列策略的表示，以促进测试时的行为引导。由于 MDP 的策略是由其占用度量唯一确定的，因此我们建议将策略表示建模为关于占用度量的状态动作特征图的期望。我们证明，对于使用基于集合的架构的一系列策略，这些表示可以统一近似。我们的模型将一组状态动作样本编码为潜在嵌入，从中我们解码策略及其对应于多个奖励的价值函数。我们使用变分生成方法来诱导平滑的潜在空间，并通过对比学习进一步塑造它，以使潜在距离与价值函数的差异保持一致。这种几何结构允许直接在潜在空间中进行基于梯度的优化。利用这种能力，我们解决了一个新颖的行为综合任务，其中策略被引导以满足以前未见过的价值函数约束，而无需额外的训练。</li>
</ul>

<h3>Title: Understanding Efficiency: Quantization, Batching, and Serving Strategies in LLM Energy Use</h3>
<ul>
<li><strong>Authors: </strong>Julien Delavande, Regis Pierrard, Sasha Luccioni</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22362">https://arxiv.org/abs/2601.22362</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22362">https://arxiv.org/pdf/2601.22362</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22362]] Understanding Efficiency: Quantization, Batching, and Serving Strategies in LLM Energy Use(https://arxiv.org/abs/2601.22362)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) are increasingly deployed in production, contributing towards shifting the burden in terms of computational resources and energy demands from training to inference. While prior work has examined the energy cost of inference per prompt or per token, we highlight how \emph{system-level design choices} - such as numerical precision, batching strategy, and request scheduling - can lead to orders-of-magnitude differences in energy consumption for the same model. We perform a detailed empirical study of LLM inference energy and latency on NVIDIA H100 GPUs, analyzing the impact of quantization, batch size, and serving configuration (e.g., with Hugging Face's Text Generation Inference server). Our results reveal that lower-precision formats only yield energy gains in compute-bound regimes; that batching improves energy efficiency, especially in memory-bound phases like decoding; and that structured request timing (arrival shaping) can reduce per-request energy by up to 100 times. We argue that sustainable LLM deployment depends not only on model internals, but also on the orchestration of the serving stack. Our findings motivate phase-aware energy profiling and system-level optimizations for greener AI services.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 越来越多地部署在生产中，有助于将计算资源和能源需求方面的负担从训练转移到推理。虽然之前的工作已经检查了每个提示或每个标记的推理能源成本，但我们强调了 \emph{系统级设计选择} - 例如数值精度、批处理策略和请求调度 - 如何导致同一模型的能源消耗出现数量级的差异。我们对 NVIDIA H100 GPU 上的 LLM 推理能量和延迟进行了详细的实证研究，分析了量化、批量大小和服务配置（例如，使用 Hugging Face 的文本生成推理服务器）的影响。我们的结果表明，较低精度的格式只能在计算受限的情况下产生能量增益；批处理提高了能源效率，尤其是在解码等内存限制阶段；结构化请求计时（到达整形）可以将每个请求的能量减少多达 100 倍。我们认为可持续的 LLM 部署不仅取决于模型内部，还取决于服务堆栈的编排。我们的研究结果推动了阶段感知能源分析和系统级优化，以实现更绿色的人工智能服务。</li>
</ul>

<h3>Title: Jailbreaks on Vision Language Model via Multimodal Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Aarush Noheria, Yuguang Yao</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22398">https://arxiv.org/abs/2601.22398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22398">https://arxiv.org/pdf/2601.22398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22398]] Jailbreaks on Vision Language Model via Multimodal Reasoning(https://arxiv.org/abs/2601.22398)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Vision-language models (VLMs) have become central to tasks such as visual question answering, image captioning, and text-to-image generation. However, their outputs are highly sensitive to prompt variations, which can reveal vulnerabilities in safety alignment. In this work, we present a jailbreak framework that exploits post-training Chain-of-Thought (CoT) prompting to construct stealthy prompts capable of bypassing safety filters. To further increase attack success rates (ASR), we propose a ReAct-driven adaptive noising mechanism that iteratively perturbs input images based on model feedback. This approach leverages the ReAct paradigm to refine adversarial noise in regions most likely to activate safety defenses, thereby enhancing stealth and evasion. Experimental results demonstrate that the proposed dual-strategy significantly improves ASR while maintaining naturalness in both text and visual domains.</li>
<li><strong>摘要：</strong>视觉语言模型 (VLM) 已成为视觉问答、图像字幕和文本到图像生成等任务的核心。然而，它们的输出对即时变化高度敏感，这可能会揭示安全调整中的漏洞。在这项工作中，我们提出了一个越狱框架，该框架利用训练后的思想链（CoT）提示来构造能够绕过安全过滤器的隐秘提示。为了进一步提高攻击成功率（ASR），我们提出了一种 ReAct 驱动的自适应噪声机制，该机制根据模型反馈迭代地扰动输入图像。这种方法利用 ReAct 范式来细化最有可能激活安全防御的区域的对抗噪音，从而增强隐身性和规避能力。实验结果表明，所提出的双重策略显着提高了 ASR，同时保持了文本和视觉领域的自然度。</li>
</ul>

<h3>Title: MetaLead: A Comprehensive Human-Curated Leaderboard Dataset for Transparent Reporting of Machine Learning Experiments</h3>
<ul>
<li><strong>Authors: </strong>Roelien C. Timmer, Necva Bölücü, Stephen Wan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22420">https://arxiv.org/abs/2601.22420</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22420">https://arxiv.org/pdf/2601.22420</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22420]] MetaLead: A Comprehensive Human-Curated Leaderboard Dataset for Transparent Reporting of Machine Learning Experiments(https://arxiv.org/abs/2601.22420)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Leaderboards are crucial in the machine learning (ML) domain for benchmarking and tracking progress. However, creating leaderboards traditionally demands significant manual effort. In recent years, efforts have been made to automate leaderboard generation, but existing datasets for this purpose are limited by capturing only the best results from each paper and limited metadata. We present MetaLead, a fully human-annotated ML Leaderboard dataset that captures all experimental results for result transparency and contains extra metadata, such as the result experimental type: baseline, proposed method, or variation of proposed method for experiment-type guided comparisons, and explicitly separates train and test dataset for cross-domain assessment. This enriched structure makes MetaLead a powerful resource for more transparent and nuanced evaluations across ML research.</li>
<li><strong>摘要：</strong>排行榜在机器学习 (ML) 领域中对于基准测试和跟踪进度至关重要。然而，创建排行榜传统上需要大量的手动工作。近年来，人们一直在努力实现排行榜生成的自动化，但用于此目的的现有数据集因仅捕获每篇论文的最佳结果和有限的元数据而受到限制。我们提出了 MetaLead，这是一个完全由人工注释的 ML 排行榜数据集，它捕获所有实验结果以实现结果透明度，并包含额外的元数据，例如结果实验类型：基线、建议方法或用于实验类型引导比较的建议方法的变体，并明确区分训练和测试数据集以进行跨域评估。这种丰富的结构使 MetaLead 成为整个机器学习研究中更透明、更细致的评估的强大资源。</li>
</ul>

<h3>Title: Automating Forecasting Question Generation and Resolution for AI Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Nikos I. Bosse, Peter Mühlbacher, Jack Wildman, Lawrence Phillips, Dan Schwarz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22444">https://arxiv.org/abs/2601.22444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22444">https://arxiv.org/pdf/2601.22444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22444]] Automating Forecasting Question Generation and Resolution for AI Evaluation(https://arxiv.org/abs/2601.22444)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Forecasting future events is highly valuable in decision-making and is a robust measure of general intelligence. As forecasting is probabilistic, developing and evaluating AI forecasters requires generating large numbers of diverse and difficult questions, and accurately resolving them. Previous efforts to automate this laborious work relied on recurring data sources (e.g., weather, stocks), limiting diversity and utility. In this work, we present a system for generating and resolving high-quality forecasting questions automatically and at scale using LLM-powered web research agents. We use this system to generate 1499 diverse, real-world forecasting questions, and to resolve them several months later. We estimate that our system produces verifiable, unambiguous questions approximately 96% of the time, exceeding the rate of Metaculus, a leading human-curated forecasting platform. We also find that our system resolves questions at approximately 95% accuracy. We verify that forecasting agents powered by more intelligent LLMs perform better on these questions (Brier score of 0.134 for Gemini 3 Pro, 0.149 for GPT-5, and 0.179 for Gemini 2.5 Flash). Finally, we demonstrate how our system can be leveraged to directly improve forecasting, by evaluating a question decomposition strategy on a generated question set, yielding a significant improvement in Brier scores (0.132 vs. 0.141).</li>
<li><strong>摘要：</strong>预测未来事件对于决策非常有价值，并且是通用智力的有力衡量标准。由于预测是概率性的，开发和评估人工智能预测器需要产生大量多样化且困难的问题，并准确地解决它们。以前自动化这项繁重工作的努力依赖于重复的数据源（例如天气、股票），限制了多样性和实用性。在这项工作中，我们提出了一个使用法学硕士支持的网络研究代理自动大规模生成和解决高质量预测问题的系统。我们使用该系统生成 1499 个多样化的现实世界预测问题，并在几个月后解决它们。我们估计，我们的系统在大约 96% 的时间内产生可验证、明确的问题，超过了领先的人工预测平台 Metaculus 的速度。我们还发现我们的系统解决问题的准确率约为 95%。我们验证了由更智能的 LLM 支持的预测代理在这些问题上表现更好（Gemini 3 Pro 的 Brier 得分为 0.134，GPT-5 的得分为 0.149，Gemini 2.5 Flash 的得分为 0.179）。最后，我们演示了如何利用我们的系统通过评估生成的问题集的问题分解策略来直接改进预测，从而显着提高 Brier 分数（0.132 与 0.141）。</li>
</ul>

<h3>Title: HeaPA: Difficulty-Aware Heap Sampling and On-Policy Query Augmentation for LLM Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Weiqi Wang, Xin Liu, Binxuan Huang, Hejie Cui, Rongzhi Zhang, Changlong Yu, Shuowei Jin, Jingfeng Yang, Qingyu Yin, Zhengyang Wang, Zheng Li, Yifan Gao, Priyanka Nigam, Bing Yin, Lihong Li, Yangqiu Song</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22448">https://arxiv.org/abs/2601.22448</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22448">https://arxiv.org/pdf/2601.22448</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22448]] HeaPA: Difficulty-Aware Heap Sampling and On-Policy Query Augmentation for LLM Reinforcement Learning(https://arxiv.org/abs/2601.22448)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>RLVR is now a standard way to train LLMs on reasoning tasks with verifiable outcomes, but when rollout generation dominates the cost, efficiency depends heavily on which prompts you sample and when. In practice, prompt pools are often static or only loosely tied to the model's learning progress, so uniform sampling can't keep up with the shifting capability frontier and ends up wasting rollouts on prompts that are already solved or still out of reach. Existing approaches improve efficiency through filtering, curricula, adaptive rollout allocation, or teacher guidance, but they typically assume a fixed pool-which makes it hard to support stable on-policy pool growth-or they add extra teacher cost and latency. We introduce HeaPA (Heap Sampling and On-Policy Query Augmentation), which maintains a bounded, evolving pool, tracks the frontier using heap-based boundary sampling, expands the pool via on-policy augmentation with lightweight asynchronous validation, and stabilizes correlated queries through topology-aware re-estimation of pool statistics and controlled reinsertion. Across two training corpora, two training recipes, and seven benchmarks, HeaPA consistently improves accuracy and reaches target performance with fewer computations while keeping wall-clock time comparable. Our analyses suggest these gains come from frontier-focused sampling and on-policy pool growth, with the benefits becoming larger as model scale increases. Our code is available at this https URL.</li>
<li><strong>摘要：</strong>RLVR 现在是训练法学硕士推理任务并具有可验证结果的标准方法，但当部署生成主导成本时，效率在很大程度上取决于提示您采样的内容和时间。在实践中，提示池通常是静态的或仅与模型的学习进度松散相关，因此统一采样无法跟上不断变化的能力前沿，最终会浪费在已经解决或仍然无法实现的提示上的推出。现有的方法通过过滤、课程、自适应部署分配或教师指导来提高效率，但它们通常假设一个固定的池——这使得很难支持稳定的策略池增长——或者它们增加了额外的教师成本和延迟。我们引入了 HeaPA（堆采样和策略查询增强），它维护一个有界的、不断演变的池，使用基于堆的边界采样跟踪前沿，通过轻量级异步验证的策略增强来扩展池，并通过池统计的拓扑感知重新估计和受控重新插入来稳定相关查询。在两个训练语料库、两个训练配方和七个基准测试中，HeaPA 持续提高准确性并以更少的计算达到目标性能，同时保持挂钟时间可比。我们的分析表明，这些收益来自于前沿抽样和策略池增长，随着模型规模的增加，收益会变得更大。我们的代码可以在这个 https URL 上找到。</li>
</ul>

<h3>Title: Tuning the Implicit Regularizer of Masked Diffusion Language Models: Enhancing Generalization via Insights from $k$-Parity</h3>
<ul>
<li><strong>Authors: </strong>Jianhao Huang, Baharan Mirzasoleiman</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22450">https://arxiv.org/abs/2601.22450</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22450">https://arxiv.org/pdf/2601.22450</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22450]] Tuning the Implicit Regularizer of Masked Diffusion Language Models: Enhancing Generalization via Insights from $k$-Parity(https://arxiv.org/abs/2601.22450)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Masked Diffusion Language Models have recently emerged as a powerful generative paradigm, yet their generalization properties remain understudied compared to their auto-regressive counterparts. In this work, we investigate these properties within the setting of the $k$-parity problem (computing the XOR sum of $k$ relevant bits), where neural networks typically exhibit grokking -- a prolonged plateau of chance-level performance followed by sudden generalization. We theoretically decompose the Masked Diffusion (MD) objective into a Signal regime which drives feature learning, and a Noise regime which serves as an implicit regularizer. By training nanoGPT using MD objective on the $k$-parity problem, we demonstrate that MD objective fundamentally alters the learning landscape, enabling rapid and simultaneous generalization without experiencing grokking. Furthermore, we leverage our theoretical insights to optimize the distribution of the mask probability in the MD objective. Our method significantly improves perplexity for 50M-parameter models and achieves superior results across both pre-training from scratch and supervised fine-tuning. Specifically, we observe performance gains peaking at $8.8\%$ and $5.8\%$, respectively, on 8B-parameter models, confirming the scalability and effectiveness of our framework in large-scale masked diffusion language model regimes.</li>
<li><strong>摘要：</strong>掩蔽扩散语言模型最近已成为一种强大的生成范式，但与自回归模型相比，它们的泛化特性仍然未被充分研究。在这项工作中，我们在 $k$ 奇偶校验问题（计算 $k$ 相关位的 XOR 和）的设置中研究这些属性，其中神经网络通常表现出 grokking——机会级性能的长期稳定状态，然后突然泛化。从理论上讲，我们将掩蔽扩散（MD）目标分解为驱动特征学习的信号机制和充当隐式正则化器的噪声机制。通过使用 MD 目标在 $k$ 奇偶校验问题上训练 nanoGPT，我们证明 MD 目标从根本上改变了学习环境，无需经历摸索就能实现快速、同步的泛化。此外，我们利用我们的理论见解来优化 MD 目标中掩模概率的分布。我们的方法显着改善了 50M 参数模型的困惑度，并在从头开始的预训练和监督微调方面取得了优异的结果。具体来说，我们在 8B 参数模型上观察到性能增益分别达到 $8.8\%$ 和 $5.8\%$ 的峰值，证实了我们的框架在大规模掩码扩散语言模型体系中的可扩展性和有效性。</li>
</ul>

<h3>Title: Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework</h3>
<ul>
<li><strong>Authors: </strong>Shiyu Liu, Xinyi Wen, Zhibin Lan, Ante Wang, Jinsong Su</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22451">https://arxiv.org/abs/2601.22451</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22451">https://arxiv.org/pdf/2601.22451</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22451]] Countering the Over-Reliance Trap: Mitigating Object Hallucination for LVLMs via a Self-Validation Framework(https://arxiv.org/abs/2601.22451)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Despite progress in Large Vision Language Models (LVLMs), object hallucination remains a critical issue in image captioning task, where models generate descriptions of non-existent objects, compromising their reliability. Previous work attributes this to LVLMs' over-reliance on language priors and attempts to mitigate it through logits calibration. However, they still lack a thorough analysis of the over-reliance. To gain a deeper understanding of over-reliance, we conduct a series of preliminary experiments, indicating that as the generation length increases, LVLMs' over-reliance on language priors leads to inflated probability of hallucinated object tokens, consequently exacerbating object hallucination. To circumvent this issue, we propose Language-Prior-Free Verification to enable LVLMs to faithfully verify the confidence of object existence. Based on this, we propose a novel training-free Self-Validation Framework to counter the over-reliance trap. It first validates objects' existence in sampled candidate captions and further mitigates object hallucination via caption selection or aggregation. Experiment results demonstrate that our framework mitigates object hallucination significantly in image captioning task (e.g., 65.6% improvement on CHAIRI metric with LLaVA-v1.5-7B), surpassing the previous SOTA methods. This result highlights a novel path towards mitigating hallucination by unlocking the inherent potential within LVLMs themselves.</li>
<li><strong>摘要：</strong>尽管大视觉语言模型（LVLM）取得了进展，但物体幻觉仍然是图像字幕任务中的一个关键问题，其中模型生成不存在物体的描述，从而损害了其可靠性。之前的工作将此归因于 LVLM 对语言先验的过度依赖，并尝试通过 logits 校准来缓解这一问题。然而，他们仍然缺乏对过度依赖的彻底分析。为了更深入地理解过度依赖，我们进行了一系列初步实验，结果表明，随着生成长度的增加，LVLM 对语言先验的过度依赖会导致幻觉对象标记的概率增大，从而加剧对象幻觉。为了解决这个问题，我们提出了 Language-Prior-Free Verification，使 LVLM 能够忠实地验证对象存在的置信度。基于此，我们提出了一种新颖的免培训自我验证框架来应对过度依赖陷阱。它首先验证采样的候选字幕中对象的存在，并通过字幕选择或聚合进一步减轻对象幻觉。实验结果表明，我们的框架在图像字幕任务中显着减轻了物体幻觉（例如，LLaVA-v1.5-7B 的 CHAIRI 指标提高了 65.6%），超越了之前的 SOTA 方法。这一结果凸显了一条通过释放 LVLM 本身内在潜力来减轻幻觉的新途径。</li>
</ul>

<h3>Title: ScribbleSense: Generative Scribble-Based Texture Editing with Intent Prediction</h3>
<ul>
<li><strong>Authors: </strong>Yudi Zhang, Yeming Geng, Lei Zhang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22455">https://arxiv.org/abs/2601.22455</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22455">https://arxiv.org/pdf/2601.22455</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22455]] ScribbleSense: Generative Scribble-Based Texture Editing with Intent Prediction(https://arxiv.org/abs/2601.22455)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Interactive 3D model texture editing presents enhanced opportunities for creating 3D assets, with freehand drawing style offering the most intuitive experience. However, existing methods primarily support sketch-based interactions for outlining, while the utilization of coarse-grained scribble-based interaction remains limited. Furthermore, current methodologies often encounter challenges due to the abstract nature of scribble instructions, which can result in ambiguous editing intentions and unclear target semantic locations. To address these issues, we propose ScribbleSense, an editing method that combines multimodal large language models (MLLMs) and image generation models to effectively resolve these challenges. We leverage the visual capabilities of MLLMs to predict the editing intent behind the scribbles. Once the semantic intent of the scribble is discerned, we employ globally generated images to extract local texture details, thereby anchoring local semantics and alleviating ambiguities concerning the target semantic locations. Experimental results indicate that our method effectively leverages the strengths of MLLMs, achieving state-of-the-art interactive editing performance for scribble-based texture editing.</li>
<li><strong>摘要：</strong>交互式 3D 模型纹理编辑为创建 3D 资源提供了更多机会，手绘风格提供最直观的体验。然而，现有方法主要支持基于草图的交互进行轮廓绘制，而基于粗粒度涂鸦的交互的利用仍然有限。此外，由于涂鸦指令的抽象性质，当前的方法经常遇到挑战，这可能导致模糊的编辑意图和不清楚的目标语义位置。为了解决这些问题，我们提出了 ScribbleSense，一种结合多模态大语言模型（MLLM）和图像生成模型的编辑方法，可以有效解决这些挑战。我们利用 MLLM 的视觉功能来预测涂鸦背后的编辑意图。一旦识别出涂鸦的语义意图，我们就使用全局生成的图像来提取局部纹理细节，从而锚定局部语义并减轻有关目标语义位置的歧义。实验结果表明，我们的方法有效地利用了 MLLM 的优势，为基于涂鸦的纹理编辑实现了最先进的交互式编辑性能。</li>
</ul>

<h3>Title: EvoEGF-Mol: Evolving Exponential Geodesic Flow for Structure-based Drug Design</h3>
<ul>
<li><strong>Authors: </strong>Yaowei Jin, Junjie Wang, Cheng Cao, Penglei Wang, Duo An, Qian Shi</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22466">https://arxiv.org/abs/2601.22466</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22466">https://arxiv.org/pdf/2601.22466</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22466]] EvoEGF-Mol: Evolving Exponential Geodesic Flow for Structure-based Drug Design(https://arxiv.org/abs/2601.22466)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Structure-Based Drug Design (SBDD) aims to discover bioactive ligands. Conventional approaches construct probability paths separately in Euclidean and probabilistic spaces for continuous atomic coordinates and discrete chemical categories, leading to a mismatch with the underlying statistical manifolds. We address this issue from an information-geometric perspective by modeling molecules as composite exponential-family distributions and defining generative flows along exponential geodesics under the Fisher-Rao metric. To avoid the instantaneous trajectory collapse induced by geodesics directly targeting Dirac distributions, we propose Evolving Exponential Geodesic Flow for SBDD (EvoEGF-Mol), which replaces static Dirac targets with dynamically concentrating distributions, ensuring stable training via a progressive-parameter-refinement architecture. Our model approaches a reference-level PoseBusters passing rate (93.4%) on CrossDock, demonstrating remarkable geometric precision and interaction fidelity, while outperforming baselines on real-world MolGenBench tasks by recovering bioactive scaffolds and generating candidates that meet established MedChem filters.</li>
<li><strong>摘要：</strong>基于结构的药物设计（SBDD）旨在发现生物活性配体。传统方法在欧几里得空间和概率空间中分别为连续原子坐标和离散化学类别构建概率路径，导致与基础统计流形的不匹配。我们从信息几何的角度解决这个问题，将分子建模为复合指数族分布，并在 Fisher-Rao 度量下定义沿指数测地线的生成流。为了避免直接针对狄拉克分布的测地线引起的瞬时轨迹崩溃，我们提出了 SBDD 的演化指数测地线流（EvoEGF-Mol），它用动态集中分布取代静态狄拉克目标，通过渐进参数细化架构确保稳定的训练。我们的模型在 CrossDock 上接近参考水平的 PoseBusters 通过率 (93.4%)，展示了卓越的几何精度和交互保真度，同时通过恢复生物活性支架并生成满足既定 MedChem 过滤器的候选材料，在现实世界的 MolGenBench 任务中表现优于基线。</li>
</ul>

<h3>Title: Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector</h3>
<ul>
<li><strong>Authors: </strong>Wenqiang Zu, Shenghao Xie, Bo Lei, Lei Ma</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22468">https://arxiv.org/abs/2601.22468</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22468">https://arxiv.org/pdf/2601.22468</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22468]] Training-Free Representation Guidance for Diffusion Models with a Representation Alignment Projector(https://arxiv.org/abs/2601.22468)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Recent progress in generative modeling has enabled high-quality visual synthesis with diffusion-based frameworks, supporting controllable sampling and large-scale training. Inference-time guidance methods such as classifier-free and representative guidance enhance semantic alignment by modifying sampling dynamics; however, they do not fully exploit unsupervised feature representations. Although such visual representations contain rich semantic structure, their integration during generation is constrained by the absence of ground-truth reference images at inference. This work reveals semantic drift in the early denoising stages of diffusion transformers, where stochasticity results in inconsistent alignment even under identical conditioning. To mitigate this issue, we introduce a guidance scheme using a representation alignment projector that injects representations predicted by a projector into intermediate sampling steps, providing an effective semantic anchor without modifying the model architecture. Experiments on SiTs and REPAs show notable improvements in class-conditional ImageNet synthesis, achieving substantially lower FID scores; for example, REPA-XL/2 improves from 5.9 to 3.3, and the proposed method outperforms representative guidance when applied to SiT models. The approach further yields complementary gains when combined with classifier-free guidance, demonstrating enhanced semantic coherence and visual fidelity. These results establish representation-informed diffusion sampling as a practical strategy for reinforcing semantic preservation and image consistency.</li>
<li><strong>摘要：</strong>生成建模的最新进展使得基于扩散的框架实现了高质量的视觉合成，支持可控采样和大规模训练。推理时指导方法，例如无分类器和代表性指导，通过修改采样动态来增强语义对齐；然而，他们并没有充分利用无监督的特征表示。尽管这种视觉表示包含丰富的语义结构，但它们在生成过程中的集成受到推理时缺乏真实参考图像的限制。这项工作揭示了扩散变压器早期降噪阶段的语义漂移，即使在相同的条件下，随机性也会导致不一致的对齐。为了缓解这个问题，我们引入了一种使用表示对齐投影仪的指导方案，该方案将投影仪预测的表示注入到中间采样步骤中，从而在不修改模型架构的情况下提供有效的语义锚点。 SiT 和 REPA 上的实验表明类条件 ImageNet 合成有显着改进，显着降低了 FID 分数；例如，REPA-XL/2 从 5.9 提高到 3.3，并且所提出的方法在应用于 SiT 模型时优于代表性指导。当与无分类器指导相结合时，该方法进一步产生互补收益，证明了增强的语义连贯性和视觉保真度。这些结果将基于表示的扩散采样确立为增强语义保存和图像一致性的实用策略。</li>
</ul>

<h3>Title: Gradual Fine-Tuning for Flow Matching Models</h3>
<ul>
<li><strong>Authors: </strong>Gudrun Thorkelsdottir, Arindam Banerjee</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22495">https://arxiv.org/abs/2601.22495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22495">https://arxiv.org/pdf/2601.22495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22495]] Gradual Fine-Tuning for Flow Matching Models(https://arxiv.org/abs/2601.22495)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Fine-tuning flow matching models is a central challenge in settings with limited data, evolving distributions, or strict efficiency demands, where unconstrained fine-tuning can erode the accuracy and efficiency gains learned during pretraining. Prior work has produced theoretical guarantees and empirical advances for reward-based fine-tuning formulations, but these methods often impose restrictions on permissible drift structure or training techniques. In this work, we propose Gradual Fine-Tuning (GFT), a principled framework for fine-tuning flow-based generative models when samples from the target distribution are available. For stochastic flows, GFT defines a temperature-controlled sequence of intermediate objectives that smoothly interpolate between the pretrained and target drifts, approaching the true target as the temperature approaches zero. We prove convergence results for both marginal and conditional GFT objectives, enabling the use of suitable (e.g., optimal transport) couplings during GFT while preserving correctness. Empirically, GFT improves convergence stability and shortens probability paths, resulting in faster inference, while maintaining generation quality comparable to standard fine-tuning. Our results position GFT as a theoretically grounded and practically effective alternative for scalable adaptation of flow matching models under distribution shift.</li>
<li><strong>摘要：</strong>在数据有限、分布不断变化或效率要求严格的环境中，微调流匹配模型是一个核心挑战，在这些环境中，无约束的微调可能会削弱预训练期间学到的准确性和效率增益。先前的工作已经为基于奖励的微调公式提供了理论保证和实证进展，但这些方法通常对允许的漂移结构或训练技术施加限制。在这项工作中，我们提出了渐进微调（GFT），这是一种原则框架，用于在目标分布中的样本可用时微调基于流的生成模型。对于随机流，GFT 定义了中间目标的温度控制序列，该序列在预训练漂移和目标漂移之间平滑插值，当温度接近零时接近真实目标。我们证明了边际和条件 GFT 目标的收敛结果，从而能够在 GFT 期间使用合适的（例如最佳传输）耦合，同时保持正确性。根据经验，GFT 提高了收敛稳定性并缩短了概率路径，从而加快了推理速度，同时保持了与标准微调相当的生成质量。我们的结果将 GFT 定位为一种理论上有根据且实际上有效的替代方案，可用于在分布变化下对流量匹配模型进行可扩展的适应。</li>
</ul>

<h3>Title: MIRRORTALK: Forging Personalized Avatars Via Disentangled Style and Hierarchical Motion Control</h3>
<ul>
<li><strong>Authors: </strong>Renjie Lu, Xulong Zhang, Xiaoyang Qu, Jianzong Wang, Shangfei Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.SD</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22501">https://arxiv.org/abs/2601.22501</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22501">https://arxiv.org/pdf/2601.22501</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22501]] MIRRORTALK: Forging Personalized Avatars Via Disentangled Style and Hierarchical Motion Control(https://arxiv.org/abs/2601.22501)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Synthesizing personalized talking faces that uphold and highlight a speaker's unique style while maintaining lip-sync accuracy remains a significant challenge. A primary limitation of existing approaches is the intrinsic confounding of speaker-specific talking style and semantic content within facial motions, which prevents the faithful transfer of a speaker's unique persona to arbitrary speech. In this paper, we propose MirrorTalk, a generative framework based on a conditional diffusion model, combined with a Semantically-Disentangled Style Encoder (SDSE) that can distill pure style representations from a brief reference video. To effectively utilize this representation, we further introduce a hierarchical modulation strategy within the diffusion process. This mechanism guides the synthesis by dynamically balancing the contributions of audio and style features across distinct facial regions, ensuring both precise lip-sync accuracy and expressive full-face dynamics. Extensive experiments demonstrate that MirrorTalk achieves significant improvements over state-of-the-art methods in terms of lip-sync accuracy and personalization preservation.</li>
<li><strong>摘要：</strong>合成个性化的说话面孔，以维护和突出演讲者的独特风格，同时保持口型同步的准确性，仍然是一个重大挑战。现有方法的主要局限性是特定于说话者的谈话风格和面部动作中的语义内容的内在混淆，这阻碍了将说话者的独特角色忠实地转移到任意语音。在本文中，我们提出了 MirrorTalk，一种基于条件扩散模型的生成框架，与语义解缠风格编码器（SDSE）相结合，可以从简短的参考视频中提取纯风格表示。为了有效地利用这种表示，我们进一步在扩散过程中引入分层调制策略。该机制通过动态平衡不同面部区域的音频和风格特征的贡献来指导合成，确保精确的唇形同步准确性和富有表现力的全脸动态。大量实验表明，MirrorTalk 在口型同步准确性和个性化保留方面比最先进的方法取得了显着改进。</li>
</ul>

<h3>Title: DreamVAR: Taming Reinforced Visual Autoregressive Model for High-Fidelity Subject-Driven Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Xin Jiang, Jingwen Chen, Yehao Li, Yingwei Pan, Kezhou Chen, Zechao Li, Ting Yao, Tao Mei</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22507">https://arxiv.org/abs/2601.22507</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22507">https://arxiv.org/pdf/2601.22507</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22507]] DreamVAR: Taming Reinforced Visual Autoregressive Model for High-Fidelity Subject-Driven Image Generation(https://arxiv.org/abs/2601.22507)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Recent advances in subject-driven image generation using diffusion models have attracted considerable attention for their remarkable capabilities in producing high-quality images. Nevertheless, the potential of Visual Autoregressive (VAR) models, despite their unified architecture and efficient inference, remains underexplored. In this work, we present DreamVAR, a novel framework for subject-driven image synthesis built upon a VAR model that employs next-scale prediction. Technically, multi-scale features of the reference subject are first extracted by a visual tokenizer. Instead of interleaving these conditional features with target image tokens across scales, our DreamVAR pre-fills the full subject feature sequence prior to predicting target image tokens. This design simplifies autoregressive dependencies and mitigates the train-test discrepancy in multi-scale conditioning scenario within the VAR paradigm. DreamVAR further incorporates reinforcement learning to jointly enhance semantic alignment and subject consistency. Extensive experiments demonstrate that DreamVAR achieves superior appearance preservation compared to leading diffusion-based methods.</li>
<li><strong>摘要：</strong>使用扩散模型的主题驱动图像生成的最新进展因其在生成高质量图像方面的卓越能力而引起了广泛关注。然而，尽管视觉自回归（VAR）模型具有统一的架构和高效的推理，但其潜力仍未得到充分开发。在这项工作中，我们提出了 DreamVAR，这是一种基于主题驱动的图像合成的新颖框架，它建立在采用下一代预测的 VAR 模型上。从技术上讲，首先通过视觉标记器提取参考对象的多尺度特征。我们的 DreamVAR 不是将这些条件特征与跨尺度的目标图像标记交错，而是在预测目标图像标记之前预先填充完整的主题特征序列。这种设计简化了自回归依赖性，并减轻了 VAR 范式内多尺度调节场景中的训练测试差异。 DreamVAR 进一步结合强化学习，共同增强语义对齐和主题一致性。大量实验表明，与领先的基于扩散的方法相比，DreamVAR 实现了卓越的外观保留。</li>
</ul>

<h3>Title: DNA: Uncovering Universal Latent Forgery Knowledge</h3>
<ul>
<li><strong>Authors: </strong>Jingtong Dou, Chuancheng Shi, Yemin Wang, Shiming Guo, Anqi Yi, Wenhua Wu, Li Zhang, Fei Shen, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22515">https://arxiv.org/abs/2601.22515</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22515">https://arxiv.org/pdf/2601.22515</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22515]] DNA: Uncovering Universal Latent Forgery Knowledge(https://arxiv.org/abs/2601.22515)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As generative AI achieves hyper-realism, superficial artifact detection has become obsolete. While prevailing methods rely on resource-intensive fine-tuning of black-box backbones, we propose that forgery detection capability is already encoded within pre-trained models rather than requiring end-to-end retraining. To elicit this intrinsic capability, we propose the discriminative neural anchors (DNA) framework, which employs a coarse-to-fine excavation mechanism. First, by analyzing feature decoupling and attention distribution shifts, we pinpoint critical intermediate layers where the focus of the model logically transitions from global semantics to local anomalies. Subsequently, we introduce a triadic fusion scoring metric paired with a curvature-truncation strategy to strip away semantic redundancy, precisely isolating the forgery-discriminative units (FDUs) inherently imprinted with sensitivity to forgery traces. Moreover, we introduce HIFI-Gen, a high-fidelity synthetic benchmark built upon the very latest models, to address the lag in existing datasets. Experiments demonstrate that by solely relying on these anchors, DNA achieves superior detection performance even under few-shot conditions. Furthermore, it exhibits remarkable robustness across diverse architectures and against unseen generative models, validating that waking up latent neurons is more effective than extensive fine-tuning.</li>
<li><strong>摘要：</strong>随着生成式人工智能实现超现实主义，表面的伪影检测已经过时。虽然流行的方法依赖于黑盒主干的资源密集型微调，但我们建议伪造检测功能已经编码在预训练的模型中，而不需要端到端的再训练。为了激发这种内在能力，我们提出了判别性神经锚（DNA）框架，该框架采用从粗到细的挖掘机制。首先，通过分析特征解耦和注意力分布变化，我们查明了关键的中间层，模型的焦点在逻辑上从全局语义过渡到局部异常。随后，我们引入了三元融合评分度量与曲率截断策略相结合，以消除语义冗余，精确隔离本质上对伪造痕迹敏感的伪造判别单元（FDU）。此外，我们还引入了 HIFI-Gen，这是一种基于最新模型构建的高保真综合基准，以解决现有数据集的滞后问题。实验表明，仅依靠这些锚定点，DNA 即使在少样本条件下也能实现卓越的检测性能。此外，它在不同的架构和针对看不见的生成模型的情况下表现出卓越的鲁棒性，验证了唤醒潜在神经元比广泛的微调更有效。</li>
</ul>

<h3>Title: SCOPE-PD: Explainable AI on Subjective and Clinical Objective Measurements of Parkinson's Disease for Precision Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Md Mezbahul Islam, John Michael Templeton, Masrur Sobhan, Christian Poellabauer, Ananda Mohan Mondal</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22516">https://arxiv.org/abs/2601.22516</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22516">https://arxiv.org/pdf/2601.22516</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22516]] SCOPE-PD: Explainable AI on Subjective and Clinical Objective Measurements of Parkinson's Disease for Precision Decision-Making(https://arxiv.org/abs/2601.22516)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Parkinson's disease (PD) is a chronic and complex neurodegenerative disorder influenced by genetic, clinical, and lifestyle factors. Predicting this disease early is challenging because it depends on traditional diagnostic methods that face issues of subjectivity, which commonly delay diagnosis. Several objective analyses are currently in practice to help overcome the challenges of subjectivity; however, a proper explanation of these analyses is still lacking. While machine learning (ML) has demonstrated potential in supporting PD diagnosis, existing approaches often rely on subjective reports only and lack interpretability for individualized risk estimation. This study proposes SCOPE-PD, an explainable AI-based prediction framework, by integrating subjective and objective assessments to provide personalized health decisions. Subjective and objective clinical assessment data are collected from the Parkinson's Progression Markers Initiative (PPMI) study to construct a multimodal prediction framework. Several ML techniques are applied to these data, and the best ML model is selected to interpret the results. Model interpretability is examined using SHAP-based analysis. The Random Forest algorithm achieves the highest accuracy of 98.66 percent using combined features from both subjective and objective test data. Tremor, bradykinesia, and facial expression are identified as the top three contributing features from the MDS-UPDRS test in the prediction of PD.</li>
<li><strong>摘要：</strong>帕金森病 (PD) 是一种受遗传、临床和生活方式因素影响的慢性复杂神经退行性疾病。早期预测这种疾病具有挑战性，因为它依赖于面临主观性问题的传统诊断方法，这通常会延迟诊断。目前在实践中有几种客观分析可以帮助克服主观性的挑战；然而，这些分析仍然缺乏适当的解释。虽然机器学习 (ML) 已显示出支持 PD 诊断的潜力，但现有方法通常仅依赖于主观报告，并且缺乏个性化风险评估的可解释性。本研究提出了 SCOPE-PD，一种可解释的基于人工智能的预测框架，通过整合主观和客观评估来提供个性化的健康决策。从帕金森病进展标志物倡议 (PPMI) 研究中收集主观和客观临床评估数据，以构建多模式预测框架。多种机器学习技术应用于这些数据，并选择最佳的机器学习模型来解释结果。使用基于 SHAP 的分析来检查模型的可解释性。随机森林算法结合主观和客观测试数据的特征，达到了 98.66% 的最高准确率。 MDS-UPDRS 测试将震颤、运动迟缓和面部表情确定为预测 PD 的三大重要特征。</li>
</ul>

<h3>Title: Variational Bayesian Flow Network for Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Yida Xiong, Jiameng Chen, Xiuwen Gong, Jia Wu, Shirui Pan, Wenbin Hu</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22524">https://arxiv.org/abs/2601.22524</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22524">https://arxiv.org/pdf/2601.22524</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22524]] Variational Bayesian Flow Network for Graph Generation(https://arxiv.org/abs/2601.22524)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Graph generation aims to sample discrete node and edge attributes while satisfying coupled structural constraints. Diffusion models for graphs often adopt largely factorized forward-noising, and many flow-matching methods start from factorized reference noise and coordinate-wise interpolation, so node-edge coupling is not encoded by the generative geometry and must be recovered implicitly by the core network, which can be brittle after discrete decoding. Bayesian Flow Networks (BFNs) evolve distribution parameters and naturally support discrete generation. But classical BFNs typically rely on factorized beliefs and independent channels, which limit geometric evidence fusion. We propose Variational Bayesian Flow Network (VBFN), which performs a variational lifting to a tractable joint Gaussian variational belief family governed by structured precisions. Each Bayesian update reduces to solving a symmetric positive definite linear system, enabling coupled node and edge updates within a single fusion step. We construct sample-agnostic sparse precisions from a representation-induced dependency graph, thereby avoiding label leakage while enforcing node-edge consistency. On synthetic and molecular graph datasets, VBFN improves fidelity and diversity, and surpasses baseline methods.</li>
<li><strong>摘要：</strong>图生成旨在对离散节点和边属性进行采样，同时满足耦合结构约束。图的扩散模型通常采用大量因式分解的前向噪声，并且许多流匹配方法从因式分解的参考噪声和坐标插值开始，因此节点-边缘耦合不是由生成几何编码的，必须由核心网络隐式恢复，这在离散解码后可能很脆弱。贝叶斯流网络 (BFN) 演化分布参数并自然支持离散生成。但经典的 BFN 通常依赖于因式分解的信念和独立的通道，这限制了几何证据融合。我们提出了变分贝叶斯流网络（VBFN），它对由结构化精度控制的易处理的联合高斯变分信念族进行变分提升。每个贝叶斯更新都简化为求解对称正定线性系统，从而在单个融合步骤中实现耦合节点和边缘更新。我们从表示引起的依赖图构建与样本无关的稀疏精度，从而避免标签泄漏，同时强制节点边缘一致性。在合成和分子图数据集上，VBFN 提高了保真度和多样性，并超越了基线方法。</li>
</ul>

<h3>Title: DELNet: Continuous All-in-One Weather Removal via Dynamic Expert Library</h3>
<ul>
<li><strong>Authors: </strong>Shihong Liu, Kun Zuo, Hanguang Xiao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22573">https://arxiv.org/abs/2601.22573</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22573">https://arxiv.org/pdf/2601.22573</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22573]] DELNet: Continuous All-in-One Weather Removal via Dynamic Expert Library(https://arxiv.org/abs/2601.22573)</code><input type="text"></li>
<li><strong>Keywords: </strong>restoration</a></li>
<li><strong>Abstract: </strong>All-in-one weather image restoration methods are valuable in practice but depend on pre-collected data and require retraining for unseen degradations, leading to high cost. We propose DELNet, a continual learning framework for weather image restoration. DELNet integrates a judging valve that measures task similarity to distinguish new from known tasks, and a dynamic expert library that stores experts trained on different degradations. For new tasks, the valve selects top-k experts for knowledge transfer while adding new experts to capture task-specific features; for known tasks, the corresponding experts are directly reused. This design enables continuous optimization without retraining existing models. Experiments on OTS, Rain100H, and Snow100K demonstrate that DELNet surpasses state-of-the-art continual learning methods, achieving PSNR gains of 16\%, 11\%, and 12\%, respectively. These results highlight the effectiveness, robustness, and efficiency of DELNet, which reduces retraining cost and enables practical deployment in real-world scenarios.</li>
<li><strong>摘要：</strong>一体化天气图像恢复方法在实践中很有价值，但依赖于预先收集的数据，并且需要针对看不见的退化进行重新训练，从而导致成本高昂。我们提出了 DELNet，一种用于天气图像恢复的持续学习框架。 DELNet 集成了一个判断阀，用于测量任务相似性以区分新任务和已知任务，以及一个动态专家库，用于存储经过不同退化训练的专家。对于新任务，阀门选择top-k专家进行知识转移，同时添加新专家来捕获特定任务的特征；对于已知的任务，直接重用相应的专家。这种设计可以实现持续优化，而无需重新训练现有模型。在 OTS、Rain100H 和 Snow100K 上的实验表明，DELNet 超越了最先进的持续学习方法，分别实现了 16%、11% 和 12% 的 PSNR 增益。这些结果凸显了 DELNet 的有效性、鲁棒性和效率，它降低了再训练成本并能够在现实场景中进行实际部署。</li>
</ul>

<h3>Title: PhoStream: Benchmarking Real-World Streaming for Omnimodal Assistants in Mobile Scenarios</h3>
<ul>
<li><strong>Authors: </strong>Xudong Lu, Huankang Guan, Yang Bo, Jinpeng Chen, Xintong Guo, Shuhan Li, Fang Liu, Peiwen Sun, Xueying Li, Wei Zhang, Xue Yang, Rui Liu, Hongsheng Li</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22575">https://arxiv.org/abs/2601.22575</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22575">https://arxiv.org/pdf/2601.22575</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22575]] PhoStream: Benchmarking Real-World Streaming for Omnimodal Assistants in Mobile Scenarios(https://arxiv.org/abs/2601.22575)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Multimodal Large Language Models excel at offline audio-visual understanding, but their ability to serve as mobile assistants in continuous real-world streams remains underexplored. In daily phone use, mobile assistants must track streaming audio-visual inputs and respond at the right time, yet existing benchmarks are often restricted to multiple-choice questions or use shorter videos. In this paper, we introduce PhoStream, the first mobile-centric streaming benchmark that unifies on-screen and off-screen scenarios to evaluate video, audio, and temporal reasoning. PhoStream contains 5,572 open-ended QA pairs from 578 videos across 4 scenarios and 10 capabilities. We build it with an Automated Generative Pipeline backed by rigorous human verification, and evaluate models using a realistic Online Inference Pipeline and LLM-as-a-Judge evaluation for open-ended responses. Experiments reveal a temporal asymmetry in LLM-judged scores (0-100): models perform well on Instant and Backward tasks (Gemini 3 Pro exceeds 80), but drop sharply on Forward tasks (16.40), largely due to early responses before the required visual and audio cues appear. This highlights a fundamental limitation: current MLLMs struggle to decide when to speak, not just what to say. Code and datasets used in this work will be made publicly accessible at this https URL.</li>
<li><strong>摘要：</strong>多模态大语言模型擅长离线视听理解，但它们在连续的现实世界流中充当移动助手的能力仍未得到充分开发。在日常手机使用中，移动助手必须跟踪流式视听输入并在正确的时间做出响应，但现有的基准通常仅限于多项选择题或使用较短的视频。在本文中，我们介绍了 PhoStream，这是第一个以移动设备为中心的流媒体基准测试，它统一了屏幕上和屏幕外的场景来评估视频、音频和时间推理。 PhoStream 包含来自 578 个视频的 5,572 个开放式 QA 对，涉及 4 个场景和 10 种功能。我们使用由严格的人工验证支持的自动生成管道来构建它，并使用现实的在线推理管道和法学硕士作为法官评估开放式响应来评估模型。实验揭示了 LLM 判定分数 (0-100) 的时间不对称性：模型在即时和后向任务中表现良好（Gemini 3 Pro 超过 80），但在前向任务中表现急剧下降 (16.40)，这主要是由于在所需的视觉和音频提示出现之前的早期响应。这凸显了一个根本性的局限性：当前的 MLLM 很难决定何时发言，而不仅仅是决定说什么。这项工作中使用的代码和数据集将通过此 https URL 公开访问。</li>
</ul>

<h3>Title: FedDis: A Causal Disentanglement Framework for Federated Traffic Prediction</h3>
<ul>
<li><strong>Authors: </strong>Chengyang Zhou, Zijian Zhang, Chunxu Zhang, Hao Miao, Yulin Zhang, Kedi Lyu, Juncheng Hu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22578">https://arxiv.org/abs/2601.22578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22578">https://arxiv.org/pdf/2601.22578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22578]] FedDis: A Causal Disentanglement Framework for Federated Traffic Prediction(https://arxiv.org/abs/2601.22578)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Federated learning offers a promising paradigm for privacy-preserving traffic prediction, yet its performance is often challenged by the non-identically and independently distributed (non-IID) nature of decentralized traffic data. Existing federated methods frequently struggle with this data heterogeneity, typically entangling globally shared patterns with client-specific local dynamics within a single representation. In this work, we postulate that this heterogeneity stems from the entanglement of two distinct generative sources: client-specific localized dynamics and cross-client global spatial-temporal patterns. Motivated by this perspective, we introduce FedDis, a novel framework that, to the best of our knowledge, is the first to leverage causal disentanglement for federated spatial-temporal prediction. Architecturally, FedDis comprises a dual-branch design wherein a Personalized Bank learns to capture client-specific factors, while a Global Pattern Bank distills common knowledge. This separation enables robust cross-client knowledge transfer while preserving high adaptability to unique local environments. Crucially, a mutual information minimization objective is employed to enforce informational orthogonality between the two branches, thereby ensuring effective disentanglement. Comprehensive experiments conducted on four real-world benchmark datasets demonstrate that FedDis consistently achieves state-of-the-art performance, promising efficiency, and superior expandability.</li>
<li><strong>摘要：</strong>联邦学习为保护隐私的流量预测提供了一种有前途的范例，但其性能经常受到去中心化流量数据的非同一独立分布（非 IID）性质的挑战。现有的联合方法经常与这种数据异构性作斗争，通常将全局共享模式与单个表示中特定于客户的本地动态纠缠在一起。在这项工作中，我们假设这种异质性源于两个不同生成源的纠缠：特定于客户的局部动态和跨客户的全局时空模式。受这一观点的启发，我们引入了 FedDis，这是一个新颖的框架，据我们所知，它是第一个利用因果解耦进行联合时空预测的框架。从架构上来说，FedDis 包含双分支设计，其中个性化银行学习捕获客户特定因素，而全球模式银行则提炼共同知识。这种分离实现了强大的跨客户端知识传输，同时保留了对独特本地环境的高度适应性。至关重要的是，采用互信息最小化目标来强制两个分支之间的信息正交，从而确保有效解开。对四个真实世界基准数据集进行的综合实验表明，FedDis 始终如一地实现了最先进的性能、有希望的效率和卓越的可扩展性。</li>
</ul>

<h3>Title: LINA: Linear Autoregressive Image Generative Models with Continuous Tokens</h3>
<ul>
<li><strong>Authors: </strong>Jiahao Wang, Ting Pan, Haoge Deng, Dongchen Han, Taiqiang Wu, Xinlong Wang, Ping Luo</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22630">https://arxiv.org/abs/2601.22630</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22630">https://arxiv.org/pdf/2601.22630</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22630]] LINA: Linear Autoregressive Image Generative Models with Continuous Tokens(https://arxiv.org/abs/2601.22630)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Autoregressive models with continuous tokens form a promising paradigm for visual generation, especially for text-to-image (T2I) synthesis, but they suffer from high computational cost. We study how to design compute-efficient linear attention within this framework. Specifically, we conduct a systematic empirical analysis of scaling behavior with respect to parameter counts under different design choices, focusing on (1) normalization paradigms in linear attention (division-based vs. subtraction-based) and (2) depthwise convolution for locality augmentation. Our results show that although subtraction-based normalization is effective for image classification, division-based normalization scales better for linear generative transformers. In addition, incorporating convolution for locality modeling plays a crucial role in autoregressive generation, consistent with findings in diffusion models. We further extend gating mechanisms, commonly used in causal linear attention, to the bidirectional setting and propose a KV gate. By introducing data-independent learnable parameters to the key and value states, the KV gate assigns token-wise memory weights, enabling flexible memory management similar to forget gates in language models. Based on these findings, we present LINA, a simple and compute-efficient T2I model built entirely on linear attention, capable of generating high-fidelity 1024x1024 images from user instructions. LINA achieves competitive performance on both class-conditional and T2I benchmarks, obtaining 2.18 FID on ImageNet (about 1.4B parameters) and 0.74 on GenEval (about 1.5B parameters). A single linear attention module reduces FLOPs by about 61 percent compared to softmax attention. Code and models are available at: this https URL.</li>
<li><strong>摘要：</strong>具有连续标记的自回归模型为视觉生成，尤其是文本到图像（T2I）合成，形成了一种有前途的范例，但它们的计算成本很高。我们研究如何在这个框架内设计计算效率高的线性注意力。具体来说，我们对不同设计选择下参数计数的缩放行为进行了系统的实证分析，重点关注（1）线性注意力中的归一化范式（基于除法与基于减法）和（2）用于局部增强的深度卷积。我们的结果表明，虽然基于减法的归一化对于图像分类是有效的，但基于除法的归一化对于线性生成变换器的缩放效果更好。此外，将卷积纳入局部建模在自回归生成中起着至关重要的作用，这与扩散模型中的发现一致。我们进一步将因果线性注意力中常用的门控机制扩展到双向设置，并提出了 KV 门。通过向键和值状态引入与数据无关的可学习参数，KV 门分配 token-wise 内存权重，从而实现类似于语言模型中的遗忘门的灵活内存管理。基于这些发现，我们提出了 LINA，这是一种完全基于线性注意力构建的简单且计算高效的 T2I 模型，能够根据用户指令生成高保真 1024x1024 图像。 LINA 在类条件和 T2I 基准测试上都取得了具有竞争力的性能，在 ImageNet 上获得了 2.18 FID（约 1.4B 参数），在 GenEval 上获得了 0.74（约 1.5B 参数）。与 softmax 注意力相比，单个线性注意力模块可将 FLOP 减少约 61%。代码和模型可在以下位置获得：此 https URL。</li>
</ul>

<h3>Title: Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification</h3>
<ul>
<li><strong>Authors: </strong>Chuxue Cao, Jinluan Yang, Haoran Li, Kunhao Pan, Zijian Zhao, Zhengyu Chen, Yuchen Tian, Lijun Wu, Conghui He, Sirui Han, Yike Guo</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22642">https://arxiv.org/abs/2601.22642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22642">https://arxiv.org/pdf/2601.22642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22642]] Pushing the Boundaries of Natural Reasoning: Interleaved Bonus from Formal-Logic Verification(https://arxiv.org/abs/2601.22642)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) show remarkable capabilities, yet their stochastic next-token prediction creates logical inconsistencies and reward hacking that formal symbolic systems avoid. To bridge this gap, we introduce a formal logic verification-guided framework that dynamically interleaves formal symbolic verification with the natural language generation process, providing real-time feedback to detect and rectify errors as they occur. Distinguished from previous neuro-symbolic methods limited by passive post-hoc validation, our approach actively penalizes intermediate fallacies during the reasoning chain. We operationalize this framework via a novel two-stage training pipeline that synergizes formal logic verification-guided supervised fine-tuning and policy optimization. Extensive evaluation on six benchmarks spanning mathematical, logical, and general reasoning demonstrates that our 7B and 14B models outperform state-of-the-art baselines by average margins of 10.4% and 14.2%, respectively. These results validate that formal verification can serve as a scalable mechanism to significantly push the performance boundaries of advanced LLM reasoning.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）显示出非凡的能力，但它们的随机下一个标记预测会造成逻辑不一致，并奖励正式符号系统避免的黑客攻击。为了弥补这一差距，我们引入了一种形式逻辑验证引导的框架，该框架动态地将形式符号验证与自然语言生成过程交织在一起，提供实时反馈以检测和纠正发生的错误。与之前受被动事后验证限制的神经符号方法不同，我们的方法主动惩罚推理链中的中间谬误。我们通过新颖的两阶段训练管道来操作该框架，该管道将形式逻辑验证引导的监督微调和策略优化相结合。对涵盖数学、逻辑和一般推理的六个基准的广泛评估表明，我们的 7B 和 14B 模型的平均性能分别优于最先进的基线 10.4% 和 14.2%。这些结果验证了形式验证可以作为一种可扩展的机制，显着突破高级法学硕士推理的性能界限。</li>
</ul>

<h3>Title: GUDA: Counterfactual Group-wise Training Data Attribution for Diffusion Models via Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Naoki Murata, Yuhta Takida, Chieh-Hsin Lai, Toshimitsu Uesaka, Bac Nguyen, Stefano Ermon, Yuki Mitsufuji</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22651">https://arxiv.org/abs/2601.22651</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22651">https://arxiv.org/pdf/2601.22651</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22651]] GUDA: Counterfactual Group-wise Training Data Attribution for Diffusion Models via Unlearning(https://arxiv.org/abs/2601.22651)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Training-data attribution for vision generative models aims to identify which training data influenced a given output. While most methods score individual examples, practitioners often need group-level answers (e.g., artistic styles or object classes). Group-wise attribution is counterfactual: how would a model's behavior on a generated sample change if a group were absent from training? A natural realization of this counterfactual is Leave-One-Group-Out (LOGO) retraining, which retrains the model with each group removed; however, it becomes computationally prohibitive as the number of groups grows. We propose GUDA (Group Unlearning-based Data Attribution) for diffusion models, which approximates each counterfactual model by applying machine unlearning to a shared full-data model instead of training from scratch. GUDA quantifies group influence using differences in a likelihood-based scoring rule (ELBO) between the full model and each unlearned counterfactual. Experiments on CIFAR-10 and artistic style attribution with Stable Diffusion show that GUDA identifies primary contributing groups more reliably than semantic similarity, gradient-based attribution, and instance-level unlearning approaches, while achieving x100 speedup on CIFAR-10 over LOGO retraining.</li>
<li><strong>摘要：</strong>视觉生成模型的训练数据归因旨在识别哪些训练数据影响给定的输出。虽然大多数方法对单个示例进行评分，但从业者通常需要群体级别的答案（例如，艺术风格或对象类别）。分组归因是反事实的：如果一个组没有参加训练，模型在生成样本上的行为会如何变化？这种反事实的自然实现是留一组（LOGO）再训练，它在删除每个组的情况下重新训练模型；然而，随着组数量的增加，它在计算上变得令人望而却步。我们提出了针对扩散模型的 GUDA（基于群体遗忘的数据归因），它通过将机器遗忘应用于共享的全数据模型而不是从头开始训练来近似每个反事实模型。 GUDA 使用完整模型和每个未学习的反事实之间基于可能性的评分规则 (ELBO) 的差异来量化群体影响力。 CIFAR-10 和稳定扩散的艺术风格归因实验表明，GUDA 比语义相似性、基于梯度的归因和实例级遗忘方法更可靠地识别主要贡献群体，同时在 CIFAR-10 上比 LOGO 重新训练实现 100 倍加速。</li>
</ul>

<h3>Title: Stabilizing Consistency Training: A Flow Map Analysis and Self-Distillation</h3>
<ul>
<li><strong>Authors: </strong>Youngjoong Kim, Duhoe Kim, Woosung Kim, Jaesik Park</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22679">https://arxiv.org/abs/2601.22679</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22679">https://arxiv.org/pdf/2601.22679</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22679]] Stabilizing Consistency Training: A Flow Map Analysis and Self-Distillation(https://arxiv.org/abs/2601.22679)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Consistency models have been proposed for fast generative modeling, achieving results competitive with diffusion and flow models. However, these methods exhibit inherent instability and limited reproducibility when training from scratch, motivating subsequent work to explain and stabilize these issues. While these efforts have provided valuable insights, the explanations remain fragmented, and the theoretical relationships remain unclear. In this work, we provide a theoretical examination of consistency models by analyzing them from a flow map-based perspective. This joint analysis clarifies how training stability and convergence behavior can give rise to degenerate solutions. Building on these insights, we revisit self-distillation as a practical remedy for certain forms of suboptimal convergence and reformulate it to avoid excessive gradient norms for stable optimization. We further demonstrate that our strategy extends beyond image generation to diffusion-based policy learning, without reliance on a pretrained diffusion model for initialization, thereby illustrating its broader applicability.</li>
<li><strong>摘要：</strong>一致性模型已被提出用于快速生成建模，取得了与扩散和流动模型相媲美的结果。然而，这些方法在从头开始训练时表现出固有的不稳定性和有限的可重复性，从而激发了后续工作来解释和稳定这些问题。尽管这些努力提供了有价值的见解，但解释仍然支离破碎，理论关系仍不清楚。在这项工作中，我们通过从基于流程图的角度分析一致性模型，对一致性模型进行了理论检验。这项联合分析阐明了训练稳定性和收敛行为如何导致退化解决方案。基于这些见解，我们重新审视自蒸馏作为某些形式的次优收敛的实际补救措施，并重新制定它以避免稳定优化的过度梯度范数。我们进一步证明，我们的策略超越了图像生成，扩展到基于扩散的策略学习，而不依赖于预训练的扩散模型进行初始化，从而说明了其更广泛的适用性。</li>
</ul>

<h3>Title: Visual Personalization Turing Test</h3>
<ul>
<li><strong>Authors: </strong>Rameen Abdal, James Burgess, Sergey Tulyakov, Kuan-Chieh Jackson Wang</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22680">https://arxiv.org/abs/2601.22680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22680">https://arxiv.org/pdf/2601.22680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22680]] Visual Personalization Turing Test(https://arxiv.org/abs/2601.22680)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce the Visual Personalization Turing Test (VPTT), a new paradigm for evaluating contextual visual personalization based on perceptual indistinguishability, rather than identity replication. A model passes the VPTT if its output (image, video, 3D asset, etc.) is indistinguishable to a human or calibrated VLM judge from content a given person might plausibly create or share. To operationalize VPTT, we present the VPTT Framework, integrating a 10k-persona benchmark (VPTT-Bench), a visual retrieval-augmented generator (VPRAG), and the VPTT Score, a text-only metric calibrated against human and VLM judgments. We show high correlation across human, VLM, and VPTT evaluations, validating the VPTT Score as a reliable perceptual proxy. Experiments demonstrate that VPRAG achieves the best alignment-originality balance, offering a scalable and privacy-safe foundation for personalized generative AI.</li>
<li><strong>摘要：</strong>我们引入了视觉个性化图灵测试（VPTT），这是一种基于感知不可区分性而不是身份复制来评估上下文视觉个性化的新范式。如果模型的输出（图像、视频、3D 资产等）对于人类或经过校准的 VLM 判断无法与给定人员可能创建或共享的内容区分开来，则该模型通过 VPTT。为了实施 VPTT，我们提出了 VPTT 框架，集成了 10k 角色基准 (VPTT-Bench)、视觉检索增强生成器 (VPRAG) 和 VPTT 分数（根据人类和 VLM 判断进行校准的纯文本指标）。我们显示了人类、VLM 和 VPTT 评估之间的高度相关性，验证了 VPTT 分数作为可靠的感知代理。实验表明，VPRAG 实现了最佳的对齐与原创性平衡，为个性化生成 AI 提供了可扩展且隐私安全的基础。</li>
</ul>

<h3>Title: Do Transformers Have the Ability for Periodicity Generalization?</h3>
<ul>
<li><strong>Authors: </strong>Huanyu Liu, Ge Li, Yihong Dong, Sihan Wu, Peixu Wang, Sihao Cheng, Taozhi Chen, Kechi Zhang, Hao Zhu, Tongxuan Liu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22690">https://arxiv.org/abs/2601.22690</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22690">https://arxiv.org/pdf/2601.22690</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22690]] Do Transformers Have the Ability for Periodicity Generalization?(https://arxiv.org/abs/2601.22690)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) based on the Transformer have demonstrated strong performance across diverse tasks. However, current models still exhibit substantial limitations in out-of-distribution (OOD) generalization compared with humans. We investigate this gap through periodicity, one of the basic OOD scenarios. Periodicity captures invariance amid variation. Periodicity generalization represents a model's ability to extract periodic patterns from training data and generalize to OOD scenarios. We introduce a unified interpretation of periodicity from the perspective of abstract algebra and reasoning, including both single and composite periodicity, to explain why Transformers struggle to generalize periodicity. Then we construct Coper about composite periodicity, a controllable generative benchmark with two OOD settings, Hollow and Extrapolation. Experiments reveal that periodicity generalization in Transformers is limited, where models can memorize periodic data during training, but cannot generalize to unseen composite periodicity. We release the source code to support future research.</li>
<li><strong>摘要：</strong>基于 Transformer 的大型语言模型 (LLM) 在不同的任务中表现出了强大的性能。然而，与人类相比，当前模型在分布外（OOD）泛化方面仍然表现出很大的局限性。我们通过周期性（基本 OOD 场景之一）来调查这一差距。周期性体现了变化中的不变性。周期性泛化代表模型从训练数据中提取周期性模式并泛化到 OOD 场景的能力。我们从抽象代数和推理的角度引入对周期性的统一解释，包括单一周期性和复合周期性，以解释为什么变形金刚很难概括周期性。然后我们构建了关于复合周期性的 Coper，这是一个具有两种 OOD 设置（Hollow 和 Extrapolation）的可控生成基准。实验表明，Transformers 中的周期性泛化是有限的，模型可以在训练期间记忆周期性数据，但不能泛化到不可见的复合周期性。我们发布源代码以支持未来的研究。</li>
</ul>

<h3>Title: Metric Hub: A metric library and practical selection workflow for use-case-driven data quality assessment in medical AI</h3>
<ul>
<li><strong>Authors: </strong>Katinka Becker, Maximilian P. Oppelt, Tobias S. Zech, Martin Seyferth, Sandie Cabon, Vanja Miskovic, Ivan Cimrak, Michal Kozubek, Giuseppe D'Avenio, Ilaria Campioni, Jana Fehr, Kanjar De, Ismail Mahmoudi, Emilio Dolgener Cantu, Laurenz Ottmann, Andreas Klaß, Galaad Altares, Jackie Ma, Alireza Salehi M., Nadine R. Lang-Richter, Tobias Schaeffter, Daniel Schwabe</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22702">https://arxiv.org/abs/2601.22702</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22702">https://arxiv.org/pdf/2601.22702</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22702]] Metric Hub: A metric library and practical selection workflow for use-case-driven data quality assessment in medical AI(https://arxiv.org/abs/2601.22702)</code><input type="text"></li>
<li><strong>Keywords: </strong>quality assessment</a></li>
<li><strong>Abstract: </strong>Machine learning (ML) in medicine has transitioned from research to concrete applications aimed at supporting several medical purposes like therapy selection, monitoring and treatment. Acceptance and effective adoption by clinicians and patients, as well as regulatory approval, require evidence of trustworthiness. A major factor for the development of trustworthy AI is the quantification of data quality for AI model training and testing. We have recently proposed the METRIC-framework for systematically evaluating the suitability (fit-for-purpose) of data for medical ML for a given task. Here, we operationalize this theoretical framework by introducing a collection of data quality metrics - the metric library - for practically measuring data quality dimensions. For each metric, we provide a metric card with the most important information, including definition, applicability, examples, pitfalls and recommendations, to support the understanding and implementation of these metrics. Furthermore, we discuss strategies and provide decision trees for choosing an appropriate set of data quality metrics from the metric library given specific use cases. We demonstrate the impact of our approach exemplarily on the PTB-XL ECG-dataset. This is a first step to enable fit-for-purpose evaluation of training and test data in practice as the base for establishing trustworthy AI in medicine.</li>
<li><strong>摘要：</strong>医学中的机器学习 (ML) 已从研究转变为具体应用，旨在支持治疗选择、监测和治疗等多种医疗目的。临床医生和患者的接受和有效采用以及监管部门的批准都需要可信度的证据。发展可信人工智能的一个主要因素是人工智能模型训练和测试的数据质量的量化。我们最近提出了 METRIC 框架，用于系统地评估医疗 ML 数据对于给定任务的适用性（适合目的）。在这里，我们通过引入一组数据质量指标（指标库）来操作这个理论框架，以实际测量数据质量维度。对于每个指标，我们提供了一个包含最重要信息的指标卡，包括定义、适用性、示例、陷阱和建议，以支持对这些指标的理解和实施。此外，我们讨论策略并提供决策树，用于根据特定用例从度量库中选择一组适当的数据质量度量。我们以 PTB-XL 心电图数据集为例展示了我们的方法的影响。这是在实践中对训练和测试数据进行适合目的评估的第一步，作为在医学领域建立值得信赖的人工智能的基础。</li>
</ul>

<h3>Title: Deep Learning-Based Early-Stage IR-Drop Estimation via CNN Surrogate Modeling</h3>
<ul>
<li><strong>Authors: </strong>Ritesh Bhadana</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.AR, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22707">https://arxiv.org/abs/2601.22707</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22707">https://arxiv.org/pdf/2601.22707</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22707]] Deep Learning-Based Early-Stage IR-Drop Estimation via CNN Surrogate Modeling(https://arxiv.org/abs/2601.22707)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>IR-drop is a critical power integrity challenge in modern VLSI designs that can cause timing degradation, reliability issues, and functional failures if not detected early in the design flow. Conventional IR-drop analysis relies on physics-based signoff tools, which provide high accuracy but incur significant computational cost and require near-final layout information, making them unsuitable for rapid early-stage design exploration. In this work, we propose a deep learning-based surrogate modeling approach for early-stage IR-drop estimation using a CNN. The task is formulated as a dense pixel-wise regression problem, where spatial physical layout features are mapped directly to IR-drop heatmaps. A U-Net-based encoder-decoder architecture with skip connections is employed to effectively capture both local and global spatial dependencies within the layout. The model is trained on a physics-inspired synthetic dataset generated by us, which incorporates key physical factors including power grid structure, cell density distribution, and switching activity. Model performance is evaluated using standard regression metrics such as Mean Squared Error (MSE) and Peak Signal-to-Noise Ratio (PSNR). Experimental results demonstrate that the proposed approach can accurately predict IR-drop distributions with millisecond-level inference time, enabling fast pre-signoff screening and iterative design optimization. The proposed framework is intended as a complementary early-stage analysis tool, providing designers with rapid IR-drop insight prior to expensive signoff analysis. The implementation, dataset generation scripts, and the interactive inference application are publicly available at: this https URL. The live application can be accessed at: this https URL.</li>
<li><strong>摘要：</strong>IR 压降是现代 VLSI 设计中的一个关键电源完整性挑战，如果没有在设计流程的早期检测到，可能会导致时序退化、可靠性问题和功能故障。传统的 IR 压降分析依赖于基于物理的签核工具，该工具提供高精度，但会产生大量计算成本，并且需要接近最终的布局信息，这使得它们不适合快速的早期设计探索。在这项工作中，我们提出了一种基于深度学习的代理建模方法，用于使用 CNN 进行早期 IR 压降估计。该任务被表述为密集的像素级回归问题，其中空间物理布局特征直接映射到红外压降热图。采用具有跳跃连接的基于 U-Net 的编码器-解码器架构来有效捕获布局内的局部和全局空间依赖性。该模型是在我们生成的受物理启发的合成数据集上进行训练的，该数据集包含关键的物理因素，包括电网结构、单元密度分布和开关活动。使用均方误差 (MSE) 和峰值信噪比 (PSNR) 等标准回归指标评估模型性能。实验结果表明，所提出的方法可以以毫秒级的推理时间准确预测 IR 压降分布，从而实现快速的签核前筛选和迭代设计优化。所提出的框架旨在作为补充的早期分析工具，在昂贵的签核分析之前为设计人员提供快速的 IR 压降洞察。实现、数据集生成脚本和交互式推理应用程序可在以下网址公开获取：此 https URL。可以通过以下网址访问实时应用程序：此 https URL。</li>
</ul>

<h3>Title: A Unified Study of LoRA Variants: Taxonomy, Review, Codebase, and Empirical Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Haonan He, Jingqi Ye, Minglei Li, Zhengbo Wang, Tao Chen, Lei Bai, Peng Ye</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22708">https://arxiv.org/abs/2601.22708</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22708">https://arxiv.org/pdf/2601.22708</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22708]] A Unified Study of LoRA Variants: Taxonomy, Review, Codebase, and Empirical Evaluation(https://arxiv.org/abs/2601.22708)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Low-Rank Adaptation (LoRA) is a fundamental parameter-efficient fine-tuning method that balances efficiency and performance in large-scale neural networks. However, the proliferation of LoRA variants has led to fragmentation in methodology, theory, code, and evaluation. To this end, this work presents the first unified study of LoRA variants, offering a systematic taxonomy, unified theoretical review, structured codebase, and standardized empirical assessment. First, we categorize LoRA variants along four principal axes: rank, optimization dynamics, initialization, and integration with Mixture-of-Experts. Then, we review their relationships and evolution within a common theoretical framework focused on low-rank update dynamics. Further, we introduce LoRAFactory, a modular codebase that implements variants through a unified interface, supporting plug-and-play experimentation and fine-grained analysis. Last, using this codebase, we conduct a large-scale evaluation across natural language generation, natural language understanding, and image classification tasks, systematically exploring key hyperparameters. Our results uncover several findings, notably: LoRA and its variants exhibit pronounced sensitivity to the choices of learning rate compared to other hyperparameters; moreover, with proper hyperparameter configurations, LoRA consistently matches or surpasses the performance of most of its variants.</li>
<li><strong>摘要：</strong>低秩适应（LoRA）是一种基本的参数高效微调方法，可以平衡大规模神经网络的效率和性能。然而，LoRA 变体的激增导致了方法论、理论、代码和评估的碎片化。为此，这项工作首次提出了 LoRA 变体的统一研究，提供了系统的分类、统一的理论回顾、结构化的代码库和标准化的实证评估。首先，我们沿着四个主轴对 LoRA 变体进行分类：等级、优化动态、初始化以及与专家混合的集成。然后，我们在一个关注低阶更新动态的共同理论框架内回顾它们的关系和演变。此外，我们还引入了 LoRAFactory，这是一个模块化代码库，通过统一接口实现变体，支持即插即用实验和细粒度分析。最后，使用这个代码库，我们对自然语言生成、自然语言理解和图像分类任务进行了大规模评估，系统地探索了关键的超参数。我们的结果揭示了几个发现，特别是：与其他超参数相比，LoRA 及其变体对学习率的选择表现出明显的敏感性；此外，通过适当的超参数配置，LoRA 始终能够匹配或超越其大多数变体的性能。</li>
</ul>

<h3>Title: OSNIP: Breaking the Privacy-Utility-Efficiency Trilemma in LLM Inference via Obfuscated Semantic Null Space</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Cao, Zeyu Ma, Chenhao Yang, Han Zheng, Mingang Chen</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22752">https://arxiv.org/abs/2601.22752</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22752">https://arxiv.org/pdf/2601.22752</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22752]] OSNIP: Breaking the Privacy-Utility-Efficiency Trilemma in LLM Inference via Obfuscated Semantic Null Space(https://arxiv.org/abs/2601.22752)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose Obfuscated Semantic Null space Injection for Privacy (OSNIP), a lightweight client-side encryption framework for privacy-preserving LLM inference. Generalizing the geometric intuition of linear kernels to the high-dimensional latent space of LLMs, we formally define the ``Obfuscated Semantic Null Space'', a high-dimensional regime that preserves semantic fidelity while enforcing near-orthogonality to the original embedding. By injecting perturbations that project the original embedding into this space, OSNIP ensures privacy without any post-processing. Furthermore, OSNIP employs a key-dependent stochastic mapping that synthesizes individualized perturbation trajectories unique to each user. Evaluations on 12 generative and classification benchmarks show that OSNIP achieves state-of-the-art performance, sharply reducing attack success rates while maintaining strong model utility under strict security constraints.</li>
<li><strong>摘要：</strong>我们提出了模糊语义空空间隐私注入（OSNIP），这是一种用于保护隐私的 LLM 推理的轻量级客户端加密框架。将线性核的几何直觉推广到 LLM 的高维潜在空间，我们正式定义了“模糊语义空空间”，这是一种高维机制，可以保留语义保真度，同时强制执行与原始嵌入的近正交性。通过注入将原始嵌入投影到该空间的扰动，OSNIP 无需任何后处理即可确保隐私。此外，OSNIP 采用依赖于键的随机映射来合成每个用户独有的个性化扰动轨迹。对 12 个生成和分类基准的评估表明，OSNIP 实现了最先进的性能，大幅降低了攻击成功率，同时在严格的安全约束下保持了强大的模型实用性。</li>
</ul>

<h3>Title: Unveiling Scaling Behaviors in Molecular Language Models: Effects of Model Size, Data, and Representation</h3>
<ul>
<li><strong>Authors: </strong>Dong Xu, Qihua Pan, Sisi Yuan, Jianqiang Li, Zexuan Zhu, Junkai Ji</a></li>
<li><strong>Subjects: </strong>cs.LG, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22757">https://arxiv.org/abs/2601.22757</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22757">https://arxiv.org/pdf/2601.22757</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22757]] Unveiling Scaling Behaviors in Molecular Language Models: Effects of Model Size, Data, and Representation(https://arxiv.org/abs/2601.22757)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Molecular generative models, often employing GPT-style language modeling on molecular string representations, have shown promising capabilities when scaled to large datasets and model sizes. However, it remains unclear and subject to debate whether these models adhere to predictable scaling laws under fixed computational budgets, which is a crucial understanding for optimally allocating resources between model size, data volume, and molecular representation. In this study, we systematically investigate the scaling behavior of molecular language models across both pretraining and downstream tasks. We train 300 models and conduct over 10,000 experiments, rigorously controlling compute budgets while independently varying model size, number of training tokens, and molecular representation. Our results demonstrate clear scaling laws in molecular models for both pretraining and downstream transfer, reveal the substantial impact of molecular representation on performance, and explain previously observed inconsistencies in scaling behavior for molecular generation. Additionally, we publicly release the largest library of molecular language models to date to facilitate future research and development. Code and models are available at this https URL.</li>
<li><strong>摘要：</strong>分子生成模型通常在分子字符串表示上采用 GPT 风格的语言建模，在扩展到大型数据集和模型大小时显示出有前途的功能。然而，目前尚不清楚这些模型是否在固定计算预算下遵循可预测的缩放定律，这对于在模型大小、数据量和分子表示之间优化资源分配至关重要。在这项研究中，我们系统地研究了分子语言模型在预训练和下游任务中的扩展行为。我们训练了 300 个模型并进行了 10,000 多个实验，严格控制计算预算，同时独立改变模型大小、训练标记数量和分子表示。我们的结果证明了分子模型中预训练和下游转移的清晰缩放规律，揭示了分子表示对性能的重大影响，并解释了之前观察到的分子生成缩放行为的不一致。此外，我们公开发布了迄今为止最大的分子语言模型库，以促进未来的研究和开发。代码和模型可从此 https URL 获取。</li>
</ul>

<h3>Title: Color Matters: Demosaicing-Guided Color Correlation Training for Generalizable AI-Generated Image Detection</h3>
<ul>
<li><strong>Authors: </strong>Nan Zhong, Yiran Xu, Mian Zou</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.CR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22778">https://arxiv.org/abs/2601.22778</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22778">https://arxiv.org/pdf/2601.22778</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22778]] Color Matters: Demosaicing-Guided Color Correlation Training for Generalizable AI-Generated Image Detection(https://arxiv.org/abs/2601.22778)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>As realistic AI-generated images threaten digital authenticity, we address the generalization failure of generative artifact-based detectors by exploiting the intrinsic properties of the camera imaging pipeline. Concretely, we investigate color correlations induced by the color filter array (CFA) and demosaicing, and propose a Demosaicing-guided Color Correlation Training (DCCT) framework for AI-generated image detection. By simulating the CFA sampling pattern, we decompose each color image into a single-channel input (as the condition) and the remaining two channels as the ground-truth targets (for prediction). A self-supervised U-Net is trained to model the conditional distribution of the missing channels from the given one, parameterized via a mixture of logistic functions. Our theoretical analysis reveals that DCCT targets a provable distributional difference in color-correlation features between photographic and AI-generated images. By leveraging these distinct features to construct a binary classifier, DCCT achieves state-of-the-art generalization and robustness, significantly outperforming prior methods across over 20 unseen generators.</li>
<li><strong>摘要：</strong>由于真实的人工智能生成的图像威胁到数字真实性，我们通过利用相机成像管道的内在属性来解决基于生成伪影的检测器的泛化失败。具体来说，我们研究了由滤色器阵列（CFA）和去马赛克引起的颜色相关性，并提出了一种用于人工智能生成图像检测的去马赛克引导的颜色相关性训练（DCCT）框架。通过模拟 CFA 采样模式，我们将每个彩色图像分解为单通道输入（作为条件），其余两个通道作为真实目标（用于预测）。自监督 U-Net 经过训练，可以对给定通道中缺失通道的条件分布进行建模，并通过混合逻辑函数进行参数化。我们的理论分析表明，DCCT 的目标是摄影图像和人工智能生成图像之间颜色相关特征的可证明的分布差异。通过利用这些独特的特征构建二元分类器，DCCT 实现了最先进的泛化性和鲁棒性，在 20 多个看不见的生成器中显着优于先前的方法。</li>
</ul>

<h3>Title: Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features</h3>
<ul>
<li><strong>Authors: </strong>Markus Mueller, Kathrin Gruber, Dennis Fok</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22816">https://arxiv.org/abs/2601.22816</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22816">https://arxiv.org/pdf/2601.22816</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22816]] Cascaded Flow Matching for Heterogeneous Tabular Data with Mixed-Type Features(https://arxiv.org/abs/2601.22816)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Advances in generative modeling have recently been adapted to tabular data containing discrete and continuous features. However, generating mixed-type features that combine discrete states with an otherwise continuous distribution in a single feature remains challenging. We advance the state-of-the-art in diffusion models for tabular data with a cascaded approach. We first generate a low-resolution version of a tabular data row, that is, the collection of the purely categorical features and a coarse categorical representation of numerical features. Next, this information is leveraged in the high-resolution flow matching model via a novel guided conditional probability path and data-dependent coupling. The low-resolution representation of numerical features explicitly accounts for discrete outcomes, such as missing or inflated values, and therewith enables a more faithful generation of mixed-type features. We formally prove that this cascade tightens the transport cost bound. The results indicate that our model generates significantly more realistic samples and captures distributional details more accurately, for example, the detection score increases by 40%.</li>
<li><strong>摘要：</strong>生成建模的进步最近已适应包含离散和连续特征的表格数据。然而，生成将离散状态与单个特征中的连续分布相结合的混合类型特征仍然具有挑战性。我们通过级联方法推进了表格数据扩散模型的最先进技术。我们首先生成表格数据行的低分辨率版本，即纯分类特征的集合和数字特征的粗略分类表示。接下来，通过新颖的引导条件概率路径和数据相关耦合，在高分辨率流匹配模型中利用该信息。数字特征的低分辨率表示明确地解释了离散结果，例如缺失或夸大的值，从而能够更忠实地生成混合类型特征。我们正式证明这种级联收紧了运输成本界限。结果表明，我们的模型生成了明显更真实的样本，并且更准确地捕获了分布细节，例如，检测分数提高了 40%。</li>
</ul>

<h3>Title: NativeTok: Native Visual Tokenization for Improved Image Generation</h3>
<ul>
<li><strong>Authors: </strong>Bin Wu, Mengqi Huang, Weinan Jia, Zhendong Mao</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22837">https://arxiv.org/abs/2601.22837</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22837">https://arxiv.org/pdf/2601.22837</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22837]] NativeTok: Native Visual Tokenization for Improved Image Generation(https://arxiv.org/abs/2601.22837)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>VQ-based image generation typically follows a two-stage pipeline: a tokenizer encodes images into discrete tokens, and a generative model learns their dependencies for reconstruction. However, improved tokenization in the first stage does not necessarily enhance the second-stage generation, as existing methods fail to constrain token dependencies. This mismatch forces the generative model to learn from unordered distributions, leading to bias and weak coherence. To address this, we propose native visual tokenization, which enforces causal dependencies during tokenization. Building on this idea, we introduce NativeTok, a framework that achieves efficient reconstruction while embedding relational constraints within token sequences. NativeTok consists of: (1) a Meta Image Transformer (MIT) for latent image modeling, and (2) a Mixture of Causal Expert Transformer (MoCET), where each lightweight expert block generates a single token conditioned on prior tokens and latent features. We further design a Hierarchical Native Training strategy that updates only new expert blocks, ensuring training efficiency. Extensive experiments demonstrate the effectiveness of NativeTok.</li>
<li><strong>摘要：</strong>基于 VQ 的图像生成通常遵循两阶段流程：标记器将图像编码为离散标记，生成模型学习它们的依赖关系以进行重建。然而，第一阶段改进的标记化并不一定会增强第二阶段的生成，因为现有方法无法限制标记依赖性。这种不匹配迫使生成模型从无序分布中学习，从而导致偏差和弱一致性。为了解决这个问题，我们提出了原生视觉标记化，它在标记化过程中强制执行因果依赖性。基于这个想法，我们引入了 NativeTok，这是一个框架，可以在令牌序列中嵌入关系约束的同时实现高效的重建。 NativeTok 包括：(1) 用于潜在图像建模的元图像转换器 (MIT)，以及 (2) 因果专家转换器混合器 (MoCET)，其中每个轻量级专家块生成一个以先验令牌和潜在特征为条件的单个令牌。我们进一步设计了分层原生训练策略，仅更新新的专家块，确保训练效率。大量的实验证明了 NativeTok 的有效性。</li>
</ul>

<h3>Title: Unconditional flow-based time series generation with equivariance-regularised latent spaces</h3>
<ul>
<li><strong>Authors: </strong>Camilo Carvajal Reyes, Felipe Tobar</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22848">https://arxiv.org/abs/2601.22848</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22848">https://arxiv.org/pdf/2601.22848</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22848]] Unconditional flow-based time series generation with equivariance-regularised latent spaces(https://arxiv.org/abs/2601.22848)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Flow-based models have proven successful for time-series generation, particularly when defined in lower-dimensional latent spaces that enable efficient sampling. However, how to design latent representations with desirable equivariance properties for time-series generative modelling remains underexplored. In this work, we propose a latent flow-matching framework in which equivariance is explicitly encouraged through a simple regularisation of a pre-trained autoencoder. Specifically, we introduce an equivariance loss that enforces consistency between transformed signals and their reconstructions, and use it to fine-tune latent spaces with respect to basic time-series transformations such as translation and amplitude scaling. We show that these equivariance-regularised latent spaces improve generation quality while preserving the computational advantages of latent flow models. Experiments on multiple real-world datasets demonstrate that our approach consistently outperforms existing diffusion-based baselines in standard time-series generation metrics, while achieving orders-of-magnitude faster sampling. These results highlight the practical benefits of incorporating geometric inductive biases into latent generative models for time series.</li>
<li><strong>摘要：</strong>事实证明，基于流的模型对于时间序列生成来说是成功的，特别是在能够实现高效采样的低维潜在空间中定义时。然而，如何为时间序列生成建模设计具有所需等方差属性的潜在表示仍有待探索。在这项工作中，我们提出了一个潜在的流匹配框架，其中通过预训练自动编码器的简单正则化明确鼓励等方差。具体来说，我们引入了等方差损失，它可以强制变换信号及其重建之间的一致性，并使用它来微调基本时间序列变换（例如平移和幅度缩放）的潜在空间。我们表明，这些等方差正则化的潜在空间提高了生成质量，同时保留了潜在流模型的计算优势。对多个现实世界数据集的实验表明，我们的方法在标准时间序列生成指标中始终优于现有的基于扩散的基线，同时实现了数量级的更快采样。这些结果凸显了将几何归纳偏差纳入时间序列的潜在生成模型的实际好处。</li>
</ul>

<h3>Title: OptiMAG: Structure-Semantic Alignment via Unbalanced Optimal Transport</h3>
<ul>
<li><strong>Authors: </strong>Yilong Zuo, Xunkai Li, Zhihan Zhang, Qiangqiang Dai, Ronghua Li, Guoren Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22856">https://arxiv.org/abs/2601.22856</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22856">https://arxiv.org/pdf/2601.22856</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22856]] OptiMAG: Structure-Semantic Alignment via Unbalanced Optimal Transport(https://arxiv.org/abs/2601.22856)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Multimodal Attributed Graphs (MAGs) have been widely adopted for modeling complex systems by integrating multi-modal information, such as text and images, on nodes. However, we identify a discrepancy between the implicit semantic structure induced by different modality embeddings and the explicit graph structure. For instance, neighbors in the explicit graph structure may be close in one modality but distant in another. Since existing methods typically perform message passing over the fixed explicit graph structure, they inadvertently aggregate dissimilar features, introducing modality-specific noise and impeding effective node representation learning. To address this, we propose OptiMAG, an Unbalanced Optimal Transport-based regularization framework. OptiMAG employs the Fused Gromov-Wasserstein distance to explicitly guide cross-modal structural consistency within local neighborhoods, effectively mitigating structural-semantic conflicts. Moreover, a KL divergence penalty enables adaptive handling of cross-modal inconsistencies. This framework can be seamlessly integrated into existing multimodal graph models, acting as an effective drop-in regularizer. Experiments demonstrate that OptiMAG consistently outperforms baselines across multiple tasks, ranging from graph-centric tasks (e.g., node classification, link prediction) to multimodal-centric generation tasks (e.g., graph2text, graph2image). The source code will be available upon acceptance.</li>
<li><strong>摘要：</strong>多模态属性图（MAG）已被广泛用于通过在节点上集成多模态信息（例如文本和图像）来建模复杂系统。然而，我们发现不同模态嵌入引起的隐式语义结构和显式图结构之间存在差异。例如，显式图结构中的邻居可能在一种模态中接近，但在另一种模态中遥远。由于现有方法通常在固定的显式图结构上执行消息传递，因此它们无意中聚合了不同的特征，引入了特定于模态的噪声并阻碍了有效的节点表示学习。为了解决这个问题，我们提出了 OptiMAG，一种基于不平衡最优传输的正则化框架。 OptiMAG 采用融合 Gromov-Wasserstein 距离来明确指导局部邻域内的跨模态结构一致性，有效缓解结构语义冲突。此外，KL 散度惩罚可以自适应处理跨模式不一致问题。该框架可以无缝集成到现有的多模态图模型中，充当有效的插入式正则化器。实验表明，OptiMAG 在多个任务中始终优于基线，从以图为中心的任务（例如，节点分类、链接预测）到以多模态为中心的生成任务（例如，graph2text、graph2image）。源代码将在接受后提供。</li>
</ul>

<h3>Title: Synthetic Time Series Generation via Complex Networks</h3>
<ul>
<li><strong>Authors: </strong>Jaime Vale, Vanessa Freitas Silva, Maria Eduarda Silva, Fernando Silva</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22879">https://arxiv.org/abs/2601.22879</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22879">https://arxiv.org/pdf/2601.22879</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22879]] Synthetic Time Series Generation via Complex Networks(https://arxiv.org/abs/2601.22879)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Time series data are essential for a wide range of applications, particularly in developing robust machine learning models. However, access to high-quality datasets is often limited due to privacy concerns, acquisition costs, and labeling challenges. Synthetic time series generation has emerged as a promising solution to address these constraints. In this work, we present a framework for generating synthetic time series by leveraging complex networks mappings. Specifically, we investigate whether time series transformed into Quantile Graphs (QG) -- and then reconstructed via inverse mapping -- can produce synthetic data that preserve the statistical and structural properties of the original. We evaluate the fidelity and utility of the generated data using both simulated and real-world datasets, and compare our approach against state-of-the-art Generative Adversarial Network (GAN) methods. Results indicate that our quantile graph-based methodology offers a competitive and interpretable alternative for synthetic time series generation.</li>
<li><strong>摘要：</strong>时间序列数据对于广泛的应用至关重要，特别是在开发强大的机器学习模型时。然而，由于隐私问题、获取成本和标签挑战，对高质量数据集的访问通常受到限制。合成时间序列生成已成为解决这些限制的有前途的解决方案。在这项工作中，我们提出了一个通过利用复杂网络映射生成合成时间序列的框架。具体来说，我们研究时间序列转换为分位数图（QG），然后通过逆映射重建，是否可以生成保留原始数据的统计和结构特性的合成数据。我们使用模拟和真实数据集评估生成数据的保真度和实用性，并将我们的方法与最先进的生成对抗网络（GAN）方法进行比较。结果表明，我们基于分位数图的方法为合成时间序列生成提供了一种有竞争力且可解释的替代方案。</li>
</ul>

<h3>Title: MoVE: Mixture of Value Embeddings -- A New Axis for Scaling Parametric Memory in Autoregressive Models</h3>
<ul>
<li><strong>Authors: </strong>Yangyan Li</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22887">https://arxiv.org/abs/2601.22887</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22887">https://arxiv.org/pdf/2601.22887</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22887]] MoVE: Mixture of Value Embeddings -- A New Axis for Scaling Parametric Memory in Autoregressive Models(https://arxiv.org/abs/2601.22887)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Autoregressive sequence modeling stands as the cornerstone of modern Generative AI, powering results across diverse modalities ranging from text generation to image generation. However, a fundamental limitation of this paradigm is the rigid structural coupling of model capacity to computational cost: expanding a model's parametric memory -- its repository of factual knowledge or visual patterns -- traditionally requires deepening or widening the network, which incurs a proportional rise in active FLOPs. In this work, we introduce $\textbf{MoVE (Mixture of Value Embeddings)}$, a mechanism that breaks this coupling and establishes a new axis for scaling capacity. MoVE decouples memory from compute by introducing a global bank of learnable value embeddings shared across all attention layers. For every step in the sequence, the model employs a differentiable soft gating mechanism to dynamically mix retrieved concepts from this bank into the standard value projection. This architecture allows parametric memory to be scaled independently of network depth by simply increasing the number of embedding slots. We validate MoVE through strictly controlled experiments on two representative applications of autoregressive modeling: Text Generation and Image Generation. In both domains, MoVE yields consistent performance improvements over standard and layer-wise memory baselines, enabling the construction of "memory-dense" models that achieve lower perplexity and higher fidelity than their dense counterparts at comparable compute budgets.</li>
<li><strong>摘要：</strong>自回归序列建模是现代生成人工智能的基石，为从文本生成到图像生成等多种模式的结果提供动力。然而，这种范式的一个根本限制是模型容量与计算成本之间的严格结构耦合：扩展模型的参数存储器（事实知识或视觉模式的存储库）传统上需要加深或拓宽网络，这会导致活跃 FLOP 成比例增加。在这项工作中，我们引入了 $\textbf{MoVE (Mixture of Value Embeddings)}$，这是一种打破这种耦合并建立扩展容量的新轴的机制。 MoVE 通过引入跨所有注意力层共享的全局可学习价值嵌入库，将内存与计算解耦。对于序列中的每一步，该模型都采用可微分的软门控机制来动态地将从该库检索到的概念混合到标准值投影中。该架构允许通过简单地增加嵌入槽的数量来独立于网络深度来扩展参数存储器。我们通过对自回归建模的两个代表性应用（文本生成和图像生成）进行严格控制的实验来验证 MoVE。在这两个领域中，MoVE 都比标准和分层内存基线实现了一致的性能改进，从而能够构建“内存密集”模型，在可比较的计算预算下，与密集模型相比，该模型可以实现更低的复杂性和更高的保真度。</li>
</ul>

<h3>Title: DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation</h3>
<ul>
<li><strong>Authors: </strong>Hun Chang, Byunghee Cha, Jong Chul Ye</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22904">https://arxiv.org/abs/2601.22904</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22904">https://arxiv.org/pdf/2601.22904</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22904]] DINO-SAE: DINO Spherical Autoencoder for High-Fidelity Image Reconstruction and Generation(https://arxiv.org/abs/2601.22904)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Recent studies have explored using pretrained Vision Foundation Models (VFMs) such as DINO for generative autoencoders, showing strong generative performance. Unfortunately, existing approaches often suffer from limited reconstruction fidelity due to the loss of high-frequency details. In this work, we present the DINO Spherical Autoencoder (DINO-SAE), a framework that bridges semantic representation and pixel-level reconstruction. Our key insight is that semantic information in contrastive representations is primarily encoded in the direction of feature vectors, while forcing strict magnitude matching can hinder the encoder from preserving fine-grained details. To address this, we introduce Hierarchical Convolutional Patch Embedding module that enhances local structure and texture preservation, and Cosine Similarity Alignment objective that enforces semantic consistency while allowing flexible feature magnitudes for detail retention. Furthermore, leveraging the observation that SSL-based foundation model representations intrinsically lie on a hypersphere, we employ Riemannian Flow Matching to train a Diffusion Transformer (DiT) directly on this spherical latent manifold. Experiments on ImageNet-1K demonstrate that our approach achieves state-of-the-art reconstruction quality, reaching 0.37 rFID and 26.2 dB PSNR, while maintaining strong semantic alignment to the pretrained VFM. Notably, our Riemannian Flow Matching-based DiT exhibits efficient convergence, achieving a gFID of 3.47 at 80 epochs.</li>
<li><strong>摘要：</strong>最近的研究探索了使用预训练的视觉基础模型（VFM）（例如 DINO）进行生成自动编码器，显示出强大的生成性能。不幸的是，由于高频细节的丢失，现有方法常常受到重建保真度有限的影响。在这项工作中，我们提出了 DINO 球形自动编码器 (DINO-SAE)，这是一个连接语义表示和像素级重建的框架。我们的主要见解是，对比表示中的语义信息主要按照特征向量的方向进行编码，而强制严格的幅度匹配可能会阻碍编码器保留细粒度的细节。为了解决这个问题，我们引入了分层卷积补丁嵌入模块，该模块增强了局部结构和纹理保留，以及余弦相似度对齐目标，该目标增强了语义一致性，同时允许灵活的特征量值以保留细节。此外，利用基于 SSL 的基础模型表示本质上位于超球面上的观察结果，我们采用黎曼流匹配直接在该球形潜在流形上训练扩散变换器 (DiT)。 ImageNet-1K 上的实验表明，我们的方法实现了最先进的重建质量，达到 0.37 rFID 和 26.2 dB PSNR，同时保持与预训练 VFM 的强大语义对齐。值得注意的是，我们基于黎曼流匹配的 DiT 表现出高效的收敛性，在 80 个时期实现了 3.47 的 gFID。</li>
</ul>

<h3>Title: Q-Hawkeye: Reliable Visual Policy Optimization for Image Quality Assessment</h3>
<ul>
<li><strong>Authors: </strong>Wulin Xie, Rui Dai, Ruidong Ding, Kaikui Liu, Xiangxiang Chu, Xinwen Hou, Jie Wen</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22920">https://arxiv.org/abs/2601.22920</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22920">https://arxiv.org/pdf/2601.22920</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22920]] Q-Hawkeye: Reliable Visual Policy Optimization for Image Quality Assessment(https://arxiv.org/abs/2601.22920)</code><input type="text"></li>
<li><strong>Keywords: </strong>quality assessment</a></li>
<li><strong>Abstract: </strong>Image Quality Assessment (IQA) predicts perceptual quality scores consistent with human judgments. Recent RL-based IQA methods built on MLLMs focus on generating visual quality descriptions and scores, ignoring two key reliability limitations: (i) although the model's prediction stability varies significantly across training samples, existing GRPO-based methods apply uniform advantage weighting, thereby amplifying noisy signals from unstable samples in gradient updates; (ii) most works emphasize text-grounded reasoning over images while overlooking the model's visual perception ability of image content. In this paper, we propose Q-Hawkeye, an RL-based reliable visual policy optimization framework that redesigns the learning signal through unified Uncertainty-Aware Dynamic Optimization and Perception-Aware Optimization. Q-Hawkeye estimates predictive uncertainty using the variance of predicted scores across multiple rollouts and leverages this uncertainty to reweight each sample's update strength, stabilizing policy optimization. To strengthen perceptual reliability, we construct paired inputs of degraded images and their original images and introduce an Implicit Perception Loss that constrains the model to ground its quality judgments in genuine visual evidence. Extensive experiments demonstrate that Q-Hawkeye outperforms state-of-the-art methods and generalizes better across multiple datasets. The code and models will be made available.</li>
<li><strong>摘要：</strong>图像质量评估 (IQA) 预测与人类判断一致的感知质量分数。最近建立在 MLLM 上的基于 RL 的 IQA 方法专注于生成视觉质量描述和分数，忽略了两个关键的可靠性限制：（i）尽管模型的预测稳定性在训练样本之间存在显着差异，但现有的基于 GRPO 的方法应用统一的优势权重，从而在梯度更新中放大来自不稳定样本的噪声信号； （ii）大多数作品强调基于文本的图像推理，而忽视了模型对图像内容的视觉感知能力。在本文中，我们提出了 Q-Hawkeye，一种基于强化学习的可靠视觉策略优化框架，通过统一的不确定性感知动态优化和感知感知优化来重新设计学习信号。 Q-Hawkeye 使用多次部署中预测分数的方差来估计预测不确定性，并利用这种不确定性来重新加权每个样本的更新强度，从而稳定策略优化。为了增强感知可靠性，我们构建了退化图像及其原始图像的配对输入，并引入了隐式感知损失，该损失限制模型将其质量判断建立在真实的视觉证据上。大量实验表明，Q-Hawkeye 的性能优于最先进的方法，并且在多个数据集上具有更好的泛化能力。代码和模型将公开。</li>
</ul>

<h3>Title: Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion</h3>
<ul>
<li><strong>Authors: </strong>Dennis Sprute, Hanna Senke, Holger Flatt</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.22961">https://arxiv.org/abs/2601.22961</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.22961">https://arxiv.org/pdf/2601.22961</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.22961]] Improving Supervised Machine Learning Performance in Optical Quality Control via Generative AI for Dataset Expansion(https://arxiv.org/abs/2601.22961)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Supervised machine learning algorithms play a crucial role in optical quality control within industrial production. These approaches require representative datasets for effective model training. However, while non-defective components are frequent, defective parts are rare in production, resulting in highly imbalanced datasets that adversely impact model performance. Existing strategies to address this challenge, such as specialized loss functions or traditional data augmentation techniques, have limitations, including the need for careful hyperparameter tuning or the alteration of only simple image features. Therefore, this work explores the potential of generative artificial intelligence (GenAI) as an alternative method for expanding limited datasets and enhancing supervised machine learning performance. Specifically, we investigate Stable Diffusion and CycleGAN as image generation models, focusing on the segmentation of combine harvester components in thermal images for subsequent defect detection. Our results demonstrate that dataset expansion using Stable Diffusion yields the most significant improvement, enhancing segmentation performance by 4.6 %, resulting in a Mean Intersection over Union (Mean IoU) of 84.6 %.</li>
<li><strong>摘要：</strong>有监督的机器学习算法在工业生产中的光学质量控制中发挥着至关重要的作用。这些方法需要代表性数据集来进行有效的模型训练。然而，虽然无缺陷的部件很常见，但有缺陷的部件在生产中很少见，导致数据集高度不平衡，对模型性能产生不利影响。解决这一挑战的现有策略（例如专门的损失函数或传统的数据增强技术）具有局限性，包括需要仔细的超参数调整或仅更改简单的图像特征。因此，这项工作探讨了生成人工智能（GenAI）作为扩展有限数据集和增强监督机器学习性能的替代方法的潜力。具体来说，我们研究了 Stable Diffusion 和 CycleGAN 作为图像生成模型，重点关注热图像中联合收割机组件的分割，以进行后续的缺陷检测。我们的结果表明，使用稳定扩散的数据集扩展产生了最显着的改进，将分割性能提高了 4.6%，平均交集比并集（平均 IoU）达到 84.6%。</li>
</ul>

<h3>Title: Leveraging Convolutional Sparse Autoencoders for Robust Movement Classification from Low-Density sEMG</h3>
<ul>
<li><strong>Authors: </strong>Blagoj Hristov, Zoran Hadzi-Velkov, Katerina Hadzi-Velkova Saneva, Gorjan Nadzinski, Vesna Ojleska Latkoska</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23011">https://arxiv.org/abs/2601.23011</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23011">https://arxiv.org/pdf/2601.23011</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23011]] Leveraging Convolutional Sparse Autoencoders for Robust Movement Classification from Low-Density sEMG(https://arxiv.org/abs/2601.23011)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Reliable control of myoelectric prostheses is often hindered by high inter-subject variability and the clinical impracticality of high-density sensor arrays. This study proposes a deep learning framework for accurate gesture recognition using only two surface electromyography (sEMG) channels. The method employs a Convolutional Sparse Autoencoder (CSAE) to extract temporal feature representations directly from raw signals, eliminating the need for heuristic feature engineering. On a 6-class gesture set, our model achieved a multi-subject F1-score of 94.3% $\pm$ 0.3%. To address subject-specific differences, we present a few-shot transfer learning protocol that improved performance on unseen subjects from a baseline of 35.1% $\pm$ 3.1% to 92.3% $\pm$ 0.9% with minimal calibration data. Furthermore, the system supports functional extensibility through an incremental learning strategy, allowing for expansion to a 10-class set with a 90.0% $\pm$ 0.2% F1-score without full model retraining. By combining high precision with minimal computational and sensor overhead, this framework provides a scalable and efficient approach for the next generation of affordable and adaptive prosthetic systems.</li>
<li><strong>摘要：</strong>肌电假体的可靠控制常常受到受试者间高变异性和高密度传感器阵列的临床不实用性的阻碍。本研究提出了一种仅使用两个表面肌电图 (sEMG) 通道进行准确手势识别的深度学习框架。该方法采用卷积稀疏自动编码器（CSAE）直接从原始信号中提取时间特征表示，从而无需启发式特征工程。在 6 类手势集上，我们的模型获得了 94.3% $\pm$ 0.3% 的多主体 F1 分数。为了解决特定于主题的差异，我们提出了一种几次迁移学习协议，该协议可以使用最少的校准数据将未见过的主题的性能从 35.1% $\pm$ 3.1% 的基线提高到 92.3% $\pm$ 0.9%。此外，该系统通过增量学习策略支持功能可扩展性，允许扩展至 10 类集，且无需进行完整的模型再训练，F1 分数为 90.0% $\pm$ 0.2%。通过将高精度与最小的计算和传感器开销相结合，该框架为下一代经济实惠的自适应假肢系统提供了可扩展且高效的方法。</li>
</ul>

<h3>Title: Divide-and-Conquer CoT: RL for Reducing Latency via Parallel Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Arvind Mahankali, Kaiyue Wen, Tengyu Ma</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23027">https://arxiv.org/abs/2601.23027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23027">https://arxiv.org/pdf/2601.23027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23027]] Divide-and-Conquer CoT: RL for Reducing Latency via Parallel Reasoning(https://arxiv.org/abs/2601.23027)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Long chain-of-thought reasoning (Long CoT) is now fundamental to state-of-the-art LLMs, especially in mathematical reasoning. However, LLM generation is highly sequential, and long CoTs lead to a high latency. We propose to train Divide-and-Conquer CoT (DC-CoT) to reduce the latency. With DC-CoT, the model can act as a director that identifies distinct subtasks that can be performed in parallel in its reasoning process, and then spawns workers to execute the subtasks. Our goal is to achieve high accuracy, with a low longest path length, which is a theoretical measure of the latency needed for the response. We start with a long CoT base model (DeepScaleR-1.5B-Preview), and first use SFT with a small curated demonstration set to initialize its ability to spawn workers in a certain format. Because SFT degrades the accuracy significantly, we design a multi-stage RL algorithm, with various data filtering strategies, to recover the accuracy while decreasing the longest path length. Across several benchmarks including AIME 2024 and HMMT 2025, DC-CoT achieves similar accuracy as DeepScaleR-1.5B-Preview while decreasing longest path length by 35-40%. Our code, SFT dataset and models are publicly available at this https URL.</li>
<li><strong>摘要：</strong>长链思维推理（Long CoT）现在是最先进的法学硕士的基础，尤其是在数学推理方面。然而，LLM 的生成是高度连续的，长 CoT 会导致高延迟。我们建议训练分治 CoT（DC-CoT）来减少延迟。使用 DC-CoT，模型可以充当控制器，识别可以在其推理过程中并行执行的不同子任务，然后生成工作器来执行子任务。我们的目标是实现高精度和较短的最长路径长度，这是响应所需延迟的理论度量。我们从一个长的 CoT 基础模型 (DeepScaleR-1.5B-Preview) 开始，首先使用 SFT 和一个小型的策划演示集来初始化其以某种格式生成工作人员的能力。由于 SFT 会显着降低精度，因此我们设计了一种多级 RL 算法，采用各种数据过滤策略，以在减少最长路径长度的同时恢复精度。在包括 AIME 2024 和 HMMT 2025 在内的多个基准测试中，DC-CoT 实现了与 DeepScaleR-1.5B-Preview 相似的精度，同时将最长路径长度减少了 35-40%。我们的代码、SFT 数据集和模型可通过此 https URL 公开获取。</li>
</ul>

<h3>Title: One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs</h3>
<ul>
<li><strong>Authors: </strong>Youxu Shi, Suorong Yang, Dong Liu</a></li>
<li><strong>Subjects: </strong>cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23041">https://arxiv.org/abs/2601.23041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23041">https://arxiv.org/pdf/2601.23041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23041]] One-shot Optimized Steering Vector for Hallucination Mitigation for VLMs(https://arxiv.org/abs/2601.23041)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Vision Language Models (VLMs) achieve strong performance on multimodal tasks but still suffer from hallucination and safety-related failures that persist even at scale. Steering offers a lightweight technique to improve model performance. However, steering, whether input-dependent or input-independent, achieves a meaningful trade-off between efficiency and effectiveness. In this work, we observe that steering vectors can generalize across inputs when tasks share aligned semantic intent. Based on this insight, we propose \textbf{OSGA} (\textbf{O}ne-shot \textbf{S}teering with \textbf{G}enerative \textbf{A}nchor), an input-independent framework that improves model performance with a single optimization instance. OSGA first selects an informative sample via a variance-based data selection strategy and learns a single steering vector with a contrastive objective with generative anchor regularization. The resulting vector can be universally applied at a certain layer during inference time without modifying model parameters. Experiments across multiple benchmarks show that a single OSGA-optimized steering vector consistently improves hallucination mitigation and safety enhancement with negligible overhead, highlighting one-shot steering as a practical and scalable solution for reliable VLMs.</li>
<li><strong>摘要：</strong>视觉语言模型 (VLM) 在多模式任务上取得了出色的性能，但仍然遭受幻觉和安全相关故障的困扰，即使在规模上也是如此。转向提供了一种轻量级技术来提高模型性能。然而，无论是依赖于输入还是独立于输入，引导都可以在效率和效果之间实现有意义的权衡。在这项工作中，我们观察到，当任务共享一致的语义意图时，引导向量可以跨输入进行泛化。基于这一见解，我们提出了 \textbf{OSGA} （\textbf{O}ne-shot \textbf{S}teering with \textbf{G}enerative \textbf{A}nchor），这是一种独立于输入的框架，可以通过单个优化实例提高模型性能。 OSGA 首先通过基于方差的数据选择策略选择信息样本，并通过生成锚正则化学习具有对比目标的单个引导向量。得到的向量可以在推理时间内普遍应用于某一层，而无需修改模型参数。跨多个基准的实验表明，单个 OSGA 优化的转向矢量能够持续改善幻觉缓解和安全增强，而开销可以忽略不计，凸显一次性转向作为可靠 VLM 的实用且可扩展的解决方案。</li>
</ul>

<h3>Title: Adaptive Edge Learning for Density-Aware Graph Generation</h3>
<ul>
<li><strong>Authors: </strong>Seyedeh Ava Razi Razavi, James Sargant, Sheridan Houghten, Renata Dividino</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23052">https://arxiv.org/abs/2601.23052</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23052">https://arxiv.org/pdf/2601.23052</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23052]] Adaptive Edge Learning for Density-Aware Graph Generation(https://arxiv.org/abs/2601.23052)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>Generating realistic graph-structured data is challenging due to discrete structures, variable sizes, and class-specific connectivity patterns that resist conventional generative modelling. While recent graph generation methods employ generative adversarial network (GAN) frameworks to handle permutation invariance and irregular topologies, they typically rely on random edge sampling with fixed probabilities, limiting their capacity to capture complex structural dependencies between nodes. We propose a density-aware conditional graph generation framework using Wasserstein GANs (WGAN) that replaces random sampling with a learnable distance-based edge predictor. Our approach embeds nodes into a latent space where proximity correlates with edge likelihood, enabling the generator to learn meaningful connectivity patterns. A differentiable edge predictor determines pairwise relationships directly from node embeddings, while a density-aware selection mechanism adaptively controls edge density to match class-specific sparsity distributions observed in real graphs. We train the model using a WGAN with gradient penalty, employing a GCN-based critic to ensure generated graphs exhibit realistic topology and align with target class distributions. Experiments on benchmark datasets demonstrate that our method produces graphs with superior structural coherence and class-consistent connectivity compared to existing baselines. The learned edge predictor captures complex relational patterns beyond simple heuristics, generating graphs whose density and topology closely match real structural distributions. Our results show improved training stability and controllable synthesis, making the framework effective for realistic graph generation and data augmentation. Source code is publicly available at this https URL.</li>
<li><strong>摘要：</strong>由于离散结构、可变大小和特定于类的连接模式阻碍了传统的生成建模，生成真实的图结构数据具有挑战性。虽然最近的图生成方法采用生成对抗网络（GAN）框架来处理排列不变性和不规则拓扑，但它们通常依赖于具有固定概率的随机边缘采样，限制了它们捕获节点之间复杂结构依赖性的能力。我们提出了一种使用 Wasserstein GAN (WGAN) 的密度感知条件图生成框架，用可学习的基于距离的边缘预测器代替随机采样。我们的方法将节点嵌入到潜在空间中，其中邻近度与边缘可能性相关，使生成器能够学习有意义的连接模式。可微边缘预测器直接从节点嵌入确定成对关系，而密度感知选择机制自适应控制边缘密度以匹配真实图中观察到的特定于类的稀疏分布。我们使用带有梯度惩罚的 WGAN 来训练模型，采用基于 GCN 的批评器来确保生成的图表现出真实的拓扑并与目标类分布保持一致。对基准数据集的实验表明，与现有基线相比，我们的方法生成的图具有出色的结构一致性和类一致性连接性。学习到的边缘预测器捕获超出简单启发式的复杂关系模式，生成密度和拓扑结构与真实结构分布紧密匹配的图。我们的结果表明，训练稳定性和可控合成得到了改善，使该框架能够有效地实现真实的图形生成和数据增强。源代码可通过此 https URL 公开获取。</li>
</ul>

<h3>Title: From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Wenzhe Niu, Wei He, Zongxia Xie, Jinpeng Ou, Huichuan Fan, Yuchen Ge, Yanru Sun, Ziyin Wang, Yizhao Sun, Chengshun Shi, Jiuchong Gao, Jinghua Hao, Renqing He</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23058">https://arxiv.org/abs/2601.23058</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23058">https://arxiv.org/pdf/2601.23058</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23058]] From Absolute to Relative: Rethinking Reward Shaping in Group-Based Reinforcement Learning(https://arxiv.org/abs/2601.23058)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Reinforcement learning has become a cornerstone for enhancing the reasoning capabilities of Large Language Models, where group-based approaches such as GRPO have emerged as efficient paradigms that optimize policies by leveraging intra-group performance differences. However, these methods typically rely on absolute numerical rewards, introducing intrinsic limitations. In verifiable tasks, identical group evaluations often result in sparse supervision, while in open-ended scenarios, the score range instability of reward models undermines advantage estimation based on group means. To address these limitations, we propose Reinforcement Learning with Relative Rewards (RLRR), a framework that shifts reward shaping from absolute scoring to relative ranking. Complementing this framework, we introduce the Ranking Reward Model, a listwise preference model tailored for group-based optimization to directly generate relative rankings. By transforming raw evaluations into robust relative signals, RLRR effectively mitigates signal sparsity and reward instability. Experimental results demonstrate that RLRR yields consistent performance improvements over standard group-based baselines across reasoning benchmarks and open-ended generation tasks.</li>
<li><strong>摘要：</strong>强化学习已成为增强大型语言模型推理能力的基石，其中 GRPO 等基于群体的方法已成为通过利用群体内性能差异来优化策略的有效范式。然而，这些方法通常依赖于绝对数字奖励，从而引入了内在的局限性。在可验证的任务中，相同的群体评估通常会导致稀疏监督，而在开放式场景中，奖励模型的分数范围不稳定会破坏基于群体均值的优势估计。为了解决这些限制，我们提出了相对奖励强化学习（RLRR），这是一个将奖励塑造从绝对评分转变为相对排名的框架。为了补充这个框架，我们引入了排名奖励模型，这是一种专为基于组的优化而定制的列表偏好模型，可直接生成相对排名。通过将原始评估转化为稳健的相对信号，RLRR 有效地减轻了信号稀疏性和奖励不稳定性。实验结果表明，与标准的基于组的基线相比，RLRR 在推理基准测试和开放式生成任务中产生了一致的性能改进。</li>
</ul>

<h3>Title: HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation</h3>
<ul>
<li><strong>Authors: </strong>Hari Krishna Gadi, Daniel Matos, Hongyi Luo, Lu Liu, Yongliang Wang, Yanfeng Zhang, Liqiu Meng</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23064">https://arxiv.org/abs/2601.23064</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23064">https://arxiv.org/pdf/2601.23064</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23064]] HierLoc: Hyperbolic Entity Embeddings for Hierarchical Visual Geolocation(https://arxiv.org/abs/2601.23064)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Visual geolocalization, the task of predicting where an image was taken, remains challenging due to global scale, visual ambiguity, and the inherently hierarchical structure of geography. Existing paradigms rely on either large-scale retrieval, which requires storing a large number of image embeddings, grid-based classifiers that ignore geographic continuity, or generative models that diffuse over space but struggle with fine detail. We introduce an entity-centric formulation of geolocation that replaces image-to-image retrieval with a compact hierarchy of geographic entities embedded in Hyperbolic space. Images are aligned directly to country, region, subregion, and city entities through Geo-Weighted Hyperbolic contrastive learning by directly incorporating haversine distance into the contrastive objective. This hierarchical design enables interpretable predictions and efficient inference with 240k entity embeddings instead of over 5 million image embeddings on the OSV5M benchmark, on which our method establishes a new state-of-the-art performance. Compared to the current methods in the literature, it reduces mean geodesic error by 19.5\%, while improving the fine-grained subregion accuracy by 43%. These results demonstrate that geometry-aware hierarchical embeddings provide a scalable and conceptually new alternative for global image geolocation.</li>
<li><strong>摘要：</strong>由于全球规模、视觉模糊性和地理固有的层次结构，视觉地理定位（预测图像拍摄地点的任务）仍然具有挑战性。现有的范例依赖于大规模检索（需要存储大量图像嵌入）、基于网格的分类器（忽略地理连续性）或生成模型（在空间上扩散但难以处理精细细节）。我们引入了一种以实体为中心的地理定位公式，它用嵌入双曲空间中的地理实体的紧凑层次结构取代了图像到图像检索。通过地理加权双曲对比学习，将半正矢距离直接纳入对比目标，将图像直接与国家、地区、次区域和城市实体对齐。这种分层设计通过 24 万个实体嵌入（而不是 OSV5M 基准上超过 500 万个图像嵌入）实现可解释的预测和高效推理，我们的方法在此基础上建立了新的最先进的性能。与现有文献方法相比，平均测地误差降低了19.5%，同时细粒度分区精度提高了43%。这些结果表明，几何感知的分层嵌入为全局图像地理定位提供了一种可扩展且概念上新的替代方案。</li>
</ul>

<h3>Title: SplineFlow: Flow Matching for Dynamical Systems with B-Spline Interpolants</h3>
<ul>
<li><strong>Authors: </strong>Santanu Subhash Rathod, Pietro Liò, Xiao Zhang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23072">https://arxiv.org/abs/2601.23072</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23072">https://arxiv.org/pdf/2601.23072</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23072]] SplineFlow: Flow Matching for Dynamical Systems with B-Spline Interpolants(https://arxiv.org/abs/2601.23072)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Flow matching is a scalable generative framework for characterizing continuous normalizing flows with wide-range applications. However, current state-of-the-art methods are not well-suited for modeling dynamical systems, as they construct conditional paths using linear interpolants that may not capture the underlying state evolution, especially when learning higher-order dynamics from irregular sampled observations. Constructing unified paths that satisfy multi-marginal constraints across observations is challenging, since naïve higher-order polynomials tend to be unstable and oscillatory. We introduce SplineFlow, a theoretically grounded flow matching algorithm that jointly models conditional paths across observations via B-spline interpolation. Specifically, SplineFlow exploits the smoothness and stability of B-spline bases to learn the complex underlying dynamics in a structured manner while ensuring the multi-marginal requirements are met. Comprehensive experiments across various deterministic and stochastic dynamical systems of varying complexity, as well as on cellular trajectory inference tasks, demonstrate the strong improvement of SplineFlow over existing baselines. Our code is available at: this https URL.</li>
<li><strong>摘要：</strong>流匹配是一种可扩展的生成框架，用于表征具有广泛应用的连续标准化流。然而，当前最先进的方法不太适合动态系统建模，因为它们使用线性插值构建条件路径，可能无法捕获潜在的状态演化，特别是在从不规则采样观测中学习高阶动态时。构建满足跨观测值的多边际约束的统一路径具有挑战性，因为朴素的高阶多项式往往不稳定且振荡。我们引入了 SplineFlow，这是一种理论上有基础的流匹配算法，它通过 B 样条插值联合模拟跨观测值的条件路径。具体来说，SplineFlow 利用 B 样条基的平滑性和稳定性以结构化方式学习复杂的基础动力学，同时确保满足多边际要求。跨不同复杂度的各种确定性和随机动力系统以及细胞轨迹推理任务的综合实验证明了 SplineFlow 相对于现有基线的显着改进。我们的代码位于：此 https URL。</li>
</ul>

<h3>Title: To See Far, Look Close: Evolutionary Forecasting for Long-term Time Series</h3>
<ul>
<li><strong>Authors: </strong>Jiaming Ma, Siyuan Mu, Ruilin Tang, Haofeng Ma, Qihe Huang, Zhengyang Zhou, Pengkun Wang, Binwu Wang, Yang Wang</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23114">https://arxiv.org/abs/2601.23114</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23114">https://arxiv.org/pdf/2601.23114</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23114]] To See Far, Look Close: Evolutionary Forecasting for Long-term Time Series(https://arxiv.org/abs/2601.23114)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>The prevailing Direct Forecasting (DF) paradigm dominates Long-term Time Series Forecasting (LTSF) by forcing models to predict the entire future horizon in a single forward pass. While efficient, this rigid coupling of output and evaluation horizons necessitates computationally prohibitive re-training for every target horizon. In this work, we uncover a counter-intuitive optimization anomaly: models trained on short horizons-when coupled with our proposed Evolutionary Forecasting (EF) paradigm-significantly outperform those trained directly on long horizons. We attribute this success to the mitigation of a fundamental optimization pathology inherent in DF, where conflicting gradients from distant futures cripple the learning of local dynamics. We establish EF as a unified generative framework, proving that DF is merely a degenerate special case of EF. Extensive experiments demonstrate that a singular EF model surpasses task-specific DF ensembles across standard benchmarks and exhibits robust asymptotic stability in extreme extrapolation. This work propels a paradigm shift in LTSF: moving from passive Static Mapping to autonomous Evolutionary Reasoning.</li>
<li><strong>摘要：</strong>流行的直接预测 (DF) 范式通过迫使模型在一次前向传递中预测整个未来范围，从而主导了长期时间序列预测 (LTSF)。虽然有效，但输出和评估范围的这种严格耦合需要对每个目标范围进行计算上令人望而却步的重新训练。在这项工作中，我们发现了一个反直觉的优化异常：在短期训练的模型与我们提出的进化预测（EF）范式相结合时，显着优于直接在长期训练的模型。我们将这一成功归因于 DF 固有的基本优化病理学的缓解，其中来自遥远未来的冲突梯度削弱了局部动力学的学习。我们将 EF 建立为统一的生成框架，证明 DF 只是 EF 的退化特例。大量实验表明，单一 EF 模型在标准基准测试中超越了特定于任务的 DF 集成，并在极端外推中表现出强大的渐近稳定性。这项工作推动了 LTSF 的范式转变：从被动静态映射转向自主进化推理。</li>
</ul>

<h3>Title: Manifold-Aware Perturbations for Constrained Generative Modeling</h3>
<ul>
<li><strong>Authors: </strong>Katherine Keegan, Lars Ruthotto</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23151">https://arxiv.org/abs/2601.23151</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23151">https://arxiv.org/pdf/2601.23151</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23151]] Manifold-Aware Perturbations for Constrained Generative Modeling(https://arxiv.org/abs/2601.23151)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative models have enjoyed widespread success in a variety of applications. However, they encounter inherent mathematical limitations in modeling distributions where samples are constrained by equalities, as is frequently the setting in scientific domains. In this work, we develop a computationally cheap, mathematically justified, and highly flexible distributional modification for combating known pitfalls in equality-constrained generative models. We propose perturbing the data distribution in a constraint-aware way such that the new distribution has support matching the ambient space dimension while still implicitly incorporating underlying manifold geometry. Through theoretical analyses and empirical evidence on several representative tasks, we illustrate that our approach consistently enables data distribution recovery and stable sampling with both diffusion models and normalizing flows.</li>
<li><strong>摘要：</strong>生成模型在各种应用中取得了广泛的成功。然而，它们在建模分布时遇到了固有的数学限制，其中样本受到等式的约束，这在科学领域中经​​常出现。在这项工作中，我们开发了一种计算成本低、数学上合理且高度灵活的分布修改，以克服等式约束生成模型中的已知陷阱。我们建议以约束感知的方式扰动数据分布，以便新的分布支持匹配环境空间维度，同时仍然隐式地合并底层流形几何形状。通过对几个代表性任务的理论分析和经验证据，我们表明我们的方法始终能够通过扩散模型和标准化流实现数据分布恢复和稳定采样。</li>
</ul>

<h3>Title: Behemoth: Benchmarking Unlearning in LLMs Using Fully Synthetic Data</h3>
<ul>
<li><strong>Authors: </strong>Eugenia Iofinova, Dan Alistarh</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23153">https://arxiv.org/abs/2601.23153</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23153">https://arxiv.org/pdf/2601.23153</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23153]] Behemoth: Benchmarking Unlearning in LLMs Using Fully Synthetic Data(https://arxiv.org/abs/2601.23153)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>As artificial neural networks, and specifically large language models, have improved rapidly in capabilities and quality, they have increasingly been deployed in real-world applications, from customer service to Google search, despite the fact that they frequently make factually incorrect or undesirable statements. This trend has inspired practical and academic interest in model editing, that is, in adjusting the weights of the model to modify its likely outputs for queries relating to a specific fact or set of facts. This may be done either to amend a fact or set of facts, for instance, to fix a frequent error in the training data, or to suppress a fact or set of facts entirely, for instance, in case of dangerous knowledge. Multiple methods have been proposed to do such edits. However, at the same time, it has been shown that such model editing can be brittle and incomplete. Moreover the effectiveness of any model editing method necessarily depends on the data on which the model is trained, and, therefore, a good understanding of the interaction of the training data distribution and the way it is stored in the network is necessary and helpful to reliably perform model editing. However, working with large language models trained on real-world data does not allow us to understand this relationship or fully measure the effects of model editing. We therefore propose Behemoth, a fully synthetic data generation framework. To demonstrate the practical insights from the framework, we explore model editing in the context of simple tabular data, demonstrating surprising findings that, in some cases, echo real-world results, for instance, that in some cases restricting the update rank results in a more effective update. The code is available at this https URL.</li>
<li><strong>摘要：</strong>随着人工神经网络，特别是大型语言模型，在功能和质量方面迅速提高，它们越来越多地被部署在现实世界的应用中，从客户服务到谷歌搜索，尽管它们经常做出事实不正确或不良的陈述。这种趋势激发了人们对模型编辑的实际和学术兴趣，即调整模型的权重以修改与特定事实或事实集相关的查询的可能输出。这样做可以是为了修改一个事实或一组事实，例如，修复训练数据中的常见错误，或者完全抑制一个事实或一组事实，例如，在危险知识的情况下。已经提出了多种方法来进行此类编辑。然而，与此同时，事实表明，这种模型编辑可能很脆弱且不完整。此外，任何模型编辑方法的有效性都必然取决于模型训练所用的数据，因此，充分理解训练数据分布的交互及其在网络中的存储方式对于可靠地执行模型编辑是必要且有助于的。然而，使用在现实世界数据上训练的大型语言模型并不能让我们理解这种关系或充分衡量模型编辑的效果。因此，我们提出了 Behemoth，一个完全合成的数据生成框架。为了展示该框架的实用见解，我们在简单的表格数据背景下探索模型编辑，展示了令人惊讶的发现，在某些情况下，与现实世界的结果相呼应，例如，在某些情况下限制更新排名会导致更有效的更新。该代码可从此 https URL 获取。</li>
</ul>

<h3>Title: Probing the Trajectories of Reasoning Traces in Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Marthe Ballon, Brecht Verbeken, Vincent Ginis, Andres Algaba</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23163">https://arxiv.org/abs/2601.23163</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23163">https://arxiv.org/pdf/2601.23163</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23163]] Probing the Trajectories of Reasoning Traces in Large Language Models(https://arxiv.org/abs/2601.23163)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) increasingly solve difficult problems by producing "reasoning traces" before emitting a final response. However, it remains unclear how accuracy and decision commitment evolve along a reasoning trajectory, and whether intermediate trace segments provide answer-relevant information beyond generic length or stylistic effects. Here, we propose a protocol to systematically probe the trajectories of reasoning traces in LLMs by 1) generating a model's reasoning trace, 2) truncating it at fixed token-percentiles, and 3) injecting each partial trace back into the model (or a different model) to measure the induced distribution over answer choices via next-token probabilities. We apply this protocol to the open-source Qwen3-4B/-8B/-14B and gpt-oss-20b/-120b models across the multiple-choice GPQA Diamond and MMLU-Pro benchmarks. We find that accuracy and decision commitment consistently increase as the percentage of provided reasoning tokens grows. These gains are primarily driven by relevant content in the model generation rather than context length or generic "reasoning style" effects. Stronger models often backtrack successfully from incorrect partial traces, but immediate answers often remain anchored in the weaker model's incorrect response. More broadly, we show that trajectory probing provides diagnostics for efficient and safer deployment of reasoning models as the measurements can inform practical trace-handling and monitoring policies that improve reliability without assuming intermediate tokens are inherently faithful explanations.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）越来越多地通过在发出最终响应之前产生“推理痕迹”来解决难题。然而，目前尚不清楚准确性和决策承诺如何沿着推理轨迹演变，以及中间痕迹片段是否提供超出通用长度或风格效果的与答案相关的信息。在这里，我们提出了一个协议，通过 1）生成模型的推理轨迹，2）在固定的令牌百分位数处截断它，以及 3）将每个部分轨迹重新注入到模型（或不同的模型）中，以通过下一个令牌概率测量答案选择的诱导分布，系统地探测 LLM 中推理轨迹的轨迹。我们将此协议应用于多选 GPQA Diamond 和 MMLU-Pro 基准测试中的开源 Qwen3-4B/-8B/-14B 和 gpt-oss-20b/-120b 模型。我们发现，随着提供的推理代币百分比的增加，准确性和决策承诺不断增加。这些收益主要是由模型生成中的相关内容驱动的，而不是上下文长度或通用的“推理风格”效果。较强的模型通常会成功地从不正确的部分轨迹中回溯，但即时答案通常仍锚定在较弱模型的错误响应中。更广泛地说，我们表明轨迹探测为推理模型的高效和更安全的部署提供了诊断，因为测量可以为实际的跟踪处理和监控策略提供信息，从而提高可靠性，而无需假设中间标记本质上是忠实的解释。</li>
</ul>

<h3>Title: TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification</h3>
<ul>
<li><strong>Authors: </strong>Haoyun Jiang, Junqi He, Feng Hong, Xinlong Yang, Jianwei Zhang, Zheng Li, Zhengyang Zhuge, Zhiyong Chen, Bo Han, Junyang Lin, Jiangchao Yao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23180">https://arxiv.org/abs/2601.23180</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23180">https://arxiv.org/pdf/2601.23180</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23180]] TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification(https://arxiv.org/abs/2601.23180)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Inference efficiency in Large Language Models (LLMs) is fundamentally limited by their serial, autoregressive generation, especially as reasoning becomes a key capability and response sequences grow longer. Speculative decoding (SD) offers a powerful solution, providing significant speed-ups through its lightweight drafting and parallel verification mechanism. While existing work has nearly saturated improvements in draft effectiveness and efficiency, this paper advances SD from a new yet critical perspective: the verification cost. We propose TriSpec, a novel ternary SD framework that, at its core, introduces a lightweight proxy to significantly reduce computational cost by approving easily verifiable draft sequences and engaging the full target model only when encountering uncertain tokens. TriSpec can be integrated with state-of-the-art SD methods like EAGLE-3 to further reduce verification costs, achieving greater acceleration. Extensive experiments on the Qwen3 and DeepSeek-R1-Distill-Qwen/LLaMA families show that TriSpec achieves up to 35\% speedup over standard SD, with up to 50\% fewer target model invocations while maintaining comparable accuracy.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 的推理效率从根本上受到其串行自回归生成的限制，特别是当推理成为关键功能并且响应序列变得更长时。推测性解码 (SD) 提供了强大的解决方案，通过其轻量级起草和并行验证机制显着提高了速度。虽然现有工作在草案有效性和效率方面的改进已接近饱和，但本文从一个新的但关键的角度推进了 SD：验证成本。我们提出了 TriSpec，一种新颖的三元 SD 框架，其核心引入了一个轻量级代理，通过批准易于验证的草稿序列并仅在遇到不确定标记时才使用完整的目标模型，从而显着降低计算成本。 TriSpec 可以与 EAGLE-3 等最先进的 SD 方法集成，以进一步降低验证成本，实现更大的加速。对 Qwen3 和 DeepSeek-R1-Distill-Qwen/LLaMA 系列进行的大量实验表明，TriSpec 比标准 SD 实现了高达 35% 的加速，目标模型调用量减少了 50%，同时保持了相当的精度。</li>
</ul>

<h3>Title: ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search</h3>
<ul>
<li><strong>Authors: </strong>Tao Yu, Haopeng Jin, Hao Wang, Shenghua Chai, Yujia Yang, Junhao Gong, Jiaming Guo, Minghui Zhang, Xinlong Chen, Zhenghao Zhang, Yuxuan Zhou, Yanpei Gong, YuanCheng Liu, Yiming Ding, Kangwei Zeng, Pengfei Yang, Zhongtian Luo, Yufei Xiong, Shanbin Zhang, Shaoxiong Cheng, Huang Ruilin, Li Shuo, Yuxi Niu, Xinyuan Zhang, Yueya Xu, Jie Mao, Ruixuan Ji, Yaru Zhao, Mingchen Zhang, Jiabing Yang, Jiaqi Liu, YiFan Zhang, Hongzhu Yi, Xinming Wang, Cheng Zhong, Xiao Ma, Zhang Zhang, Yan Huang, Liang Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23232">https://arxiv.org/abs/2601.23232</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23232">https://arxiv.org/pdf/2601.23232</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23232]] ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search(https://arxiv.org/abs/2601.23232)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes editing requirements as keyframe-oriented shot descriptions and introduces five types of controllable single-factor constraints: Temporal order, Color, Visual style, Audio, and Resolution. We curate 1,210 high-quality samples from YouTube across 20 thematic categories, using large models for generation with human verification. Based on the benchmark, we propose ShotFinder, a text-driven three-stage retrieval and localization pipeline: (1) query expansion via video imagination, (2) candidate video retrieval with a search engine, and (3) description-guided temporal localization. Experiments on multiple closed-source and open-source models reveal a significant gap to human performance, with clear imbalance across constraints: temporal localization is relatively tractable, while color and visual style remain major challenges. These results reveal that open-domain video shot retrieval is still a critical capability that multimodal large models have yet to overcome.</li>
<li><strong>摘要：</strong>近年来，大型语言模型（LLM）在信息检索方面取得了快速进展，但现有研究主要集中在文本或静态多模态设置上。开放域视频镜头检索涉及更丰富的时间结构和更复杂的语义，仍然缺乏系统的基准测试和分析。为了填补这一空白，我们引入了 ShotFinder，这是一个基准测试，它将编辑要求形式化为面向关键帧的镜头描述，并引入了五种类型的可控单因素约束：时间顺序、颜色、视觉风格、音频和分辨率。我们从 YouTube 收集了 20 个主题类别的 1,210 个高质量样本，使用大型模型进行人工验证生成。基于该基准，我们提出了 ShotFinder，一种文本驱动的三阶段检索和本地化管道：（1）通过视频想象进行查询扩展，（2）使用搜索引擎检索候选视频，以及（3）描述引导的时间本地化。对多个闭源和开源模型的实验揭示了人类表现的显着差距，约束之间存在明显的不平衡：时间定位相对容易处理，而颜色和视觉风格仍然是主要挑战。这些结果表明，开放域视频镜头检索仍然是多模态大型模型尚未克服的关键能力。</li>
</ul>

<h3>Title: Sequence Diffusion Model for Temporal Link Prediction in Continuous-Time Dynamic Graph</h3>
<ul>
<li><strong>Authors: </strong>Nguyen Minh Duc, Viet Cuong Ta</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23233">https://arxiv.org/abs/2601.23233</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23233">https://arxiv.org/pdf/2601.23233</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23233]] Sequence Diffusion Model for Temporal Link Prediction in Continuous-Time Dynamic Graph(https://arxiv.org/abs/2601.23233)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Temporal link prediction in dynamic graphs is a fundamental problem in many real-world systems. Existing temporal graph neural networks mainly focus on learning representations of historical interactions. Despite their strong performance, these models are still purely discriminative, producing point estimates for future links and lacking an explicit mechanism to capture the uncertainty and sequential structure of future temporal interactions. In this paper, we propose SDG, a novel sequence-level diffusion framework that unifies dynamic graph learning with generative denoising. Specifically, SDG injects noise into the entire historical interaction sequence and jointly reconstructs all interaction embeddings through a conditional denoising process, thereby enabling the model to capture more comprehensive interaction distributions. To align the generative process with temporal link prediction, we employ a cross-attention denoising decoder to guide the reconstruction of the destination sequence and optimize the model in an end-to-end manner. Extensive experiments on various temporal graph benchmarks show that SDG consistently achieves state-of-the-art performance in the temporal link prediction task.</li>
<li><strong>摘要：</strong>动态图中的时间链接预测是许多现实系统中的一个基本问题。现有的时间图神经网络主要集中于学习历史交互的表示。尽管它们的性能很强，但这些模型仍然是纯粹的判别性，为未来的链接生成点估计，并且缺乏明确的机制来捕获未来时间交互的不确定性和顺序结构。在本文中，我们提出了 SDG，一种新颖的序列级扩散框架，它将动态图学习与生成去噪相结合。具体来说，SDG将噪声注入到整个历史交互序列中，并通过条件去噪过程联合重建所有交互嵌入，从而使模型能够捕获更全面的交互分布。为了使生成过程与时间链接预测保持一致，我们采用交叉注意去噪解码器来指导目标序列的重建并以端到端的方式优化模型。对各种时间图基准的大量实验表明，SDG 在时间链接预测任务中始终实现了最先进的性能。</li>
</ul>

<h3>Title: How well do generative models solve inverse problems? A benchmark study</h3>
<ul>
<li><strong>Authors: </strong>Patrick Krüger, Patrick Materne, Werner Krebs, Hanno Gottschalk</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23238">https://arxiv.org/abs/2601.23238</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23238">https://arxiv.org/pdf/2601.23238</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23238]] How well do generative models solve inverse problems? A benchmark study(https://arxiv.org/abs/2601.23238)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>Generative learning generates high dimensional data based on low dimensional conditions, also called prompts. Therefore, generative learning algorithms are eligible for solving (Bayesian) inverse problems. In this article we compare a traditional Bayesian inverse approach based on a forward regression model and a prior sampled with the Markov Chain Monte Carlo method with three state of the art generative learning models, namely conditional Generative Adversarial Networks, Invertible Neural Networks and Conditional Flow Matching. We apply them to a problem of gas turbine combustor design where we map six independent design parameters to three performance labels. We propose several metrics for the evaluation of this inverse design approaches and measure the accuracy of the labels of the generated designs along with the diversity. We also study the performance as a function of the training dataset size. Our benchmark has a clear winner, as Conditional Flow Matching consistently outperforms all competing approaches.</li>
<li><strong>摘要：</strong>生成学习根据低维条件生成高维数据，也称为提示。因此，生成学习算法适合解决（贝叶斯）逆问题。在本文中，我们将基于前向回归模型和马尔可夫链蒙特卡罗方法先验采样的传统贝叶斯逆方法与三种最先进的生成学习模型（即条件生成对抗网络、可逆神经网络和条件流匹配）进行比较。我们将它们应用于燃气轮机燃烧室设计问题，其中我们将六个独立的设计参数映射到三个性能标签。我们提出了几个评估这种逆向设计方法的指标，并衡量生成的设计标签的准确性以及多样性。我们还研究了性能与训练数据集大小的函数关系。我们的基准测试有一个明显的赢家，因为条件流匹配始终优于所有竞争方法。</li>
</ul>

<h3>Title: Agnostic Language Identification and Generation</h3>
<ul>
<li><strong>Authors: </strong>Mikael Møller Høgsgaard, Chirag Pabbaraju</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23258">https://arxiv.org/abs/2601.23258</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23258">https://arxiv.org/pdf/2601.23258</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23258]] Agnostic Language Identification and Generation(https://arxiv.org/abs/2601.23258)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Recent works on language identification and generation have established tight statistical rates at which these tasks can be achieved. These works typically operate under a strong realizability assumption: that the input data is drawn from an unknown distribution necessarily supported on some language in a given collection. In this work, we relax this assumption of realizability entirely, and impose no restrictions on the distribution of the input data. We propose objectives to study both language identification and generation in this more general "agnostic" setup. Across both problems, we obtain novel interesting characterizations and nearly tight rates.</li>
<li><strong>摘要：</strong>最近关于语言识别和生成的工作已经建立了严格的统计率来实现这些任务。这些工作通常在很强的可实现性假设下运行：输入数据是从给定集合中的某种语言必然支持的未知分布中提取的。在这项工作中，我们完全放松了这种可实现性的假设，并且对输入数据的分布没有施加任何限制。我们提出的目标是在这种更普遍的“不可知论”设置中研究语言识别和生成。在这两个问题上，我们都获得了新颖有趣的特征和近乎严格的比率。</li>
</ul>

<h3>Title: Particle-Guided Diffusion Models for Partial Differential Equations</h3>
<ul>
<li><strong>Authors: </strong>Andrew Millard, Fredrik Lindsten, Zheng Zhao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23262">https://arxiv.org/abs/2601.23262</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23262">https://arxiv.org/pdf/2601.23262</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23262]] Particle-Guided Diffusion Models for Partial Differential Equations(https://arxiv.org/abs/2601.23262)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We introduce a guided stochastic sampling method that augments sampling from diffusion models with physics-based guidance derived from partial differential equation (PDE) residuals and observational constraints, ensuring generated samples remain physically admissible. We embed this sampling procedure within a new Sequential Monte Carlo (SMC) framework, yielding a scalable generative PDE solver. Across multiple benchmark PDE systems as well as multiphysics and interacting PDE systems, our method produces solution fields with lower numerical error than existing state-of-the-art generative methods.</li>
<li><strong>摘要：</strong>我们引入了一种引导随机采样方法，该方法通过从偏微分方程（PDE）残差和观测约束导出的基于物理的指导来增强扩散模型的采样，确保生成的样本在物理上保持可接受的状态。我们将此采样过程嵌入到新的顺序蒙特卡罗 (SMC) 框架中，从而生成可扩展的生成 PDE 求解器。在多个基准偏微分方程系统以及多物理场和交互偏微分方程系统中，我们的方法产生的解域的数值误差比现有最先进的生成方法更低。</li>
</ul>

<h3>Title: FOCUS: DLLMs Know How to Tame Their Compute Bound</h3>
<ul>
<li><strong>Authors: </strong>Kaihua Liang, Xin Tan, An Zhong, Hong Xu, Marco Canini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AR, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23278">https://arxiv.org/abs/2601.23278</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23278">https://arxiv.org/pdf/2601.23278</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23278]] FOCUS: DLLMs Know How to Tame Their Compute Bound(https://arxiv.org/abs/2601.23278)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation</a></li>
<li><strong>Abstract: </strong>Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. We further observe a strong correlation between attention-derived token importance and token-wise decoding probability. Based on this insight, we propose FOCUS -- an inference system designed for DLLMs. By dynamically focusing computation on decodable tokens and evicting non-decodable ones on-the-fly, FOCUS increases the effective batch size, alleviating compute limitations and enabling scalable throughput. Empirical evaluations demonstrate that FOCUS achieves up to 3.52$\times$ throughput improvement over the production-grade engine LMDeploy, while preserving or improving generation quality across multiple benchmarks. The FOCUS system is publicly available on GitHub: this https URL.</li>
<li><strong>摘要：</strong>扩散大型语言模型 (DLLM) 为自回归模型提供了一种引人注目的替代方案，但其部署受到高解码成本的限制。在这项工作中，我们发现了 DLLM 解码中的一个关键低效问题：虽然计算在令牌块上并行化，但在每个扩散步骤中只有一小部分令牌是可解码的，导致大部分计算浪费在不可解码的令牌上。我们进一步观察到注意力衍生令牌重要性与令牌明智解码概率之间的强相关性。基于这一见解，我们提出了 FOCUS——一种专为 DLLM 设计的推理系统。通过动态地将计算集中在可解码令牌上并即时驱逐不可解码令牌，FOCUS 增加了有效批量大小，减轻了计算限制并实现了可扩展的吞吐量。实证评估表明，与生产级引擎 LMDeploy 相比，FOCUS 的吞吐量提高了高达 3.52$\times$，同时在多个基准测试中保持或提高了生成质量。 FOCUS 系统在 GitHub 上公开可用：此 https URL。</li>
</ul>

<h3>Title: Decoupled Diffusion Sampling for Inverse Problems on Function Spaces</h3>
<ul>
<li><strong>Authors: </strong>Thomas Y.L. Lin, Jiachen Yao, Lufang Chiang, Julius Berner, Anima Anandkumar</a></li>
<li><strong>Subjects: </strong>cs.LG, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23280">https://arxiv.org/abs/2601.23280</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23280">https://arxiv.org/pdf/2601.23280</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23280]] Decoupled Diffusion Sampling for Inverse Problems on Function Spaces(https://arxiv.org/abs/2601.23280)</code><input type="text"></li>
<li><strong>Keywords: </strong>generative</a></li>
<li><strong>Abstract: </strong>We propose a data-efficient, physics-aware generative framework in function space for inverse PDE problems. Existing plug-and-play diffusion posterior samplers represent physics implicitly through joint coefficient-solution modeling, requiring substantial paired supervision. In contrast, our Decoupled Diffusion Inverse Solver (DDIS) employs a decoupled design: an unconditional diffusion learns the coefficient prior, while a neural operator explicitly models the forward PDE for guidance. This decoupling enables superior data efficiency and effective physics-informed learning, while naturally supporting Decoupled Annealing Posterior Sampling (DAPS) to avoid over-smoothing in Diffusion Posterior Sampling (DPS). Theoretically, we prove that DDIS avoids the guidance attenuation failure of joint models when training data is scarce. Empirically, DDIS achieves state-of-the-art performance under sparse observation, improving $l_2$ error by 11% and spectral error by 54% on average; when data is limited to 1%, DDIS maintains accuracy with 40% advantage in $l_2$ error compared to joint models.</li>
<li><strong>摘要：</strong>我们在函数空间中针对反偏微分方程问题提出了一种数据高效、物理感知的生成框架。现有的即插即用扩散后采样器通过联合系数解建模隐式地表示物理现象，需要大量的配对监督。相比之下，我们的解耦扩散逆求解器 (DDIS) 采用解耦设计：无条件扩散先验系数，而神经算子显式建模前向偏微分方程以提供指导。这种解耦可实现卓越的数据效率和有效的物理信息学习，同时自然地支持解耦退火后采样 (DAPS)，以避免扩散后采样 (DPS) 中的过度平滑。理论上，我们证明了DDIS避免了训练数据稀缺时联合模型的制导衰减失效。根据经验，DDIS 在稀疏观测下实现了最先进的性能，平均将 $l_2$ 误差改善了 11%，谱误差平均改善了 54%；当数据限制为 1% 时，DDIS 保持精度，与联合模型相比，$l_2$ 误差有 40% 的优势。</li>
</ul>

<h3>Title: VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation</h3>
<ul>
<li><strong>Authors: </strong>Hongyang Du, Junjie Ye, Xiaoyan Cong, Runhao Li, Jingcheng Ni, Aman Agarwal, Zeqi Zhou, Zekun Li, Randall Balestriero, Yue Wang</a></li>
<li><strong>Subjects: </strong>cs.CV, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2601.23286">https://arxiv.org/abs/2601.23286</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2601.23286">https://arxiv.org/pdf/2601.23286</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2601.23286]] VideoGPA: Distilling Geometry Priors for 3D-Consistent Video Generation(https://arxiv.org/abs/2601.23286)</code><input type="text"></li>
<li><strong>Keywords: </strong>generation, generative</a></li>
<li><strong>Abstract: </strong>While recent video diffusion models (VDMs) produce visually impressive results, they fundamentally struggle to maintain 3D structural consistency, often resulting in object deformation or spatial drift. We hypothesize that these failures arise because standard denoising objectives lack explicit incentives for geometric coherence. To address this, we introduce VideoGPA (Video Geometric Preference Alignment), a data-efficient self-supervised framework that leverages a geometry foundation model to automatically derive dense preference signals that guide VDMs via Direct Preference Optimization (DPO). This approach effectively steers the generative distribution toward inherent 3D consistency without requiring human annotations. VideoGPA significantly enhances temporal stability, physical plausibility, and motion coherence using minimal preference pairs, consistently outperforming state-of-the-art baselines in extensive experiments.</li>
<li><strong>摘要：</strong>虽然最近的视频扩散模型 (VDM) 产生了令人印象深刻的视觉效果，但它们从根本上难以保持 3D 结构一致性，常常导致对象变形或空间漂移。我们假设这些失败的出现是因为标准去噪目标缺乏对几何一致性的明确激励。为了解决这个问题，我们引入了 VideoGPA（视频几何偏好对齐），这是一种数据高效的自我监督框架，利用几何基础模型自动导出密集偏好信号，通过直接偏好优化 (DPO) 指导 VDM。这种方法有效地将生成分布引导至固有的 3D 一致性，而不需要人工注释。 VideoGPA 使用最小偏好对显着增强了时间稳定性、物理合理性和运动连贯性，在广泛的实验中始终优于最先进的基线。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
