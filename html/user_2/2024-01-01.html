<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-01</h1>
<h2>language model</h2>
<h3>Title: From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models. (arXiv:2312.17256v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17256">http://arxiv.org/abs/2312.17256</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17256]] From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models(http://arxiv.org/abs/2312.17256)</code></li>
<li>Summary: <p>Large language models (LLMs) are able to engage in natural-sounding
conversations with humans, showcasing unprecedented capabilities for
information retrieval and automated decision support. They have disrupted
human-technology interaction and the way businesses operate. However,
technologies based on generative artificial intelligence (GenAI) are known to
hallucinate, misinform, and display biases introduced by the massive datasets
on which they are trained. Existing research indicates that humans may
unconsciously internalize these biases, which can persist even after they stop
using the programs. This study explores the cultural self-perception of LLMs by
prompting ChatGPT (OpenAI) and Bard (Google) with value questions derived from
the GLOBE project. The findings reveal that their cultural self-perception is
most closely aligned with the values of English-speaking countries and
countries characterized by sustained economic competitiveness. Recognizing the
cultural biases of LLMs and understanding how they work is crucial for all
members of society because one does not want the black box of artificial
intelligence to perpetuate bias in humans, who might, in turn, inadvertently
create and train even more biased algorithms.
</p></li>
</ul>

<h3>Title: Evolving Large Language Model Assistant with Long-Term Conditional Memory. (arXiv:2312.17257v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17257">http://arxiv.org/abs/2312.17257</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17257]] Evolving Large Language Model Assistant with Long-Term Conditional Memory(http://arxiv.org/abs/2312.17257)</code></li>
<li>Summary: <p>With the rapid development of large language models, AI assistants like
ChatGPT have widely entered people's works and lives. In this paper, we present
an evolving large language model assistant that utilizes verbal long-term
memory. It focuses on preserving the knowledge and experience from the history
dialogue between the user and AI assistant, which can be applied to future
dialogue for generating a better response. The model generates a set of records
for each finished dialogue and stores them in the memory. In later usage, given
a new user input, the model uses it to retrieve its related memory to improve
the quality of the response. To find the best form of memory, we explore
different ways of constructing the memory and propose a new memorizing
mechanism called conditional memory to solve the problems in previous methods.
We also investigate the retrieval and usage of memory in the generation
process. The assistant uses GPT-4 as the backbone and we evaluate it on three
constructed test datasets focusing on different abilities required by an AI
assistant with long-term memory.
</p></li>
</ul>

<h3>Title: Empowering Working Memory for Large Language Model Agents. (arXiv:2312.17259v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17259">http://arxiv.org/abs/2312.17259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17259]] Empowering Working Memory for Large Language Model Agents(http://arxiv.org/abs/2312.17259)</code></li>
<li>Summary: <p>Large language models (LLMs) have achieved impressive linguistic
capabilities. However, a key limitation persists in their lack of human-like
memory faculties. LLMs exhibit constrained memory retention across sequential
interactions, hindering complex reasoning. This paper explores the potential of
applying cognitive psychology's working memory frameworks, to enhance LLM
architecture. The limitations of traditional LLM memory designs are analyzed,
including their isolation of distinct dialog episodes and lack of persistent
memory links. To address this, an innovative model is proposed incorporating a
centralized Working Memory Hub and Episodic Buffer access to retain memories
across episodes. This architecture aims to provide greater continuity for
nuanced contextual reasoning during intricate tasks and collaborative
scenarios. While promising, further research is required into optimizing
episodic memory encoding, storage, prioritization, retrieval, and security.
Overall, this paper provides a strategic blueprint for developing LLM agents
with more sophisticated, human-like memory capabilities, highlighting memory
mechanisms as a vital frontier in artificial general intelligence.
</p></li>
</ul>

<h3>Title: Conversational Question Answering with Reformulations over Knowledge Graph. (arXiv:2312.17269v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17269">http://arxiv.org/abs/2312.17269</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17269]] Conversational Question Answering with Reformulations over Knowledge Graph(http://arxiv.org/abs/2312.17269)</code></li>
<li>Summary: <p>conversational question answering (convQA) over knowledge graphs (KGs)
involves answering multi-turn natural language questions about information
contained in a KG. State-of-the-art methods of ConvQA often struggle with
inexplicit question-answer pairs. These inputs are easy for human beings to
understand given a conversation history, but hard for a machine to interpret,
which can degrade ConvQA performance. To address this problem, we propose a
reinforcement learning (RL) based model, CornNet, which utilizes question
reformulations generated by large language models (LLMs) to improve ConvQA
performance. CornNet adopts a teacher-student architecture where a teacher
model learns question representations using human writing reformulations, and a
student model to mimic the teacher model's output via reformulations generated
by LLMs. The learned question representation is then used by an RL model to
locate the correct answer in a KG. Extensive experimental results show that
CornNet outperforms state-of-the-art convQA models.
</p></li>
</ul>

<h3>Title: AI Content Self-Detection for Transformer-based Large Language Models. (arXiv:2312.17289v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17289">http://arxiv.org/abs/2312.17289</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17289]] AI Content Self-Detection for Transformer-based Large Language Models(http://arxiv.org/abs/2312.17289)</code></li>
<li>Summary: <p>$ $The usage of generative artificial intelligence (AI) tools based on large
language models, including ChatGPT, Bard, and Claude, for text generation has
many exciting applications with the potential for phenomenal productivity
gains. One issue is authorship attribution when using AI tools. This is
especially important in an academic setting where the inappropriate use of
generative AI tools may hinder student learning or stifle research by creating
a large amount of automatically generated derivative work. Existing plagiarism
detection systems can trace the source of submitted text but are not yet
equipped with methods to accurately detect AI-generated text. This paper
introduces the idea of direct origin detection and evaluates whether generative
AI systems can recognize their output and distinguish it from human-written
texts. We argue why current transformer-based models may be able to self-detect
their own generated text and perform a small empirical study using zero-shot
learning to investigate if that is the case. Results reveal varying
capabilities of AI systems to identify their generated text. Google's Bard
model exhibits the largest capability of self-detection with an accuracy of
94\%, followed by OpenAI's ChatGPT with 83\%. On the other hand, Anthropic's
Claude model seems to be not able to self-detect.
</p></li>
</ul>

<h3>Title: AQUALLM: Audio Question Answering Data Generation Using Large Language Models. (arXiv:2312.17343v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17343">http://arxiv.org/abs/2312.17343</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17343]] AQUALLM: Audio Question Answering Data Generation Using Large Language Models(http://arxiv.org/abs/2312.17343)</code></li>
<li>Summary: <p>Audio Question Answering (AQA) constitutes a pivotal task in which machines
analyze both audio signals and natural language questions to produce precise
natural language answers. The significance of possessing high-quality, diverse,
and extensive AQA datasets cannot be overstated when aiming for the precision
of an AQA system. While there has been notable focus on developing accurate and
efficient AQA models, the creation of high-quality, diverse, and extensive
datasets for the specific task at hand has not garnered considerable attention.
To address this challenge, this work makes several contributions. We introduce
a scalable AQA data generation pipeline, denoted as the AQUALLM framework,
which relies on Large Language Models (LLMs). This framework utilizes existing
audio-caption annotations and incorporates state-of-the-art LLMs to generate
expansive, high-quality AQA datasets. Additionally, we present three extensive
and high-quality benchmark datasets for AQA, contributing significantly to the
progression of AQA research. AQA models trained on the proposed datasets set
superior benchmarks compared to the existing state-of-the-art. Moreover, models
trained on our datasets demonstrate enhanced generalizability when compared to
models trained using human-annotated AQA data. Code and datasets will be
accessible on GitHub~\footnote{\url{https://github.com/swarupbehera/AQUALLM}}.
</p></li>
</ul>

<h3>Title: SMoT: Think in State Machine. (arXiv:2312.17445v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17445">http://arxiv.org/abs/2312.17445</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17445]] SMoT: Think in State Machine(http://arxiv.org/abs/2312.17445)</code></li>
<li>Summary: <p>Current prompting approach for language model inference mainly rely on
Language Model's (LLM) autonomous exploration of reasoning paths, confronts an
inevitable retracing operation when erroneous routes are encountered. This is
followed by the pursuit of alternative reasoning paths. However, humans are
adept at abstracting optimal solutions from problems, thereby facilitating
swift and precise reasoning for similar problems resolution. In light of this,
we delves into the potential of harnessing expert knowledge to enhance
problem-solving within LLMs. We introduce a novel paradigm, the State Machine
of Thought (SMoT), which employs predefined state machines to furnish LLMs with
efficient reasoning paths, thereby eliminating fruitless exploration.
Furthermore, we propose a multi-agent mechanism that assigns different
objectives to agents, aiming to enhance the accuracy of SMoT reasoning. The
experimental results, derived from an array reasoning task, reveal that SMoT
realizes an extraordinary accuracy of 95\%, surpassing the performance of the
state-of-the-art baselines.
</p></li>
</ul>

<h3>Title: EHR Interaction Between Patients and AI: NoteAid EHR Interaction. (arXiv:2312.17475v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17475">http://arxiv.org/abs/2312.17475</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17475]] EHR Interaction Between Patients and AI: NoteAid EHR Interaction(http://arxiv.org/abs/2312.17475)</code></li>
<li>Summary: <p>With the rapid advancement of Large Language Models (LLMs) and their
outstanding performance in semantic and contextual comprehension, the potential
of LLMs in specialized domains warrants exploration. This paper introduces the
NoteAid EHR Interaction Pipeline, an innovative approach developed using
generative LLMs to assist in patient education, a task stemming from the need
to aid patients in understanding Electronic Health Records (EHRs). Building
upon the NoteAid work, we designed two novel tasks from the patient's
perspective: providing explanations for EHR content that patients may not
understand and answering questions posed by patients after reading their EHRs.
We extracted datasets containing 10,000 instances from MIMIC Discharge
Summaries and 876 instances from the MADE medical notes collection,
respectively, executing the two tasks through the NoteAid EHR Interaction
Pipeline with these data. Performance data of LLMs on these tasks were
collected and constructed as the corresponding NoteAid EHR Interaction Dataset.
Through a comprehensive evaluation of the entire dataset using LLM assessment
and a rigorous manual evaluation of 64 instances, we showcase the potential of
LLMs in patient education. Besides, the results provide valuable data support
for future exploration and applications in this domain while also supplying
high-quality synthetic datasets for in-house system training.
</p></li>
</ul>

<h3>Title: Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning. (arXiv:2312.17484v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17484">http://arxiv.org/abs/2312.17484</a></li>
<li>Code URL: <a href="https://github.com/jongjyh/trfr">https://github.com/jongjyh/trfr</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17484]] Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning(http://arxiv.org/abs/2312.17484)</code></li>
<li>Summary: <p>Despite the great success of large language models (LLMs) in various tasks,
they suffer from generating hallucinations. We introduce Truth Forest, a method
that enhances truthfulness in LLMs by uncovering hidden truth representations
using multi-dimensional orthogonal probes. Specifically, it creates multiple
orthogonal bases for modeling truth by incorporating orthogonal constraints
into the probes. Moreover, we introduce Random Peek, a systematic technique
considering an extended range of positions within the sequence, reducing the
gap between discerning and generating truth features in LLMs. By employing this
approach, we improved the truthfulness of Llama-2-7B from 40.8\% to 74.5\% on
TruthfulQA. Likewise, significant improvements are observed in fine-tuned
models. We conducted a thorough analysis of truth features using probes. Our
visualization results show that orthogonal probes capture complementary
truth-related features, forming well-defined clusters that reveal the inherent
structure of the dataset. Code: \url{https://github.com/jongjyh/trfr}
</p></li>
</ul>

<h3>Title: Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception. (arXiv:2312.17532v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17532">http://arxiv.org/abs/2312.17532</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17532]] Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception(http://arxiv.org/abs/2312.17532)</code></li>
<li>Summary: <p>Quantities are distinct and critical components of texts that characterize
the magnitude properties of entities, providing a precise perspective for the
understanding of natural language, especially for reasoning tasks. In recent
years, there has been a flurry of research on reasoning tasks based on large
language models (LLMs), most of which solely focus on numerical values,
neglecting the dimensional concept of quantities with units despite its
importance. We argue that the concept of dimension is essential for precisely
understanding quantities and of great significance for LLMs to perform
quantitative reasoning. However, the lack of dimension knowledge and
quantity-related benchmarks has resulted in low performance of LLMs. Hence, we
present a framework to enhance the quantitative reasoning ability of language
models based on dimension perception. We first construct a dimensional unit
knowledge base (DimUnitKB) to address the knowledge gap in this area. We
propose a benchmark DimEval consisting of seven tasks of three categories to
probe and enhance the dimension perception skills of LLMs. To evaluate the
effectiveness of our methods, we propose a quantitative reasoning task and
conduct experiments. The experimental results show that our dimension
perception method dramatically improves accuracy (43.55%-&gt;50.67%) on
quantitative reasoning tasks compared to GPT-4.
</p></li>
</ul>

<h3>Title: Building Efficient Universal Classifiers with Natural Language Inference. (arXiv:2312.17543v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17543">http://arxiv.org/abs/2312.17543</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17543]] Building Efficient Universal Classifiers with Natural Language Inference(http://arxiv.org/abs/2312.17543)</code></li>
<li>Summary: <p>Generative Large Language Models (LLMs) have become the mainstream choice for
fewshot and zeroshot learning thanks to the universality of text generation.
Many users, however, do not need the broad capabilities of generative LLMs when
they only want to automate a classification task. Smaller BERT-like models can
also learn universal tasks, which allow them to do any text classification task
without requiring fine-tuning (zeroshot classification) or to learn new tasks
with only a few examples (fewshot), while being significantly more efficient
than generative LLMs. This paper (1) explains how Natural Language Inference
(NLI) can be used as a universal classification task that follows similar
principles as instruction fine-tuning of generative LLMs, (2) provides a
step-by-step guide with reusable Jupyter notebooks for building a universal
classifier, and (3) shares the resulting universal classifier that is trained
on 33 datasets with 389 diverse classes. Parts of the code we share has been
used to train our older zeroshot classifiers that have been downloaded more
than 55 million times via the Hugging Face Hub as of December 2023. Our new
classifier improves zeroshot performance by 9.4%.
</p></li>
</ul>

<h3>Title: Action-Item-Driven Summarization of Long Meeting Transcripts. (arXiv:2312.17581v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17581">http://arxiv.org/abs/2312.17581</a></li>
<li>Code URL: <a href="https://github.com/logangolia/meeting-summarization">https://github.com/logangolia/meeting-summarization</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17581]] Action-Item-Driven Summarization of Long Meeting Transcripts(http://arxiv.org/abs/2312.17581)</code></li>
<li>Summary: <p>The increased prevalence of online meetings has significantly enhanced the
practicality of a model that can automatically generate the summary of a given
meeting. This paper introduces a novel and effective approach to automate the
generation of meeting summaries. Current approaches to this problem generate
general and basic summaries, considering the meeting simply as a long dialogue.
However, our novel algorithms can generate abstractive meeting summaries that
are driven by the action items contained in the meeting transcript. This is
done by recursively generating summaries and employing our action-item
extraction algorithm for each section of the meeting in parallel. All of these
sectional summaries are then combined and summarized together to create a
coherent and action-item-driven summary. In addition, this paper introduces
three novel methods for dividing up long transcripts into topic-based sections
to improve the time efficiency of our algorithm, as well as to resolve the
issue of large language models (LLMs) forgetting long-term dependencies. Our
pipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an
approximately 4.98% increase from the current state-of-the-art result produced
by a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.
</p></li>
</ul>

<h3>Title: Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models. (arXiv:2312.17661v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17661">http://arxiv.org/abs/2312.17661</a></li>
<li>Code URL: <a href="https://github.com/eternityyw/gemini-commonsense-evaluation">https://github.com/eternityyw/gemini-commonsense-evaluation</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17661]] Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models(http://arxiv.org/abs/2312.17661)</code></li>
<li>Summary: <p>The burgeoning interest in Multimodal Large Language Models (MLLMs), such as
OpenAI's GPT-4V(ision), has significantly impacted both academic and industrial
realms. These models enhance Large Language Models (LLMs) with advanced visual
understanding capabilities, facilitating their application in a variety of
multimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM
designed specifically for multimodal integration. Despite its advancements,
preliminary benchmarks indicate that Gemini lags behind GPT models in
commonsense reasoning tasks. However, this assessment, based on a limited
dataset (i.e., HellaSWAG), does not fully capture Gemini's authentic
commonsense reasoning potential. To address this gap, our study undertakes a
thorough evaluation of Gemini's performance in complex reasoning tasks that
necessitate the integration of commonsense knowledge across modalities. We
carry out a comprehensive analysis of 12 commonsense reasoning datasets,
ranging from general to domain-specific tasks. This includes 11 datasets
focused solely on language, as well as one that incorporates multimodal
elements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's
competitive commonsense reasoning capabilities. Additionally, we identify
common challenges faced by current LLMs and MLLMs in addressing commonsense
problems, underscoring the need for further advancements in enhancing the
commonsense reasoning abilities of these models.
</p></li>
</ul>

<h3>Title: Faithful Model Evaluation for Model-Based Metrics. (arXiv:2312.17254v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17254">http://arxiv.org/abs/2312.17254</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17254]] Faithful Model Evaluation for Model-Based Metrics(http://arxiv.org/abs/2312.17254)</code></li>
<li>Summary: <p>Statistical significance testing is used in natural language processing (NLP)
to determine whether the results of a study or experiment are likely to be due
to chance or if they reflect a genuine relationship. A key step in significance
testing is the estimation of confidence interval which is a function of sample
variance. Sample variance calculation is straightforward when evaluating
against ground truth. However, in many cases, a metric model is often used for
evaluation. For example, to compare toxicity of two large language models, a
toxicity classifier is used for evaluation. Existing works usually do not
consider the variance change due to metric model errors, which can lead to
wrong conclusions. In this work, we establish the mathematical foundation of
significance testing for model-based metrics. With experiments on public
benchmark datasets and a production system, we show that considering metric
model errors to calculate sample variances for model-based metrics changes the
conclusions in certain experiments.
</p></li>
</ul>

<h3>Title: Multimodal Classification of Teaching Activities from University Lecture Recordings. (arXiv:2312.17262v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17262">http://arxiv.org/abs/2312.17262</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17262]] Multimodal Classification of Teaching Activities from University Lecture Recordings(http://arxiv.org/abs/2312.17262)</code></li>
<li>Summary: <p>The way of understanding online higher education has greatly changed due to
the worldwide pandemic situation. Teaching is undertaken remotely, and the
faculty incorporate lecture audio recordings as part of the teaching material.
This new online teaching-learning setting has largely impacted university
classes. While online teaching technology that enriches virtual classrooms has
been abundant over the past two years, the same has not occurred in supporting
students during online learning. {To overcome this limitation, our aim is to
work toward enabling students to easily access the piece of the lesson
recording in which the teacher explains a theoretical concept, solves an
exercise, or comments on organizational issues of the course. To that end, we
present a multimodal classification algorithm that identifies the type of
activity that is being carried out at any time of the lesson by using a
transformer-based language model that exploits features from the audio file and
from the automated lecture transcription. The experimental results will show
that some academic activities are more easily identifiable with the audio
signal while resorting to the text transcription is needed to identify others.
All in all, our contribution aims to recognize the academic activities of a
teacher during a lesson.
</p></li>
</ul>

<h3>Title: PanGu-$\pi$: Enhancing Language Model Architectures via Nonlinearity Compensation. (arXiv:2312.17276v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17276">http://arxiv.org/abs/2312.17276</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17276]] PanGu-$\pi$: Enhancing Language Model Architectures via Nonlinearity Compensation(http://arxiv.org/abs/2312.17276)</code></li>
<li>Summary: <p>The recent trend of large language models (LLMs) is to increase the scale of
both model size (\aka the number of parameters) and dataset to achieve better
generative ability, which is definitely proved by a lot of work such as the
famous GPT and Llama. However, large models often involve massive computational
costs, and practical applications cannot afford such high prices. However, the
method of constructing a strong model architecture for LLMs is rarely
discussed. We first analyze the state-of-the-art language model architectures
and observe the feature collapse problem. Based on the theoretical analysis, we
propose that the nonlinearity is also very important for language models, which
is usually studied in convolutional neural networks for vision tasks. The
series informed activation function is then introduced with tiny calculations
that can be ignored, and an augmented shortcut is further used to enhance the
model nonlinearity. We then demonstrate that the proposed approach is
significantly effective for enhancing the model nonlinearity through carefully
designed ablations; thus, we present a new efficient model architecture for
establishing modern, namely, PanGu-$\pi$. Experiments are then conducted using
the same dataset and training strategy to compare PanGu-$\pi$ with
state-of-the-art LLMs. The results show that PanGu-$\pi$-7B can achieve a
comparable performance to that of benchmarks with about 10\% inference
speed-up, and PanGu-$\pi$-1B can achieve state-of-the-art performance in terms
of accuracy and efficiency. In addition, we have deployed PanGu-$\pi$-7B in the
high-value domains of finance and law, developing an LLM named YunShan for
practical application. The results show that YunShan can surpass other models
with similar scales on benchmarks.
</p></li>
</ul>

<h3>Title: Large Language Models for Conducting Advanced Text Analytics Information Systems Research. (arXiv:2312.17278v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17278">http://arxiv.org/abs/2312.17278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17278]] Large Language Models for Conducting Advanced Text Analytics Information Systems Research(http://arxiv.org/abs/2312.17278)</code></li>
<li>Summary: <p>The exponential growth of digital content has generated massive textual
datasets, necessitating advanced analytical approaches. Large Language Models
(LLMs) have emerged as tools capable of processing and extracting insights from
massive unstructured textual datasets. However, how to leverage LLMs for
text-based Information Systems (IS) research is currently unclear. To assist IS
research in understanding how to operationalize LLMs, we propose a Text
Analytics for Information Systems Research (TAISR) framework. Our proposed
framework provides detailed recommendations grounded in IS and LLM literature
on how to conduct meaningful text-based IS research. We conducted three case
studies in business intelligence using our TAISR framework to demonstrate its
application across several IS research contexts. We also outline potential
challenges and limitations in adopting LLMs for IS. By offering a systematic
approach and evidence of its utility, our TAISR framework contributes to future
IS research streams looking to incorporate powerful LLMs for text analytics.
</p></li>
</ul>

<h3>Title: Language Model as an Annotator: Unsupervised Context-aware Quality Phrase Generation. (arXiv:2312.17349v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17349">http://arxiv.org/abs/2312.17349</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17349]] Language Model as an Annotator: Unsupervised Context-aware Quality Phrase Generation(http://arxiv.org/abs/2312.17349)</code></li>
<li>Summary: <p>Phrase mining is a fundamental text mining task that aims to identify quality
phrases from context. Nevertheless, the scarcity of extensive gold labels
datasets, demanding substantial annotation efforts from experts, renders this
task exceptionally challenging. Furthermore, the emerging, infrequent, and
domain-specific nature of quality phrases presents further challenges in
dealing with this task. In this paper, we propose LMPhrase, a novel
unsupervised context-aware quality phrase mining framework built upon large
pre-trained language models (LMs). Specifically, we first mine quality phrases
as silver labels by employing a parameter-free probing technique called
Perturbed Masking on the pre-trained language model BERT (coined as Annotator).
In contrast to typical statistic-based or distantly-supervised methods, our
silver labels, derived from large pre-trained language models, take into
account rich contextual information contained in the LMs. As a result, they
bring distinct advantages in preserving informativeness, concordance, and
completeness of quality phrases. Secondly, training a discriminative span
prediction model heavily relies on massive annotated data and is likely to face
the risk of overfitting silver labels. Alternatively, we formalize phrase
tagging task as the sequence generation problem by directly fine-tuning on the
Sequence-to-Sequence pre-trained language model BART with silver labels (coined
as Generator). Finally, we merge the quality phrases from both the Annotator
and Generator as the final predictions, considering their complementary nature
and distinct characteristics. Extensive experiments show that our LMPhrase
consistently outperforms all the existing competitors across two different
granularity phrase mining tasks, where each task is tested on two different
domain datasets.
</p></li>
</ul>

<h3>Title: Large Language Models for Generative Information Extraction: A Survey. (arXiv:2312.17617v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17617">http://arxiv.org/abs/2312.17617</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17617]] Large Language Models for Generative Information Extraction: A Survey(http://arxiv.org/abs/2312.17617)</code></li>
<li>Summary: <p>Information extraction (IE) aims to extract structural knowledge (such as
entities, relations, and events) from plain natural language texts. Recently,
generative Large Language Models (LLMs) have demonstrated remarkable
capabilities in text understanding and generation, allowing for generalization
across various domains and tasks. As a result, numerous works have been
proposed to harness abilities of LLMs and offer viable solutions for IE tasks
based on a generative paradigm. To conduct a comprehensive systematic review
and exploration of LLM efforts for IE tasks, in this study, we survey the most
recent advancements in this field. We first present an extensive overview by
categorizing these works in terms of various IE subtasks and learning
paradigms, then we empirically analyze the most advanced methods and discover
the emerging trend of IE tasks with LLMs. Based on thorough review conducted,
we identify several insights in technique and promising research directions
that deserve further exploration in future studies. We maintain a public
repository and consistently update related resources at:
\url{https://github.com/quqxui/Awesome-LLM4IE-Papers}.
</p></li>
</ul>

<h3>Title: Principled Gradient-based Markov Chain Monte Carlo for Text Generation. (arXiv:2312.17710v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17710">http://arxiv.org/abs/2312.17710</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17710]] Principled Gradient-based Markov Chain Monte Carlo for Text Generation(http://arxiv.org/abs/2312.17710)</code></li>
<li>Summary: <p>Recent papers have demonstrated the possibility of energy-based text
generation by adapting gradient-based sampling algorithms, a paradigm of MCMC
algorithms that promises fast convergence. However, as we show in this paper,
previous attempts on this approach to text generation all fail to sample
correctly from the target language model distributions. To address this
limitation, we consider the problem of designing text samplers that are
faithful, meaning that they have the target text distribution as its limiting
distribution. We propose several faithful gradient-based sampling algorithms to
sample from the target energy-based text distribution correctly, and study
their theoretical properties. Through experiments on various forms of text
generation, we demonstrate that faithful samplers are able to generate more
fluent text while adhering to the control objectives better.
</p></li>
</ul>

<h3>Title: Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning. (arXiv:2312.17493v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17493">http://arxiv.org/abs/2312.17493</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17493]] Differentially Private Low-Rank Adaptation of Large Language Model Using Federated Learning(http://arxiv.org/abs/2312.17493)</code></li>
<li>Summary: <p>The surge in interest and application of large language models (LLMs) has
sparked a drive to fine-tune these models to suit specific applications, such
as finance and medical science. However, concerns regarding data privacy have
emerged, especially when multiple stakeholders aim to collaboratively enhance
LLMs using sensitive data. In this scenario, federated learning becomes a
natural choice, allowing decentralized fine-tuning without exposing raw data to
central servers. Motivated by this, we investigate how data privacy can be
ensured in LLM fine-tuning through practical federated learning approaches,
enabling secure contributions from multiple parties to enhance LLMs. Yet,
challenges arise: 1) despite avoiding raw data exposure, there is a risk of
inferring sensitive information from model outputs, and 2) federated learning
for LLMs incurs notable communication overhead. To address these challenges,
this article introduces DP-LoRA, a novel federated learning algorithm tailored
for LLMs. DP-LoRA preserves data privacy by employing a Gaussian mechanism that
adds noise in weight updates, maintaining individual data privacy while
facilitating collaborative model training. Moreover, DP-LoRA optimizes
communication efficiency via low-rank adaptation, minimizing the transmission
of updated weights during distributed training. The experimental results across
medical, financial, and general datasets using various LLMs demonstrate that
DP-LoRA effectively ensures strict privacy constraints while minimizing
communication overhead.
</p></li>
</ul>

<h2>gpt</h2>
<h2>llm</h2>
<h3>Title: Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of LLMs. (arXiv:2312.17535v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17535">http://arxiv.org/abs/2312.17535</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17535]] Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of LLMs(http://arxiv.org/abs/2312.17535)</code></li>
<li>Summary: <p>CoT (Chain-of-Thought) is a way to solve reasoning problems for LLMs .
Recently, many researches appear for improving the CoT capability of LLMs. In
this work, we also proposed Olapa-MCoT, which is a LLMs based on llama2-13B PLM
for finetuning and alignment learning. During the alignment training, we
proposed the SimRRHF algorithm and Incorrect Data Relearning and mainly focused
on optimizing the Chinese mathematical reasoning ability of Olapa-MCoT. The
experiment achieved significant results, with the accuracy of Chinese
mathematical reasoning up to 50%, 36% rise compared to llama2-13B. In addition,
the accuracy of English reasoning ability also increased by nearly 4%.
</p></li>
</ul>

<h3>Title: ESGReveal: An LLM-based approach for extracting structured data from ESG reports. (arXiv:2312.17264v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17264">http://arxiv.org/abs/2312.17264</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17264]] ESGReveal: An LLM-based approach for extracting structured data from ESG reports(http://arxiv.org/abs/2312.17264)</code></li>
<li>Summary: <p>ESGReveal is an innovative method proposed for efficiently extracting and
analyzing Environmental, Social, and Governance (ESG) data from corporate
reports, catering to the critical need for reliable ESG information retrieval.
This approach utilizes Large Language Models (LLM) enhanced with Retrieval
Augmented Generation (RAG) techniques. The ESGReveal system includes an ESG
metadata module for targeted queries, a preprocessing module for assembling
databases, and an LLM agent for data extraction. Its efficacy was appraised
using ESG reports from 166 companies across various sectors listed on the Hong
Kong Stock Exchange in 2022, ensuring comprehensive industry and market
capitalization representation. Utilizing ESGReveal unearthed significant
insights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in
data extraction and 83.7% in disclosure analysis, which is an improvement over
baseline models. This highlights the framework's capacity to refine ESG data
analysis precision. Moreover, it revealed a demand for reinforced ESG
disclosures, with environmental and social data disclosures standing at 69.5%
and 57.2%, respectively, suggesting a pursuit for more corporate transparency.
While current iterations of ESGReveal do not process pictorial information, a
functionality intended for future enhancement, the study calls for continued
research to further develop and compare the analytical capabilities of various
LLMs. In summary, ESGReveal is a stride forward in ESG data processing,
offering stakeholders a sophisticated tool to better evaluate and advance
corporate sustainability efforts. Its evolution is promising in promoting
transparency in corporate reporting and aligning with broader sustainable
development aims.
</p></li>
</ul>

<h3>Title: Structured Packing in LLM Training Improves Long Context Utilization. (arXiv:2312.17296v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17296">http://arxiv.org/abs/2312.17296</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17296]] Structured Packing in LLM Training Improves Long Context Utilization(http://arxiv.org/abs/2312.17296)</code></li>
<li>Summary: <p>Recent advances in long-context Large Language Models (LCLMs) have generated
significant interest, especially in applications such as querying scientific
research papers. However, their potential is often limited by inadequate
context utilization. We identify the absence of long-range semantic
dependencies in typical training data as a primary hindrance. To address this,
we delve into the benefits of frequently incorporating related documents into
training inputs. Using the inherent directory structure of code data as a
source of training examples, we demonstrate improvements in perplexity, even
for tasks unrelated to coding. Building on these findings, but with a broader
focus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an
innovative method for creating training examples by using a retrieval method to
collate the most mutually relevant documents into a single training context.
Our results indicate that \method{} enhances model performance and can be used
to train large models to utilize long contexts better. We validate our results
by training a large $3$B model, showing both perplexity improvements and better
long-context performance on downstream tasks.
</p></li>
</ul>

<h3>Title: Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters. (arXiv:2312.17476v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17476">http://arxiv.org/abs/2312.17476</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17476]] Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters(http://arxiv.org/abs/2312.17476)</code></li>
<li>Summary: <p>The advancement of Large Language Models (LLMs) has led to their widespread
use across a broad spectrum of tasks including decision making. Prior studies
have compared the decision making abilities of LLMs with those of humans from a
psychological perspective. However, these studies have not always properly
accounted for the sensitivity of LLMs' behavior to hyperparameters and
variations in the prompt. In this study, we examine LLMs' performance on the
Horizon decision making task studied by Binz and Schulz (2023) analyzing how
LLMs respond to variations in prompts and hyperparameters. By experimenting on
three OpenAI language models possessing different capabilities, we observe that
the decision making abilities fluctuate based on the input prompts and
temperature settings. Contrary to previous findings language models display a
human-like exploration exploitation tradeoff after simple adjustments to the
prompt.
</p></li>
</ul>

<h2>long context</h2>
<h2>lora</h2>
<h2>hallucination</h2>
<h2>prompt</h2>
<h3>Title: Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17267">http://arxiv.org/abs/2312.17267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17267]] Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning(http://arxiv.org/abs/2312.17267)</code></li>
<li>Summary: <p>Recently, prompt-tuning with pre-trained language models (PLMs) has
demonstrated the significantly enhancing ability of relation extraction (RE)
tasks. However, in low-resource scenarios, where the available training data is
scarce, previous prompt-based methods may still perform poorly for prompt-based
representation learning due to a superficial understanding of the relation. To
this end, we highlight the importance of learning high-quality relation
representation in low-resource scenarios for RE, and propose a novel
prompt-based relation representation method, named MVRE
(\underline{M}ulti-\underline{V}iew \underline{R}elation
\underline{E}xtraction), to better leverage the capacity of PLMs to improve the
performance of RE within the low-resource prompt-tuning paradigm. Specifically,
MVRE decouples each relation into different perspectives to encompass
multi-view relation representations for maximizing the likelihood during
relation inference. Furthermore, we also design a Global-Local loss and a
Dynamic-Initialization method for better alignment of the multi-view
relation-representing virtual words, containing the semantics of relation
labels during the optimization learning process and initialization. Extensive
experiments on three benchmark datasets show that our method can achieve
state-of-the-art in low-resource settings.
</p></li>
</ul>

<h3>Title: Overview of the PromptCBLUE Shared Task in CHIP2023. (arXiv:2312.17522v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17522">http://arxiv.org/abs/2312.17522</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17522]] Overview of the PromptCBLUE Shared Task in CHIP2023(http://arxiv.org/abs/2312.17522)</code></li>
<li>Summary: <p>This paper presents an overview of the PromptCBLUE shared task
(<a href="http://cips-chip.org.cn/2023/eval1">this http URL</a>) held in the CHIP-2023 Conference. This
shared task reformualtes the CBLUE benchmark, and provide a good testbed for
Chinese open-domain or medical-domain large language models (LLMs) in general
medical natural language processing. Two different tracks are held: (a) prompt
tuning track, investigating the multitask prompt tuning of LLMs, (b) probing
the in-context learning capabilities of open-sourced LLMs. Many teams from both
the industry and academia participated in the shared tasks, and the top teams
achieved amazing test results. This paper describes the tasks, the datasets,
evaluation metrics, and the top systems for both tasks. Finally, the paper
summarizes the techniques and results of the evaluation of the various
approaches explored by the participating teams.
</p></li>
</ul>

<h2>code</h2>
<h3>Title: Culturally-Attuned Moral Machines: Implicit Learning of Human Value Systems by AI through Inverse Reinforcement Learning. (arXiv:2312.17479v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17479">http://arxiv.org/abs/2312.17479</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17479]] Culturally-Attuned Moral Machines: Implicit Learning of Human Value Systems by AI through Inverse Reinforcement Learning(http://arxiv.org/abs/2312.17479)</code></li>
<li>Summary: <p>Constructing a universal moral code for artificial intelligence (AI) is
difficult or even impossible, given that different human cultures have
different definitions of morality and different societal norms. We therefore
argue that the value system of an AI should be culturally attuned: just as a
child raised in a particular culture learns the specific values and norms of
that culture, we propose that an AI agent operating in a particular human
community should acquire that community's moral, ethical, and cultural codes.
How AI systems might acquire such codes from human observation and interaction
has remained an open question. Here, we propose using inverse reinforcement
learning (IRL) as a method for AI agents to acquire a culturally-attuned value
system implicitly. We test our approach using an experimental paradigm in which
AI agents use IRL to learn different reward functions, which govern the agents'
moral values, by observing the behavior of different cultural groups in an
online virtual world requiring real-time decision making. We show that an AI
agent learning from the average behavior of a particular cultural group can
acquire altruistic characteristics reflective of that group's behavior, and
this learned value system can generalize to new scenarios requiring altruistic
judgments. Our results provide, to our knowledge, the first demonstration that
AI agents could potentially be endowed with the ability to continually learn
their values and norms from observing and interacting with humans, thereby
becoming attuned to the culture they are operating in.
</p></li>
</ul>

<h3>Title: TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification. (arXiv:2312.17263v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17263">http://arxiv.org/abs/2312.17263</a></li>
<li>Code URL: <a href="https://github.com/songruiecho/tacit">https://github.com/songruiecho/tacit</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17263]] TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification(http://arxiv.org/abs/2312.17263)</code></li>
<li>Summary: <p>Cross-domain text classification aims to transfer models from label-rich
source domains to label-poor target domains, giving it a wide range of
practical applications. Many approaches promote cross-domain generalization by
capturing domain-invariant features. However, these methods rely on unlabeled
samples provided by the target domains, which renders the model ineffective
when the target domain is agnostic. Furthermore, the models are easily
disturbed by shortcut learning in the source domain, which also hinders the
improvement of domain generalization ability. To solve the aforementioned
issues, this paper proposes TACIT, a target domain agnostic feature
disentanglement framework which adaptively decouples robust and unrobust
features by Variational Auto-Encoders. Additionally, to encourage the
separation of unrobust features from robust features, we design a feature
distillation task that compels unrobust features to approximate the output of
the teacher. The teacher model is trained with a few easy samples that are easy
to carry potential unknown shortcuts. Experimental results verify that our
framework achieves comparable results to state-of-the-art baselines while
utilizing only source domain data.
</p></li>
</ul>

<h3>Title: Stateful FastConformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17279">http://arxiv.org/abs/2312.17279</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17279]] Stateful FastConformer with Cache-based Inference for Streaming Automatic Speech Recognition(http://arxiv.org/abs/2312.17279)</code></li>
<li>Summary: <p>In this paper, we propose an efficient and accurate streaming speech
recognition model based on the FastConformer architecture. We adapted the
FastConformer architecture for streaming applications through: (1) constraining
both the look-ahead and past contexts in the encoder, and (2) introducing an
activation caching mechanism to enable the non-autoregressive encoder to
operate autoregressively during inference. The proposed model is thoughtfully
designed in a way to eliminate the accuracy disparity between the train and
inference time which is common for many streaming models. Furthermore, our
proposed encoder works with various decoder configurations including
Connectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders.
Additionally, we introduced a hybrid CTC/RNNT architecture which utilizes a
shared encoder with both a CTC and RNNT decoder to boost the accuracy and save
computation. We evaluate the proposed model on LibriSpeech dataset and a
multi-domain large scale dataset and demonstrate that it can achieve better
accuracy with lower latency and inference time compared to a conventional
buffered streaming model baseline. We also showed that training a model with
multiple latencies can achieve better accuracy than single latency models while
it enables us to support multiple latencies with a single model. Our
experiments also showed the hybrid architecture would not only speedup the
convergence of the CTC decoder but also improves the accuracy of streaming
models compared to single decoder models.
</p></li>
</ul>

<h3>Title: MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining. (arXiv:2312.17482v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17482">http://arxiv.org/abs/2312.17482</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17482]] MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining(http://arxiv.org/abs/2312.17482)</code></li>
<li>Summary: <p>Although BERT-style encoder models are heavily used in NLP research, many
researchers do not pretrain their own BERTs from scratch due to the high cost
of training. In the past half-decade since BERT first rose to prominence, many
advances have been made with other transformer architectures and training
configurations that have yet to be systematically incorporated into BERT. Here,
we introduce MosaicBERT, a BERT-style encoder architecture and training recipe
that is empirically optimized for fast pretraining. This efficient architecture
incorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear
Units (GLU), a module to dynamically remove padded tokens, and low precision
LayerNorm into the classic transformer encoder block. The training recipe
includes a 30% masking ratio for the Masked Language Modeling (MLM) objective,
bfloat16 precision, and vocabulary size optimized for GPU throughput, in
addition to best-practices from RoBERTa and other encoder models. When
pretrained from scratch on the C4 dataset, this base model achieves a
downstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs
at a cost of roughly $20. We plot extensive accuracy vs. pretraining speed
Pareto curves and show that MosaicBERT base and large are consistently Pareto
optimal when compared to a competitive BERT base and large. This empirical
speed up in pretraining enables researchers and engineers to pretrain custom
BERT-style models at low cost instead of finetune on existing generic models.
We open source our model weights and code.
</p></li>
</ul>

<h3>Title: Integrating Chemical Language and Molecular Graph in Multimodal Fused Deep Learning for Drug Property Prediction. (arXiv:2312.17495v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17495">http://arxiv.org/abs/2312.17495</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17495]] Integrating Chemical Language and Molecular Graph in Multimodal Fused Deep Learning for Drug Property Prediction(http://arxiv.org/abs/2312.17495)</code></li>
<li>Summary: <p>Accurately predicting molecular properties is a challenging but essential
task in drug discovery. Recently, many mono-modal deep learning methods have
been successfully applied to molecular property prediction. However, the
inherent limitation of mono-modal learning arises from relying solely on one
modality of molecular representation, which restricts a comprehensive
understanding of drug molecules and hampers their resilience against data
noise. To overcome the limitations, we construct multimodal deep learning
models to cover different molecular representations. We convert drug molecules
into three molecular representations, SMILES-encoded vectors, ECFP
fingerprints, and molecular graphs. To process the modal information,
Transformer-Encoder, bi-directional gated recurrent units (BiGRU), and graph
convolutional network (GCN) are utilized for feature learning respectively,
which can enhance the model capability to acquire complementary and naturally
occurring bioinformatics information. We evaluated our triple-modal model on
six molecule datasets. Different from bi-modal learning models, we adopt five
fusion methods to capture the specific features and leverage the contribution
of each modal information better. Compared with mono-modal models, our
multimodal fused deep learning (MMFDL) models outperform single models in
accuracy, reliability, and resistance capability against noise. Moreover, we
demonstrate its generalization ability in the prediction of binding constants
for protein-ligand complex molecules in the refined set of PDBbind. The
advantage of the multimodal model lies in its ability to process diverse
sources of data using proper models and suitable fusion methods, which would
enhance the noise resistance of the model while obtaining data diversity.
</p></li>
</ul>

<h3>Title: Data Augmentation for Supervised Graph Outlier Detection with Latent Diffusion Models. (arXiv:2312.17679v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17679">http://arxiv.org/abs/2312.17679</a></li>
<li>Code URL: <a href="https://github.com/kayzliu/godm">https://github.com/kayzliu/godm</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17679]] Data Augmentation for Supervised Graph Outlier Detection with Latent Diffusion Models(http://arxiv.org/abs/2312.17679)</code></li>
<li>Summary: <p>Graph outlier detection is a prominent task of research and application in
the realm of graph neural networks. It identifies the outlier nodes that
exhibit deviation from the majority in the graph. One of the fundamental
challenges confronting supervised graph outlier detection algorithms is the
prevalent issue of class imbalance, where the scarcity of outlier instances
compared to normal instances often results in suboptimal performance.
Conventional methods mitigate the imbalance by reweighting instances in the
estimation of the loss function, assigning higher weights to outliers and lower
weights to inliers. Nonetheless, these strategies are prone to overfitting and
underfitting, respectively. Recently, generative models, especially diffusion
models, have demonstrated their efficacy in synthesizing high-fidelity images.
Despite their extraordinary generation quality, their potential in data
augmentation for supervised graph outlier detection remains largely
underexplored.
</p>
<p>To bridge this gap, we introduce GODM, a novel data augmentation for
mitigating class imbalance in supervised Graph Outlier detection with latent
Diffusion Models. Specifically, our proposed method consists of three key
components: (1) Variantioanl Encoder maps the heterogeneous information
inherent within the graph data into a unified latent space. (2) Graph Generator
synthesizes graph data that are statistically similar to real outliers from
latent space, and (3) Latent Diffusion Model learns the latent space
distribution of real organic data by iterative denoising. Extensive experiments
conducted on multiple datasets substantiate the effectiveness and efficiency of
GODM. The case study further demonstrated the generation quality of our
synthetic data. To foster accessibility and reproducibility, we encapsulate
GODM into a plug-and-play package and release it at the Python Package Index
(PyPI).
</p></li>
</ul>

<h2>chat</h2>
<h3>Title: Research on the Laws of Multimodal Perception and Cognition from a Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example. (arXiv:2312.17642v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17642">http://arxiv.org/abs/2312.17642</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17642]] Research on the Laws of Multimodal Perception and Cognition from a Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example(http://arxiv.org/abs/2312.17642)</code></li>
<li>Summary: <p>This study aims to explore the complex relationship between perceptual and
cognitive interactions in multimodal data analysis,with a specific emphasis on
spatial experience design in overseas Chinese gardens. It is found that
evaluation content and images on social media can reflect individuals' concerns
and sentiment responses, providing a rich data base for cognitive research that
contains both sentimental and image-based cognitive information. Leveraging
deep learning techniques, we analyze textual and visual data from social media,
thereby unveiling the relationship between people's perceptions and sentiment
cognition within the context of overseas Chinese gardens. In addition, our
study introduces a multi-agent system (MAS)alongside AI agents. Each agent
explores the laws of aesthetic cognition through chat scene simulation combined
with web search. This study goes beyond the traditional approach of translating
perceptions into sentiment scores, allowing for an extension of the research
methodology in terms of directly analyzing texts and digging deeper into
opinion data. This study provides new perspectives for understanding aesthetic
experience and its impact on architecture and landscape design across diverse
cultural contexts, which is an essential contribution to the field of cultural
communication and aesthetic understanding.
</p></li>
</ul>

<h2>retrieval augmented generation</h2>
<h2>retrieval-augmented generation</h2>
<h2>rag</h2>
<h3>Title: ClST: A Convolutional Transformer Framework for Automatic Modulation Recognition by Knowledge Distillation. (arXiv:2312.17446v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17446">http://arxiv.org/abs/2312.17446</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17446]] ClST: A Convolutional Transformer Framework for Automatic Modulation Recognition by Knowledge Distillation(http://arxiv.org/abs/2312.17446)</code></li>
<li>Summary: <p>With the rapid development of deep learning (DL) in recent years, automatic
modulation recognition (AMR) with DL has achieved high accuracy. However,
insufficient training signal data in complicated channel environments and
large-scale DL models are critical factors that make DL methods difficult to
deploy in practice. Aiming to these problems, we propose a novel neural network
named convolution-linked signal transformer (ClST) and a novel knowledge
distillation method named signal knowledge distillation (SKD). The ClST is
accomplished through three primary modifications: a hierarchy of transformer
containing convolution, a novel attention mechanism named parallel
spatial-channel attention (PSCA) mechanism and a novel convolutional
transformer block named convolution-transformer projection (CTP) to leverage a
convolutional projection. The SKD is a knowledge distillation method to
effectively reduce the parameters and complexity of neural networks. We train
two lightweight neural networks using the SKD algorithm, KD-CNN and
KD-MobileNet, to meet the demand that neural networks can be used on
miniaturized devices. The simulation results demonstrate that the ClST
outperforms advanced neural networks on all datasets. Moreover, both KD-CNN and
KD-MobileNet obtain higher recognition accuracy with less network complexity,
which is very beneficial for the deployment of AMR on miniaturized
communication devices.
</p></li>
</ul>

<h3>Title: TuPy-E: detecting hate speech in Brazilian Portuguese social media with a novel dataset and comprehensive analysis of models. (arXiv:2312.17704v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17704">http://arxiv.org/abs/2312.17704</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17704]] TuPy-E: detecting hate speech in Brazilian Portuguese social media with a novel dataset and comprehensive analysis of models(http://arxiv.org/abs/2312.17704)</code></li>
<li>Summary: <p>Social media has become integral to human interaction, providing a platform
for communication and expression. However, the rise of hate speech on these
platforms poses significant risks to individuals and communities. Detecting and
addressing hate speech is particularly challenging in languages like Portuguese
due to its rich vocabulary, complex grammar, and regional variations. To
address this, we introduce TuPy-E, the largest annotated Portuguese corpus for
hate speech detection. TuPy-E leverages an open-source approach, fostering
collaboration within the research community. We conduct a detailed analysis
using advanced techniques like BERT models, contributing to both academic
understanding and practical applications
</p></li>
</ul>

<h3>Title: PINN surrogate of Li-ion battery models for parameter inference. Part I: Implementation and multi-fidelity hierarchies for the single-particle model. (arXiv:2312.17329v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17329">http://arxiv.org/abs/2312.17329</a></li>
<li>Code URL: <a href="https://github.com/nrel/pinnstripes">https://github.com/nrel/pinnstripes</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17329]] PINN surrogate of Li-ion battery models for parameter inference(http://arxiv.org/abs/2312.17329)</code></li>
<li>Summary: <p>To plan and optimize energy storage demands that account for Li-ion battery
aging dynamics, techniques need to be developed to diagnose battery internal
states accurately and rapidly. This study seeks to reduce the computational
resources needed to determine a battery's internal states by replacing
physics-based Li-ion battery models -- such as the single-particle model (SPM)
and the pseudo-2D (P2D) model -- with a physics-informed neural network (PINN)
surrogate. The surrogate model makes high-throughput techniques, such as
Bayesian calibration, tractable to determine battery internal parameters from
voltage responses. This manuscript is the first of a two-part series that
introduces PINN surrogates of Li-ion battery models for parameter inference
(i.e., state-of-health diagnostics). In this first part, a method is presented
for constructing a PINN surrogate of the SPM. A multi-fidelity hierarchical
training, where several neural nets are trained with multiple physics-loss
fidelities is shown to significantly improve the surrogate accuracy when only
training on the governing equation residuals. The implementation is made
available in a companion repository (https://github.com/NREL/pinnstripes). The
techniques used to develop a PINN surrogate of the SPM are extended in Part II
for the PINN surrogate for the P2D battery model, and explore the Bayesian
calibration capabilities of both surrogates.
</p></li>
</ul>

<h3>Title: Embedded feature selection in LSTM networks with multi-objective evolutionary ensemble learning for time series forecasting. (arXiv:2312.17517v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17517">http://arxiv.org/abs/2312.17517</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17517]] Embedded feature selection in LSTM networks with multi-objective evolutionary ensemble learning for time series forecasting(http://arxiv.org/abs/2312.17517)</code></li>
<li>Summary: <p>Time series forecasting plays a crucial role in diverse fields, necessitating
the development of robust models that can effectively handle complex temporal
patterns. In this article, we present a novel feature selection method embedded
in Long Short-Term Memory networks, leveraging a multi-objective evolutionary
algorithm. Our approach optimizes the weights and biases of the LSTM in a
partitioned manner, with each objective function of the evolutionary algorithm
targeting the root mean square error in a specific data partition. The set of
non-dominated forecast models identified by the algorithm is then utilized to
construct a meta-model through stacking-based ensemble learning. Furthermore,
our proposed method provides an avenue for attribute importance determination,
as the frequency of selection for each attribute in the set of non-dominated
forecasting models reflects their significance. This attribute importance
insight adds an interpretable dimension to the forecasting process.
Experimental evaluations on air quality time series data from Italy and
southeast Spain demonstrate that our method substantially improves the
generalization ability of conventional LSTMs, effectively reducing overfitting.
Comparative analyses against state-of-the-art CancelOut and EAR-FS methods
highlight the superior performance of our approach.
</p></li>
</ul>

<h2>multi-run</h2>
<h2>chain-of-thought</h2>
<h2>tree-of-thought</h2>
<h2>agent</h2>
<h3>Title: FedLED: Label-Free Equipment Fault Diagnosis with Vertical Federated Transfer Learning. (arXiv:2312.17451v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17451">http://arxiv.org/abs/2312.17451</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17451]] FedLED: Label-Free Equipment Fault Diagnosis with Vertical Federated Transfer Learning(http://arxiv.org/abs/2312.17451)</code></li>
<li>Summary: <p>Intelligent equipment fault diagnosis based on Federated Transfer Learning
(FTL) attracts considerable attention from both academia and industry. It
allows real-world industrial agents with limited samples to construct a fault
diagnosis model without jeopardizing their raw data privacy. Existing
approaches, however, can neither address the intense sample heterogeneity
caused by different working conditions of practical agents, nor the extreme
fault label scarcity, even zero, of newly deployed equipment. To address these
issues, we present FedLED, the first unsupervised vertical FTL equipment fault
diagnosis method, where knowledge of the unlabeled target domain is further
exploited for effective unsupervised model transfer. Results of extensive
experiments using data of real equipment monitoring demonstrate that FedLED
obviously outperforms SOTA approaches in terms of both diagnosis accuracy (up
to 4.13 times) and generality. We expect our work to inspire further study on
label-free equipment fault diagnosis systematically enhanced by target domain
knowledge.
</p></li>
</ul>

<h3>Title: LARP: Language-Agent Role Play for Open-World Games. (arXiv:2312.17653v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17653">http://arxiv.org/abs/2312.17653</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17653]] LARP: Language-Agent Role Play for Open-World Games(http://arxiv.org/abs/2312.17653)</code></li>
<li>Summary: <p>Language agents have shown impressive problem-solving skills within defined
settings and brief timelines. Yet, with the ever-evolving complexities of
open-world simulations, there's a pressing need for agents that can flexibly
adapt to complex environments and consistently maintain a long-term memory to
ensure coherent actions. To bridge the gap between language agents and
open-world games, we introduce Language Agent for Role-Playing (LARP), which
includes a cognitive architecture that encompasses memory processing and a
decision-making assistant, an environment interaction module with a
feedback-driven learnable action space, and a postprocessing method that
promotes the alignment of various personalities. The LARP framework refines
interactions between users and agents, predefined with unique backgrounds and
personalities, ultimately enhancing the gaming experience in open-world
contexts. Furthermore, it highlights the diverse uses of language models in a
range of areas such as entertainment, education, and various simulation
scenarios. The project page is released at https://miao-ai-lab.github.io/LARP/.
</p></li>
</ul>

<h3>Title: Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game. (arXiv:2312.17515v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.17515">http://arxiv.org/abs/2312.17515</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.17515]] Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game(http://arxiv.org/abs/2312.17515)</code></li>
<li>Summary: <p>Multi-agent collaboration with Large Language Models (LLMs) demonstrates
proficiency in basic tasks, yet its efficiency in more complex scenarios
remains unexplored. In gaming environments, these agents often face situations
without established coordination protocols, requiring them to make intelligent
inferences about teammates from limited data. This problem motivates the area
of ad hoc teamwork, in which an agent may potentially cooperate with a variety
of teammates to achieve a shared goal. Our study focuses on the ad hoc teamwork
problem where the agent operates in an environment driven by natural language.
Our findings reveal the potential of LLM agents in team collaboration,
highlighting issues related to hallucinations in communication. To address this
issue, we develop CodeAct, a general agent that equips LLM with enhanced memory
and code-driven reasoning, enabling the repurposing of partial information for
rapid adaptation to new teammates.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
