<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>language model</h2>
<h3>Title: Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation. (arXiv:2312.05276v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05276">http://arxiv.org/abs/2312.05276</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05276]] Making Large Language Models Better Knowledge Miners for Online Marketing with Progressive Prompting Augmentation(http://arxiv.org/abs/2312.05276)</code></li>
<li>Summary: <p>Nowadays, the rapid development of mobile economy has promoted the
flourishing of online marketing campaigns, whose success greatly hinges on the
efficient matching between user preferences and desired marketing campaigns
where a well-established Marketing-oriented Knowledge Graph (dubbed as MoKG)
could serve as the critical "bridge" for preference propagation. In this paper,
we seek to carefully prompt a Large Language Model (LLM) with domain-level
knowledge as a better marketing-oriented knowledge miner for marketing-oriented
knowledge graph construction, which is however non-trivial, suffering from
several inevitable issues in real-world marketing scenarios, i.e.,
uncontrollable relation generation of LLMs,insufficient prompting ability of a
single prompt, the unaffordable deployment cost of LLMs. To this end, we
propose PAIR, a novel Progressive prompting Augmented mIning fRamework for
harvesting marketing-oriented knowledge graph with LLMs. In particular, we
reduce the pure relation generation to an LLM based adaptive relation filtering
process through the knowledge-empowered prompting technique. Next, we steer
LLMs for entity expansion with progressive prompting augmentation,followed by a
reliable aggregation with comprehensive consideration of both self-consistency
and semantic relatedness. In terms of online serving, we specialize in a small
and white-box PAIR (i.e.,LightPAIR),which is fine-tuned with a high-quality
corpus provided by a strong teacher-LLM. Extensive experiments and practical
applications in audience targeting verify the effectiveness of the proposed
(Light)PAIR.
</p></li>
</ul>

<h3>Title: Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis. (arXiv:2312.05488v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05488">http://arxiv.org/abs/2312.05488</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05488]] Can Large Language Models Serve as Rational Players in Game Theory? A Systematic Analysis(http://arxiv.org/abs/2312.05488)</code></li>
<li>Summary: <p>Game theory, as an analytical tool, is frequently utilized to analyze human
behavior in social science research. With the high alignment between the
behavior of Large Language Models (LLMs) and humans, a promising research
direction is to employ LLMs as substitutes for humans in game experiments,
enabling social science research. However, despite numerous empirical
researches on the combination of LLMs and game theory, the capability
boundaries of LLMs in game theory remain unclear. In this research, we endeavor
to systematically analyze LLMs in the context of game theory. Specifically,
rationality, as the fundamental principle of game theory, serves as the metric
for evaluating players' behavior -- building a clear desire, refining belief
about uncertainty, and taking optimal actions. Accordingly, we select three
classical games (dictator game, Rock-Paper-Scissors, and ring-network game) to
analyze to what extent LLMs can achieve rationality in these three aspects. The
experimental results indicate that even the current state-of-the-art LLM
(GPT-4) exhibits substantial disparities compared to humans in game theory. For
instance, LLMs struggle to build desires based on uncommon preferences, fail to
refine belief from many simple patterns, and may overlook or modify refined
belief when taking actions. Therefore, we consider that introducing LLMs into
game experiments in the field of social science should be approached with
greater caution.
</p></li>
</ul>

<h3>Title: Using Captum to Explain Generative Language Models. (arXiv:2312.05491v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05491">http://arxiv.org/abs/2312.05491</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05491]] Using Captum to Explain Generative Language Models(http://arxiv.org/abs/2312.05491)</code></li>
<li>Summary: <p>Captum is a comprehensive library for model explainability in PyTorch,
offering a range of methods from the interpretability literature to enhance
users' understanding of PyTorch models. In this paper, we introduce new
features in Captum that are specifically designed to analyze the behavior of
generative language models. We provide an overview of the available
functionalities and example applications of their potential for understanding
learned associations within generative language models.
</p></li>
</ul>

<h3>Title: Aligner: One Global Token is Worth Millions of Parameters When Aligning Large Language Models. (arXiv:2312.05503v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05503">http://arxiv.org/abs/2312.05503</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05503]] Aligner: One Global Token is Worth Millions of Parameters When Aligning Large Language Models(http://arxiv.org/abs/2312.05503)</code></li>
<li>Summary: <p>We introduce Aligner, a novel Parameter-Efficient Fine-Tuning (PEFT) method
for aligning multi-billion-parameter-sized Large Language Models (LLMs).
Aligner employs a unique design that constructs a globally shared set of
tunable tokens that modify the attention of every layer. Remarkably with this
method, even when using one token accounting for a mere 5,000 parameters,
Aligner can still perform comparably well to state-of-the-art LLM adaptation
methods like LoRA that require millions of parameters. This capacity is
substantiated in both instruction following and value alignment tasks. Besides
the multiple order-of-magnitude improvement in parameter efficiency, the
insight Aligner provides into the internal mechanisms of LLMs is also valuable.
The architectural features and efficacy of our method, in addition to our
experiments demonstrate that an LLM separates its internal handling of "form"
and "knowledge" in a somewhat orthogonal manner. This finding promises to
motivate new research into LLM mechanism understanding and value alignment.
</p></li>
</ul>

<h3>Title: KEN: Kernel Extensions using Natural Language. (arXiv:2312.05531v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05531">http://arxiv.org/abs/2312.05531</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05531]] KEN: Kernel Extensions using Natural Language(http://arxiv.org/abs/2312.05531)</code></li>
<li>Summary: <p>The ability to modify and extend an operating system is an important feature
for improving a system's security, reliability, and performance. The extended
Berkeley Packet Filters (eBPF) ecosystem has emerged as the standard mechanism
for extending the Linux kernel and has recently been ported to Windows. eBPF
programs inject new logic into the kernel that the system will execute before
or after existing logic. While the eBPF ecosystem provides a flexible mechanism
for kernel extension, it is difficult for developers to write eBPF programs
today. An eBPF developer must have deep knowledge of the internals of the
operating system to determine where to place logic and cope with programming
limitations on the control flow and data accesses of their eBPF program
enforced by the eBPF verifier. This paper presents KEN, an alternative
framework that alleviates the difficulty of writing an eBPF program by allowing
Kernel Extensions to be written in Natural language. KEN uses recent advances
in large language models (LLMs) to synthesize an eBPF program given a user's
English language prompt. To ensure that LLM's output is semantically equivalent
to the user's prompt, KEN employs a combination of LLM-empowered program
comprehension, symbolic execution, and a series of feedback loops. KEN's key
novelty is the combination of these techniques. In particular, the system uses
symbolic execution in a novel structure that allows it to combine the results
of program synthesis and program comprehension and build on the recent success
that LLMs have shown for each of these tasks individually. To evaluate KEN, we
developed a new corpus of natural language prompts for eBPF programs. We show
that KEN produces correct eBPF programs on 80% which is an improvement of a
factor of 2.67 compared to an LLM-empowered program synthesis baseline.
</p></li>
</ul>

<h3>Title: Frugal LMs Trained to Invoke Symbolic Solvers Achieve Parameter-Efficient Arithmetic Reasoning. (arXiv:2312.05571v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05571">http://arxiv.org/abs/2312.05571</a></li>
<li>Code URL: https://github.com/joykirat18/syrelm</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05571]] Frugal LMs Trained to Invoke Symbolic Solvers Achieve Parameter-Efficient Arithmetic Reasoning(http://arxiv.org/abs/2312.05571)</code></li>
<li>Summary: <p>Large Language Models (LLM) exhibit zero-shot mathematical reasoning capacity
as a behavior emergent with scale, commonly manifesting as chain-of-thoughts
(CoT) reasoning. However, multiple empirical findings suggest that this prowess
is exclusive to LLMs with exorbitant sizes (beyond 50 billion parameters).
Meanwhile, educational neuroscientists suggest that symbolic algebraic
manipulation be introduced around the same time as arithmetic word problems to
modularize language-to-formulation, symbolic manipulation of the formulation,
and endgame arithmetic. In this paper, we start with the hypothesis that much
smaller LMs, which are weak at multi-step reasoning, can achieve reasonable
arithmetic reasoning if arithmetic word problems are posed as a
formalize-then-solve task. In our architecture, which we call SYRELM, the LM
serves the role of a translator to map natural language arithmetic questions
into a formal language (FL) description. A symbolic solver then evaluates the
FL expression to obtain the answer. A small frozen LM, equipped with an
efficient low-rank adapter, is capable of generating FL expressions that
incorporate natural language descriptions of the arithmetic problem (e.g.,
variable names and their purposes, formal expressions combining variables,
etc.). We adopt policy-gradient reinforcement learning to train the adapted LM,
informed by the non-differentiable symbolic solver. This marks a sharp
departure from the recent development in tool-augmented LLMs, in which the
external tools (e.g., calculator, Web search, etc.) are essentially detached
from the learning phase of the LM. SYRELM shows massive improvements (e.g.,
+30.65 absolute point improvement in accuracy on the SVAMP dataset using GPT-J
6B model) over base LMs, while keeping our testbed easy to diagnose, interpret
and within reach of most researchers.
</p></li>
</ul>

<h3>Title: Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding Bugs. (arXiv:2312.05588v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05588">http://arxiv.org/abs/2312.05588</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05588]] Language-assisted Vision Model Debugger: A Sample-Free Approach to Finding Bugs(http://arxiv.org/abs/2312.05588)</code></li>
<li>Summary: <p>Vision models with high overall accuracy often exhibit systematic errors in
specific scenarios, posing potential serious safety concerns. Diagnosing bugs
of vision models is gaining increased attention, however traditional diagnostic
approaches require annotation efforts (\eg rich metadata accompanying each
samples of CelebA). To address this issue,We propose a language-assisted
diagnostic method that uses texts instead of images to diagnose bugs in vision
models based on multi-modal models (\eg CLIP). Our approach connects the
embedding space of CLIP with the buggy vision model to be diagnosed; meanwhile,
utilizing a shared classifier and the cross-modal transferability of embedding
space from CLIP, the text-branch of CLIP become a proxy model to find bugs in
the buggy model. The proxy model can classify texts paired with images. During
the diagnosis, a Large Language Model (LLM) is employed to obtain task-relevant
corpora, and this corpora is used to extract keywords. Descriptions constructed
with templates containing these keywords serve as input text to probe errors in
the proxy model. Finally, we validate the ability to diagnose existing visual
models using language on the Waterbirds and CelebA datasets, we can identify
bugs comprehensible to human experts, uncovering not only known bugs but also
previously unknown ones.
</p></li>
</ul>

<h3>Title: Lyrics: Boosting Fine-grained Language-Vision Alignment and Comprehension via Semantic-aware Visual Objects. (arXiv:2312.05278v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05278">http://arxiv.org/abs/2312.05278</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05278]] Lyrics: Boosting Fine-grained Language-Vision Alignment and Comprehension via Semantic-aware Visual Objects(http://arxiv.org/abs/2312.05278)</code></li>
<li>Summary: <p>Large Vision Language Models (LVLMs) have demonstrated impressive zero-shot
capabilities in various vision-language dialogue scenarios. However, the
absence of fine-grained visual object detection hinders the model from
understanding the details of images, leading to irreparable visual
hallucinations and factual errors. In this paper, we propose Lyrics, a novel
multi-modal pre-training and instruction fine-tuning paradigm that bootstraps
vision-language alignment from fine-grained cross-modal collaboration. Building
on the foundation of BLIP-2, Lyrics infuses local visual features extracted
from a visual refiner that includes image tagging, object detection and
semantic segmentation modules into the Querying Transformer, while on the text
side, the language inputs equip the boundary boxes and tags derived from the
visual refiner. We further introduce a two-stage training scheme, in which the
pre-training stage bridges the modality gap through explicit and comprehensive
vision-language alignment targets. During the instruction fine-tuning stage, we
introduce semantic-aware visual feature extraction, a crucial method that
enables the model to extract informative features from concrete visual objects.
Our approach achieves strong performance on 13 held-out datasets across various
vision-language tasks, and demonstrates promising multi-modal understanding and
detailed depiction capabilities in real dialogue scenarios.
</p></li>
</ul>

<h3>Title: Towards Controlled Table-to-Text Generation with Scientific Reasoning. (arXiv:2312.05402v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05402">http://arxiv.org/abs/2312.05402</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05402]] Towards Controlled Table-to-Text Generation with Scientific Reasoning(http://arxiv.org/abs/2312.05402)</code></li>
<li>Summary: <p>The sheer volume of scientific experimental results and complex technical
statements, often presented in tabular formats, presents a formidable barrier
to individuals acquiring preferred information. The realms of scientific
reasoning and content generation that adhere to user preferences encounter
distinct challenges. In this work, we present a new task for generating fluent
and logical descriptions that match user preferences over scientific tabular
data, aiming to automate scientific document analysis. To facilitate research
in this direction, we construct a new challenging dataset CTRLSciTab consisting
of table-description pairs extracted from the scientific literature, with
highlighted cells and corresponding domain-specific knowledge base. We
evaluated popular pre-trained language models to establish a baseline and
proposed a novel architecture outperforming competing approaches. The results
showed that large models struggle to produce accurate content that aligns with
user preferences. As the first of its kind, our work should motivate further
research in scientific domains.
</p></li>
</ul>

<h3>Title: Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models. (arXiv:2312.05434v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05434">http://arxiv.org/abs/2312.05434</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05434]] Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning Distilled from Large Language Models(http://arxiv.org/abs/2312.05434)</code></li>
<li>Summary: <p>The age of social media is rife with memes. Understanding and detecting
harmful memes pose a significant challenge due to their implicit meaning that
is not explicitly conveyed through the surface text and image. However,
existing harmful meme detection approaches only recognize superficial
harm-indicative signals in an end-to-end classification manner but ignore
in-depth cognition of the meme text and image. In this paper, we attempt to
detect harmful memes based on advanced reasoning over the interplay of
multimodal information in memes. Inspired by the success of Large Language
Models (LLMs) on complex reasoning, we first conduct abductive reasoning with
LLMs. Then we propose a novel generative framework to learn reasonable thoughts
from LLMs for better multimodal fusion and lightweight fine-tuning, which
consists of two training stages: 1) Distill multimodal reasoning knowledge from
LLMs; and 2) Fine-tune the generative framework to infer harmfulness. Extensive
experiments conducted on three meme datasets demonstrate that our proposed
approach achieves superior performance than state-of-the-art methods on the
harmful meme detection task.
</p></li>
</ul>

<h3>Title: Domain Adaptation of a State of the Art Text-to-SQL Model: Lessons Learned and Challenges Found. (arXiv:2312.05448v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05448">http://arxiv.org/abs/2312.05448</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05448]] Domain Adaptation of a State of the Art Text-to-SQL Model: Lessons Learned and Challenges Found(http://arxiv.org/abs/2312.05448)</code></li>
<li>Summary: <p>There are many recent advanced developments for the Text-to-SQL task, where
the Picard model is one of the the top performing models as measured by the
Spider dataset competition. However, bringing Text-to-SQL systems to realistic
use-cases through domain adaptation remains a tough challenge. We analyze how
well the base T5 Language Model and Picard perform on query structures
different from the Spider dataset, we fine-tuned the base model on the Spider
data and on independent databases (DB). To avoid accessing the DB content
online during inference, we also present an alternative way to disambiguate the
values in an input question using a rule-based approach that relies on an
intermediate representation of the semantic concepts of an input question. In
our results we show in what cases T5 and Picard can deliver good performance,
we share the lessons learned, and discuss current domain adaptation challenges.
</p></li>
</ul>

<h3>Title: Teamwork Dimensions Classification Using BERT. (arXiv:2312.05483v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05483">http://arxiv.org/abs/2312.05483</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05483]] Teamwork Dimensions Classification Using BERT(http://arxiv.org/abs/2312.05483)</code></li>
<li>Summary: <p>Teamwork is a necessary competency for students that is often inadequately
assessed. Towards providing a formative assessment of student teamwork, an
automated natural language processing approach was developed to identify
teamwork dimensions of students' online team chat. Developments in the field of
natural language processing and artificial intelligence have resulted in
advanced deep transfer learning approaches namely the Bidirectional Encoder
Representations from Transformers (BERT) model that allow for more in-depth
understanding of the context of the text. While traditional machine learning
algorithms were used in the previous work for the automatic classification of
chat messages into the different teamwork dimensions, our findings have shown
that classifiers based on the pre-trained language model BERT provides improved
classification performance, as well as much potential for generalizability in
the language use of varying team chat contexts and team member demographics.
This model will contribute towards an enhanced learning analytics tool for
teamwork assessment and feedback.
</p></li>
</ul>

<h3>Title: History Matters: Temporal Knowledge Editing in Large Language Model. (arXiv:2312.05497v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05497">http://arxiv.org/abs/2312.05497</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05497]] History Matters: Temporal Knowledge Editing in Large Language Model(http://arxiv.org/abs/2312.05497)</code></li>
<li>Summary: <p>The imperative task of revising or updating the knowledge stored within large
language models arises from two distinct sources: intrinsic errors inherent in
the model which should be corrected and outdated knowledge due to external
shifts in the real world which should be updated. Prevailing efforts in model
editing conflate these two distinct categories of edits arising from distinct
reasons and directly modify the original knowledge in models into new
knowledge. However, we argue that preserving the model's original knowledge
remains pertinent. Specifically, if a model's knowledge becomes outdated due to
evolving worldly dynamics, it should retain recollection of the historical
knowledge while integrating the newfound knowledge. In this work, we introduce
the task of Temporal Knowledge Editing (TKE) and establish a benchmark AToKe
(Assessment of TempOral Knowledge Editing) to evaluate current model editing
methods. We find that while existing model editing methods are effective at
making models remember new knowledge, the edited model catastrophically forgets
historical knowledge. To address this gap, we propose a simple and general
framework termed Multi-Editing with Time Objective (METO) for enhancing
existing editing models, which edits both historical and new knowledge
concurrently and optimizes the model's prediction for the time of each fact.
Our assessments demonstrate that while AToKe is still difficult, METO maintains
the effectiveness of learning new knowledge and meanwhile substantially
improves the performance of edited models on utilizing historical knowledge.
</p></li>
</ul>

<h3>Title: Enhancing Medical Specialty Assignment to Patients using NLP Techniques. (arXiv:2312.05585v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05585">http://arxiv.org/abs/2312.05585</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05585]] Enhancing Medical Specialty Assignment to Patients using NLP Techniques(http://arxiv.org/abs/2312.05585)</code></li>
<li>Summary: <p>The introduction of Large Language Models (LLMs), and the vast volume of
publicly available medical data, amplified the application of NLP to the
medical domain. However, LLMs are pretrained on data that are not explicitly
relevant to the domain that are applied to and are often biased towards the
original data they were pretrained upon. Even when pretrained on domainspecific
data, these models typically require time-consuming fine-tuning to achieve good
performance for a specific task. To address these limitations, we propose an
alternative approach that achieves superior performance while being
computationally efficient. Specifically, we utilize keywords to train a deep
learning architecture that outperforms a language model pretrained on a large
corpus of text. Our proposal does not require pretraining nor fine-tuning and
can be applied directly to a specific setting for performing multi-label
classification. Our objective is to automatically assign a new patient to the
specialty of the medical professional they require, using a dataset that
contains medical transcriptions and relevant keywords. To this end, we
fine-tune the PubMedBERT model on this dataset, which serves as the baseline
for our experiments. We then twice train/fine-tune a DNN and the RoBERTa
language model, using both the keywords and the full transcriptions as input.
We compare the performance of these approaches using relevant metrics. Our
results demonstrate that utilizing keywords for text classification
significantly improves classification performance, for both a basic DL
architecture and a large language model. Our approach represents a promising
and efficient alternative to traditional methods for finetuning language models
on domain-specific data and has potential applications in various medical
domains
</p></li>
</ul>

<h3>Title: Stateful Large Language Model Serving with Pensieve. (arXiv:2312.05516v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05516">http://arxiv.org/abs/2312.05516</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05516]] Stateful Large Language Model Serving with Pensieve(http://arxiv.org/abs/2312.05516)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have recently experienced great success, as
evident in the widespread popularity of ChatGPT. Existing LLM serving systems
are stateless across requests. Consequently, when LLMs are used in the common
setting of multi-turn conversations, a growing log of the conversation history
must be processed alongside any request by the serving system at each turn,
resulting in repeated history processing. In this paper, we design $Pensieve$,
a system optimized for multi-turn conversation LLM serving. $Pensieve$
maintains the conversation state across requests by caching previously
processed history to avoid duplicate processing. $Pensieve$'s multi-tier
caching strategy can utilize both GPU and CPU memory to efficiently store and
retrieve cached data. $Pensieve$ also generalizes the recent PagedAttention
kernel to support attention between multiple input tokens with a GPU cache
spread over non-contiguous memory. Our evaluation shows that $Pensieve$ is able
to achieve 1.51-1.95x throughput compared to vLLM and reduce latency by 60-75%.
</p></li>
</ul>

<h2>gpt</h2>
<h3>Title: Image and Data Mining in Reticular Chemistry Using GPT-4V. (arXiv:2312.05468v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05468">http://arxiv.org/abs/2312.05468</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05468]] Image and Data Mining in Reticular Chemistry Using GPT-4V(http://arxiv.org/abs/2312.05468)</code></li>
<li>Summary: <p>The integration of artificial intelligence into scientific research has
reached a new pinnacle with GPT-4V, a large language model featuring enhanced
vision capabilities, accessible through ChatGPT or an API. This study
demonstrates the remarkable ability of GPT-4V to navigate and obtain complex
data for metal-organic frameworks, especially from graphical sources. Our
approach involved an automated process of converting 346 scholarly articles
into 6240 images, which represents a benchmark dataset in this task, followed
by deploying GPT-4V to categorize and analyze these images using natural
language prompts. This methodology enabled GPT-4V to accurately identify and
interpret key plots integral to MOF characterization, such as nitrogen
isotherms, PXRD patterns, and TGA curves, among others, with accuracy and
recall above 93%. The model's proficiency in extracting critical information
from these plots not only underscores its capability in data mining but also
highlights its potential in aiding the creation of comprehensive digital
databases for reticular chemistry. In addition, the extracted nitrogen isotherm
data from the selected literature allowed for a comparison between theoretical
and experimental porosity values for over 200 compounds, highlighting certain
discrepancies and underscoring the importance of integrating computational and
experimental data. This work highlights the potential of AI in accelerating
scientific discovery and innovation, bridging the gap between computational
tools and experimental research, and paving the way for more efficient,
inclusive, and comprehensive scientific inquiry.
</p></li>
</ul>

<h3>Title: Artificial Intelligence in the automatic coding of interviews on Landscape Quality Objectives. Comparison and case study. (arXiv:2312.05597v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05597">http://arxiv.org/abs/2312.05597</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05597]] Artificial Intelligence in the automatic coding of interviews on Landscape Quality Objectives(http://arxiv.org/abs/2312.05597)</code></li>
<li>Summary: <p>In this study, we conducted a comparative analysis of the automated coding
provided by three Artificial Intelligence functionalities (At-las.ti, ChatGPT
and Google Bard) in relation to the manual coding of 12 research interviews
focused on Landscape Quality Objectives for a small island in the north of Cuba
(Cayo Santa Mar\'ia). For this purpose, the following comparison criteria were
established: Accuracy, Comprehensiveness, Thematic Coherence, Redundancy,
Clarity, Detail and Regularity. The analysis showed the usefulness of AI for
the intended purpose, albeit with numerous flaws and shortcomings. In summary,
today the automatic coding of AIs can be considered useful as a guide towards a
subsequent in-depth and meticulous analysis of the information by the
researcher. However, as this is such a recently developed field, rapid
evolution is expected to bring the necessary improvements to these tools.
</p></li>
</ul>

<h2>llm</h2>
<h3>Title: Dynamic Adjustment of Matching Radii under the Broadcasting Mode: A Novel Multitask Learning Strategy and Temporal Modeling Approach. (arXiv:2312.05576v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05576">http://arxiv.org/abs/2312.05576</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05576]] Dynamic Adjustment of Matching Radii under the Broadcasting Mode: A Novel Multitask Learning Strategy and Temporal Modeling Approach(http://arxiv.org/abs/2312.05576)</code></li>
<li>Summary: <p>As ride-hailing services have experienced significant growth, the majority of
research has concentrated on the dispatching mode, where drivers must adhere to
the platform's assigned routes. However, the broadcasting mode, in which
drivers can freely choose their preferred orders from those broadcast by the
platform, has received less attention. One important but challenging task in
such a system is the determination of the optimal matching radius, which
usually varies across space, time, and real-time supply/demand characteristics.
This study develops a Transformer-Encoder-Based (TEB) model that predicts key
system performance metrics for a range of matching radii, which enables the
ride-hailing platform to select an optimal matching radius that maximizes
overall system performance according to real-time supply and demand
information. To simultaneously maximize multiple system performance metrics for
matching radius determination, we devise a novel multi-task learning algorithm
that enhances convergence speed of each task (corresponding to the optimization
of one metric) and delivers more accurate overall predictions. We evaluate our
methods in a simulation environment specifically designed for
broadcasting-mode-based ride-hailing service. Our findings reveal that
dynamically adjusting matching radii based on our proposed
predict-then-optimize approach significantly improves system performance, e.g.,
increasing platform revenue by 7.55% and enhancing order fulfillment rate by
13% compared to benchmark algorithms.
</p></li>
</ul>

<h2>long context</h2>
<h2>lora</h2>
<h3>Title: A Review of Hybrid and Ensemble in Deep Learning for Natural Language Processing. (arXiv:2312.05589v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05589">http://arxiv.org/abs/2312.05589</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05589]] A Review of Hybrid and Ensemble in Deep Learning for Natural Language Processing(http://arxiv.org/abs/2312.05589)</code></li>
<li>Summary: <p>This review presents a comprehensive exploration of hybrid and ensemble deep
learning models within Natural Language Processing (NLP), shedding light on
their transformative potential across diverse tasks such as Sentiment Analysis,
Named Entity Recognition, Machine Translation, Question Answering, Text
Classification, Generation, Speech Recognition, Summarization, and Language
Modeling. The paper systematically introduces each task, delineates key
architectures from Recurrent Neural Networks (RNNs) to Transformer-based models
like BERT, and evaluates their performance, challenges, and computational
demands. The adaptability of ensemble techniques is emphasized, highlighting
their capacity to enhance various NLP applications. Challenges in
implementation, including computational overhead, overfitting, and model
interpretation complexities, are addressed alongside the trade-off between
interpretability and performance. Serving as a concise yet invaluable guide,
this review synthesizes insights into tasks, architectures, and challenges,
offering a holistic perspective for researchers and practitioners aiming to
advance language-driven applications through ensemble deep learning in NLP.
</p></li>
</ul>

<h3>Title: Towards On-device Learning on the Edge: Ways to Select Neurons to Update under a Budget Constraint. (arXiv:2312.05282v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05282">http://arxiv.org/abs/2312.05282</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05282]] Towards On-device Learning on the Edge: Ways to Select Neurons to Update under a Budget Constraint(http://arxiv.org/abs/2312.05282)</code></li>
<li>Summary: <p>In the realm of efficient on-device learning under extreme memory and
computation constraints, a significant gap in successful approaches persists.
Although considerable effort has been devoted to efficient inference, the main
obstacle to efficient learning is the prohibitive cost of backpropagation. The
resources required to compute gradients and update network parameters often
exceed the limits of tightly constrained memory budgets. This paper challenges
conventional wisdom and proposes a series of experiments that reveal the
existence of superior sub-networks. Furthermore, we hint at the potential for
substantial gains through a dynamic neuron selection strategy when fine-tuning
a target task. Our efforts extend to the adaptation of a recent dynamic neuron
selection strategy pioneered by Bragagnolo et al. (NEq), revealing its
effectiveness in the most stringent scenarios. Our experiments demonstrate, in
the average case, the superiority of a NEq-inspired approach over a random
selection. This observation prompts a compelling avenue for further exploration
in the area, highlighting the opportunity to design a new class of algorithms
designed to facilitate parameter update selection. Our findings usher in a new
era of possibilities in the field of on-device learning under extreme
constraints and encourage the pursuit of innovative strategies for efficient,
resource-friendly model fine-tuning.
</p></li>
</ul>

<h3>Title: Enhancing the Accuracy of Predictors of Activity Sequences of Business Processes. (arXiv:2312.05560v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05560">http://arxiv.org/abs/2312.05560</a></li>
<li>Code URL: https://github.com/awaisali37405/lstm---daemon-action</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05560]] Enhancing the Accuracy of Predictors of Activity Sequences of Business Processes(http://arxiv.org/abs/2312.05560)</code></li>
<li>Summary: <p>Predictive process monitoring is an evolving research field that studies how
to train and use predictive models for operational decision-making. One of the
problems studied in this field is that of predicting the sequence of upcoming
activities in a case up to its completion, a.k.a. the case suffix. The
prediction of case suffixes provides input to estimate short-term workloads and
execution times under different resource schedules. Existing methods to address
this problem often generate suffixes wherein some activities are repeated many
times, whereas this pattern is not observed in the data. Closer examination
shows that this shortcoming stems from the approach used to sample the
successive activity instances to generate a case suffix. Accordingly, the paper
introduces a sampling approach aimed at reducing repetitions of activities in
the predicted case suffixes. The approach, namely Daemon action, strikes a
balance between exploration and exploitation when generating the successive
activity instances. We enhance a deep learning approach for case suffix
predictions using this sampling approach, and experimentally show that the
enhanced approach outperforms the unenhanced ones with respect to control-flow
accuracy measures.
</p></li>
</ul>

<h2>hallucination</h2>
<h2>prompt</h2>
<h2>code</h2>
<h3>Title: Multimodal Group Emotion Recognition In-the-wild Using Privacy-Compliant Features. (arXiv:2312.05265v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05265">http://arxiv.org/abs/2312.05265</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05265]] Multimodal Group Emotion Recognition In-the-wild Using Privacy-Compliant Features(http://arxiv.org/abs/2312.05265)</code></li>
<li>Summary: <p>This paper explores privacy-compliant group-level emotion recognition
''in-the-wild'' within the EmotiW Challenge 2023. Group-level emotion
recognition can be useful in many fields including social robotics,
conversational agents, e-coaching and learning analytics. This research imposes
itself using only global features avoiding individual ones, i.e. all features
that can be used to identify or track people in videos (facial landmarks, body
poses, audio diarization, etc.). The proposed multimodal model is composed of a
video and an audio branches with a cross-attention between modalities. The
video branch is based on a fine-tuned ViT architecture. The audio branch
extracts Mel-spectrograms and feed them through CNN blocks into a transformer
encoder. Our training paradigm includes a generated synthetic dataset to
increase the sensitivity of our model on facial expression within the image in
a data-driven way. The extensive experiments show the significance of our
methodology. Our privacy-compliant proposal performs fairly on the EmotiW
challenge, with 79.24% and 75.13% of accuracy respectively on validation and
test set for the best models. Noticeably, our findings highlight that it is
possible to reach this accuracy level with privacy-compliant features using
only 5 frames uniformly distributed on the video.
</p></li>
</ul>

<h3>Title: Emergence and Function of Abstract Representations in Self-Supervised Transformers. (arXiv:2312.05361v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05361">http://arxiv.org/abs/2312.05361</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05361]] Emergence and Function of Abstract Representations in Self-Supervised Transformers(http://arxiv.org/abs/2312.05361)</code></li>
<li>Summary: <p>Human intelligence relies in part on our brains' ability to create abstract
mental models that succinctly capture the hidden blueprint of our reality. Such
abstract world models notably allow us to rapidly navigate novel situations by
generalizing prior knowledge, a trait deep learning systems have historically
struggled to replicate. However, the recent shift from supervised to
self-supervised objectives, combined with expressive transformer-based
architectures, have yielded powerful foundation models that appear to learn
versatile representations that can support a wide range of downstream tasks.
This promising development raises the intriguing possibility of such models
developing in silico abstract world models. We test this hypothesis by studying
the inner workings of small-scale transformers trained to reconstruct partially
masked visual scenes generated from a simple blueprint. We show that the
network develops intermediate abstract representations, or abstractions, that
encode all semantic features of the dataset. These abstractions manifest as
low-dimensional manifolds where the embeddings of semantically related tokens
transiently converge, thus allowing for the generalization of downstream
computations. Using precise manipulation experiments, we demonstrate that
abstractions are central to the network's decision-making process. Our research
also suggests that these abstractions are compositionally structured,
exhibiting features like contextual independence and part-whole relationships
that mirror the compositional nature of the dataset. Finally, we introduce a
Language-Enhanced Architecture (LEA) designed to encourage the network to
articulate its computations. We find that LEA develops an abstraction-centric
language that can be easily interpreted, allowing us to more readily access and
steer the network's decision-making process.
</p></li>
</ul>

<h3>Title: Large-scale Training of Foundation Models for Wearable Biosignals. (arXiv:2312.05409v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05409">http://arxiv.org/abs/2312.05409</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05409]] Large-scale Training of Foundation Models for Wearable Biosignals(http://arxiv.org/abs/2312.05409)</code></li>
<li>Summary: <p>Tracking biosignals is crucial for monitoring wellness and preempting the
development of severe medical conditions. Today, wearable devices can
conveniently record various biosignals, creating the opportunity to monitor
health status without disruption to one's daily routine. Despite widespread use
of wearable devices and existing digital biomarkers, the absence of curated
data with annotated medical labels hinders the development of new biomarkers to
measure common health conditions. In fact, medical datasets are usually small
in comparison to other domains, which is an obstacle for developing neural
network models for biosignals. To address this challenge, we have employed
self-supervised learning using the unlabeled sensor data collected under
informed consent from the large longitudinal Apple Heart and Movement Study
(AHMS) to train foundation models for two common biosignals:
photoplethysmography (PPG) and electrocardiogram (ECG) recorded on Apple Watch.
We curated PPG and ECG datasets from AHMS that include data from ~141K
participants spanning ~3 years. Our self-supervised learning framework includes
participant level positive pair selection, stochastic augmentation module and a
regularized contrastive loss optimized with momentum training, and generalizes
well to both PPG and ECG modalities. We show that the pre-trained foundation
models readily encode information regarding participants' demographics and
health conditions. To the best of our knowledge, this is the first study that
builds foundation models using large-scale PPG and ECG data collected via
wearable consumer devices $\unicode{x2013}$ prior works have commonly used
smaller-size datasets collected in clinical and experimental settings. We
believe PPG and ECG foundation models can enhance future wearable devices by
reducing the reliance on labeled data and hold the potential to help the users
improve their health.
</p></li>
</ul>

<h3>Title: Stochastic Directly-Follows Process Discovery Using Grammatical Inference. (arXiv:2312.05433v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05433">http://arxiv.org/abs/2312.05433</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05433]] Stochastic Directly-Follows Process Discovery Using Grammatical Inference(http://arxiv.org/abs/2312.05433)</code></li>
<li>Summary: <p>Starting with a collection of traces generated by process executions, process
discovery is the task of constructing a simple model that describes the
process, where simplicity is often measured in terms of model size. The
challenge of process discovery is that the process of interest is unknown, and
that while the input traces constitute positive examples of process executions,
no negative examples are available. Many commercial tools discover
Directly-Follows Graphs, in which nodes represent the observable actions of the
process, and directed arcs indicate execution order possibilities over the
actions. We propose a new approach for discovering sound Directly-Follows
Graphs that is grounded in grammatical inference over the input traces. To
promote the discovery of small graphs that also describe the process accurately
we design and evaluate a genetic algorithm that supports the convergence of the
inference parameters to the areas that lead to the discovery of interesting
models. Experiments over real-world datasets confirm that our new approach can
construct smaller models that represent the input traces and their frequencies
more accurately than the state-of-the-art technique. Reasoning over the
frequencies of encoded traces also becomes possible, due to the stochastic
semantics of the action graphs we propose, which, for the first time, are
interpreted as models that describe the stochastic languages of action traces.
</p></li>
</ul>

<h3>Title: Deeper Understanding of Black-box Predictions via Generalized Influence Functions. (arXiv:2312.05586v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05586">http://arxiv.org/abs/2312.05586</a></li>
<li>Code URL: https://github.com/hslyu/gif</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05586]] Deeper Understanding of Black-box Predictions via Generalized Influence Functions(http://arxiv.org/abs/2312.05586)</code></li>
<li>Summary: <p>Influence functions (IFs) elucidate how learning data affects model behavior.
However, growing non-convexity and the number of parameters in modern
large-scale models lead to imprecise influence approximation and instability in
computations. We highly suspect that the first-order approximation in large
models causes such fragility, as IFs change all parameters including possibly
nuisance parameters that are irrelevant to the examined data. Thus, we attempt
to selectively analyze parameters associated with the data. However, simply
computing influence from the chosen parameters can be misleading, as it fails
to nullify the subliminal impact of unselected parameters. Our approach
introduces generalized IFs, precisely estimating target parameters' influence
while considering fixed parameters' effects. Unlike the classic IFs, we newly
adopt a method to identify pertinent target parameters closely associated with
the analyzed data. Furthermore, we tackle computational instability with a
robust inverse-Hessian-vector product approximation. Remarkably, the proposed
approximation algorithm guarantees convergence regardless of the network
configurations. We evaluated our approach on ResNet-18 and VGG-11 for class
removal and backdoor model recovery. Modifying just 10\% of the network yields
results comparable to the network retrained from scratch. Aligned with our
first guess, we also confirm that modifying an excessive number of parameters
results in a decline in network utility. We believe our proposal can become a
versatile tool for model analysis across various AI domains, appealing to both
specialists and general readers. Codes are available at
https://github.com/hslyu/GIF.
</p></li>
</ul>

<h3>Title: Target to Source: Guidance-Based Diffusion Model for Test-Time Adaptation. (arXiv:2312.05274v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05274">http://arxiv.org/abs/2312.05274</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05274]] Target to Source: Guidance-Based Diffusion Model for Test-Time Adaptation(http://arxiv.org/abs/2312.05274)</code></li>
<li>Summary: <p>Most recent works of test-time adaptation (TTA) aim to alleviate domain shift
problems by re-training source classifiers in each domain. On the other hand,
the emergence of the diffusion model provides another solution to TTA, which
directly maps the test data from the target domain to the source domain based
on a diffusion model pre-trained in the source domain. The source classifier
does not need to be fine-tuned. However, 1) the semantic information loss from
test data to the source domain and 2) the model shift between the source
classifier and diffusion model would prevent the diffusion model from mapping
the test data back to the source domain correctly. In this paper, we propose a
novel guidance-based diffusion-driven adaptation (GDDA) to overcome the data
shift and let the diffusion model find a better way to go back to the source.
Concretely, we first propose detail and global guidance to better keep the
common semantics of the test and source data. The two guidance include a
contrastive loss and mean squared error to alleviate the information loss by
fully exploring the diffusion model and the test data. Meanwhile, we propose a
classifier-aware guidance to reduce the bias caused by the model shift, which
can incorporate the source classifier's information into the generation process
of the diffusion model. Extensive experiments on three image datasets with
three classifier backbones demonstrate that GDDA significantly performs better
than the state-of-the-art baselines. On CIFAR-10C, CIFAR-100C, and ImageNetC,
GDDA achieves 11.54\%, 19.05\%, and 11.63\% average accuracy improvements,
respectively. GDDA even achieves equal performance compared with methods of
re-training classifiers. The code is available in the supplementary material.
</p></li>
</ul>

<h3>Title: On the calibration of compartmental epidemiological models. (arXiv:2312.05456v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05456">http://arxiv.org/abs/2312.05456</a></li>
<li>Code URL: https://github.com/nikunj-gupta/on-the-calibration-of-compartmental-epidemiological-models</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05456]] On the calibration of compartmental epidemiological models(http://arxiv.org/abs/2312.05456)</code></li>
<li>Summary: <p>Epidemiological compartmental models are useful for understanding infectious
disease propagation and directing public health policy decisions. Calibration
of these models is an important step in offering accurate forecasts of disease
dynamics and the effectiveness of interventions. In this study, we present an
overview of calibrating strategies that can be employed, including several
optimization methods and reinforcement learning (RL). We discuss the benefits
and drawbacks of these methods and highlight relevant practical conclusions
from our experiments. Optimization methods iteratively adjust the parameters of
the model until the model output matches the available data, whereas RL uses
trial and error to learn the optimal set of parameters by maximizing a reward
signal. Finally, we discuss how the calibration of parameters of
epidemiological compartmental models is an emerging field that has the
potential to improve the accuracy of disease modeling and public health
decision-making. Further research is needed to validate the effectiveness and
scalability of these approaches in different epidemiological contexts. All
codes and resources are available on
\url{https://github.com/Nikunj-Gupta/On-the-Calibration-of-Compartmental-Epidemiological-Models}.
We hope this work can facilitate related research.
</p></li>
</ul>

<h3>Title: Isomorphic-Consistent Variational Graph Auto-Encoders for Multi-Level Graph Representation Learning. (arXiv:2312.05519v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05519">http://arxiv.org/abs/2312.05519</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05519]] Isomorphic-Consistent Variational Graph Auto-Encoders for Multi-Level Graph Representation Learning(http://arxiv.org/abs/2312.05519)</code></li>
<li>Summary: <p>Graph representation learning is a fundamental research theme and can be
generalized to benefit multiple downstream tasks from the node and link levels
to the higher graph level. In practice, it is desirable to develop
task-agnostic general graph representation learning methods that are typically
trained in an unsupervised manner. Related research reveals that the power of
graph representation learning methods depends on whether they can differentiate
distinct graph structures as different embeddings and map isomorphic graphs to
consistent embeddings (i.e., the isomorphic consistency of graph models).
However, for task-agnostic general graph representation learning, existing
unsupervised graph models, represented by the variational graph auto-encoders
(VGAEs), can only keep the isomorphic consistency within the subgraphs of 1-hop
neighborhoods and thus usually manifest inferior performance on the more
difficult higher-level tasks. To overcome the limitations of existing
unsupervised methods, in this paper, we propose the Isomorphic-Consistent VGAE
(IsoC-VGAE) for multi-level task-agnostic graph representation learning. We
first devise a decoding scheme to provide a theoretical guarantee of keeping
the isomorphic consistency under the settings of unsupervised learning. We then
propose the Inverse Graph Neural Network (Inv-GNN) decoder as its intuitive
realization, which trains the model via reconstructing the GNN node embeddings
with multi-hop neighborhood information, so as to maintain the high-order
isomorphic consistency within the VGAE framework. We conduct extensive
experiments on the representative graph learning tasks at different levels,
including node classification, link prediction and graph classification, and
the results verify that our proposed model generally outperforms both the
state-of-the-art unsupervised methods and representative supervised methods.
</p></li>
</ul>

<h3>Title: Multi-granularity Causal Structure Learning. (arXiv:2312.05549v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05549">http://arxiv.org/abs/2312.05549</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05549]] Multi-granularity Causal Structure Learning(http://arxiv.org/abs/2312.05549)</code></li>
<li>Summary: <p>Unveil, model, and comprehend the causal mechanisms underpinning natural
phenomena stand as fundamental endeavors across myriad scientific disciplines.
Meanwhile, new knowledge emerges when discovering causal relationships from
data. Existing causal learning algorithms predominantly focus on the isolated
effects of variables, overlook the intricate interplay of multiple variables
and their collective behavioral patterns. Furthermore, the ubiquity of
high-dimensional data exacts a substantial temporal cost for causal algorithms.
In this paper, we develop a novel method called MgCSL (Multi-granularity Causal
Structure Learning), which first leverages sparse auto-encoder to explore
coarse-graining strategies and causal abstractions from micro-variables to
macro-ones. MgCSL then takes multi-granularity variables as inputs to train
multilayer perceptrons and to delve the causality between variables. To enhance
the efficacy on high-dimensional data, MgCSL introduces a simplified acyclicity
constraint to adeptly search the directed acyclic graph among variables.
Experimental results show that MgCSL outperforms competitive baselines, and
finds out explainable causal connections on fMRI datasets.
</p></li>
</ul>

<h3>Title: Boosting the Cross-Architecture Generalization of Dataset Distillation through an Empirical Study. (arXiv:2312.05598v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05598">http://arxiv.org/abs/2312.05598</a></li>
<li>Code URL: https://github.com/lirui-zhao/elf</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05598]] Boosting the Cross-Architecture Generalization of Dataset Distillation through an Empirical Study(http://arxiv.org/abs/2312.05598)</code></li>
<li>Summary: <p>The poor cross-architecture generalization of dataset distillation greatly
weakens its practical significance. This paper attempts to mitigate this issue
through an empirical study, which suggests that the synthetic datasets undergo
an inductive bias towards the distillation model. Therefore, the evaluation
model is strictly confined to having similar architectures of the distillation
model. We propose a novel method of EvaLuation with distillation Feature (ELF),
which utilizes features from intermediate layers of the distillation model for
the cross-architecture evaluation. In this manner, the evaluation model learns
from bias-free knowledge therefore its architecture becomes unfettered while
retaining performance. By performing extensive experiments, we successfully
prove that ELF can well enhance the cross-architecture generalization of
current DD methods. Code of this project is at
\url{https://github.com/Lirui-Zhao/ELF}.
</p></li>
</ul>

<h2>chat</h2>
<h3>Title: Fine-Grained Analysis of Team Collaborative Dialogue. (arXiv:2312.05471v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05471">http://arxiv.org/abs/2312.05471</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05471]] Fine-Grained Analysis of Team Collaborative Dialogue(http://arxiv.org/abs/2312.05471)</code></li>
<li>Summary: <p>Natural language analysis of human collaborative chat dialogues is an
understudied domain with many unique challenges: a large number of dialogue act
labels, underspecified and dynamic tasks, interleaved topics, and long-range
contextual dependence. While prior work has studied broad metrics of team
dialogue and associated performance using methods such as LSA, there has been
little effort in generating fine-grained descriptions of team dynamics and
individual performance from dialogue. We describe initial work towards
developing an explainable analytics tool in the software development domain
using Slack chats mined from our organization, including generation of a novel,
hierarchical labeling scheme; design of descriptive metrics based on the
frequency of occurrence of dialogue acts; and initial results using a
transformer + CRF architecture to incorporate long-range context.
</p></li>
</ul>

<h2>retrieval augmented generation</h2>
<h2>rag</h2>
<h3>Title: Optimizing the Passenger Flow for Airport Security Check. (arXiv:2312.05259v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05259">http://arxiv.org/abs/2312.05259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05259]] Optimizing the Passenger Flow for Airport Security Check(http://arxiv.org/abs/2312.05259)</code></li>
<li>Summary: <p>Due to the necessary security for the airport and flight, passengers are
required to have strict security check before getting aboard. However, there
are frequent complaints of wasting huge amount of time while waiting for the
security check. This paper presents a potential solution aimed at optimizing
gate setup procedures specifically tailored for Chicago OHare International
Airport. By referring to queueing theory and performing Monte Carlo
simulations, we propose an approach to significantly diminish the average
waiting time to a more manageable level. Additionally, our study meticulously
examines and identifies the influential factors contributing to this
optimization, providing a comprehensive understanding of their impact.
</p></li>
</ul>

<h3>Title: Sparse Variational Student-t Processes. (arXiv:2312.05568v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05568">http://arxiv.org/abs/2312.05568</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05568]] Sparse Variational Student-t Processes(http://arxiv.org/abs/2312.05568)</code></li>
<li>Summary: <p>The theory of Bayesian learning incorporates the use of Student-t Processes
to model heavy-tailed distributions and datasets with outliers. However,
despite Student-t Processes having a similar computational complexity as
Gaussian Processes, there has been limited emphasis on the sparse
representation of this model. This is mainly due to the increased difficulty in
modeling and computation compared to previous sparse Gaussian Processes. Our
motivation is to address the need for a sparse representation framework that
reduces computational complexity, allowing Student-t Processes to be more
flexible for real-world datasets. To achieve this, we leverage the conditional
distribution of Student-t Processes to introduce sparse inducing points.
Bayesian methods and variational inference are then utilized to derive a
well-defined lower bound, facilitating more efficient optimization of our model
through stochastic gradient descent. We propose two methods for computing the
variational lower bound, one utilizing Monte Carlo sampling and the other
employing Jensen's inequality to compute the KL regularization term in the loss
function. We propose adopting these approaches as viable alternatives to
Gaussian processes when the data might contain outliers or exhibit heavy-tailed
behavior, and we provide specific recommendations for their applicability. We
evaluate the two proposed approaches on various synthetic and real-world
datasets from UCI and Kaggle, demonstrating their effectiveness compared to
baseline methods in terms of computational complexity and accuracy, as well as
their robustness to outliers.
</p></li>
</ul>

<h3>Title: Not All Data Matters: An End-to-End Adaptive Dataset Pruning Framework for Enhancing Model Performance and Efficiency. (arXiv:2312.05599v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05599">http://arxiv.org/abs/2312.05599</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05599]] Not All Data Matters: An End-to-End Adaptive Dataset Pruning Framework for Enhancing Model Performance and Efficiency(http://arxiv.org/abs/2312.05599)</code></li>
<li>Summary: <p>While deep neural networks have demonstrated remarkable performance across
various tasks, they typically require massive training data. Due to the
presence of redundancies and biases in real-world datasets, not all data in the
training dataset contributes to the model performance. To address this issue,
dataset pruning techniques have been introduced to enhance model performance
and efficiency by eliminating redundant training samples and reducing
computational and memory overhead. However, previous works most rely on
manually crafted scalar scores, limiting their practical performance and
scalability across diverse deep networks and datasets. In this paper, we
propose AdaPruner, an end-to-end Adaptive DAtaset PRUNing framEwoRk. AdaPruner
can perform effective dataset pruning without the need for explicitly defined
metrics. Our framework jointly prunes training data and fine-tunes models with
task-specific optimization objectives. AdaPruner leverages (1) An adaptive
dataset pruning (ADP) module, which iteratively prunes redundant samples to an
expected pruning ratio; and (2) A pruning performance controller (PPC) module,
which optimizes the model performance for accurate pruning. Therefore,
AdaPruner exhibits high scalability and compatibility across various datasets
and deep networks, yielding improved dataset distribution and enhanced model
performance. AdaPruner can still significantly enhance model performance even
after pruning up to 10-30\% of the training data. Notably, these improvements
are accompanied by substantial savings in memory and computation costs.
Qualitative and quantitative experiments suggest that AdaPruner outperforms
other state-of-the-art dataset pruning methods by a large margin.
</p></li>
</ul>

<h3>Title: AI Competitions and Benchmarks: The life cycle of challenges and benchmarks. (arXiv:2312.05296v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05296">http://arxiv.org/abs/2312.05296</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05296]] AI Competitions and Benchmarks: The life cycle of challenges and benchmarks(http://arxiv.org/abs/2312.05296)</code></li>
<li>Summary: <p>Data Science research is undergoing a revolution fueled by the transformative
power of technology, the Internet, and an ever increasing computational
capacity. The rate at which sophisticated algorithms can be developed is
unprecedented, yet they remain outpaced by the massive amounts of data that are
increasingly available to researchers. Here we argue for the need to creatively
leverage the scientific research and algorithm development community as an axis
of robust innovation. Engaging these communities in the scientific discovery
enterprise by critical assessments, community experiments, and/or crowdsourcing
will multiply opportunities to develop new data driven, reproducible and well
benchmarked algorithmic solutions to fundamental and applied problems of
current interest. Coordinated community engagement in the analysis of highly
complex and massive data has emerged as one approach to find robust
methodologies that best address these challenges. When community engagement is
done in the form of competitions, also known as challenges, the validation of
the analytical methodology is inherently addressed, establishing performance
benchmarks. Finally, challenges foster open innovation across multiple
disciplines to create communities that collaborate directly or indirectly to
address significant scientific gaps. Together, participants can solve important
problems as varied as health research, climate change, and social equity.
Ultimately, challenges can catalyze and accelerate the synthesis of complex
data into knowledge or actionable information, and should be viewed a powerful
tool to make lasting social and research contributions.
</p></li>
</ul>

<h3>Title: Multi-dimensional Fair Federated Learning. (arXiv:2312.05551v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2312.05551">http://arxiv.org/abs/2312.05551</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2312.05551]] Multi-dimensional Fair Federated Learning(http://arxiv.org/abs/2312.05551)</code></li>
<li>Summary: <p>Federated learning (FL) has emerged as a promising collaborative and secure
paradigm for training a model from decentralized data without compromising
privacy. Group fairness and client fairness are two dimensions of fairness that
are important for FL. Standard FL can result in disproportionate disadvantages
for certain clients, and it still faces the challenge of treating different
groups equitably in a population. The problem of privately training fair FL
models without compromising the generalization capability of disadvantaged
clients remains open. In this paper, we propose a method, called mFairFL, to
address this problem and achieve group fairness and client fairness
simultaneously. mFairFL leverages differential multipliers to construct an
optimization objective for empirical risk minimization with fairness
constraints. Before aggregating locally trained models, it first detects
conflicts among their gradients, and then iteratively curates the direction and
magnitude of gradients to mitigate these conflicts. Theoretical analysis proves
mFairFL facilitates the fairness in model development. The experimental
evaluations based on three benchmark datasets show significant advantages of
mFairFL compared to seven state-of-the-art baselines.
</p></li>
</ul>

<h2>multi-run</h2>
<h2>chain-of-thought</h2>
<h2>tree-of-thought</h2>
<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
