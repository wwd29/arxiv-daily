<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-25</h1>
<h3>Title: A General-purpose AI Avatar in Healthcare</h3>
<ul>
<li><strong>Authors: </strong>Nicholas Yan, Gil Alterovitz</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12981">https://arxiv.org/abs/2401.12981</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12981">https://arxiv.org/pdf/2401.12981</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12981]] A General-purpose AI Avatar in Healthcare(https://arxiv.org/abs/2401.12981)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt, chat, agent</a></li>
<li><strong>Abstract: </strong>Recent advancements in machine learning and natural language processing have led to the rapid development of artificial intelligence (AI) as a valuable tool in the healthcare industry. Using large language models (LLMs) as conversational agents or chatbots has the potential to assist doctors in diagnosing patients, detecting early symptoms of diseases, and providing health advice to patients. This paper focuses on the role of chatbots in healthcare and explores the use of avatars to make AI interactions more appealing to patients. A framework of a general-purpose AI avatar application is demonstrated by using a three-category prompt dictionary and prompt improvement mechanism. A two-phase approach is suggested to fine-tune a general-purpose AI language model and create different AI avatars to discuss medical issues with users. Prompt engineering enhances the chatbot's conversational abilities and personality traits, fostering a more human-like interaction with patients. Ultimately, the injection of personality into the chatbot could potentially increase patient engagement. Future directions for research include investigating ways to improve chatbots' understanding of context and ensuring the accuracy of their outputs through fine-tuning with specialized medical data sets.</li>
<li><strong>摘要：</strong>机器学习和自然语言处理的最新进展导致人工智能（AI）作为医疗保健行业的宝贵工具迅速发展。使用大语言模型（LLM）作为对话代理或聊天机器人有可能帮助医生诊断患者、检测疾病的早期症状以及为患者提供健康建议。本文重点讨论聊天机器人在医疗保健中的作用，并探讨使用化身使人工智能交互对患者更具吸引力。利用三类提示词典和提示改进机制，演示了通用AI虚拟形象应用的框架。建议采用两阶段方法来微调通用人工智能语言模型，并创建不同的人工智能化身来与用户讨论医疗问题。及时的工程增强了聊天机器人的对话能力和个性特征，促进与患者更加人性化的互动。最终，为聊天机器人注入个性可能会增加患者的参与度。未来的研究方向包括研究如何提高聊天机器人对上下文的理解，并通过专门的医疗数据集进行微调来确保其输出的准确性。</li>
</ul>

<h3>Title: Assessing Large Language Models in Mechanical Engineering Education: A  Study on Mechanics-Focused Conceptual Understanding</h3>
<ul>
<li><strong>Authors: </strong>Jie Tian, Jixin Hou, Zihao Wu, Peng Shu, Zhengliang Liu, Yujie Xiang, Beikang Gu, Nicholas Filla, Yiwei Li, Ning Liu, Xianyan Chen, Keke Tang, Tianming Liu, Xianqiao Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, physics.ed-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12983">https://arxiv.org/abs/2401.12983</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12983">https://arxiv.org/pdf/2401.12983</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12983]] Assessing Large Language Models in Mechanical Engineering Education: A  Study on Mechanics-Focused Conceptual Understanding(https://arxiv.org/abs/2401.12983)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt, chat</a></li>
<li><strong>Abstract: </strong>This study is a pioneering endeavor to investigate the capabilities of Large Language Models (LLMs) in addressing conceptual questions within the domain of mechanical engineering with a focus on mechanics. Our examination involves a manually crafted exam encompassing 126 multiple-choice questions, spanning various aspects of mechanics courses, including Fluid Mechanics, Mechanical Vibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of Elasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5), ChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against engineering faculties and students with or without mechanical engineering background. The findings reveal GPT-4's superior performance over the other two LLMs and human cohorts in answering questions across various mechanics topics, except for Continuum Mechanics. This signals the potential future improvements for GPT models in handling symbolic calculations and tensor analyses. The performances of LLMs were all significantly improved with explanations prompted prior to direct responses, underscoring the crucial role of prompt engineering. Interestingly, GPT-3.5 demonstrates improved performance with prompts covering a broader domain, while GPT-4 excels with prompts focusing on specific subjects. Finally, GPT-4 exhibits notable advancements in mitigating input bias, as evidenced by guessing preferences for humans. This study unveils the substantial potential of LLMs as highly knowledgeable assistants in both mechanical pedagogy and scientific research.</li>
<li><strong>摘要：</strong>这项研究是一项开创性的研究，旨在调查大型语言模型 (LLM) 在解决机械工程领域内概念性问题（重点是力学）的能力。我们的考试是手工制作的考试，包含 126 道多项选择题，涵盖力学课程的各个方面，包括流体力学、机械振动、工程静力学和动力学、材料力学、弹性理论和连续体力学。包括 ChatGPT (GPT-3.5)、ChatGPT (GPT-4) 和 Claude (Claude-2.1) 在内的三名法学硕士接受了针对工程学院和有或没有机械工程背景的学生的评估。研究结果表明，GPT-4 在回答各种力学主题的问题（连续介质力学除外）方面优于其他两个法学硕士和人类队列。这标志着 GPT 模型在处理符号计算和张量分析方面未来可能会得到改进。通过在直接答复之前提示解释，法学硕士的表现均得到显着提高，强调了即时工程的关键作用。有趣的是，GPT-3.5 通过涵盖更广泛领域的提示展示了改进的性能，而 GPT-4 则在专注于特定主题的提示方面表现出色。最后，GPT-4 在减轻输入偏差方面表现出了显着的进步，猜测人类的偏好就证明了这一点。这项研究揭示了法学硕士作为机械教学和科学研究方面知识渊博的助手的巨大潜力。</li>
</ul>

<h3>Title: The Effect of Human v/s Synthetic Test Data and Round-tripping on  Assessment of Sentiment Analysis Systems for Bias</h3>
<ul>
<li><strong>Authors: </strong>Kausik Lakkaraju, Aniket Gupta, Biplav Srivastava, Marco Valtorta, Dezhi Wu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12985">https://arxiv.org/abs/2401.12985</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12985">https://arxiv.org/pdf/2401.12985</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12985]] The Effect of Human v/s Synthetic Test Data and Round-tripping on  Assessment of Sentiment Analysis Systems for Bias(https://arxiv.org/abs/2401.12985)</code><input type="text"></li>
<li><strong>Keywords: </strong>code, chat</a></li>
<li><strong>Abstract: </strong>Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence (AI) systems that output polarity and emotional intensity when given a piece of text as input. Like other AIs, SASs are also known to have unstable behavior when subjected to changes in data which can make it problematic to trust out of concerns like bias when AI works with humans and data has protected attributes like gender, race, and age. Recently, an approach was introduced to assess SASs in a blackbox setting without training data or code, and rating them for bias using synthetic English data. We augment it by introducing two human-generated chatbot datasets and also consider a round-trip setting of translating the data from one language to the same through an intermediate language. We find that these settings show SASs performance in a more realistic light. Specifically, we find that rating SASs on the chatbot data showed more bias compared to the synthetic data, and round-tripping using Spanish and Danish as intermediate languages reduces the bias (up to 68% reduction) in human-generated data while, in synthetic data, it takes a surprising turn by increasing the bias! Our findings will help researchers and practitioners refine their SAS testing strategies and foster trust as SASs are considered part of more mission-critical applications for global use.</li>
<li><strong>摘要：</strong>情绪分析系统 (SAS) 是数据驱动的人工智能 (AI) 系统，当输入一段文本时，该系统会输出极性和情绪强度。与其他人工智能一样，SAS 在受到数据变化时也会表现出不稳定的行为，当人工智能与人类合作且数据具有性别、种族和年龄等受保护的属性时，由于偏见等担忧，SAS 可能会出现信任问题。最近，引入了一种在没有训练数据或代码的黑盒环境中评估 SAS 的方法，并使用合成英语数据对它们进行偏差评级。我们通过引入两个人类生成的聊天机器人数据集来增强它，并考虑通过中间语言将数据从一种语言翻译为同一种语言的往返设置。我们发现这些设置以更真实的方式显示 SAS 性能。具体来说，我们发现，与合成数据相比，对聊天机器人数据进行 SAS 评级显示出更多偏差，并且使用西班牙语和丹麦语作为中间语言的往返可以减少人类生成数据的偏差（最多减少 68%），而在合成数据中数据，通过增加偏差，它发生了令人惊讶的转变！我们的研究结果将帮助研究人员和从业人员完善他们的 SAS 测试策略并培养信任，因为 SAS 被认为是全球使用的更关键任务应用程序的一部分。</li>
</ul>

<h3>Title: Crowdsourced Adaptive Surveys</h3>
<ul>
<li><strong>Authors: </strong>Yamil Velez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.HC, stat.AP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12986">https://arxiv.org/abs/2401.12986</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12986">https://arxiv.org/pdf/2401.12986</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12986]] Crowdsourced Adaptive Surveys(https://arxiv.org/abs/2401.12986)</code><input type="text"></li>
<li><strong>Keywords: </strong>lora</a></li>
<li><strong>Abstract: </strong>Public opinion surveys are vital for informing democratic decision-making, but responding to rapidly changing information environments and measuring beliefs within niche communities can be challenging for traditional survey methods. This paper introduces a crowdsourced adaptive survey methodology (CSAS) that unites advances in natural language processing and adaptive algorithms to generate question banks that evolve with user input. The CSAS method converts open-ended text provided by participants into Likert-style items and applies a multi-armed bandit algorithm to determine user-provided questions that should be prioritized in the survey. The method's adaptive nature allows for the exploration of new survey questions, while imposing minimal costs in survey length. Applications in the domains of Latino information environments and issue importance showcase CSAS's ability to identify claims or issues that might otherwise be difficult to track using standard approaches. I conclude by discussing the method's potential for studying topics where participant-generated content might improve our understanding of public opinion.</li>
<li><strong>摘要：</strong>民意调查对于为民主决策提供信息至关重要，但应对快速变化的信息环境和衡量利基社区内的信念对传统调查方法来说可能具有挑战性。本文介绍了一种众包自适应调查方法（CSAS），该方法结合了自然语言处理和自适应算法的进步，生成随用户输入而变化的问题库。 CSAS 方法将参与者提供的开放式文本转换为 Likert 风格的项目，并应用多臂老虎机算法来确定用户提供的应在调查中优先考虑的问题。该方法的适应性允许探索新的调查问题，同时将调查长度的成本降至最低。拉丁美洲信息环境和问题重要性领域的应用展示了 CSAS 识别索赔或问题的能力，否则使用标准方法可能难以跟踪这些索赔或问题。最后，我讨论了该方法在研究参与者生成的内容可能会提高我们对公众舆论的理解的主题方面的潜力。</li>
</ul>

<h3>Title: TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition  in Conversation</h3>
<ul>
<li><strong>Authors: </strong>Taeyang Yun, Hyunkuk Lim, Jeonghwan Lee, Min Song</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12987">https://arxiv.org/abs/2401.12987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12987">https://arxiv.org/pdf/2401.12987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12987]] TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition  in Conversation(https://arxiv.org/abs/2401.12987)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Emotion Recognition in Conversation (ERC) plays a crucial role in enabling dialogue systems to effectively respond to user requests. The emotions in a conversation can be identified by the representations from various modalities, such as audio, visual, and text. However, due to the weak contribution of non-verbal modalities to recognize emotions, multimodal ERC has always been considered a challenging task. In this paper, we propose Teacher-leading Multimodal fusion network for ERC (TelME). TelME incorporates cross-modal knowledge distillation to transfer information from a language model acting as the teacher to the non-verbal students, thereby optimizing the efficacy of the weak modalities. We then combine multimodal features using a shifting fusion approach in which student networks support the teacher. TelME achieves state-of-the-art performance in MELD, a multi-speaker conversation dataset for ERC. Finally, we demonstrate the effectiveness of our components through additional experiments.</li>
<li><strong>摘要：</strong>对话中的情绪识别 (ERC) 在使对话系统有效响应用户请求方面发挥着至关重要的作用。对话中的情绪可以通过各种形式（例如音频、视觉和文本）的表示来识别。然而，由于非语言方式对情绪识别的贡献较弱，多模态 ERC 一直被认为是一项具有挑战性的任务。在本文中，我们提出了教师主导的 ERC 多模态融合网络（TelME）。 TelME 结合了跨模态知识蒸馏，将信息从充当教师的语言模型传递给非语言学生，从而优化弱模态的功效。然后，我们使用学生网络支持教师的移动融合方法来组合多模态特征。 TelME 在 MELD（ERC 的多说话人对话数据集）中实现了最先进的性能。最后，我们通过额外的实验证明了我们组件的有效性。</li>
</ul>

<h3>Title: Few-Shot Learning for Chronic Disease Management: Leveraging Large  Language Models and Multi-Prompt Engineering with Medical Knowledge Injection</h3>
<ul>
<li><strong>Authors: </strong>Haoxin Liu, Wenli Zhang, Jiaheng Xie, Buomsoo Kim, Zhu Zhang, Yidong Chai</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12988">https://arxiv.org/abs/2401.12988</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12988">https://arxiv.org/pdf/2401.12988</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12988]] Few-Shot Learning for Chronic Disease Management: Leveraging Large  Language Models and Multi-Prompt Engineering with Medical Knowledge Injection(https://arxiv.org/abs/2401.12988)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, prompt, rag</a></li>
<li><strong>Abstract: </strong>This study harnesses state-of-the-art AI technology for chronic disease management, specifically in detecting various mental disorders through user-generated textual content. Existing studies typically rely on fully supervised machine learning, which presents challenges such as the labor-intensive manual process of annotating extensive training data for each disease and the need to design specialized deep learning architectures for each problem. To address such challenges, we propose a novel framework that leverages advanced AI techniques, including large language models and multi-prompt engineering. Specifically, we address two key technical challenges in data-driven chronic disease management: (1) developing personalized prompts to represent each user's uniqueness and (2) incorporating medical knowledge into prompts to provide context for chronic disease detection, instruct learning objectives, and operationalize prediction goals. We evaluate our method using four mental disorders, which are prevalent chronic diseases worldwide, as research cases. On the depression detection task, our method (F1 = 0.975~0.978) significantly outperforms traditional supervised learning paradigms, including feature engineering (F1 = 0.760) and architecture engineering (F1 = 0.756). Meanwhile, our approach demonstrates success in few-shot learning, i.e., requiring only a minimal number of training examples to detect chronic diseases based on user-generated textual content (i.e., only 2, 10, or 100 subjects). Moreover, our method can be generalized to other mental disorder detection tasks, including anorexia, pathological gambling, and self-harm (F1 = 0.919~0.978).</li>
<li><strong>摘要：</strong>这项研究利用最先进的人工智能技术进行慢性病管理，特别是通过用户生成的文本内容检测各种精神障碍。现有的研究通常依赖于完全监督的机器学习，这带来了挑战，例如为每种疾病注释大量训练数据的劳动密集型手动过程以及需要为每个问题设计专门的深度学习架构。为了应对这些挑战，我们提出了一种利用先进人工智能技术的新颖框架，包括大型语言模型和多提示工程。具体来说，我们解决了数据驱动的慢性病管理中的两个关键技术挑战：（1）开发个性化提示来代表每个用户的独特性；（2）将医学知识融入提示中，为慢性病检测提供背景，指导学习目标并实施预测目标。我们使用四种精神障碍（全球流行的慢性疾病）作为研究案例来评估我们的方法。在抑郁症检测任务上，我们的方法（F1 = 0.975~0.978）显着优于传统的监督学习范式，包括特征工程（F1 = 0.760）和架构工程（F1 = 0.756）。同时，我们的方法在少样本学习方面取得了成功，即仅需要最少数量的训练示例即可根据用户生成的文本内容（即仅 2、10 或 100 个受试者）检测慢性疾病。此外，我们的方法可以推广到其他精神障碍检测任务，包括厌食症、病态赌博和自残（F1 = 0.919~0.​​978）。</li>
</ul>

<h3>Title: Into the crossfire: evaluating the use of a language model to  crowdsource gun violence reports</h3>
<ul>
<li><strong>Authors: </strong>Adriano Belisario, Scott Hale, Luc Rocher</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12989">https://arxiv.org/abs/2401.12989</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12989">https://arxiv.org/pdf/2401.12989</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12989]] Into the crossfire: evaluating the use of a language model to  crowdsource gun violence reports(https://arxiv.org/abs/2401.12989)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Gun violence is a pressing and growing human rights issue that affects nearly every dimension of the social fabric, from healthcare and education to psychology and the economy. Reliable data on firearm events is paramount to developing more effective public policy and emergency responses. However, the lack of comprehensive databases and the risks of in-person surveys prevent human rights organizations from collecting needed data in most countries. Here, we partner with a Brazilian human rights organization to conduct a systematic evaluation of language models to assist with monitoring real-world firearm events from social media data. We propose a fine-tuned BERT-based model trained on Twitter (now X) texts to distinguish gun violence reports from ordinary Portuguese texts. Our model achieves a high AUC score of 0.97. We then incorporate our model into a web application and test it in a live intervention. We study and interview Brazilian analysts who continuously fact-check social media texts to identify new gun violence events. Qualitative assessments show that our solution helped all analysts use their time more efficiently and expanded their search capacities. Quantitative assessments show that the use of our model was associated with more analysts' interactions with online users reporting gun violence. Taken together, our findings suggest that modern Natural Language Processing techniques can help support the work of human rights organizations.</li>
<li><strong>摘要：</strong>枪支暴力是一个紧迫且日益严重的人权问题，几乎影响到社会结构的各个方面，从医疗保健和教育到心理和经济。有关枪支事件的可靠数据对于制定更有效的公共政策和应急响应至关重要。然而，由于缺乏全面的数据库以及现场调查的风险，人权组织无法在大多数国家收集所需的数据。在这里，我们与巴西人权组织合作，对语言模型进行系统评估，以协助从社交媒体数据监控现实世界的枪支事件。我们提出了一个基于 BERT 的微调模型，在 Twitter（现在是 X）文本上进行训练，以区分枪支暴力报告和普通葡萄牙语文本。我们的模型获得了 0.97 的高 AUC 分数。然后，我们将我们的模型合并到网络应用程序中，并在现场干预中对其进行测试。我们研究并采访了巴西分析师，他们不断对社交媒体文本进行事实核查，以发现新的枪支暴力事件。定性评估表明，我们的解决方案帮助所有分析师更有效地利用时间并扩展了他们的搜索能力。定量评估表明，我们模型的使用与更多分析师与报告枪支暴力的在线用户的互动有关。总而言之，我们的研究结果表明，现代自然语言处理技术可以帮助支持人权组织的工作。</li>
</ul>

<h3>Title: TranSentence: Speech-to-speech Translation via Language-agnostic  Sentence-level Speech Encoding without Language-parallel Data</h3>
<ul>
<li><strong>Authors: </strong>Seung-Bin Kim, Sang-Hoon Lee, Seong-Whan Lee</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12992">https://arxiv.org/abs/2401.12992</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12992">https://arxiv.org/pdf/2401.12992</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12992]] TranSentence: Speech-to-speech Translation via Language-agnostic  Sentence-level Speech Encoding without Language-parallel Data(https://arxiv.org/abs/2401.12992)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Although there has been significant advancement in the field of speech-to-speech translation, conventional models still require language-parallel speech data between the source and target languages for training. In this paper, we introduce TranSentence, a novel speech-to-speech translation without language-parallel speech data. To achieve this, we first adopt a language-agnostic sentence-level speech encoding that captures the semantic information of speech, irrespective of language. We then train our model to generate speech based on the encoded embedding obtained from a language-agnostic sentence-level speech encoder that is pre-trained with various languages. With this method, despite training exclusively on the target language's monolingual data, we can generate target language speech in the inference stage using language-agnostic speech embedding from the source language speech. Furthermore, we extend TranSentence to multilingual speech-to-speech translation. The experimental results demonstrate that TranSentence is superior to other models.</li>
<li><strong>摘要：</strong>尽管语音到语音翻译领域已经取得了显着进步，但传统模型仍然需要源语言和目标语言之间的语言并行语音数据进行训练。在本文中，我们介绍了 TranSentence，一种无需语言并行语音数据的新型语音到语音翻译。为了实现这一目标，我们首先采用与语言无关的句子级语音编码，无论语言如何，它都可以捕获语音的语义信息。然后，我们训练模型以根据从与语言无关的句子级语音编码器获得的编码嵌入生成语音，该编码器是用各种语言预先训练的。通过这种方法，尽管仅对目标语言的单语数据进行训练，但我们可以在推理阶段使用源语言语音中与语言无关的语音嵌入来生成目标语言语音。此外，我们将 TranSentence 扩展到多语言语音到语音翻译。实验结果表明 TranSentence 优于其他模型。</li>
</ul>

<h3>Title: Automated Scoring of Clinical Patient Notes using Advanced NLP and  Pseudo Labeling</h3>
<ul>
<li><strong>Authors: </strong>Jingyu Xu, Yifeng Jiang, Bin Yuan, Shulin Li, Tianbo Song</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12994">https://arxiv.org/abs/2401.12994</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12994">https://arxiv.org/pdf/2401.12994</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12994]] Automated Scoring of Clinical Patient Notes using Advanced NLP and  Pseudo Labeling(https://arxiv.org/abs/2401.12994)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, rag</a></li>
<li><strong>Abstract: </strong>Clinical patient notes are critical for documenting patient interactions, diagnoses, and treatment plans in medical practice. Ensuring accurate evaluation of these notes is essential for medical education and certification. However, manual evaluation is complex and time-consuming, often resulting in variability and resource-intensive assessments. To tackle these challenges, this research introduces an approach leveraging state-of-the-art Natural Language Processing (NLP) techniques, specifically Masked Language Modeling (MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and effectiveness, significantly reducing training time without compromising performance. Experimental results showcase improved model performance, indicating a potential transformation in clinical note assessment.</li>
<li><strong>摘要：</strong>临床患者笔记对于记录医疗实践中的患者互动、诊断和治疗计划至关重要。确保准确评估这些笔记对于医学教育和认证至关重要。然而，手动评估复杂且耗时，通常会导致评估的可变性和资源密集型。为了应对这些挑战，本研究引入了一种利用最先进的自然语言处理 (NLP) 技术的方法，特别是掩码语言建模 (MLM) 预训练和伪标签。我们的方法提高了效率和效果，在不影响性能的情况下显着减少了培训时间。实验结果展示了模型性能的改进，表明临床记录评估的潜在转变。</li>
</ul>

<h3>Title: Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed  Response Generation in Dialogues</h3>
<ul>
<li><strong>Authors: </strong>Shivani Kumar, Tanmoy Chakraborty</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12995">https://arxiv.org/abs/2401.12995</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12995">https://arxiv.org/pdf/2401.12995</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12995]] Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed  Response Generation in Dialogues(https://arxiv.org/abs/2401.12995)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Code-mixing, the blending of multiple languages within a single conversation, introduces a distinctive challenge, particularly in the context of response generation. Capturing the intricacies of code-mixing proves to be a formidable task, given the wide-ranging variations influenced by individual speaking styles and cultural backgrounds. In this study, we explore response generation within code-mixed conversations. We introduce a novel approach centered on harnessing the Big Five personality traits acquired in an unsupervised manner from the conversations to bolster the performance of response generation. These inferred personality attributes are seamlessly woven into the fabric of the dialogue context, using a novel fusion mechanism, PA3. It uses an effective two-step attention formulation to fuse the dialogue and personality information. This fusion not only enhances the contextual relevance of generated responses but also elevates the overall performance of the model. Our experimental results, grounded in a dataset comprising of multi-party Hindi-English code-mix conversations, highlight the substantial advantages offered by personality-infused models over their conventional counterparts. This is evident in the increase observed in ROUGE and BLUE scores for the response generation task when the identified personality is seamlessly integrated into the dialogue context. Qualitative assessment for personality identification and response generation aligns well with our quantitative results.</li>
<li><strong>摘要：</strong>代码混合（即在一次对话中混合多种语言）带来了独特的挑战，特别是在响应生成的情况下。考虑到个人说话风格和文化背景影响的广泛变化，捕获代码混合的复杂性被证明是一项艰巨的任务。在本研究中，我们探讨了代码混合对话中的响应生成。我们引入了一种新颖的方法，其核心是利用从对话中以无监督的方式获得的“大五人格特征”来增强响应生成的性能。使用新颖的融合机制 PA3，将这些推断出的个性属性无缝地融入到对话上下文的结构中。它使用有效的两步注意力公式来融合对话和个性信息。这种融合不仅增强了生成响应的上下文相关性，而且还提高了模型的整体性能。我们的实验结果基于由多方印地语-英语代码混合对话组成的数据集，突出了个性注入模型相对于传统模型所提供的巨大优势。当识别的个性无缝集成到对话上下文中时，响应生成任务的 ROUGE 和 BLUE 分数增加，这一点很明显。个性识别和响应生成的定性评估与我们的定量结果非常吻合。</li>
</ul>

<h3>Title: A Comparison of Veterans with Problematic Opioid Use Identified through  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes</h3>
<ul>
<li><strong>Authors: </strong>Terri Elizabeth Workman, Joel Kupersmith, Phillip Ma, Christopher Spevak, Friedhelm Sandbrink, Yan Cheng Qing Zeng-Treitler</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12996">https://arxiv.org/abs/2401.12996</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12996">https://arxiv.org/pdf/2401.12996</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12996]] A Comparison of Veterans with Problematic Opioid Use Identified through  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes(https://arxiv.org/abs/2401.12996)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Background: Electronic health records (EHRs) are a data source for opioid research. Opioid use disorder is known to be under-coded as a diagnosis, yet problematic opioid use can be documented in clinical notes. Objectives: Our goals were 1) to identify problematic opioid use from a full range of clinical notes; and 2) to compare the characteristics of patients identified as having problematic opioid use, exclusively documented in clinical notes, to those having documented ICD opioid use disorder diagnostic codes. Materials and Methods: We developed and applied a natural language processing (NLP) tool to the clinical notes of a patient cohort (n=222,371) from two Veteran Affairs service regions to identify patients with problematic opioid use. We also used a set of ICD diagnostic codes to identify patients with opioid use disorder from the same cohort. We compared the demographic and clinical characteristics of patients identified only through NLP, to those of patients identified through ICD codes. Results: NLP exclusively identified 57,331 patients; 6,997 patients had positive ICD code identifications. Patients exclusively identified through NLP were more likely to be women. Those identified through ICD codes were more likely to be male, younger, have concurrent benzodiazepine prescriptions, more comorbidities, more care encounters, and less likely to be married. Patients in the NLP and ICD groups had substantially elevated comorbidity levels compared to patients not documented as experiencing problematic opioid use. Conclusions: NLP is a feasible approach for identifying problematic opioid use not otherwise recorded by ICD codes. Clinicians may be reluctant to code for opioid use disorder. It is therefore incumbent on the healthcare team to search for documentation of opioid concerns within clinical notes.</li>
<li><strong>摘要：</strong>背景：电子健康记录 (EHR) 是阿片类药物研究的数据源。众所周知，阿片类药物使用障碍的诊断编码不足，但有问题的阿片类药物使用可以记录在临床记录中。目标：我们的目标是 1) 从全方位的临床记录中识别有问题的阿片类药物使用； 2) 将临床记录中专门记录的被确定为阿片类药物使用有问题的患者的特征与记录有 ICD 阿片类药物使用障碍诊断代码的患者的特征进行比较。材料和方法：我们开发了一种自然语言处理 (NLP) 工具，并将其应用于来自两个退伍军人事务服务区域的患者队列 (n=222,371) 的临床记录，以识别阿片类药物使用有问题的患者。我们还使用一组 ICD 诊断代码来识别同一队列中患有阿片类药物使用障碍的患者。我们将仅通过 NLP 识别的患者与通过 ICD 代码识别的患者的人口统计和临床特征进行了比较。结果：NLP 独家识别了 57,331 名患者； 6,997 名患者的 ICD 代码识别呈阳性。通过 NLP 专门识别的患者更有可能是女性。通过 ICD 代码识别的人更有可能是男性、更年轻、同时服用苯二氮卓类药物、更多合并症、更多护理经历，并且结婚的可能性较小。与没有记录为阿片类药物使用问题的患者相比，NLP 和 ICD 组的患者的合并症水平显着升高。结论：NLP 是识别 ICD 代码未记录的有问题的阿片类药物使用的可行方法。临床医生可能不愿意对阿片类药物使用障碍进行编码。因此，医疗团队有责任在临床记录中搜索阿片类药物问题的记录。</li>
</ul>

<h3>Title: Progressive Distillation Based on Masked Generation Feature Method for  Knowledge Graph Completion</h3>
<ul>
<li><strong>Authors: </strong>Cunhang Fan, Yujie Chen, Jun Xue, Yonghui Kong, Jianhua Tao, Zhao Lv</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12997">https://arxiv.org/abs/2401.12997</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12997">https://arxiv.org/pdf/2401.12997</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12997]] Progressive Distillation Based on Masked Generation Feature Method for  Knowledge Graph Completion(https://arxiv.org/abs/2401.12997)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>In recent years, knowledge graph completion (KGC) models based on pre-trained language model (PLM) have shown promising results. However, the large number of parameters and high computational cost of PLM models pose challenges for their application in downstream tasks. This paper proposes a progressive distillation method based on masked generation features for KGC task, aiming to significantly reduce the complexity of pre-trained models. Specifically, we perform pre-distillation on PLM to obtain high-quality teacher models, and compress the PLM network to obtain multi-grade student models. However, traditional feature distillation suffers from the limitation of having a single representation of information in teacher models. To solve this problem, we propose masked generation of teacher-student features, which contain richer representation information. Furthermore, there is a significant gap in representation ability between teacher and student. Therefore, we design a progressive distillation method to distill student models at each grade level, enabling efficient knowledge transfer from teachers to students. The experimental results demonstrate that the model in the pre-distillation stage surpasses the existing state-of-the-art methods. Furthermore, in the progressive distillation stage, the model significantly reduces the model parameters while maintaining a certain level of performance. Specifically, the model parameters of the lower-grade student model are reduced by 56.7\% compared to the baseline.</li>
<li><strong>摘要：</strong>近年来，基于预训练语言模型（PLM）的知识图补全（KGC）模型已经显示出可喜的结果。然而，PLM模型的大量参数和高计算成本对其在下游任务中的应用提出了挑战。本文针对KGC任务提出了一种基于屏蔽生成特征的渐进蒸馏方法，旨在显着降低预训练模型的复杂度。具体来说，我们对PLM进行预蒸馏以获得高质量的教师模型，并对PLM网络进行压缩以获得多年级的学生模型。然而，传统的特征蒸馏受到教师模型中信息单一表示的限制。为了解决这个问题，我们提出了师生特征的掩码生成，其中包含更丰富的表示信息。此外，教师和学生之间的表达能力也存在显着差距。因此，我们设计了一种渐进式蒸馏方法来蒸馏每个年级的学生模型，从而实现从教师到学生的高效知识转移。实验结果表明，预蒸馏阶段的模型超越了现有的最先进的方法。此外，在渐进蒸馏阶段，该模型在保持一定性能水平的同时显着减少了模型参数。具体来说，低年级学生模型的模型参数相比基线减少了 56.7%。</li>
</ul>

<h3>Title: Evaluating and Enhancing Large Language Models Performance in  Domain-specific Medicine: Osteoarthritis Management with DocOA</h3>
<ul>
<li><strong>Authors: </strong>Xi Chen, MingKe You, Li Wang, WeiZhi Liu, Yu Fu, Jie Xu, Shaoting Zhang, Gang Chen, Jian Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.12998">https://arxiv.org/abs/2401.12998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.12998">https://arxiv.org/pdf/2401.12998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.12998]] Evaluating and Enhancing Large Language Models Performance in  Domain-specific Medicine: Osteoarthritis Management with DocOA(https://arxiv.org/abs/2401.12998)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt, retrieval-augmented generation, rag</a></li>
<li><strong>Abstract: </strong>The efficacy of large language models (LLMs) in domain-specific medicine, particularly for managing complex diseases such as osteoarthritis (OA), remains largely unexplored. This study focused on evaluating and enhancing the clinical capabilities of LLMs in specific domains, using osteoarthritis (OA) management as a case study. A domain specific benchmark framework was developed, which evaluate LLMs across a spectrum from domain-specific knowledge to clinical applications in real-world clinical scenarios. DocOA, a specialized LLM tailored for OA management that integrates retrieval-augmented generation (RAG) and instruction prompts, was developed. The study compared the performance of GPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human evaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less effective in the specialized domain of OA management, particularly in providing personalized treatment recommendations. However, DocOA showed significant improvements. This study introduces a novel benchmark framework which assesses the domain-specific abilities of LLMs in multiple aspects, highlights the limitations of generalized LLMs in clinical contexts, and demonstrates the potential of tailored approaches for developing domain-specific medical LLMs.</li>
<li><strong>摘要：</strong>大语言模型 (LLM) 在特定领域医学中的功效，特别是在治疗骨关节炎 (OA) 等复杂疾病方面的功效，在很大程度上仍未得到探索。这项研究的重点是评估和提高法学硕士在特定领域的临床能力，以骨关节炎 (OA) 管理作为案例研究。开发了一个特定领域的基准框架，该框架对从特定领域知识到现实临床场景中的临床应用的法学硕士进行评估。 DocOA是专为OA管理量身定制的专业法学硕士，集成了检索增强生成（RAG）和指令提示。该研究使用客观和人工评估来比较 GPT-3.5、GPT-4 和专业助手 DocOA 的性能。结果显示，GPT-3.5 和 GPT-4 等普通法学硕士在 OA 管理专业领域效果较差，特别是在提供个性化治疗建议方面。然而，DocOA 显示出显着的改进。本研究引入了一个新颖的基准框架，该框架从多个方面评估法学硕士的特定领域能力，强调了广义法学硕士在临床环境中的局限性，并展示了开发特定领域医学法学硕士的定制方法的潜力。</li>
</ul>

<h3>Title: CIMGEN: Controlled Image Manipulation by Finetuning Pretrained  Generative Models on Limited Data</h3>
<ul>
<li><strong>Authors: </strong>Chandrakanth Gudavalli, Erik Rosten, Lakshmanan Nataraj, Shivkumar Chandrasekaran, B. S. Manjunath</a></li>
<li><strong>Subjects: </strong>cs.AI, cs.LG, eess.IV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13006">https://arxiv.org/abs/2401.13006</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13006">https://arxiv.org/pdf/2401.13006</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13006]] CIMGEN: Controlled Image Manipulation by Finetuning Pretrained  Generative Models on Limited Data(https://arxiv.org/abs/2401.13006)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Content creation and image editing can benefit from flexible user controls. A common intermediate representation for conditional image generation is a semantic map, that has information of objects present in the image. When compared to raw RGB pixels, the modification of semantic map is much easier. One can take a semantic map and easily modify the map to selectively insert, remove, or replace objects in the map. The method proposed in this paper takes in the modified semantic map and alter the original image in accordance to the modified map. The method leverages traditional pre-trained image-to-image translation GANs, such as CycleGAN or Pix2Pix GAN, that are fine-tuned on a limited dataset of reference images associated with the semantic maps. We discuss the qualitative and quantitative performance of our technique to illustrate its capacity and possible applications in the fields of image forgery and image editing. We also demonstrate the effectiveness of the proposed image forgery technique in thwarting the numerous deep learning-based image forensic techniques, highlighting the urgent need to develop robust and generalizable image forensic tools in the fight against the spread of fake media.</li>
<li><strong>摘要：</strong>内容创建和图像编辑可以受益于灵活的用户控件。条件图像生成的常见中间表示是语义图，它具有图像中存在的对象的信息。与原始 RGB 像素相比，语义图的修改要容易得多。人们可以获取语义图并轻松修改该图以有选择地插入、删除或替换图中的对象。本文提出的方法接收修改后的语义图并根据修改后的图改变原始图像。该方法利用传统的预训练图像到图像转换 GAN，例如 CycleGAN 或 Pix2Pix GAN，它们在与语义图相关的有限参考图像数据集上进行微调。我们讨论了我们技术的定性和定量性能，以说明其能力以及在图像伪造和图像编辑领域的可能应用。我们还证明了所提出的图像伪造技术在阻止众多基于深度学习的图像取证技术方面的有效性，强调了在打击虚假媒体传播的斗争中迫切需要开发强大且通用的图像取证工具。</li>
</ul>

<h3>Title: Locality Sensitive Sparse Encoding for Learning World Models Online</h3>
<ul>
<li><strong>Authors: </strong>Zichen Liu, Chao Du, Wee Sun Lee, Min Lin</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13034">https://arxiv.org/abs/2401.13034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13034">https://arxiv.org/pdf/2401.13034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13034]] Locality Sensitive Sparse Encoding for Learning World Models Online(https://arxiv.org/abs/2401.13034)</code><input type="text"></li>
<li><strong>Keywords: </strong>agent</a></li>
<li><strong>Abstract: </strong>Acquiring an accurate world model online for model-based reinforcement learning (MBRL) is challenging due to data nonstationarity, which typically causes catastrophic forgetting for neural networks (NNs). From the online learning perspective, a Follow-The-Leader (FTL) world model is desirable, which optimally fits all previous experiences at each round. Unfortunately, NN-based models need re-training on all accumulated data at every interaction step to achieve FTL, which is computationally expensive for lifelong agents. In this paper, we revisit models that can achieve FTL with incremental updates. Specifically, our world model is a linear regression model supported by nonlinear random features. The linear part ensures efficient FTL update while the nonlinear random feature empowers the fitting of complex environments. To best trade off model capacity and computation efficiency, we introduce a locality sensitive sparse encoding, which allows us to conduct efficient sparse updates even with very high dimensional nonlinear features. We validate the representation power of our encoding and verify that it allows efficient online learning under data covariate shift. We also show, in the Dyna MBRL setting, that our world models learned online using a single pass of trajectory data either surpass or match the performance of deep world models trained with replay and other continual learning methods.</li>
<li><strong>摘要：</strong>由于数据的非平稳性，在线获取基于模型的强化学习 (MBRL) 的准确世界模型具有挑战性，这通常会导致神经网络 (NN) 发生灾难性遗忘。从在线学习的角度来看，追随领导者（FTL）世界模型是可取的，它可以最佳地适应每轮之前的所有经验。不幸的是，基于神经网络的模型需要在每个交互步骤中对所有积累的数据进行重新训练才能实现 FTL，这对于终身代理来说计算成本很高。在本文中，我们重新审视可以通过增量更新实现 FTL 的模型。具体来说，我们的世界模型是由非线性随机特征支持的线性回归模型。线性部分保证高效的FTL更新，非线性随机特征赋能复杂环境的拟合。为了最好地权衡模型容量和计算效率，我们引入了局部敏感稀疏编码，即使对于非常高维的非线性特征，它也允许我们进行有效的稀疏更新。我们验证了编码的表示能力，并验证它是否允许在数据协变量移位下进行高效的在线学习。我们还表明，在 Dyna MBRL 设置中，我们的世界模型使用单次轨迹数据在线学习，超越或匹配通过重播和其他持续学习方法训练的深度世界模型的性能。</li>
</ul>

<h3>Title: TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced  Transformer-based Ensemble Approach for Qur'anic QA</h3>
<ul>
<li><strong>Authors: </strong>Mohammed Alaa Elkomy, Amany Sarhan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13060">https://arxiv.org/abs/2401.13060</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13060">https://arxiv.org/pdf/2401.13060</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13060]] TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced  Transformer-based Ensemble Approach for Qur'anic QA(https://arxiv.org/abs/2401.13060)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks A and B. To address the challenge of low-resourced training data, we rely on transfer learning together with a voting ensemble to improve prediction stability across multiple runs. Additionally, we employ different architectures and learning mechanisms for a range of Arabic pre-trained transformer-based models for both tasks. To identify unanswerable questions, we propose using a thresholding mechanism. Our top-performing systems greatly surpass the baseline performance on the hidden split, achieving a MAP score of 25.05% for task A and a partial Average Precision (pAP) of 57.11% for task B.</li>
<li><strong>摘要：</strong>在本文中，我们提出了解决《古兰经 QA 2023》共享任务 A 和 B 的方法。为了解决训练数据资源不足的挑战，我们依靠迁移学习和投票集成来提高多次运行的预测稳定性。此外，我们针对这两项任务对一系列基于阿拉伯语预训练的 Transformer 模型采用了不同的架构和学习机制。为了识别无法回答的问题，我们建议使用阈值机制。我们表现​​最好的系统大大超越了隐藏分割的基线性能，任务 A 的 MAP 得分为 25.05%，任务 B 的部分平均精度 (pAP) 为 57.11%。</li>
</ul>

<h3>Title: IndiText Boost: Text Augmentation for Low Resource India Languages</h3>
<ul>
<li><strong>Authors: </strong>Onkar Litake, Niraj Yagnik, Shreyas Labhsetwar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13085">https://arxiv.org/abs/2401.13085</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13085">https://arxiv.org/pdf/2401.13085</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13085]] IndiText Boost: Text Augmentation for Low Resource India Languages(https://arxiv.org/abs/2401.13085)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm</a></li>
<li><strong>Abstract: </strong>Text Augmentation is an important task for low-resource languages. It helps deal with the problem of data scarcity. A data augmentation strategy is used to deal with the problem of data scarcity. Through the years, much work has been done on data augmentation for the English language. In contrast, very less work has been done on Indian languages. This is contrary to the fact that data augmentation is used to deal with data scarcity. In this work, we focus on implementing techniques like Easy Data Augmentation, Back Translation, Paraphrasing, Text Generation using LLMs, and Text Expansion using LLMs for text classification on different languages. We focus on 6 Indian languages namely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to our knowledge, no such work exists for text augmentation on Indian languages. We carry out binary as well as multi-class text classification to make our results more comparable. We get surprising results as basic data augmentation techniques surpass LLMs.</li>
<li><strong>摘要：</strong>文本增强对于资源匮乏的语言来说是一项重要任务。它有助于解决数据稀缺的问题。数据增强策略用于解决数据稀缺问题。多年来，人们在英语数据增强方面做了大量工作。相比之下，针对印度语言所做的工作却少之又少。这与数据增强用于解决数据稀缺的事实相反。在这项工作中，我们专注于实现简单数据增强、反向翻译、释义、使用法学硕士的文本生成以及使用法学硕士的文本扩展等技术，以对不同语言进行文本分类。我们专注于 6 种印度语言，即：信德语、马拉地语、印地语、古吉拉特语、泰卢固语和梵语。据我们所知，印度语言的文本增强尚不存在这样的工作。我们进行二元和多类文本分类，以使我们的结果更具可比性。随着基本数据增强技术超越法学硕士，我们得到了令人惊讶的结果。</li>
</ul>

<h3>Title: Towards Trustable Language Models: Investigating Information Quality of  Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Rick Rejeleene, Xiaowei Xu, John Talburt</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13086">https://arxiv.org/abs/2401.13086</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13086">https://arxiv.org/pdf/2401.13086</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13086]] Towards Trustable Language Models: Investigating Information Quality of  Large Language Models(https://arxiv.org/abs/2401.13086)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination</a></li>
<li><strong>Abstract: </strong>Large language models (LLM) are generating information at a rapid pace, requiring users to increasingly rely and trust the data. Despite remarkable advances of LLM, Information generated by LLM is not completely trustworthy, due to challenges in information quality. Specifically, integrity of Information quality decreases due to unreliable, biased, tokenization during pre-training of LLM. Moreover, due to decreased information quality issues, has led towards hallucination, fabricated information. Unreliable information can lead towards flawed decisions in businesses, which impacts economic activity. In this work, we introduce novel mathematical information quality evaluation of LLM, we furthermore analyze and highlight information quality challenges, scaling laws to systematically scale language models.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 正在快速生成信息，要求用户越来越依赖和信任数据。尽管法学硕士取得了显着的进步，但由于信息质量方面的挑战，法学硕士生成的信息并不完全可信。具体来说，由于法学硕士预训练期间的不可靠、有偏见、标记化，信息质量的完整性下降。而且，由于信息质量下降的问题，导致出现幻觉、捏造信息。不可靠的信息可能会导致企业做出错误的决策，从而影响经济活动。在这项工作中，我们介绍了法学硕士的新颖的数学信息质量评估，我们进一步分析和强调了信息质量挑战，以及系统地扩展语言模型的缩放法则。</li>
</ul>

<h3>Title: Probabilistic Demand Forecasting with Graph Neural Networks</h3>
<ul>
<li><strong>Authors: </strong>Nikita Kozodoi, Elizaveta Zinovyeva, Simon Valentin, João Pereira, Rodrigo Agundez</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13096">https://arxiv.org/abs/2401.13096</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13096">https://arxiv.org/pdf/2401.13096</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13096]] Probabilistic Demand Forecasting with Graph Neural Networks(https://arxiv.org/abs/2401.13096)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Demand forecasting is a prominent business use case that allows retailers to optimize inventory planning, logistics, and core business decisions. One of the key challenges in demand forecasting is accounting for relationships and interactions between articles. Most modern forecasting approaches provide independent article-level predictions that do not consider the impact of related articles. Recent research has attempted addressing this challenge using Graph Neural Networks (GNNs) and showed promising results. This paper builds on previous research on GNNs and makes two contributions. First, we integrate a GNN encoder into a state-of-the-art DeepAR model. The combined model produces probabilistic forecasts, which are crucial for decision-making under uncertainty. Second, we propose to build graphs using article attribute similarity, which avoids reliance on a pre-defined graph structure. Experiments on three real-world datasets show that the proposed approach consistently outperforms non-graph benchmarks. We also show that our approach produces article embeddings that encode article similarity and demand dynamics and are useful for other downstream business tasks beyond forecasting.</li>
<li><strong>摘要：</strong>需求预测是一个重要的业务用例，允许零售商优化库存规划、物流和核心业务决策。需求预测的关键挑战之一是考虑文章之间的关系和交互。大多数现代预测方法提供独立的文章级预测，不考虑相关文章的影响。最近的研究尝试使用图神经网络（GNN）来解决这一挑战，并显示出有希望的结果。本文建立在之前关于 GNN 的研究的基础上，并做出了两个贡献。首先，我们将 GNN 编码器集成到最先进的 DeepAR 模型中。组合模型产生概率预测，这对于不确定性下的决策至关重要。其次，我们建议使用文章属性相似性来构建图，这避免了对预定义图结构的依赖。对三个现实世界数据集的实验表明，所提出的方法始终优于非图基准。我们还表明，我们的方法生成的文章嵌入对文章相似性和需求动态进行编码，并且对于预测之外的其他下游业务任务很有用。</li>
</ul>

<h3>Title: XAI for All: Can Large Language Models Simplify Explainable AI?</h3>
<ul>
<li><strong>Authors: </strong>Philip Mavrepis, Georgios Makridis, Georgios Fatouros, Vasileios Koukos, Maria Margarita Separdani, Dimosthenis Kyriazis</a></li>
<li><strong>Subjects: </strong>cs.AI, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13110">https://arxiv.org/abs/2401.13110</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13110">https://arxiv.org/pdf/2401.13110</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13110]] XAI for All: Can Large Language Models Simplify Explainable AI?(https://arxiv.org/abs/2401.13110)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, chat</a></li>
<li><strong>Abstract: </strong>The field of Explainable Artificial Intelligence (XAI) often focuses on users with a strong technical background, making it challenging for non-experts to understand XAI methods. This paper presents "x-[plAIn]", a new approach to make XAI more accessible to a wider audience through a custom Large Language Model (LLM), developed using ChatGPT Builder. Our goal was to design a model that can generate clear, concise summaries of various XAI methods, tailored for different audiences, including business professionals and academics. The key feature of our model is its ability to adapt explanations to match each audience group's knowledge level and interests. Our approach still offers timely insights, facilitating the decision-making process by the end users. Results from our use-case studies show that our model is effective in providing easy-to-understand, audience-specific explanations, regardless of the XAI method used. This adaptability improves the accessibility of XAI, bridging the gap between complex AI technologies and their practical applications. Our findings indicate a promising direction for LLMs in making advanced AI concepts more accessible to a diverse range of users.</li>
<li><strong>摘要：</strong>可解释人工智能（XAI）领域通常关注具有强大技术背景的用户，这使得非专家很难理解 XAI 方法。本文介绍了“x-[plAIn]”，这是一种通过使用 ChatGPT Builder 开发的自定义大型语言模型 (LLM) 使 XAI 更容易被更广泛受众使用的新方法。我们的目标是设计一个模型，可以生成各种 XAI 方法的清晰、简洁的摘要，并为不同的受众（包括商业专业人士和学者）量身定制。我们模型的关键特征是它能够调整解释以匹配每个受众群体的知识水平和兴趣。我们的方法仍然提供及时的见解，促进最终用户的决策过程。我们的用例研究结果表明，无论使用哪种 XAI 方法，我们的模型都能有效地提供易于理解、针对特定受众的解释。这种适应性提高了 XAI 的可访问性，弥合了复杂人工智能技术与其实际应用之间的差距。我们的研究结果表明，法学硕士在让各种用户更容易理解先进的人工智能概念方面有一个有前途的方向。</li>
</ul>

<h3>Title: DISCOUNT: Distributional Counterfactual Explanation With Optimal  Transport</h3>
<ul>
<li><strong>Authors: </strong>Lei You, Lele Cao, Mattias Nilsson</a></li>
<li><strong>Subjects: </strong>cs.AI, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13112">https://arxiv.org/abs/2401.13112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13112">https://arxiv.org/pdf/2401.13112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13112]] DISCOUNT: Distributional Counterfactual Explanation With Optimal  Transport(https://arxiv.org/abs/2401.13112)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorithm is accompanied by an analysis of its convergence rate. The efficacy of our proposed method is substantiated through a series of illustrative case studies, highlighting its potential in providing deep insights into decision-making models.</li>
<li><strong>摘要：</strong>反事实解释（CE）是一种事实上的方法，通过识别导致不同结果的替代输入实例，在黑盒决策模型中提供洞察力和可解释性。本文将 CE 的概念扩展到分布环境，将范围从单个数据点扩大到整个输入和输出分布，称为分布反事实解释（DCE）。在 DCE 中，我们的重点转向分析事实和反事实的分布特性，与评估个体实例及其最终决策的经典方法相似。我们利用最优传输（OT）来构建机会约束的优化问题，旨在导出与其事实对应物紧密一致的反事实分布，并由统计置信度证实。我们提出的优化方法 DISCOUNT，策略性地平衡了输入和输出分布的置信度。该算法附有对其收敛速度的分析。我们提出的方法的有效性通过一系列说明性案例研究得到证实，突出了其在为决策模型提供深入见解方面的潜力。</li>
</ul>

<h3>Title: Seed-Guided Fine-Grained Entity Typing in Science and Engineering  Domains</h3>
<ul>
<li><strong>Authors: </strong>Yu Zhang, Yunyi Zhang, Yanzhen Shen, Yu Deng, Lucian Popa, Larisa Shwartz, ChengXiang Zhai, Jiawei Han</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13129">https://arxiv.org/abs/2401.13129</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13129">https://arxiv.org/pdf/2401.13129</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13129]] Seed-Guided Fine-Grained Entity Typing in Science and Engineering  Domains(https://arxiv.org/abs/2401.13129)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Accurately typing entity mentions from text segments is a fundamental task for various natural language processing applications. Many previous approaches rely on massive human-annotated data to perform entity typing. Nevertheless, collecting such data in highly specialized science and engineering domains (e.g., software engineering and security) can be time-consuming and costly, without mentioning the domain gaps between training and inference data if the model needs to be applied to confidential datasets. In this paper, we study the task of seed-guided fine-grained entity typing in science and engineering domains, which takes the name and a few seed entities for each entity type as the only supervision and aims to classify new entity mentions into both seen and unseen types (i.e., those without seed entities). To solve this problem, we propose SEType which first enriches the weak supervision by finding more entities for each seen type from an unlabeled corpus using the contextualized representations of pre-trained language models. It then matches the enriched entities to unlabeled text to get pseudo-labeled samples and trains a textual entailment model that can make inferences for both seen and unseen types. Extensive experiments on two datasets covering four domains demonstrate the effectiveness of SEType in comparison with various baselines.</li>
<li><strong>摘要：</strong>准确地输入文本片段中的实体提及是各种自然语言处理应用程序的一项基本任务。以前的许多方法依赖于大量人工注释的数据来执行实体类型。然而，如果模型需要应用于机密数据集，在高度专业化的科学和工程领域（例如软件工程和安全）收集此类数据可能既耗时又昂贵，更不用说训练和推理数据之间的领域差距。在本文中，我们研究了科学和工程领域中种子引导的细粒度实体分类任务，该任务将每个实体类型的名称和一些种子实体作为唯一的监督，旨在将新实体提及分类为可见实体和看不见的类型（即没有种子实体的类型）。为了解决这个问题，我们提出了 SEType，它首先通过使用预训练语言模型的上下文表示从未标记的语料库中为每种看到的类型找到更多实体来丰富弱监督。然后，它将丰富的实体与未标记的文本进行匹配，以获得伪标记样本，并训练一个文本蕴涵模型，该模型可以对可见和不可见的类型进行推断。对涵盖四个领域的两个数据集进行的广泛实验证明了 SEType 与各种基线相比的有效性。</li>
</ul>

<h3>Title: Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace:  Insights from a Manually Annotated Twitter Dataset</h3>
<ul>
<li><strong>Authors: </strong>Ibrahim Said Ahmad, Lukman Jibril Aliyu, Abubakar Auwal Khalid, Saminu Muhammad Aliyu, Shamsuddeen Hassan Muhammad, Idris Abdulmumin, Bala Mairiga Abduljalil, Bello Shehu Bello, Amina Imam Abubakar</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13133">https://arxiv.org/abs/2401.13133</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13133">https://arxiv.org/pdf/2401.13133</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13133]] Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace:  Insights from a Manually Annotated Twitter Dataset(https://arxiv.org/abs/2401.13133)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Numerous successes have been achieved in combating the COVID-19 pandemic, initially using various precautionary measures like lockdowns, social distancing, and the use of face masks. More recently, various vaccinations have been developed to aid in the prevention or reduction of the severity of the COVID-19 infection. Despite the effectiveness of the precautionary measures and the vaccines, there are several controversies that are massively shared on social media platforms like Twitter. In this paper, we explore the use of state-of-the-art transformer-based language models to study people's acceptance of vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual tweets using relevant hashtags and keywords. Our analysis and visualizations revealed that most tweets expressed neutral sentiments about COVID-19 vaccines, with some individuals expressing positive views, and there was no strong preference for specific vaccine types, although Moderna received slightly more positive sentiment. We also found out that fine-tuning a pre-trained LLM with an appropriate dataset can yield competitive results, even if the LLM was not initially pre-trained on the specific language of that dataset.</li>
<li><strong>摘要：</strong>在抗击 COVID-19 大流行方面已经取得了许多成功，最初采取了各种预防措施，如封锁、保持社交距离和使用口罩。最近，已经开发出各种疫苗来帮助预防或减轻 COVID-19 感染的严重程度。尽管预防措施和疫苗有效，但推特等社交媒体平台上仍存在一些争议。在本文中，我们探索使用最先进的基于变压器的语言模型来研究尼日利亚人们对疫苗的接受程度。我们通过使用相关主题标签和关键词抓取多语言推文，开发了一个新颖的数据集。我们的分析和可视化显示，大多数推文表达了对 COVID-19 疫苗的中性情绪，一些人表达了积极的观点，并且对特定疫苗类型没有强烈的偏好，尽管 Moderna 收到了稍微更积极的情绪。我们还发现，使用适当的数据集对预训练的 LLM 进行微调可以产生有竞争力的结果，即使 LLM 最初并未针对该数据集的特定语言进行预训练。</li>
</ul>

<h3>Title: The Language Barrier: Dissecting Safety Challenges of LLMs in  Multilingual Contexts</h3>
<ul>
<li><strong>Authors: </strong>Lingfeng Shen, Weiting Tan, Sihao Chen, Yunmo Chen, Jingyu Zhang, Haoran Xu, Boyuan Zheng, Philipp Koehn, Daniel Khashabi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13136">https://arxiv.org/abs/2401.13136</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13136">https://arxiv.org/pdf/2401.13136</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13136]] The Language Barrier: Dissecting Safety Challenges of LLMs in  Multilingual Contexts(https://arxiv.org/abs/2401.13136)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages, we observe that (1) LLMs tend to generate unsafe responses much more often when a malicious prompt is written in a lower-resource language, and (2) LLMs tend to generate more irrelevant responses to malicious prompts in lower-resource languages. To understand where the discrepancy can be attributed, we study the effect of instruction tuning with reinforcement learning from human feedback (RLHF) or supervised finetuning (SFT) on the HH-RLHF dataset. Surprisingly, while training with high-resource languages improves model alignment, training in lower-resource languages yields minimal improvement. This suggests that the bottleneck of cross-lingual alignment is rooted in the pretraining stage. Our findings highlight the challenges in cross-lingual LLM safety, and we hope they inform future research in this direction.</li>
<li><strong>摘要：</strong>随着大语言模型 (LLM) 的影响力遍及全球社区，其在多语言环境中的安全挑战对于一致性研究变得至关重要。本文研究了不同语言的法学硕士所面临的安全挑战的差异，并讨论了缓解此类问题的方法。通过比较最先进的 LLM 如何响应用较高资源语言和较低资源语言编写的同一组恶意提示，我们观察到：(1) 当恶意提示出现时，LLM 往往会更频繁地生成不安全响应。用低资源语言编写，(2) 法学硕士往往会对低资源语言的恶意提示生成更多不相关的响应。为了了解差异的原因，我们研究了通过人类反馈强化学习 (RLHF) 或监督微调 (SFT) 对 HH-RLHF 数据集进行指令调整的效果。令人惊讶的是，虽然使用高资源语言进行训练可以改善模型对齐，但​​使用低资源语言进行训练的效果却微乎其微。这表明跨语言对齐的瓶颈根源于预训练阶段。我们的研究结果强调了跨语言法学硕士安全性的挑战，我们希望它们能为这一方向的未来研究提供信息。</li>
</ul>

<h3>Title: NLBAC: A Neural Ordinary Differential Equations-based Framework for  Stable and Safe Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Liqun Zhao, Keyan Miao, Konstantinos Gatsis, Antonis Papachristodoulou</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.RO, eess.SY</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13148">https://arxiv.org/abs/2401.13148</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13148">https://arxiv.org/pdf/2401.13148</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13148]] NLBAC: A Neural Ordinary Differential Equations-based Framework for  Stable and Safe Reinforcement Learning(https://arxiv.org/abs/2401.13148)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Reinforcement learning (RL) excels in applications such as video games and robotics, but ensuring safety and stability remains challenging when using RL to control real-world systems where using model-free algorithms suffering from low sample efficiency might be prohibitive. This paper first provides safety and stability definitions for the RL system, and then introduces a Neural ordinary differential equations-based Lyapunov-Barrier Actor-Critic (NLBAC) framework that leverages Neural Ordinary Differential Equations (NODEs) to approximate system dynamics and integrates the Control Barrier Function (CBF) and Control Lyapunov Function (CLF) frameworks with the actor-critic method to assist in maintaining the safety and stability for the system. Within this framework, we employ the augmented Lagrangian method to update the RL-based controller parameters. Additionally, we introduce an extra backup controller in situations where CBF constraints for safety and the CLF constraint for stability cannot be satisfied simultaneously. Simulation results demonstrate that the framework leads the system to approach the desired state and allows fewer violations of safety constraints with better sample efficiency compared to other methods.</li>
<li><strong>摘要：</strong>强化学习 (RL) 在视频游戏和机器人等应用中表现出色，但在使用 RL 控制现实系统时，确保安全性和稳定性仍然具有挑战性，在现实世界中，使用因样本效率低而导致的无模型算法可能会令人望而却步。本文首先提供了 RL 系统的安全性和稳定性定义，然后介绍了基于神经常微分方程的 Lyapunov-Barrier Actor-Critic (NLBAC) 框架，该框架利用神经常微分方程 (NODE) 来近似系统动力学并集成控制屏障函数 (CBF) 和控制李亚普诺夫函数 (CLF) 框架采用行动者批评家方法来协助维护系统的安全性和稳定性。在此框架内，我们采用增强拉格朗日方法来更新基于强化学习的控制器参数。此外，在无法同时满足 CBF 安全约束和 CLF 稳定性约束的情况下，我们引入了额外的备用控制器。仿真结果表明，与其他方法相比，该框架使系统接近所需状态，并允许更少地违反安全约束，并且具有更高的样本效率。</li>
</ul>

<h3>Title: SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced  Token Detection</h3>
<ul>
<li><strong>Authors: </strong>Ke Ye, Heinrich Jiang, Afshin Rostamizadeh, Ayan Chakrabarti, Giulia DeSalvo, Jean-François Kagy, Lazaros Karydas, Gui Citovsky, Sanjiv Kumar</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13160">https://arxiv.org/abs/2401.13160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13160">https://arxiv.org/pdf/2401.13160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13160]] SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced  Token Detection(https://arxiv.org/abs/2401.13160)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, code</a></li>
<li><strong>Abstract: </strong>Pre-training large language models is known to be extremely resource intensive and often times inefficient, under-utilizing the information encapsulated in the training text sequences. In this paper, we present SpacTor, a new training procedure consisting of (1) a hybrid objective combining span corruption (SC) and token replacement detection (RTD), and (2) a two-stage curriculum that optimizes the hybrid objective over the initial $\tau$ iterations, then transitions to standard SC loss. We show empirically that the effectiveness of the hybrid objective is tied to the two-stage pre-training schedule, and provide extensive analysis on why this is the case. In our experiments with encoder-decoder architectures (T5) on a variety of NLP tasks, SpacTor-T5 yields the same downstream performance as standard SC pre-training, while enabling a 50% reduction in pre-training iterations and 40% reduction in total FLOPs. Alternatively, given the same amount of computing budget, we find that SpacTor results in significantly improved downstream benchmark performance.</li>
<li><strong>摘要：</strong>众所周知，预训练大型语言模型是资源极其密集的，而且通常效率低下，没有充分利用训练文本序列中封装的信息。在本文中，我们提出了 SpacTor，一种新的训练程序，包括 (1) 结合跨度损坏 (SC) 和令牌替换检测 (RTD) 的混合目标，以及 (2) 一个两阶段课程，可优化混合目标初始 $\tau$ 迭代，然后过渡到标准 SC 损失。我们凭经验证明，混合目标的有效性与两阶段预训练计划相关，并对原因进行了广泛的分析。在我们针对各种 NLP 任务使用编码器-解码器架构 (T5) 进行的实验中，SpacTor-T5 产生了与标准 SC 预训练相同的下游性能，同时使预训练迭代次数减少了 50%，总迭代次数减少了 40%失败。另外，在计算预算相同的情况下，我们发现 SpacTor 可以显着提高下游基准测试性能。</li>
</ul>

<h3>Title: CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Zongxia Li, Ishani Mondal, Yijun Liang, Huy Nghiem, Jordan Boyd-Graber</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13170">https://arxiv.org/abs/2401.13170</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13170">https://arxiv.org/pdf/2401.13170</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13170]] CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering(https://arxiv.org/abs/2401.13170)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Question answering (QA) can only make progress if we know if an answer is correct, but for many of the most challenging and interesting QA examples, current evaluation metrics to determine answer equivalence (AE) often do not align with human judgments, particularly more verbose, free-form answers from large language models (LLM). There are two challenges: a lack of data and that models are too big: LLM-based scorers can correlate better with human judges, but this task has only been tested on limited QA datasets, and even when available, update of the model is limited because LLMs are large and often expensive. We rectify both of these issues by providing clear and consistent guidelines for evaluating AE in machine QA adopted from professional human QA contests. We also introduce a combination of standard evaluation and a more efficient, robust, and lightweight discriminate AE classifier-based matching method (CFMatch, smaller than 1 MB), trained and validated to more accurately evaluate answer correctness in accordance with adopted expert AE rules that are more aligned with human judgments.</li>
<li><strong>摘要：</strong>只有当我们知道答案是否正确时，问答 (QA) 才能取得进展，但对于许多最具挑战性和有趣的 QA 示例，当前确定答案等价性 (AE) 的评估指标通常与人类的判断不一致，尤其是更多来自大型语言模型 (LLM) 的详细、自由格式的答案。存在两个挑战：缺乏数据和模型太大：基于 LLM 的评分器可以更好地与人类评判相关联，但此任务仅在有限的 QA 数据集上进行了测试，即使可用，模型的更新也是有限的因为法学硕士规模很大而且通常很昂贵。我们通过提供清晰一致的指南来评估从专业人类 QA 竞赛中采用的机器 QA 中的 AE，从而纠正了这两个问题。我们还引入了标准评估和更高效、更稳健、更轻量级的基于判别 AE 分类器的匹配方法（CFMatch，小于 1 MB）的组合，经过训练和验证，可以根据采用的专家 AE 规则更准确地评估答案的正确性更符合人类的判断。</li>
</ul>

<h3>Title: Compositional Generative Inverse Design</h3>
<ul>
<li><strong>Authors: </strong>Tailin Wu, Takashi Maruyama, Long Wei, Tao Zhang, Yilun Du, Gianluca Iaccarino, Jure Leskovec</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13171">https://arxiv.org/abs/2401.13171</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13171">https://arxiv.org/pdf/2401.13171</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13171]] Compositional Generative Inverse Design(https://arxiv.org/abs/2401.13171)</code><input type="text"></li>
<li><strong>Keywords: </strong>code, rag</a></li>
<li><strong>Abstract: </strong>Inverse design, where we seek to design input variables in order to optimize an underlying objective function, is an important problem that arises across fields such as mechanical engineering to aerospace engineering. Inverse design is typically formulated as an optimization problem, with recent works leveraging optimization across learned dynamics models. However, as models are optimized they tend to fall into adversarial modes, preventing effective sampling. We illustrate that by instead optimizing over the learned energy function captured by the diffusion model, we can avoid such adversarial examples and significantly improve design performance. We further illustrate how such a design system is compositional, enabling us to combine multiple different diffusion models representing subcomponents of our desired system to design systems with every specified component. In an N-body interaction task and a challenging 2D multi-airfoil design task, we demonstrate that by composing the learned diffusion model at test time, our method allows us to design initial states and boundary shapes that are more complex than those in the training data. Our method outperforms state-of-the-art neural inverse design method by an average of 41.5% in prediction MAE and 14.3% in design objective for the N-body dataset and discovers formation flying to minimize drag in the multi-airfoil design task. Project website and code can be found at https://github.com/AI4Science-WestlakeU/cindm.</li>
<li><strong>摘要：</strong>逆向设计，即我们寻求设计输入变量以优化基本目标函数，是机械工程到航空航天工程等领域出现的一个重要问题。逆向设计通常被表述为优化问题，最近的工作利用了学习动态模型的优化。然而，随着模型的优化，它们往往会陷入对抗模式，从而阻碍有效采样。我们说明，通过优化扩散模型捕获的学习能量函数，我们可以避免此类对抗性示例并显着提高设计性能。我们进一步说明了这样的设计系统是如何组合的，使我们能够组合代表我们所需系统的子组件的多个不同的扩散模型，以设计具有每个指定组件的系统。在 N 体交互任务和具有挑战性的 2D 多翼型设计任务中，我们证明，通过在测试时构建学习的扩散模型，我们的方法允许我们设计比训练中更复杂的初始状态和边界形状数据。我们的方法在 N 体数据集的预测 MAE 上平均优于最先进的神经逆向设计方法 41.5%，在设计目标上平均优于最先进的神经逆设计方法 14.3%，并发现编队飞行以最小化多翼型设计任务中的阻力。项目网站和代码可以在 https://github.com/AI4Science-WestlakeU/cindm 找到。</li>
</ul>

<h3>Title: AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents</h3>
<ul>
<li><strong>Authors: </strong>Chang Ma, Junlei Zhang, Zhihao Zhu, Cheng Yang, Yujiu Yang, Yaohui Jin, Zhenzhong Lan, Lingpeng Kong, Junxian He</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13178">https://arxiv.org/abs/2401.13178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13178">https://arxiv.org/pdf/2401.13178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13178]] AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents(https://arxiv.org/abs/2401.13178)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Evaluating large language models (LLMs) as general-purpose agents is essential for understanding their capabilities and facilitating their integration into practical applications. However, the evaluation process presents substantial challenges. A primary obstacle is the benchmarking of agent performance across diverse scenarios within a unified framework, especially in maintaining partially-observable environments and ensuring multi-round interactions. Moreover, current evaluation frameworks mostly focus on the final success rate, revealing few insights during the process and failing to provide a deep understanding of the model abilities. To address these challenges, we introduce AgentBoard, a pioneering comprehensive benchmark and accompanied open-source evaluation framework tailored to analytical evaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric that captures incremental advancements as well as a comprehensive evaluation toolkit that features easy assessment of agents for multi-faceted analysis through interactive visualization. This not only sheds light on the capabilities and limitations of LLM agents but also propels the interpretability of their performance to the forefront. Ultimately, AgentBoard serves as a significant step towards demystifying agent behaviors and accelerating the development of stronger LLM agents.</li>
<li><strong>摘要：</strong>将大型语言模型 (LLM) 作为通用代理进行评估对于了解其功能并促进其集成到实际应用中至关重要。然而，评估过程面临着巨大的挑战。主要障碍是在统一框架内跨不同场景对代理性能进行基准测试，特别是在维护部分可观察的环境和确保多轮交互方面。此外，当前的评估框架大多关注最终的成功率，在过程中揭示的洞察很少，未能提供对模型能力的深入理解。为了应对这些挑战，我们引入了 AgentBoard，这是一个开创性的综合基准，并附带专为法学硕士代理的分析评估而定制的开源评估框架。 AgentBoard 提供了细粒度的进度指标，可捕获增量进展，以及全面的评估工具包，可通过交互式可视化轻松评估代理以进行多方面分析。这不仅揭示了法学硕士代理人的能力和局限性，而且还将他们的表现的可解释性推向了最前沿。最终，AgentBoard 是揭开代理行为神秘面纱并加速开发更强大的 LLM 代理的重要一步。</li>
</ul>

<h3>Title: Generative Design of Crystal Structures by Point Cloud Representations  and Diffusion Model</h3>
<ul>
<li><strong>Authors: </strong>Zhelin Li, Rami Mrad, Runxian Jiao, Guan Huang, Jun Shan, Shibing Chu, Yuanping Chen</a></li>
<li><strong>Subjects: </strong>cs.AI, cond-mat.mtrl-sci, cs.LG, physics.comp-ph</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13192">https://arxiv.org/abs/2401.13192</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13192">https://arxiv.org/pdf/2401.13192</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13192]] Generative Design of Crystal Structures by Point Cloud Representations  and Diffusion Model(https://arxiv.org/abs/2401.13192)</code><input type="text"></li>
<li><strong>Keywords: </strong>code, rag</a></li>
<li><strong>Abstract: </strong>Efficiently generating energetically stable crystal structures has long been a challenge in material design, primarily due to the immense arrangement of atoms in a crystal lattice. To facilitate the discovery of stable material, we present a framework for the generation of synthesizable materials, leveraging a point cloud representation to encode intricate structural information. At the heart of this framework lies the introduction of a diffusion model as its foundational pillar. To gauge the efficacy of our approach, we employ it to reconstruct input structures from our training datasets, rigorously validating its high reconstruction performance. Furthermore, we demonstrate the profound potential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely new materials, emphasizing their synthesizability. Our research stands as a noteworthy contribution to the advancement of materials design and synthesis through the cutting-edge avenue of generative design instead of the conventional substitution or experience-based discovery.</li>
<li><strong>摘要：</strong>有效生成能量稳定的晶体结构长期以来一直是材料设计中的一个挑战，这主要是由于晶格中原子的巨大排列。为了促进稳定材料的发现，我们提出了一个生成可合成材料的框架，利用点云表示来编码复杂的结构信息。该框架的核心在于引入扩散模型作为其基础支柱。为了衡量我们方法的有效性，我们用它来从我们的训练数据集中重建输入结构，严格验证其高重建性能。此外，我们通过生成全新材料来展示基于点云的晶体扩散（PCCD）的巨大潜力，并强调其可合成性。我们的研究通过前沿的生成设计途径而不是传统的替代或基于经验的发现，为材料设计和合成的进步做出了值得注意的贡献。</li>
</ul>

<h3>Title: Topology-aware Embedding Memory for Learning on Expanding Graphs</h3>
<ul>
<li><strong>Authors: </strong>Xikun Zhang, Dongjin Song, Yixin Chen, Dacheng Tao</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13200">https://arxiv.org/abs/2401.13200</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13200">https://arxiv.org/pdf/2401.13200</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13200]] Topology-aware Embedding Memory for Learning on Expanding Graphs(https://arxiv.org/abs/2401.13200)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Memory replay based techniques have shown great success for continual learning with incrementally accumulated Euclidean data. Directly applying them to continually expanding graphs, however, leads to the potential memory explosion problem due to the need to buffer representative nodes and their associated topological neighborhood structures. To this end, we systematically analyze the key challenges in the memory explosion problem, and present a general framework, i.e., Parameter Decoupled Graph Neural Networks (PDGNNs) with Topology-aware Embedding Memory (TEM), to tackle this issue. The proposed framework not only reduces the memory space complexity from $\mathcal{O}(nd^L)$ to $\mathcal{O}(n)$~\footnote{$n$: memory budget, $d$: average node degree, $L$: the radius of the GNN receptive field}, but also fully utilizes the topological information for memory replay. Specifically, PDGNNs decouple trainable parameters from the computation ego-subgraph via \textit{Topology-aware Embeddings} (TEs), which compress ego-subgraphs into compact vectors (i.e., TEs) to reduce the memory consumption. Based on this framework, we discover a unique \textit{pseudo-training effect} in continual learning on expanding graphs and this effect motivates us to develop a novel \textit{coverage maximization sampling} strategy that can enhance the performance with a tight memory budget. Thorough empirical studies demonstrate that, by tackling the memory explosion problem and incorporating topological information into memory replay, PDGNNs with TEM significantly outperform state-of-the-art techniques, especially in the challenging class-incremental setting.</li>
<li><strong>摘要：</strong>基于记忆重放的技术在使用增量积累的欧几里得数据进行持续学习方面取得了巨大成功。然而，由于需要缓冲代表性节点及其相关的拓扑邻域结构，直接将它们应用于不断扩展的图会导致潜在的内存爆炸问题。为此，我们系统地分析了内存爆炸问题的关键挑战，并提出了一个通用框架，即带有拓扑感知嵌入内存（TEM）的参数解耦图神经网络（PDGNN）来解决这个问题。所提出的框架不仅将内存空间复杂度从 $\mathcal{O}(nd^L)$ 降低到 $\mathcal{O}(n)$~\footnote{$n$: 内存预算，$d$: 平均值节点度，$L$：GNN感受野的半径}，同时也充分利用了拓扑信息进行记忆重放。具体来说，PDGNN 通过 \textit{拓扑感知嵌入}（TE）将可训练参数与计算自我子图解耦，将自我子图压缩为紧凑向量（即 TE）以减少内存消耗。基于这个框架，我们在扩展图的持续学习中发现了一种独特的\textit{伪训练效应}，这种效应激励我们开发一种新颖的\textit{覆盖最大化采样}策略，该策略可以在内存预算紧张的情况下提高性能。彻底的实证研究表明，通过解决内存爆炸问题并将拓扑信息纳入内存重放，具有 TEM 的 PDGNN 显着优于最先进的技术，特别是在具有挑战性的类增量设置中。</li>
</ul>

<h3>Title: Multitask Active Learning for Graph Anomaly Detection</h3>
<ul>
<li><strong>Authors: </strong>Wenjing Chang, Kay Liu, Kaize Ding, Philip S. Yu, Jianjun Yu</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13210">https://arxiv.org/abs/2401.13210</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13210">https://arxiv.org/pdf/2401.13210</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13210]] Multitask Active Learning for Graph Anomaly Detection(https://arxiv.org/abs/2401.13210)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>In the web era, graph machine learning has been widely used on ubiquitous graph-structured data. As a pivotal component for bolstering web security and enhancing the robustness of graph-based applications, the significance of graph anomaly detection is continually increasing. While Graph Neural Networks (GNNs) have demonstrated efficacy in supervised and semi-supervised graph anomaly detection, their performance is contingent upon the availability of sufficient ground truth labels. The labor-intensive nature of identifying anomalies from complex graph structures poses a significant challenge in real-world applications. Despite that, the indirect supervision signals from other tasks (e.g., node classification) are relatively abundant. In this paper, we propose a novel MultItask acTIve Graph Anomaly deTEction framework, namely MITIGATE. Firstly, by coupling node classification tasks, MITIGATE obtains the capability to detect out-of-distribution nodes without known anomalies. Secondly, MITIGATE quantifies the informativeness of nodes by the confidence difference across tasks, allowing samples with conflicting predictions to provide informative yet not excessively challenging information for subsequent training. Finally, to enhance the likelihood of selecting representative nodes that are distant from known patterns, MITIGATE adopts a masked aggregation mechanism for distance measurement, considering both inherent features of nodes and current labeled status. Empirical studies on four datasets demonstrate that MITIGATE significantly outperforms the state-of-the-art methods for anomaly detection. Our code is publicly available at: https://github.com/AhaChang/MITIGATE.</li>
<li><strong>摘要：</strong>在网络时代，图机器学习已广泛应用于无处不在的图结构数据。作为增强网络安全性和增强基于图的应用程序稳健性的关键组件，图异常检测的重要性不断增加。虽然图神经网络（GNN）已经证明了在监督和半监督图异常检测方面的功效，但它们的性能取决于是否有足够的地面真实标签。从复杂的图形结构中识别异常的劳动密集型性质在实际应用中提出了重大挑战。尽管如此，来自其他任务（例如节点分类）的间接监督信号相对丰富。在本文中，我们提出了一种新颖的多任务主动图异常检测框架，即 MITIGATE。首先，通过耦合节点分类任务，MITIGATE获得了在没有已知异常的情况下检测分布外节点的能力。其次，MITIGATE通过任务之间的置信度差异来量化节点的信息量，允许具有冲突预测的样本为后续训练提供信息丰富但不过分具有挑战性的信息。最后，为了提高选择远离已知模式的代表节点的可能性，MITIGATE采用屏蔽聚合机制进行距离测量，同时考虑节点的固有特征和当前标记状态。对四个数据集的实证研究表明，MITIGATE 显着优于最先进的异常检测方法。我们的代码公开于：https://github.com/AhaChang/MITIGATE。</li>
</ul>

<h3>Title: On Principled Local Optimization Methods for Federated Learning</h3>
<ul>
<li><strong>Authors: </strong>Honglin Yuan</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.DC, math.OC, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13216">https://arxiv.org/abs/2401.13216</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13216">https://arxiv.org/pdf/2401.13216</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13216]] On Principled Local Optimization Methods for Federated Learning(https://arxiv.org/abs/2401.13216)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions. First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective. Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled acceleration of FedAvg, which provably improves the convergence rate and communication efficiency. Our technique uses on a potential-based perturbed iterate analysis, a novel stability analysis of generalized accelerated SGD, and a strategic tradeoff between acceleration and stability. Third, we study the Federated Composite Optimization problem, which extends the classic smooth setting by incorporating a shared non-smooth regularizer. We show that direct extensions of FedAvg may suffer from the "curse of primal averaging," resulting in slow convergence. As a solution, we propose a new primal-dual algorithm, Federated Dual Averaging, which overcomes the curse of primal averaging by employing a novel inter-client dual averaging procedure.</li>
<li><strong>摘要：</strong>联合学习（FL）是一种分布式学习范式，可协作扩展设备上的学习，已成为去中心化人工智能应用程序的一种有前途的方法。联合平均 (FedAvg) 等局部优化方法是 FL 应用中最著名的方法。尽管局部优化方法简单且流行，但其理论理解还远未明确。本论文旨在从以下三个方向推进局部方法的理论基础。首先，我们为联邦学习中最流行的算法 FedAvg 建立锐界。我们展示了 FedAvg 如何受到我们称为迭代偏差的概念的影响，以及额外的三阶平滑假设如何减轻这种影响并导致更好的收敛率。我们从随机微分方程（SDE）的角度解释这一现象。其次，我们提出了联邦加速随机梯度下降（FedAc），这是 FedAvg 的第一个原则性加速，可证明提高了收敛速度和通信效率。我们的技术使用基于势的扰动迭代分析、广义加速 SGD 的新颖稳定性分析以及加速与稳定性之间的策略权衡。第三，我们研究联合复合优化问题，该问题通过合并共享非平滑正则化器来扩展经典的平滑设置。我们表明，FedAvg 的直接扩展可能会遭受“原始平均诅咒”，导致收敛缓慢。作为解决方案，我们提出了一种新的原始对偶算法，即联合对偶平均，它通过采用一种新颖的客户端间对偶平均程序来克服原始平均的诅咒。</li>
</ul>

<h3>Title: ULTRA: Unleash LLMs' Potential for Event Argument Extraction through  Hierarchical Modeling and Pair-wise Refinement</h3>
<ul>
<li><strong>Authors: </strong>Xinliang Frederick Zhang, Carter Blum, Temma Choji, Shalin Shah, Alakananda Vempala</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13218">https://arxiv.org/abs/2401.13218</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13218">https://arxiv.org/pdf/2401.13218</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13218]] ULTRA: Unleash LLMs' Potential for Event Argument Extraction through  Hierarchical Modeling and Pair-wise Refinement(https://arxiv.org/abs/2401.13218)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, chat</a></li>
<li><strong>Abstract: </strong>Structural extraction of events within discourse is critical since it avails a deeper understanding of communication patterns and behavior trends. Event argument extraction (EAE), at the core of event-centric understanding, is the task of identifying role-specific text spans (i.e., arguments) for a given event. Document-level EAE (DocEAE) focuses on arguments that are scattered across an entire document. In this work, we explore the capabilities of open source Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To this end, we propose ULTRA, a hierarchical framework that extracts event arguments more cost-effectively -- the method needs as few as 50 annotations and doesn't require hitting costly API endpoints. Further, it alleviates the positional bias issue intrinsic to LLMs. ULTRA first sequentially reads text chunks of a document to generate a candidate argument set, upon which ULTRA learns to drop non-pertinent candidates through self-refinement. We further introduce LEAFER to address the challenge LLMs face in locating the exact boundary of an argument span. ULTRA outperforms strong baselines, which include strong supervised models and ChatGPT, by 9.8% when evaluated by the exact match (EM) metric.</li>
<li><strong>摘要：</strong>话语中事件的结构提取至关重要，因为它有助于更​​深入地理解沟通模式和行为趋势。事件参数提取 (EAE) 是以事件为中心的理解的核心，它的任务是识别给定事件的特定于角色的文本范围（即参数）。文档级 EAE (DocEAE) 重点关注分散在整个文档中的参数。在这项工作中，我们探索了开源大型语言模型 (LLM)（即 Flan-UL2）对于 DocEAE 任务的功能。为此，我们提出了 ULTRA，这是一个分层框架，可以更经济有效地提取事件参数——该方法只需要 50 个注释，并且不需要访问昂贵的 API 端点。此外，它还缓解了法学硕士固有的职位偏见问题。 ULTRA 首先顺序读取文档的文本块以生成候选参数集，在此基础上 ULTRA 学习通过自我细化删除不相关的候选参数。我们进一步引入 LEAFER 来解决法学硕士在定位参数范围的精确边界时面临的挑战。当通过精确匹配 (EM) 指标进行评估时，ULTRA 的性能优于强基线（包括强监督模型和 ChatGPT）9.8%。</li>
</ul>

<h3>Title: TAT-LLM: A Specialized Language Model for Discrete Reasoning over  Tabular and Textual Data</h3>
<ul>
<li><strong>Authors: </strong>Fengbin Zhu, Ziyang Liu, Fuli Feng, Chao Wang, Moxin Li, Tat-Seng Chua</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13223">https://arxiv.org/abs/2401.13223</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13223">https://arxiv.org/pdf/2401.13223</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13223]] TAT-LLM: A Specialized Language Model for Discrete Reasoning over  Tabular and Textual Data(https://arxiv.org/abs/2401.13223)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm</a></li>
<li><strong>Abstract: </strong>In this work, we address question answering (QA) over a hybrid of tabular and textual data that are very common content on the Web (e.g. SEC filings), where discrete reasoning capabilities are often required. Recently, large language models (LLMs) like GPT-4 have demonstrated strong multi-step reasoning capabilities. We then consider harnessing the amazing power of LLMs to solve our task. We abstract a Step-wise Pipeline for tabular and textual QA, which consists of three key steps, including Extractor, Reasoner and Executor, and initially design an instruction to instantiate the pipeline and validate that GPT-4 outperforms all existing methods. However, utilizing an online LLM like GPT-4 holds various challenges in terms of cost, latency, and data security risk, which motivates us to specialize smaller LLMs in this task. We develop a TAT-LLM language model by fine-tuning LLaMA 2 with the training data generated automatically from existing expert-annotated datasets following the Step-wise Pipeline. The experimental results have verified that our TAT-LLM model can outperform all baseline models, including the previous best fine-tuned models and very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks. We hope our work can serve as a pioneering example of specializing smaller language models for specific tasks.</li>
<li><strong>摘要：</strong>在这项工作中，我们通过表格和文本数据的混合来解决问答（QA）问题，这些数据是网络上非常常见的内容（例如 SEC 文件），其中通常需要离散推理能力。最近，像 GPT-4 这样的大型语言模型（LLM）已经表现出了强大的多步推理能力。然后，我们考虑利用法学硕士的惊人力量来解决我们的任务。我们抽象了一个用于表格和文本 QA 的逐步管道，它由三个关键步骤组成，包括提取器、推理器和执行器，并初步设计了一条指令来实例化管道并验证 GPT-4 优于所有现有方法。然而，利用像 GPT-4 这样的在线法学硕士在成本、延迟和数据安全风险方面面临着各种挑战，这促使我们专注于较小的法学硕士来完成这项任务。我们通过使用从现有专家注释数据集按照逐步管道自动生成的训练数据对 LLaMA 2 进行微调，开发了 TAT-LLM 语言模型。实验结果验证了我们的 TAT-LLM 模型可以优于所有基线模型，包括之前最好的微调模型和非常大规模的 LLM，例如 FinQA、TAT-QA 和 TAT-DQA 基准上的 GPT-4。我们希望我们的工作能够成为专门针对特定任务的小型语言模型的开创性例子。</li>
</ul>

<h3>Title: Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large  Language Models</h3>
<ul>
<li><strong>Authors: </strong>Baolong Bi, Shenghua Liu, Yiwei Wang, Lingrui Mei, Xueqi Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13227">https://arxiv.org/abs/2401.13227</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13227">https://arxiv.org/pdf/2401.13227</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13227]] Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large  Language Models(https://arxiv.org/abs/2401.13227)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, prompt</a></li>
<li><strong>Abstract: </strong>Exploring the application of large-scale language models to graph learning is a novel endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to this process. This paper focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on a large language model designed for scalable link prediction on large-scale heterogeneous graphs.We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from large-scale heterogeneous graphs, and a divide-and-conquer strategy to control the input token count within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for for link prediction. Extensive experiments on a large public heterogeneous graphs demonstrate that LPNL outperforms various advanced baselines, highlighting its remarkable performance in link prediction tasks on large-scale graphs.</li>
<li><strong>摘要：</strong>探索大规模语言模型在图学习中的应用是一项新颖的尝试。然而，大图中固有的大量信息给这一过程带来了重大挑战。本文重点关注链接预测任务，并介绍了 LPNL（自然语言链接预测），这是一个基于大型语言模型的框架，专为大规模异构图上的可扩展链接预测而设计。我们为链接预测设计了新颖的提示，以阐明图细节用自然语言。我们提出了一个两阶段采样管道来从大规模异构图中提取关键信息，并提出了一种分治策略来将输入令牌数量控制在预定义的范围内，从而解决海量信息的挑战。我们根据专为链接预测而设计的自监督学习来微调 T5 模型。在大型公共异构图上进行的大量实验表明，LPNL 的性能优于各种先进基线，突显了其在大规模图上的链路预测任务中的卓越性能。</li>
</ul>

<h3>Title: From Random to Informed Data Selection: A Diversity-Based Approach to  Optimize Human Annotation and Few-Shot Learning</h3>
<ul>
<li><strong>Authors: </strong>Alexandre Alcoforado, Thomas Palmeira Ferraz, Lucas Hideki Okamura, Israel Campos Fama, Arnold Moya Lavado, Bárbara Dias Bueno, Bruno Veloso, Anna Helena Reali Costa</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13229">https://arxiv.org/abs/2401.13229</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13229">https://arxiv.org/pdf/2401.13229</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13229]] From Random to Informed Data Selection: A Diversity-Based Approach to  Optimize Human Annotation and Few-Shot Learning(https://arxiv.org/abs/2401.13229)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>A major challenge in Natural Language Processing is obtaining annotated data for supervised learning. An option is the use of crowdsourcing platforms for data annotation. However, crowdsourcing introduces issues related to the annotator's experience, consistency, and biases. An alternative is to use zero-shot methods, which in turn have limitations compared to their few-shot or fully supervised counterparts. Recent advancements driven by large language models show potential, but struggle to adapt to specialized domains with severely limited data. The most common approaches therefore involve the human itself randomly annotating a set of datapoints to build initial datasets. But randomly sampling data to be annotated is often inefficient as it ignores the characteristics of the data and the specific needs of the model. The situation worsens when working with imbalanced datasets, as random sampling tends to heavily bias towards the majority classes, leading to excessive annotated data. To address these issues, this paper contributes an automatic and informed data selection architecture to build a small dataset for few-shot learning. Our proposal minimizes the quantity and maximizes diversity of data selected for human annotation, while improving model performance.</li>
<li><strong>摘要：</strong>自然语言处理的一个主要挑战是获取用于监督学习的注释数据。一种选择是使用众包平台进行数据注释。然而，众包引入了与注释者的经验、一致性和偏见相关的问题。另一种方法是使用零样本方法，与少样本或完全监督的方法相比，零样本方法又具有局限性。由大型语言模型驱动的最新进展显示出潜力，但难以适应数据严重有限的专业领域。因此，最常见的方法涉及人类本身随机注释一组数据点以构建初始数据集。但随机采样要标注的数据往往效率低下，因为它忽略了数据的特征和模型的具体需求。当处理不平衡的数据集时，情况会变得更糟，因为随机抽样往往会严重偏向大多数类，导致注释数据过多。为了解决这些问题，本文提供了一种自动且知情的数据选择架构，以构建用于少样本学习的小型数据集。我们的建议最大限度地减少了人工注释所选择的数据的数量并最大化了其多样性，同时提高了模型性能。</li>
</ul>

<h3>Title: Adaptive Crowdsourcing Via Self-Supervised Learning</h3>
<ul>
<li><strong>Authors: </strong>Anmol Kagrecha, Henrik Marklund, Benjamin Van Roy, Hong Jun Jeon, Richard Zeckhauser</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.HC</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13239">https://arxiv.org/abs/2401.13239</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13239">https://arxiv.org/pdf/2401.13239</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13239]] Adaptive Crowdsourcing Via Self-Supervised Learning(https://arxiv.org/abs/2401.13239)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Common crowdsourcing systems average estimates of a latent quantity of interest provided by many crowdworkers to produce a group estimate. We develop a new approach -- just-predict-others -- that leverages self-supervised learning and a novel aggregation scheme. This approach adapts weights assigned to crowdworkers based on estimates they provided for previous quantities. When skills vary across crowdworkers or their estimates correlate, the weighted sum offers a more accurate group estimate than the average. Existing algorithms such as expectation maximization can, at least in principle, produce similarly accurate group estimates. However, their computational requirements become onerous when complex models, such as neural networks, are required to express relationships among crowdworkers. Just-predict-others accommodates such complexity as well as many other practical challenges. We analyze the efficacy of just-predict-others through theoretical and computational studies. Among other things, we establish asymptotic optimality as the number of engagements per crowdworker grows.</li>
<li><strong>摘要：</strong>常见的众包系统对许多众包工作者提供的潜在兴趣量进行平均估计，以产生群体估计。我们开发了一种新方法——预测他人——利用自我监督学习和新颖的聚合方案。这种方法根据众包工作者对之前数量的估计来调整分配给众包工作者的权重。当众包工作者的技能各不相同或者他们的估计相互关联时，加权总和可以提供比平均值更准确的群体估计。现有算法（例如期望最大化）至少在原则上可以产生类似准确的群体估计。然而，当需要复杂的模型（例如神经网络）来表达众包工作者之间的关系时，它们的计算要求变得繁重。 Just-predict-others 适应了这种复杂性以及许多其他实际挑战。我们通过理论和计算研究来分析“预测他人”的功效。除此之外，随着每个众包工作者的参与数量的增长，我们建立了渐近最优性。</li>
</ul>

<h3>Title: SEER: Facilitating Structured Reasoning and Explanation via  Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Guoxin Chen, Kexin Tang, Chao Yang, Fuying Ye, Yu Qiao, Yiming Qian</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13246">https://arxiv.org/abs/2401.13246</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13246">https://arxiv.org/pdf/2401.13246</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13246]] SEER: Facilitating Structured Reasoning and Explanation via  Reinforcement Learning(https://arxiv.org/abs/2401.13246)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Elucidating the reasoning process with structured explanations from question to answer is fundamentally crucial, as it significantly enhances the interpretability and trustworthiness of question-answering (QA) systems. However, structured explanations demand models to perform intricate structured reasoning, which poses great challenges. Most existing methods focus on single-step reasoning through supervised learning, ignoring logical dependencies between steps. Meanwhile, existing reinforcement learning (RL)-based methods overlook the structured relationships, impeding RL's potential in structured reasoning. In this paper, we propose SEER, a novel method that maximizes a structure-based return to facilitate structured reasoning and explanation. Our proposed structure-based return precisely describes the hierarchical and branching structure inherent in structured reasoning, effectively capturing the intricate relationships between states. We also introduce a fine-grained reward function to meticulously delineate diverse reasoning steps. Extensive experiments show that SEER significantly outperforms state-of-the-art methods, achieving an absolute improvement of 6.9% over RL-based methods on EntailmentBank, a 4.4% average improvement on STREET benchmark, and exhibiting outstanding efficiency and cross-dataset generalization performance.</li>
<li><strong>摘要：</strong>通过从问题到答案的结构化解释来阐明推理过程至关重要，因为它显着增强了问答（QA）系统的可解释性和可信度。然而，结构化解释需要模型进行复杂的结构化推理，这带来了巨大的挑战。大多数现有方法侧重于通过监督学习进行单步推理，忽略步骤之间的逻辑依赖关系。与此同时，现有的基于强化学习（RL）的方法忽视了结构化关系，阻碍了 RL 在结构化推理中的潜力。在本文中，我们提出了 SEER，这是一种最大化基于结构的回报以促进结构化推理和解释的新颖方法。我们提出的基于结构的返回精确地描述了结构化推理中固有的层次和分支结构，有效地捕获了状态之间复杂的关系。我们还引入了细粒度的奖励函数来精心描绘不同的推理步骤。大量实验表明，SEER 显着优于最先进的方法，在 EntailmentBank 上比基于 RL 的方法绝对提高了 6.9%，在 STREET 基准上平均提高了 4.4%，并表现出出色的效率和跨数据集泛化性能。</li>
</ul>

<h3>Title: UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for  Personalized Dialogue Systems</h3>
<ul>
<li><strong>Authors: </strong>Hongru Wang, Wenyu Huang, Yang Deng, Rui Wang, Zezhong Wang, Yufei Wang, Fei Mi, Jeff Z. Pan, Kam-Fai Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13256">https://arxiv.org/abs/2401.13256</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13256">https://arxiv.org/pdf/2401.13256</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13256]] UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for  Personalized Dialogue Systems(https://arxiv.org/abs/2401.13256)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, retrieval-augmented generation, rag</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) has shown exceptional capabilities in many natual language understanding and generation tasks. However, the personalization issue still remains a much-coveted property, especially when it comes to the multiple sources involved in the dialogue system. To better plan and incorporate the use of multiple sources in generating personalized response, we firstly decompose it into three sub-tasks: Knowledge Source Selection, Knowledge Retrieval, and Response Generation. We then propose a novel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG) Specifically, we unify these three sub-tasks with different formulations into the same sequence-to-sequence paradigm during the training, to adaptively retrieve evidences and evaluate the relevance on-demand using special tokens, called acting tokens and evaluation tokens. Enabling language models to generate acting tokens facilitates interaction with various knowledge sources, allowing them to adapt their behavior to diverse task requirements. Meanwhile, evaluation tokens gauge the relevance score between the dialogue context and the retrieved evidence. In addition, we carefully design a self-refinement mechanism to iteratively refine the generated response considering 1) the consistency scores between the generated response and retrieved evidence; and 2) the relevance scores. Experiments on two personalized datasets (DuLeMon and KBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge source selection and response generation task with itself as a retriever in a unified manner. Extensive analyses and discussions are provided for shedding some new perspectives for personalized dialogue systems.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 在许多自然语言理解和生成任务中表现出了卓越的能力。然而，个性化问题仍然是一个令人垂涎的属性，特别是当涉及对话系统中涉及的多个来源时。为了更好地规划和整合多个来源的使用来生成个性化响应，我们首先将其分解为三个子任务：知识源选择、知识检索和响应生成。然后，我们提出了一种新颖的统一多源检索增强生成系统（UniMS-RAG）具体来说，我们在训练期间将这三个具有不同公式的子任务统一到相同的序列到序列范式中，以自适应地检索证据并评估使用特殊令牌（称为代理令牌和评估令牌）按需关联。使语言模型能够生成动作令牌有助于与各种知识源的交互，使它们能够适应不同的任务要求。同时，评估标记衡量对话上下文和检索到的证据之间的相关性得分。此外，我们精心设计了一种自我细化机制，以迭代地细化生成的响应，考虑到：1）生成的响应与检索到的证据之间的一致性分数； 2) 相关性分数。在两个个性化数据集（DuLeMon 和 KBP）上的实验表明，UniMS-RAG 以统一的方式将自身作为检索器，在知识源选择和响应生成任务上实现了最先进的性能。提供了广泛的分析和讨论，为个性化对话系统提供了一些新的视角。</li>
</ul>

<h3>Title: MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion,  ASR Error Detection, and ASR Error Correction</h3>
<ul>
<li><strong>Authors: </strong>Jiajun He, Xiaohan Shi, Xingfeng Li, Tomoki Toda</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.MM, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13260">https://arxiv.org/abs/2401.13260</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13260">https://arxiv.org/pdf/2401.13260</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13260]] MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion,  ASR Error Detection, and ASR Error Correction(https://arxiv.org/abs/2401.13260)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>The prevalent approach in speech emotion recognition (SER) involves integrating both audio and textual information to comprehensively identify the speaker's emotion, with the text generally obtained through automatic speech recognition (ASR). An essential issue of this approach is that ASR errors from the text modality can worsen the performance of SER. Previous studies have proposed using an auxiliary ASR error detection task to adaptively assign weights of each word in ASR hypotheses. However, this approach has limited improvement potential because it does not address the coherence of semantic information in the text. Additionally, the inherent heterogeneity of different modalities leads to distribution gaps between their representations, making their fusion challenging. Therefore, in this paper, we incorporate two auxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to enhance the semantic coherence of ASR text, and further introduce a novel multi-modal fusion (MF) method to learn shared representations across modalities. We refer to our method as MF-AED-AEC. Experimental results indicate that MF-AED-AEC significantly outperforms the baseline model by a margin of 4.1\%.</li>
<li><strong>摘要：</strong>语音情感识别（SER）的流行方法是整合音频和文本信息来全面识别说话者的情感，文本一般通过自动语音识别（ASR）获得。这种方法的一个重要问题是文本模态中的 ASR 错误可能会降低 SER 的性能。先前的研究提出使用辅助 ASR 错误检测任务来自适应地分配 ASR 假设中每个单词的权重。然而，这种方法的改进潜力有限，因为它没有解决文本中语义信息的连贯性。此外，不同模态固有的异质性导致它们的表示之间存在分布差距，使得它们的融合具有挑战性。因此，在本文中，我们结合了两个辅助任务，ASR错误检测（AED）和ASR错误纠正（AEC），以增强ASR文本的语义连贯性，并进一步引入一种新颖的多模态融合（MF）方法来学习跨模式的共享表征。我们将我们的方法称为 MF-AED-AEC。实验结果表明，MF-AED-AEC 明显优于基线模型 4.1%。</li>
</ul>

<h3>Title: Can AI Assistants Know What They Don't Know?</h3>
<ul>
<li><strong>Authors: </strong>Qinyuan Cheng, Tianxiang Sun, Xiangyang Liu, Wenwei Zhang, Zhangyue Yin, Shimin Li, Linyang Li, Kai Chen, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13275">https://arxiv.org/abs/2401.13275</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13275">https://arxiv.org/pdf/2401.13275</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13275]] Can AI Assistants Know What They Don't Know?(https://arxiv.org/abs/2401.13275)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination, code</a></li>
<li><strong>Abstract: </strong>Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?" To answer this question, we construct a model-specific "I don't know" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding Idk dataset and observe whether it can refuse to answer its unknown questions after alignment. Experimental results show that after alignment with Idk datasets, the assistant can refuse to answer most its unknown questions. For questions they attempt to answer, the accuracy is significantly higher than before the alignment.</li>
<li><strong>摘要：</strong>最近，基于大语言模型（LLM）的人工智能助手在对话、解决数学问题、编写代码和使用工具等许多任务中表现出了令人惊讶的表现。尽管法学硕士拥有丰富的世界知识，但在面对一些知识密集型任务（例如开放领域问答）时，他们仍然会犯事实错误。 AI助手的这些不真实的反应可能会在实际应用中造成重大风险。我们认为，人工智能助手拒绝回答它不知道的问题是减少幻觉并使助手诚实的重要方法。因此，在本文中，我们提出了“人工智能助手能否知道他们不知道的事情并通过自然语言表达出来？”的问题。为了回答这个问题，我们基于现有的开放域问答数据集，为助手构建了一个特定于模型的“我不知道”(Idk) 数据集，其中包含已知和未知的问题。然后我们将助手与其对应的 Idk 数据集对齐，并观察对齐后它是否可以拒绝回答未知问题。实验结果表明，在与 Idk 数据集对齐后，助手可以拒绝回答大多数未知问题。对于他们试图回答的问题，准确率明显高于对齐之前。</li>
</ul>

<h3>Title: RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing</h3>
<ul>
<li><strong>Authors: </strong>Junaid Farooq, Danish Rafiq, Pantelis R. Vlachas, Mohammad Abid Bazaz</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13282">https://arxiv.org/abs/2401.13282</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13282">https://arxiv.org/pdf/2401.13282</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13282]] RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing(https://arxiv.org/abs/2401.13282)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Forecasting complex system dynamics, particularly for long-term predictions, is persistently hindered by error accumulation and computational burdens. This study presents RefreshNet, a multiscale framework developed to overcome these challenges, delivering an unprecedented balance between computational efficiency and predictive accuracy. RefreshNet incorporates convolutional autoencoders to identify a reduced order latent space capturing essential features of the dynamics, and strategically employs multiple recurrent neural network (RNN) blocks operating at varying temporal resolutions within the latent space, thus allowing the capture of latent dynamics at multiple temporal scales. The unique "refreshing" mechanism in RefreshNet allows coarser blocks to reset inputs of finer blocks, effectively controlling and alleviating error accumulation. This design demonstrates superiority over existing techniques regarding computational efficiency and predictive accuracy, especially in long-term forecasting. The framework is validated using three benchmark applications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, and Kuramoto-Sivashinsky dynamics. RefreshNet significantly outperforms state-of-the-art methods in long-term forecasting accuracy and speed, marking a significant advancement in modeling complex systems and opening new avenues in understanding and predicting their behavior.</li>
<li><strong>摘要：</strong>预测复杂的系统动力学，特别是长期预测，一直受到误差积累和计算负担的阻碍。这项研究提出了 RefreshNet，这是一个为克服这些挑战而开发的多尺度框架，在计算效率和预测准确性之间实现了前所未有的平衡。 RefreshNet 结合了卷积自动编码器来识别降阶潜在空间，捕获动态的基本特征，并策略性地采用多个循环神经网络 (RNN) 块，在潜在空间内以不同的时间分辨率运行，从而允许捕获多个时间尺度的潜在动态。 RefreshNet中独特的“刷新”机制允许较粗的块重置较细块的输入，有效控制和减轻错误累积。该设计在计算效率和预测准确性方面表现出优于现有技术的优势，尤其是在长期预测方面。该框架使用三个基准应用程序进行了验证：FitzHugh-Nagumo 系统、反应扩散方程和 Kuramoto-Sivashinsky 动力学。 RefreshNet 在长期预测准确性和速度方面显着优于最先进的方法，标志着复杂系统建模方面的重大进步，并为理解和预测其行为开辟了新途径。</li>
</ul>

<h3>Title: Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Hongzhan Lin, Ziyang Luo, Wei Gao, Jing Ma, Bo Wang, Ruichao Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13298">https://arxiv.org/abs/2401.13298</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13298">https://arxiv.org/pdf/2401.13298</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13298]] Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models(https://arxiv.org/abs/2401.13298)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>The age of social media is flooded with Internet memes, necessitating a clear grasp and effective identification of harmful ones. This task presents a significant challenge due to the implicit meaning embedded in memes, which is not explicitly conveyed through the surface text and image. However, existing harmful meme detection methods do not present readable explanations that unveil such implicit meaning to support their detection decisions. In this paper, we propose an explainable approach to detect harmful memes, achieved through reasoning over conflicting rationales from both harmless and harmful positions. Specifically, inspired by the powerful capacity of Large Language Models (LLMs) on text generation and reasoning, we first elicit multimodal debate between LLMs to generate the explanations derived from the contradictory arguments. Then we propose to fine-tune a small language model as the debate judge for harmfulness inference, to facilitate multimodal fusion between the harmfulness rationales and the intrinsic multimodal information within memes. In this way, our model is empowered to perform dialectical reasoning over intricate and implicit harm-indicative patterns, utilizing multimodal explanations originating from both harmless and harmful arguments. Extensive experiments on three public meme datasets demonstrate that our harmful meme detection approach achieves much better performance than state-of-the-art methods and exhibits a superior capacity for explaining the meme harmfulness of the model predictions.</li>
<li><strong>摘要：</strong>社交媒体时代充斥着网络模因，需要清晰掌握并有效识别有害模因。由于模因中嵌入了隐含含义，而这些隐含含义并未通过表面文本和图像明确传达，因此这项任务提出了重大挑战。然而，现有的有害模因检测方法并没有提供可读的解释来揭示这种隐含的含义来支持其检测决策。在本文中，我们提出了一种可解释的方法来检测有害模因，该方法通过从无害和有害的立场对相互冲突的理由进行推理来实现。具体来说，受到大型语言模型（LLM）在文本生成和推理方面强大能力的启发，我们首先引发LLM之间的多模态辩论，以生成从矛盾论点中得出的解释。然后，我们建议微调一个小语言模型作为有害性推断的辩论法官，以促进有害性原理与模因内内在多模态信息之间的多模态融合。通过这种方式，我们的模型能够利用源自无害和有害论点的多模态解释，对复杂且隐含的伤害指示模式进行辩证推理。对三个公共模因数据集的广泛实验表明，我们的有害模因检测方法比最先进的方法取得了更好的性能，并且表现出解释模型预测的模因危害性的卓越能力。</li>
</ul>

<h3>Title: MaLA-500: Massive Language Adaptation of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Peiqin Lin, Shaoxiong Ji, Jörg Tiedemann, André F. T. Martins, Hinrich Schütze</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13303">https://arxiv.org/abs/2401.13303</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13303">https://arxiv.org/pdf/2401.13303</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13303]] MaLA-500: Massive Language Adaptation of Large Language Models(https://arxiv.org/abs/2401.13303)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Large language models have advanced the state of the art in natural language processing. However, their predominant design for English or a limited set of languages creates a substantial gap in their effectiveness for low-resource languages. To bridge this gap, we introduce MaLA-500, a novel large language model designed to cover an extensive range of 534 languages. To train MaLA-500, we employ vocabulary extension and continued pretraining on LLaMA 2 with Glot500-c. Our experiments on SIB-200 show that MaLA-500 achieves state-of-the-art in-context learning results. We release MaLA-500 at https://huggingface.co/MaLA-LM</li>
<li><strong>摘要：</strong>大型语言模型推进了自然语言处理的最先进水平。然而，它们的主要设计针对英语或有限的一组语言，这在它们对资源匮乏的语言的有效性方面造成了巨大的差距。为了弥补这一差距，我们推出了 MaLA-500，这是一种新颖的大型语言模型，旨在涵盖广泛的 534 种语言。为了训练 MaLA-500，我们采用词汇扩展并使用 Glot500-c 在 LLaMA 2 上继续进行预训练。我们在 SIB-200 上的实验表明，MaLA-500 实现了最先进的上下文学习结果。我们在 https://huggingface.co/MaLA-LM 上发布了 MaLA-500</li>
</ul>

<h3>Title: Debiased Sample Selection for Combating Noisy Labels</h3>
<ul>
<li><strong>Authors: </strong>Qi Wei, Lei Feng, Haobo Wang, Bo An</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13360">https://arxiv.org/abs/2401.13360</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13360">https://arxiv.org/pdf/2401.13360</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13360]] Debiased Sample Selection for Combating Noisy Labels(https://arxiv.org/abs/2401.13360)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Learning with noisy labels aims to ensure model generalization given a label-corrupted training set. The sample selection strategy achieves promising performance by selecting a label-reliable subset for model training. In this paper, we empirically reveal that existing sample selection methods suffer from both data and training bias that are represented as imbalanced selected sets and accumulation errors in practice, respectively. However, only the training bias was handled in previous studies. To address this limitation, we propose a noIse-Tolerant Expert Model (ITEM) for debiased learning in sample selection. Specifically, to mitigate the training bias, we design a robust network architecture that integrates with multiple experts. Compared with the prevailing double-branch network, our network exhibits better performance of selection and prediction by ensembling these experts while training with fewer parameters. Meanwhile, to mitigate the data bias, we propose a mixed sampling strategy based on two weight-based data samplers. By training on the mixture of two class-discriminative mini-batches, the model mitigates the effect of the imbalanced training set while avoiding sparse representations that are easily caused by sampling strategies. Extensive experiments and analyses demonstrate the effectiveness of ITEM. Our code is available at this url \href{https://github.com/1998v7/ITEM}{ITEM}.</li>
<li><strong>摘要：</strong>使用噪声标签进行学习的目的是确保给定标签损坏的训练集的模型泛化能力。样本选择策略通过选择标签可靠的子集进行模型训练，实现了有希望的性能。在本文中，我们凭经验揭示现有的样本选择方法会受到数据偏差和训练偏差的影响，在实践中分别表现为不平衡的选择集和累积误差。然而，之前的研究只处理了训练偏差。为了解决这个限制，我们提出了一种抗噪声专家模型（ITEM），用于样本选择中的去偏学习。具体来说，为了减轻训练偏差，我们设计了一个与多个专家集成的强大网络架构。与流行的双分支网络相比，我们的网络通过集成这些专家并用更少的参数进行训练，表现出更好的选择和预测性能。同时，为了减轻数据偏差，我们提出了一种基于两个基于权重的数据采样器的混合采样策略。通过对两个类判别小批量的混合进行训练，该模型减轻了不平衡训练集的影响，同时避免了采样策略容易导致的稀疏表示。大量的实验和分析证明了 ITEM 的有效性。我们的代码可在以下网址 \href{https://github.com/1998v7/ITEM}{ITEM} 获取。</li>
</ul>

<h3>Title: Text Categorization Can Enhance Domain-Agnostic Stopword Extraction</h3>
<ul>
<li><strong>Authors: </strong>Houcemeddine Turki, Naome A. Etori, Mohamed Ali Hadj Taieb, Abdul-Hakeem Omotayo, Chris Chinenye Emezue, Mohamed Ben Aouicha, Ayodele Awokoya, Falalu Ibrahim Lawan, Doreen Nixdorf</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13398">https://arxiv.org/abs/2401.13398</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13398">https://arxiv.org/pdf/2401.13398</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13398]] Text Categorization Can Enhance Domain-Agnostic Stopword Extraction(https://arxiv.org/abs/2401.13398)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>This paper investigates the role of text categorization in streamlining stopword extraction in natural language processing (NLP), specifically focusing on nine African languages alongside French. By leveraging the MasakhaNEWS, African Stopwords Project, and MasakhaPOS datasets, our findings emphasize that text categorization effectively identifies domain-agnostic stopwords with over 80% detection success rate for most examined languages. Nevertheless, linguistic variances result in lower detection rates for certain languages. Interestingly, we find that while over 40% of stopwords are common across news categories, less than 15% are unique to a single category. Uncommon stopwords add depth to text but their classification as stopwords depends on context. Therefore combining statistical and linguistic approaches creates comprehensive stopword lists, highlighting the value of our hybrid method. This research enhances NLP for African languages and underscores the importance of text categorization in stopword extraction.</li>
<li><strong>摘要：</strong>本文研究了文本分类在简化自然语言处理 (NLP) 中停用词提取中的作用，特别关注法语和九种非洲语言。通过利用 MasakhaNEWS、非洲停用词项目和 MasakhaPOS 数据集，我们的研究结果强调，文本分类可以有效识别与领域无关的停用词，对于大多数检查的语言，检测成功率超过 80%。然而，语言差异会导致某些语言的检测率较低。有趣的是，我们发现虽然超过 40% 的停用词在新闻类别中很常见，但只有不到 15% 的停用词是单一类别所独有的。不常见的停用词增加了文本的深度，但它们作为停用词的分类取决于上下文。因此，结合统计和语言方法创建了全面的停用词列表，突出了我们的混合方法的价值。这项研究增强了非洲语言的 NLP，并强调了文本分类在停用词提取中的重要性。</li>
</ul>

<h3>Title: Clue-Guided Path Exploration: An Efficient Knowledge Base  Question-Answering Framework with Low Computational Resource Consumption</h3>
<ul>
<li><strong>Authors: </strong>Dehao Tao, Feng Huang, Yongfeng Huang, Minghu Jiang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13444">https://arxiv.org/abs/2401.13444</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13444">https://arxiv.org/pdf/2401.13444</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13444]] Clue-Guided Path Exploration: An Efficient Knowledge Base  Question-Answering Framework with Low Computational Resource Consumption(https://arxiv.org/abs/2401.13444)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, lora, chat</a></li>
<li><strong>Abstract: </strong>In recent times, large language models (LLMs) have showcased remarkable capabilities. However, updating their knowledge poses challenges, potentially leading to inaccuracies when confronted with unfamiliar queries. While integrating knowledge graphs with LLMs has been explored, existing approaches treat LLMs as primary decision-makers, imposing high demands on their capabilities. This is particularly unsuitable for LLMs with lower computational costs and relatively poorer performance. In this paper, we introduce a Clue-Guided Path Exploration framework (CGPE) that efficiently merges a knowledge base with an LLM, placing less stringent requirements on the model's capabilities. Inspired by the method humans use to manually retrieve knowledge, CGPE employs information from the question as clues to systematically explore the required knowledge path within the knowledge base. Experiments on open-source datasets reveal that CGPE outperforms previous methods and is highly applicable to LLMs with fewer parameters. In some instances, even ChatGLM3, with its 6 billion parameters, can rival the performance of GPT-4. Furthermore, the results indicate a minimal invocation frequency of CGPE on LLMs, suggesting reduced computational overhead. For organizations and individuals facing constraints in computational resources, our research offers significant practical value.</li>
<li><strong>摘要：</strong>近年来，大型语言模型（LLM）展现出了非凡的能力。然而，更新他们的知识会带来挑战，在遇到不熟悉的查询时可能会导致不准确。虽然人们已经探索了将知识图谱与法学硕士相结合，但现有方法将法学硕士视为主要决策者，对他们的能力提出了很高的要求。这尤其不适合计算成本较低且性能相对较差的法学硕士。在本文中，我们介绍了一种线索引导路径探索框架（CGPE），该框架有效地将知识库与法学硕士融合起来，对模型的功能提出了不太严格的要求。受到人类手动检索知识的方法的启发，CGPE 以问题中的信息为线索，系统地探索知识库中所需的知识路径。在开源数据集上的实验表明，CGPE 优于以前的方法，并且非常适用于参数较少的 LLM。在某些情况下，即使拥有 60 亿个参数的 ChatGLM3 也可以与 GPT-4 的性能相媲美。此外，结果表明 LLM 上 CGPE 的调用频率最低，这表明计算开销减少。对于面临计算资源限制的组织和个人，我们的研究提供了重要的实用价值。</li>
</ul>

<h3>Title: Multi-Agent Diagnostics for Robustness via Illuminated Diversity</h3>
<ul>
<li><strong>Authors: </strong>Mikayel Samvelyan, Davide Paglieri, Minqi Jiang, Jack Parker-Holder, Tim Rocktäschel</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13460">https://arxiv.org/abs/2401.13460</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13460">https://arxiv.org/pdf/2401.13460</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13460]] Multi-Agent Diagnostics for Robustness via Illuminated Diversity(https://arxiv.org/abs/2401.13460)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag, agent</a></li>
<li><strong>Abstract: </strong>In the rapidly advancing field of multi-agent systems, ensuring robustness in unfamiliar and adversarial settings is crucial. Notwithstanding their outstanding performance in familiar environments, these systems often falter in new situations due to overfitting during the training phase. This is especially pronounced in settings where both cooperative and competitive behaviours are present, encapsulating a dual nature of overfitting and generalisation challenges. To address this issue, we present Multi-Agent Diagnostics for Robustness via Illuminated Diversity (MADRID), a novel approach for generating diverse adversarial scenarios that expose strategic vulnerabilities in pre-trained multi-agent policies. Leveraging the concepts from open-ended learning, MADRID navigates the vast space of adversarial settings, employing a target policy's regret to gauge the vulnerabilities of these settings. We evaluate the effectiveness of MADRID on the 11vs11 version of Google Research Football, one of the most complex environments for multi-agent reinforcement learning. Specifically, we employ MADRID for generating a diverse array of adversarial settings for TiZero, the state-of-the-art approach which "masters" the game through 45 days of training on a large-scale distributed infrastructure. We expose key shortcomings in TiZero's tactical decision-making, underlining the crucial importance of rigorous evaluation in multi-agent systems.</li>
<li><strong>摘要：</strong>在快速发展的多智能体系统领域，确保在不熟悉和对抗性环境中的稳健性至关重要。尽管它们在熟悉的环境中表现出色，但由于训练阶段的过度拟合，这些系统在新情况下常常会出现问题。这在同时存在合作和竞争行为的环境中尤其明显，体现了过度拟合和泛化挑战的双重性质。为了解决这个问题，我们提出了通过照明多样性实现鲁棒性的多智能体诊断（MADRID），这是一种生成多种对抗场景的新方法，该场景暴露了预训练的多智能体策略中的战略漏洞。利用开放式学习的概念，马德里在广阔的对抗环境中导航，利用目标政策的遗憾来衡量这些环境的脆弱性。我们评估了 MADRID 在 Google Research Football 11vs11 版本上的有效性，这是多智能体强化学习最复杂的环境之一。具体来说，我们使用 MADRID 为 TiZero 生成各种对抗设置，TiZero 是最先进的方法，通过在大规模分布式基础设施上进行 45 天的训练来“掌握”游戏。我们揭示了 TiZero 战术决策中的关键缺陷，强调了多智能体系统中严格评估的至关重要性。</li>
</ul>

<h3>Title: Can GPT-3.5 Generate and Code Discharge Summaries?</h3>
<ul>
<li><strong>Authors: </strong>Matúš Falis, Aryo Pradipta Gema, Hang Dong, Luke Daines, Siddharth Basetti, Michael Holder, Rose S Penfold, Alexandra Birch, Beatrice Alex</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13512">https://arxiv.org/abs/2401.13512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13512">https://arxiv.org/pdf/2401.13512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13512]] Can GPT-3.5 Generate and Code Discharge Summaries?(https://arxiv.org/abs/2401.13512)</code><input type="text"></li>
<li><strong>Keywords: </strong>gpt, prompt, code</a></li>
<li><strong>Abstract: </strong>Objective: To investigate GPT-3.5 in generating and coding medical documents with ICD-10 codes for data augmentation on low-resources labels. Materials and Methods: Employing GPT-3.5 we generated and coded 9,606 discharge summaries based on lists of ICD-10 code descriptions of patients with infrequent (generation) codes within the MIMIC-IV dataset. Combined with the baseline training set, this formed an augmented training set. Neural coding models were trained on baseline and augmented data and evaluated on a MIMIC-IV test set. We report micro- and macro-F1 scores on the full codeset, generation codes, and their families. Weak Hierarchical Confusion Matrices were employed to determine within-family and outside-of-family coding errors in the latter codesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided self-generated data and real MIMIC-IV data. Clinical professionals evaluated the clinical acceptability of the generated documents. Results: Augmentation slightly hinders the overall performance of the models but improves performance for the generation candidate codes and their families, including one unseen in the baseline training data. Augmented models display lower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by the prompted descriptions, but performs poorly on real data. Evaluators note the correctness of generated concepts while suffering in variety, supporting information, and narrative. Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding. Augmentation positively affects generation code families but mainly benefits codes with existing examples. Augmentation reduces out-of-family errors. Discharge summaries generated by GPT-3.5 state prompted concepts correctly but lack variety, and authenticity in narratives. They are unsuitable for clinical practice.</li>
<li><strong>摘要：</strong>目的：研究 GPT-3.5 在使用 ICD-10 代码生成和编码医疗文档方面，以增强低资源标签上的数据。材料和方法：使用 GPT-3.5，我们根据 MIMIC-IV 数据集中具有不常见（生成）代码的患者的 ICD-10 代码描述列表生成并编码了 9,606 份出院摘要。与基线训练集相结合，形成了增强训练集。神经编码模型在基线和增强数据上进行训练，并在 MIMIC-IV 测试集上进行评估。我们报告完整代码集、生成代码及其家族的微观和宏观 F1 分数。采用弱分层混淆矩阵来确定后一代码集中的家族内和家族外编码错误。 GPT-3.5 的编码性能在提示引导的自生成数据和真实 MIMIC-IV 数据上进行了评估。临床专业人员评估了生成的文件的临床可接受性。结果：增强稍微阻碍了模型的整体性能，但提高了生成候选代码及其家族的性能，包括基线训练数据中未见的代码。增强模型显示出较低的家庭外错误率。 GPT-3.5可以通过提示描述识别ICD-10代码，但在真实数据上表现不佳。评估者注意到生成的概念的正确性，但同时也受到多样性、支持信息和叙述的影响。讨论和结论：GPT-3.5 单独不适用于 ICD-10 编码。增强对生成代码系列产生积极影响，但主要有利于现有示例的代码。强化可以减少家庭外错误。 GPT-3.5 生成的出院摘要正确地提示了概念，但叙述缺乏多样性和真实性。它们不适合临床实践。</li>
</ul>

<h3>Title: SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation</h3>
<ul>
<li><strong>Authors: </strong>Dong Zhang, Xin Zhang, Jun Zhan, Shimin Li, Yaqian Zhou, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.SD, eess.AS</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13527">https://arxiv.org/abs/2401.13527</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13527">https://arxiv.org/pdf/2401.13527</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13527]] SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation(https://arxiv.org/abs/2401.13527)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, code</a></li>
<li><strong>Abstract: </strong>Benefiting from effective speech modeling, current Speech Large Language Models (SLLMs) have demonstrated exceptional capabilities in in-context speech generation and efficient generalization to unseen speakers. However, the prevailing information modeling process is encumbered by certain redundancies, leading to inefficiencies in speech generation. We propose Chain-of-Information Generation (CoIG), a method for decoupling semantic and perceptual information in large-scale speech generation. Building on this, we develop SpeechGPT-Gen, an 8-billion-parameter SLLM efficient in semantic and perceptual information modeling. It comprises an autoregressive model based on LLM for semantic information modeling and a non-autoregressive model employing flow matching for perceptual information modeling. Additionally, we introduce the novel approach of infusing semantic information into the prior distribution to enhance the efficiency of flow matching. Extensive experimental results demonstrate that SpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice conversion, and speech-to-speech dialogue, underscoring CoIG's remarkable proficiency in capturing and modeling speech's semantic and perceptual dimensions. Code and models are available at https://github.com/0nutation/SpeechGPT.</li>
<li><strong>摘要：</strong>受益于有效的语音建模，当前的语音大语言模型 (SLLM) 在上下文语音生成和对看不见的说话者的有效泛化方面表现出了卓越的能力。然而，流行的信息建模过程受到某些冗余的阻碍，导致语音生成效率低下。我们提出了信息链生成（CoIG），一种在大规模语音生成中解耦语义和感知信息的方法。在此基础上，我们开发了 SpeechGPT-Gen，这是一种在语义和感知信息建模方面高效的 80 亿参数 SLLM。它包括基于LLM的用于语义信息建模的自回归模型和采用流匹配用于感知信息建模的非自回归模型。此外，我们引入了将语义信息注入先验分布的新方法，以提高流匹配的效率。大量实验结果表明，SpeechGPT-Gen 在零样本文本到语音、零样本语音转换和语音到语音对话方面表现出色，凸显了 CoIG 在捕获和建模语音语义和感知维度方面的卓越能力。代码和模型可在 https://github.com/0nutation/SpeechGPT 获取。</li>
</ul>

<h3>Title: Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein  Probabilistic Space</h3>
<ul>
<li><strong>Authors: </strong>Mingyang Yi, Bohan Wang</a></li>
<li><strong>Subjects: </strong>cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13530">https://arxiv.org/abs/2401.13530</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13530">https://arxiv.org/pdf/2401.13530</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13530]] Towards Understanding the Riemannian SGD and SVRG Flows on Wasserstein  Probabilistic Space(https://arxiv.org/abs/2401.13530)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Recently, optimization on the Riemannian manifold has provided new insights to the optimization community. In this regard, the manifold taken as the probability measure metric space equipped with the second-order Wasserstein distance is of particular interest, since optimization on it can be linked to practical sampling processes. In general, the oracle (continuous) optimization method on Wasserstein space is Riemannian gradient flow (i.e., Langevin dynamics when minimizing KL divergence). In this paper, we aim to enrich the continuous optimization methods in the Wasserstein space by extending the gradient flow into the stochastic gradient descent (SGD) flow and stochastic variance reduction gradient (SVRG) flow. The two flows on Euclidean space are standard stochastic optimization methods, while their Riemannian counterparts are not explored yet. By leveraging the structures in Wasserstein space, we construct a stochastic differential equation (SDE) to approximate the discrete dynamics of desired stochastic methods in the corresponded random vector space. Then, the flows of probability measures are naturally obtained by applying Fokker-Planck equation to such SDE. Furthermore, the convergence rates of the proposed Riemannian stochastic flows are proven, and they match the results in Euclidean space.</li>
<li><strong>摘要：</strong>最近，黎曼流形的优化为优化界提供了新的见解。在这方面，作为配备二阶 Wasserstein 距离的概率测度度量空间的流形特别令人感兴趣，因为对其的优化可以与实际采样过程联系起来。一般来说，Wasserstein 空间上的预言（连续）优化方法是黎曼梯度流（即最小化 KL 散度时的朗之万动力学）。在本文中，我们的目标是通过将梯度流扩展到随机梯度下降（SGD）流和随机方差减少梯度（SVRG）流来丰富 Wasserstein 空间中的连续优化方法。欧几里得空间上的两个流是标准的随机优化方法，而它们的黎曼对应流尚未探索。通过利用 Wasserstein 空间中的结构，我们构建了一个随机微分方程（SDE）来近似相应随机向量空间中所需随机方法的离散动力学。然后，通过将 Fokker-Planck 方程应用于此类 SDE，自然可以得到概率测度流。此外，证明了所提出的黎曼随机流的收敛速度，并且它们与欧几里得空间中的结果相匹配。</li>
</ul>

<h3>Title: Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?</h3>
<ul>
<li><strong>Authors: </strong>Ričards Marcinkevičs, Sonia Laguna, Moritz Vandenhirtz, Julia E. Vogt</a></li>
<li><strong>Subjects: </strong>cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13544">https://arxiv.org/abs/2401.13544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13544">https://arxiv.org/pdf/2401.13544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13544]] Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?(https://arxiv.org/abs/2401.13544)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the practical utility of the proposed techniques, we apply them to deep chest X-ray classifiers and show that fine-tuned black boxes can be as intervenable and more performant than CBMs.</li>
<li><strong>摘要：</strong>最近，可解释机器学习重新探索了概念瓶颈模型（CBM），包括根据原始特征逐步预测高级概念，并根据预测概念逐步预测目标变量。该模型类的一个引人注目的优势是用户能够干预预测的概念值，从而影响模型的下游输出。在这项工作中，我们介绍了一种对已经训练的神经网络执行此类基于概念的干预的方法，在给定带注释的验证集的情况下，这些神经网络在设计上是不可解释的。此外，我们将模型的可干预性形式化为基于概念的干预措施有效性的衡量标准，并利用此定义来微调黑盒模型。根据经验，我们探索了黑盒分类器在合成表格和自然图像基准上的可干预性。我们证明，微调可以提高干预效果，并且通常会产生更好校准的预测。为了展示所提出技术的实用性，我们将它们应用于深部胸部 X 射线分类器，并表明微调黑匣子可以比 CBM 更易于干预且性能更高。</li>
</ul>

<h3>Title: Large Malaysian Language Model Based on Mistral for Enhanced Local  Language Understanding</h3>
<ul>
<li><strong>Authors: </strong>Husein Zolkepli, Aisyah Razak, Kamarul Adha, Ariff Nazhan</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13565">https://arxiv.org/abs/2401.13565</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13565">https://arxiv.org/pdf/2401.13565</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13565]] Large Malaysian Language Model Based on Mistral for Enhanced Local  Language Understanding(https://arxiv.org/abs/2401.13565)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, chat</a></li>
<li><strong>Abstract: </strong>In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens. We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral. Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities. Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies. Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2. We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (Malay grammar) test set, particularly when fine-tuned with instructions. All models released at https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c</li>
<li><strong>摘要：</strong>在本文中，我们展示了 Mistral 7B（一种大规模语言模型）预训练方面的重大进展，使用 32.6 GB 的数据集（相当于 11 亿个令牌）。我们探讨了扩展上下文长度、发布上下文长度为 4096 和 32768 个令牌的模型的影响，并使用专门的 16384 上下文长度指令调整模型（我们将其称为“Malaysian Mistral”）进一步改进性能。我们的实验证明了持续预训练的有效性以及扩展上下文长度对 Mistral 7B 语言理解能力的影响。此外，我们还发布了一个专门使用 16384 上下文长度指令进行调整的模型，展示了其捕获微妙的语言复杂性的潜力。此外，我们的研究有助于将 Malaysia Mistral 与著名语言模型（包括 ChatGPT3.5 和 Claude 2）进行基准测试。我们提供了令人信服的结果，表明 Malaysia Mistral 在 Tatabahasa（马来语语法）测试集上具有卓越的性能，特别是在根据指令进行微调时。所有模型发布于 https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c</li>
</ul>

<h3>Title: Prompt Weight Experiments for LLM Instruction Fine-Tuning</h3>
<ul>
<li><strong>Authors: </strong>Mathew Huerta-Enochian</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13586">https://arxiv.org/abs/2401.13586</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13586">https://arxiv.org/pdf/2401.13586</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13586]] Prompt Weight Experiments for LLM Instruction Fine-Tuning(https://arxiv.org/abs/2401.13586)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm, prompt</a></li>
<li><strong>Abstract: </strong>We present a small study analyzing how prompt token classification loss weighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on instruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1 and LLaMA 2 using multiple instruction datasets. We found that models fine-tuned on our short-completion dataset have a negative quadratic relationship with PLW while models fine-tuned on long-completion datasets were unaffected by PLW.</li>
<li><strong>摘要：</strong>我们提出了一项小型研究，分析即时标记分类损失权重 (PLW) 如何影响在指令任务上微调的 7B 大小 LLaMA 模型的性能。我们使用多个指令数据集使用 LLaMA 1 和 LLaMA 2 重新创建了斯坦福大学的羊驼实验。我们发现，在短完成数据集上微调的模型与 PLW 具有负二次关系，而在长完成数据集上微调的模型则不受 PLW 的影响。</li>
</ul>

<h3>Title: Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes</h3>
<ul>
<li><strong>Authors: </strong>Darren Liu, Cheng Ding, Delgersuren Bold, Monique Bouvier, Jiaying Lu, Benjamin Shickel, Craig S. Jabaley, Wenhui Zhang, Soojin Park, Michael J. Young, Mark S. Wainwright, Gilles Clermont, Parisa Rashidi, Eric S. Rosenthal, Laurie Dimisko, Ran Xiao, Joo Heung Yoon, Carl Yang, Xiao Hu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13588">https://arxiv.org/abs/2401.13588</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13588">https://arxiv.org/pdf/2401.13588</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13588]] Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes(https://arxiv.org/abs/2401.13588)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt</a></li>
<li><strong>Abstract: </strong>The field of healthcare has increasingly turned its focus towards Large Language Models (LLMs) due to their remarkable performance. However, their performance in actual clinical applications has been underexplored. Traditional evaluations based on question-answering tasks don't fully capture the nuanced contexts. This gap highlights the need for more in-depth and practical assessments of LLMs in real-world healthcare settings. Objective: We sought to evaluate the performance of LLMs in the complex clinical context of adult critical care medicine using systematic and comprehensible analytic methods, including clinician annotation and adjudication. Methods: We investigated the performance of three general LLMs in understanding and processing real-world clinical notes. Concepts from 150 clinical notes were identified by MetaMap and then labeled by 9 clinicians. Each LLM's proficiency was evaluated by identifying the temporality and negation of these concepts using different prompts for an in-depth analysis. Results: GPT-4 showed overall superior performance compared to other LLMs. In contrast, both GPT-3.5 and text-davinci-003 exhibit enhanced performance when the appropriate prompting strategies are employed. The GPT family models have demonstrated considerable efficiency, evidenced by their cost-effectiveness and time-saving capabilities. Conclusion: A comprehensive qualitative performance evaluation framework for LLMs is developed and operationalized. This framework goes beyond singular performance aspects. With expert annotations, this methodology not only validates LLMs' capabilities in processing complex medical data but also establishes a benchmark for future LLM evaluations across specialized domains.</li>
<li><strong>摘要：</strong>由于其卓越的性能，医疗保健领域越来越多地将注意力转向大型语言模型（LLM）。然而，它们在实际临床应用中的性能尚未得到充分探索。基于问答任务的传统评估无法完全捕捉微妙的背景。这一差距凸显了在现实世界的医疗保健环境中对法学硕士进行更深入和实用评估的必要性。目的：我们试图使用系统且易于理解的分析方法（包括临床医生注释和裁决）来评估法学硕士在成人重症监护医学复杂临床环境中的表现。方法：我们调查了三位普通法学硕士在理解和处理现实世界临床记录方面的表现。 MetaMap 识别了 150 个临床记录中的概念，然后由 9 名临床医生进行了标记。通过使用不同的提示进行深入分析来识别这些概念的暂时性和否定性，从而评估每个法学硕士的熟练程度。结果：与其他法学硕士相比，GPT-4 表现出整体优越的表现。相比之下，当采用适当的提示策略时，GPT-3.5 和 text-davinci-003 都表现出增强的性能。 GPT 系列型号已展现出相当高的效率，其成本效益和节省时间的能力就证明了这一点。结论：制定并实施了法学硕士综合定性绩效评估框架。该框架超越了单一的性能方面。通过专家注释，该方法不仅验证了法学硕士处理复杂医疗数据的能力，还为未来跨专业领域的法学硕士评估建立了基准。</li>
</ul>

<h3>Title: Graph Guided Question Answer Generation for Procedural  Question-Answering</h3>
<ul>
<li><strong>Authors: </strong>Hai X. Pham, Isma Hadji, Xinnuo Xu, Ziedune Degutyte, Jay Rainey, Evangelos Kazakos, Afsaneh Fazly, Georgios Tzimiropoulos, Brais Martinez</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13594">https://arxiv.org/abs/2401.13594</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13594">https://arxiv.org/pdf/2401.13594</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13594]] Graph Guided Question Answer Generation for Procedural  Question-Answering(https://arxiv.org/abs/2401.13594)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, chat, rag</a></li>
<li><strong>Abstract: </strong>In this paper, we focus on task-specific question answering (QA). To this end, we introduce a method for generating exhaustive and high-quality training data, which allows us to train compact (e.g., run on a mobile device), task-specific QA models that are competitive against GPT variants. The key technological enabler is a novel mechanism for automatic question-answer generation from procedural text which can ingest large amounts of textual instructions and produce exhaustive in-domain QA training data. While current QA data generation methods can produce well-formed and varied data, their non-exhaustive nature is sub-optimal for training a QA model. In contrast, we leverage the highly structured aspect of procedural text and represent each step and the overall flow of the procedure as graphs. We then condition on graph nodes to automatically generate QA pairs in an exhaustive and controllable manner. Comprehensive evaluations of our method show that: 1) small models trained with our data achieve excellent performance on the target QA task, even exceeding that of GPT3 and ChatGPT despite being several orders of magnitude smaller. 2) semantic coverage is the key indicator for downstream QA performance. Crucially, while large language models excel at syntactic diversity, this does not necessarily result in improvements on the end QA model. In contrast, the higher semantic coverage provided by our method is critical for QA performance.</li>
<li><strong>摘要：</strong>在本文中，我们重点关注特定任务的问答（QA）。为此，我们引入了一种生成详尽且高质量的训练数据的方法，该方法使我们能够训练紧凑的（例如，在移动设备上运行）、特定于任务的 QA 模型，这些模型与 GPT 变体具有竞争力。关键的技术推动者是一种从程序文本自动生成问答的新颖机制，它可以摄取大量文本指令并生成详尽的域内 QA 训练数据。虽然当前的 QA 数据生成方法可以生成格式良好且多样化的数据，但它们的非详尽性对于训练 QA 模型而言并不是最佳选择。相比之下，我们利用程序文本的高度结构化方面，并将程序的每个步骤和整体流程表示为图形。然后，我们以图节点为条件，以详尽且可控的方式自动生成 QA 对。对我们方法的综合评估表明：1）用我们的数据训练的小模型在目标 QA 任务上取得了优异的性能，甚至超过了 GPT3 和 ChatGPT，尽管小了几个数量级。 2）语义覆盖率是下游QA性能的关键指标。至关重要的是，虽然大型语言模型在句法多样性方面表现出色，但这并不一定会导致最终 QA 模型的改进。相反，我们的方法提供的更高语义覆盖率对于 QA 性能至关重要。</li>
</ul>

<h3>Title: Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction</h3>
<ul>
<li><strong>Authors: </strong>Qi Sun, Kun Huang, Xiaocui Yang, Rong Tong, Kun Zhang, Soujanya Poria</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13598">https://arxiv.org/abs/2401.13598</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13598">https://arxiv.org/pdf/2401.13598</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13598]] Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction(https://arxiv.org/abs/2401.13598)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt, chat, rag</a></li>
<li><strong>Abstract: </strong>Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which generates labeled data by retrieval and denoising knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge. Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets. We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets. The experimental results illustrate that our GenRDK framework outperforms strong baselines.</li>
<li><strong>摘要：</strong>文档级关系三元组提取（DocRTE）是信息系统中的一项基本任务，旨在从文档中同时提取具有语义关系的实体。现有方法严重依赖大量完全标记的数据。然而，收集和注释新兴关系的数据既耗时又费力。最近先进的大型语言模型（LLM），例如 ChatGPT 和 LLaMA，展示了令人印象深刻的长文本生成能力，激励我们探索一种替代方法来获取具有新关系的自动标记文档。在本文中，我们提出了一种零样本文档级关系三元组提取（ZeroDocRTE）框架，该框架通过从法学硕士中检索和去噪知识来生成标记数据，称为 GenRDK。具体来说，我们提出了一个检索链提示来指导 ChatGPT 逐步生成带标签的长文本数据。为了提高合成数据的质量，我们提出了一种基于跨文档知识一致性的去噪策略。利用我们的去噪合成数据，我们继续微调 LLaMA2-13B-Chat 以提取文档级关系三元组。我们在两个公共数据集上进行了零样本文档级关系和三元组提取的实验。实验结果表明我们的 GenRDK 框架优于强大的基线。</li>
</ul>

<h3>Title: MM-LLMs: Recent Advances in MultiModal Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Duzhen Zhang, Yahan Yu, Chenxing Li, Jiahua Dong, Dan Su, Chenhui Chu, Dong Yu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13601">https://arxiv.org/abs/2401.13601</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13601">https://arxiv.org/pdf/2401.13601</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13601]] MM-LLMs: Recent Advances in MultiModal Large Language Models(https://arxiv.org/abs/2401.13601)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>In the past year, MultiModal Large Language Models (MM-LLMs) have undergone substantial advancements, augmenting off-the-shelf LLMs to support MM inputs or outputs via cost-effective training strategies. The resulting models not only preserve the inherent reasoning and decision-making capabilities of LLMs but also empower a diverse range of MM tasks. In this paper, we provide a comprehensive survey aimed at facilitating further research of MM-LLMs. Specifically, we first outline general design formulations for model architecture and training pipeline. Subsequently, we provide brief introductions of $26$ existing MM-LLMs, each characterized by its specific formulations. Additionally, we review the performance of MM-LLMs on mainstream benchmarks and summarize key training recipes to enhance the potency of MM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently maintaining a real-time tracking website for the latest developments in the field. We hope that this survey contributes to the ongoing advancement of the MM-LLMs domain.</li>
<li><strong>摘要：</strong>在过去的一年中，多模态大型语言模型 (MM-LLM) 取得了实质性进展，增强了现成的 LLM，以通过具有成本效益的培训策略支持 MM 输入或输出。由此产生的模型不仅保留了法学硕士固有的推理和决策能力，而且还支持各种 MM 任务。在本文中，我们提供了一项全面的调查，旨在促进 MM-LLM 的进一步研究。具体来说，我们首先概述模型架构和训练管道的一般设计公式。随后，我们简要介绍了 $26$ 现有的 MM-LLM，每个都有其特定的配方。此外，我们还回顾了 MM-LLM 在主流基准上的表现，并总结了增强 MM-LLM 效力的关键培训方法。最后，我们探索 MM-LLM 的有前途的方向，同时维护一个实时跟踪网站以了解该领域的最新发展。我们希望这项调查有助于 MM-LLM 领域的持续发展。</li>
</ul>

<h3>Title: Stream-based perception for cognitive agents in mobile ecosystems</h3>
<ul>
<li><strong>Authors: </strong>Jeremias Dötterl, Ralf Bruns, Jürgen Dunkel, Sascha Ossowski</a></li>
<li><strong>Subjects: </strong>cs.AI, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13604">https://arxiv.org/abs/2401.13604</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13604">https://arxiv.org/pdf/2401.13604</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13604]] Stream-based perception for cognitive agents in mobile ecosystems(https://arxiv.org/abs/2401.13604)</code><input type="text"></li>
<li><strong>Keywords: </strong>agent</a></li>
<li><strong>Abstract: </strong>Cognitive agent abstractions can help to engineer intelligent systems across mobile devices. On smartphones, the data obtained from onboard sensors can give valuable insights into the user's current situation. Unfortunately, today's cognitive agent frameworks cannot cope well with the challenging characteristics of sensor data. Sensor data is located on a low abstraction level and the individual data elements are not meaningful when observed in isolation. In contrast, cognitive agents operate on high-level percepts and lack the means to effectively detect complex spatio-temporal patterns in sequences of multiple percepts. In this paper, we present a stream-based perception approach that enables the agents to perceive meaningful situations in low-level sensor data streams. We present a crowdshipping case study where autonomous, self-interested agents collaborate to deliver parcels to their destinations. We show how situations derived from smartphone sensor data can trigger and guide auctions, which the agents use to reach agreements. Experiments with real smartphone data demonstrate the benefits of stream-based agent perception.</li>
<li><strong>摘要：</strong>认知代理抽象可以帮助设计跨移动设备的智能系统。在智能手机上，从机载传感器获得的数据可以为用户当前的情况提供有价值的见解。不幸的是，当今的认知代理框架无法很好地应对传感器数据的挑战性特征。传感器数据位于低抽象级别，单独观察时各个数据元素没有意义。相比之下，认知主体对高级感知进行操作，并且缺乏有效检测多个感知序列中复杂时空模式的方法。在本文中，我们提出了一种基于流的感知方法，使代理能够感知低级传感器数据流中有意义的情况。我们提出了一个众包案例研究，其中自主、自利的代理商合作将包裹运送到目的地。我们展示了从智能手机传感器数据得出的情况如何触发和指导拍卖，代理商利用拍卖来达成协议。对真实智能手机数据的实验证明了基于流的代理感知的好处。</li>
</ul>

<h3>Title: DenoSent: A Denoising Objective for Self-Supervised Sentence  Representation Learning</h3>
<ul>
<li><strong>Authors: </strong>Xinghao Wang, Junliang He, Pengyu Wang, Yunhua Zhou, Tianxiang Sun, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13621">https://arxiv.org/abs/2401.13621</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13621">https://arxiv.org/pdf/2401.13621</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13621]] DenoSent: A Denoising Objective for Self-Supervised Sentence  Representation Learning(https://arxiv.org/abs/2401.13621)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Contrastive-learning-based methods have dominated sentence representation learning. These methods regularize the representation space by pulling similar sentence representations closer and pushing away the dissimilar ones and have been proven effective in various NLP tasks, e.g., semantic textual similarity (STS) tasks. However, it is challenging for these methods to learn fine-grained semantics as they only learn from the inter-sentence perspective, i.e., their supervision signal comes from the relationship between data samples. In this work, we propose a novel denoising objective that inherits from another perspective, i.e., the intra-sentence perspective. By introducing both discrete and continuous noise, we generate noisy sentences and then train our model to restore them to their original form. Our empirical evaluations demonstrate that this approach delivers competitive results on both semantic textual similarity (STS) and a wide range of transfer tasks, standing up well in comparison to contrastive-learning-based methods. Notably, the proposed intra-sentence denoising objective complements existing inter-sentence contrastive methodologies and can be integrated with them to further enhance performance. Our code is available at https://github.com/xinghaow99/DenoSent.</li>
<li><strong>摘要：</strong>基于对比学习的方法主导了句子表示学习。这些方法通过拉近相似的句子表示并推开不相似的句子来规范表示空间，并且已在各种 NLP 任务（例如语义文本相似性（STS）任务）中被证明是有效的。然而，这些方法学习细粒度语义具有挑战性，因为它们仅从句子间的角度学习，即它们的监督信号来自数据样本之间的关系。在这项工作中，我们提出了一种新颖的去噪目标，该目标继承自另一个视角，即句子内视角。通过引入离散和连续噪声，我们生成噪声句子，然后训练我们的模型将它们恢复到原始形式。我们的实证评估表明，这种方法在语义文本相似性（STS）和广泛的迁移任务方面都提供了有竞争力的结果，与基于对比学习的方法相比，表现良好。值得注意的是，所提出的句子内去噪目标补充了现有的句子间对比方法，并且可以与它们集成以进一步提高性能。我们的代码可在 https://github.com/xinghaow99/DenoSent 获取。</li>
</ul>

<h3>Title: VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web  Tasks</h3>
<ul>
<li><strong>Authors: </strong>Jing Yu Koh, Robert Lo, Lawrence Jang, Vikram Duvvur, Ming Chong Lim, Po-Yu Huang, Graham Neubig, Shuyan Zhou, Ruslan Salakhutdinov, Daniel Fried</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.CL, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13649">https://arxiv.org/abs/2401.13649</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13649">https://arxiv.org/pdf/2401.13649</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13649]] VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web  Tasks(https://arxiv.org/abs/2401.13649)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm, code, agent</a></li>
<li><strong>Abstract: </strong>Autonomous agents capable of planning, reasoning, and executing actions on the web offer a promising avenue for automating computer tasks. However, the majority of existing benchmarks primarily focus on text-based agents, neglecting many natural tasks that require visual information to effectively solve. Given that most computer interfaces cater to human perception, visual information often augments textual data in ways that text-only models struggle to harness effectively. To bridge this gap, we introduce VisualWebArena, a benchmark designed to assess the performance of multimodal web agents on realistic \textit{visually grounded tasks}. VisualWebArena comprises of a set of diverse and complex web-based tasks that evaluate various capabilities of autonomous multimodal agents. To perform on this benchmark, agents need to accurately process image-text inputs, interpret natural language instructions, and execute actions on websites to accomplish user-defined objectives. We conduct an extensive evaluation of state-of-the-art LLM-based autonomous agents, including several multimodal models. Through extensive quantitative and qualitative analysis, we identify several limitations of text-only LLM agents, and reveal gaps in the capabilities of state-of-the-art multimodal language agents. VisualWebArena provides a framework for evaluating multimodal autonomous language agents, and offers insights towards building stronger autonomous agents for the web. Our code, baseline models, and data is publicly available at https://jykoh.com/vwa.</li>
<li><strong>摘要：</strong>能够在网络上规划、推理和执行操作的自主代理为计算机任务自动化提供了一条有前途的途径。然而，大多数现有基准主要关注基于文本的代理，忽略了许多需要视觉信息才能有效解决的自然任务。鉴于大多数计算机界面迎合人类感知，视觉信息通常会以纯文本模型难以有效利用的方式增强文本数据。为了弥补这一差距，我们引入了 VisualWebArena，这是一个基准测试，旨在评估多模式 Web 代理在现实 \textit{视觉基础任务} 上的性能。 VisualWebArena 包含一组多样化且复杂的基于 Web 的任务，用于评估自主多模式代理的各种功能。为了达到这个基准，代理需要准确地处理图像文本输入，解释自然语言指令，并在网站上执行操作以实现用户定义的目标。我们对最先进的基于 LLM 的自主代理进行了广泛的评估，包括几个多模式模型。通过广泛的定量和定性分析，我们确定了纯文本 LLM 代理的一些局限性，并揭示了最先进的多模式语言代理的能力差距。 VisualWebArena 提供了一个用于评估多模式自主语言代理的框架，并提供了构建更强大的网络自主代理的见解。我们的代码、基线模型和数据可在 https://jykoh.com/vwa 上公开获取。</li>
</ul>

<h3>Title: Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors</h3>
<ul>
<li><strong>Authors: </strong>Francesco Della Santa, Sandra Pieraccini</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI, math.NA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13652">https://arxiv.org/abs/2401.13652</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13652">https://arxiv.org/pdf/2401.13652</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13652]] Graph-Informed Neural Networks for Sparse Grid-Based Discontinuity  Detectors(https://arxiv.org/abs/2401.13652)</code><input type="text"></li>
<li><strong>Keywords: </strong>rag</a></li>
<li><strong>Abstract: </strong>In this paper, we present a novel approach for detecting the discontinuity interfaces of a discontinuous function. This approach leverages Graph-Informed Neural Networks (GINNs) and sparse grids to address discontinuity detection also in domains of dimension larger than 3. GINNs, trained to identify troubled points on sparse grids, exploit graph structures built on the grids to achieve efficient and accurate discontinuity detection performances. We also introduce a recursive algorithm for general sparse grid-based detectors, characterized by convergence properties and easy applicability. Numerical experiments on functions with dimensions n = 2 and n = 4 demonstrate the efficiency and robust generalization of GINNs in detecting discontinuity interfaces. Notably, the trained GINNs offer portability and versatility, allowing integration into various algorithms and sharing among users.</li>
<li><strong>摘要：</strong>在本文中，我们提出了一种检测不连续函数的不连续界面的新方法。这种方法利用图形信息神经网络 (GINN) 和稀疏网格来解决维度大于 3 的域中的不连续性检测。GINN 经过训练以识别稀疏网格上的问题点，利用构建在网格上的图形结构来实现高效和准确不连续性检测性能。我们还介绍了一种用于通用稀疏网格检测器的递归算法，其特点是收敛性好且易于应用。对维度 n = 2 和 n = 4 的函数进行的数值实验证明了 GINN 在检测不连续界面方面的效率和鲁棒泛化性。值得注意的是，经过训练的 GINN 具有可移植性和多功能性，允许集成到各种算法中并在用户之间共享。</li>
</ul>

<h3>Title: Inadequacy of common stochastic neural networks for reliable clinical  decision support</h3>
<ul>
<li><strong>Authors: </strong>Adrian Lindenmeyer, Malte Blattmann, Stefan Franke, Thomas Neumuth, Daniel Schneider</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13657">https://arxiv.org/abs/2401.13657</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13657">https://arxiv.org/pdf/2401.13657</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13657]] Inadequacy of common stochastic neural networks for reliable clinical  decision support(https://arxiv.org/abs/2401.13657)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>Widespread adoption of AI for medical decision making is still hindered due to ethical and safety-related concerns. For AI-based decision support systems in healthcare settings it is paramount to be reliable and trustworthy. Common deep learning approaches, however, have the tendency towards overconfidence under data shift. Such inappropriate extrapolation beyond evidence-based scenarios may have dire consequences. This highlights the importance of reliable estimation of local uncertainty and its communication to the end user. While stochastic neural networks have been heralded as a potential solution to these issues, this study investigates their actual reliability in clinical applications. We centered our analysis on the exemplary use case of mortality prediction for ICU hospitalizations using EHR from MIMIC3 study. For predictions on the EHR time series, Encoder-Only Transformer models were employed. Stochasticity of model functions was achieved by incorporating common methods such as Bayesian neural network layers and model ensembles. Our models achieve state of the art performance in terms of discrimination performance (AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality prediction benchmark. However, epistemic uncertainty is critically underestimated by the selected stochastic deep learning methods. A heuristic proof for the responsible collapse of the posterior distribution is provided. Our findings reveal the inadequacy of commonly used stochastic deep learning approaches to reliably recognize OoD samples. In both methods, unsubstantiated model confidence is not prevented due to strongly biased functional posteriors, rendering them inappropriate for reliable clinical decision support. This highlights the need for approaches with more strictly enforced or inherent distance-awareness to known data points, e.g., using kernel-based techniques.</li>
<li><strong>摘要：</strong>由于道德和安全相关问题，人工智能在医疗决策中的广泛采用仍然受到阻碍。对于医疗保健环境中基于人工智能的决策支持系统来说，可靠和值得信赖至关重要。然而，常见的深度学习方法在数据转移下有过度自信的倾向。这种超出基于证据的情景的不恰当推断可能会产生可怕的后果。这凸显了可靠估计局部不确定性及其与最终用户沟通的重要性。虽然随机神经网络被认为是这些问题的潜在解决方案，但本研究调查了它们在临床应用中的实际可靠性。我们的分析集中于使用 MIMIC3 研究中的 EHR 预测 ICU 住院死亡率的示例用例。为了对 EHR 时间序列进行预测，采用了仅编码器 Transformer 模型。模型函数的随机性是通过结合贝叶斯神经网络层和模型集成等常用方法来实现的。我们的模型在区分性能（AUC ROC：0.868+-0.011，AUC PR：0.554+-0.034）和死亡率预测基准校准方面实现了最先进的性能。然而，所选的随机深度学习方法严重低估了认知不确定性。提供了后验分布崩溃的启发式证明。我们的研究结果揭示了常用的随机深度学习方法不足以可靠地识别 OoD 样本。在这两种方法中，由于功能后验的强烈偏差，未经证实的模型置信度并没有被阻止，使得它们不适合可靠的临床决策支持。这凸显了对已知数据点具有更严格执行或固有距离感知的方法的需求，例如使用基于内核的技术。</li>
</ul>

<h3>Title: MambaByte: Token-free Selective State Space Model</h3>
<ul>
<li><strong>Authors: </strong>Junxiong Wang, Tushaar Gangavarapu, Jing Nathan Yan, Alexander M Rush</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13660">https://arxiv.org/abs/2401.13660</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13660">https://arxiv.org/pdf/2401.13660</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13660]] MambaByte: Token-free Selective State Space Model(https://arxiv.org/abs/2401.13660)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Token-free language models learn directly from raw bytes and remove the bias of subword tokenization. Operating on bytes, however, results in significantly longer sequences, and standard autoregressive Transformers scale poorly in such settings. We experiment with MambaByte, a token-free adaptation of the Mamba state space model, trained autoregressively on byte sequences. Our experiments indicate the computational efficiency of MambaByte compared to other byte-level models. We also find MambaByte to be competitive with and even outperform state-of-the-art subword Transformers. Furthermore, owing to linear scaling in length, MambaByte benefits from fast inference compared to Transformers. Our findings establish the viability of MambaByte in enabling token-free language modeling.</li>
<li><strong>摘要：</strong>无标记语言模型直接从原始字节学习并消除子词标记化的偏差。然而，对字节进行操作会导致序列明显更长，并且标准自回归 Transformer 在此类设置中的扩展性很差。我们用 MambaByte 进行实验，这是 Mamba 状态空间模型的无令牌改编，在字节序列上进行自回归训练。我们的实验表明，与其他字节级模型相比，MambaByte 的计算效率更高。我们还发现 MambaByte 可以与最先进的子词 Transformers 竞争甚至超越。此外，由于长度呈线性缩放，与 Transformer 相比，MambaByte 受益于快速推理。我们的研究结果证实了 MambaByte 在实现无令牌语言建模方面的可行性。</li>
</ul>

<h3>Title: The Definitive Guide to Policy Gradients in Deep Reinforcement Learning:  Theory, Algorithms and Implementations</h3>
<ul>
<li><strong>Authors: </strong>Matthias Lehmann</a></li>
<li><strong>Subjects: </strong>cs.LG, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2401.13662">https://arxiv.org/abs/2401.13662</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2401.13662">https://arxiv.org/pdf/2401.13662</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2401.13662]] The Definitive Guide to Policy Gradients in Deep Reinforcement Learning:  Theory, Algorithms and Implementations(https://arxiv.org/abs/2401.13662)</code><input type="text"></li>
<li><strong>Keywords: </strong>code</a></li>
<li><strong>Abstract: </strong>In recent years, various powerful policy gradient algorithms have been proposed in deep reinforcement learning. While all these algorithms build on the Policy Gradient Theorem, the specific design choices differ significantly across algorithms. We provide a holistic overview of on-policy policy gradient algorithms to facilitate the understanding of both their theoretical foundations and their practical implementations. In this overview, we include a detailed proof of the continuous version of the Policy Gradient Theorem, convergence results and a comprehensive discussion of practical algorithms. We compare the most prominent algorithms on continuous control environments and provide insights on the benefits of regularization. All code is available at https://github.com/Matt00n/PolicyGradientsJax.</li>
<li><strong>摘要：</strong>近年来，深度强化学习中提出了各种强大的策略梯度算法。虽然所有这些算法都建立在策略梯度定理的基础上，但不同算法的具体设计选择存在显着差异。我们提供了策略梯度算法的整体概述，以促进对其理论基础和实际实现的理解。在本概述中，我们包括了策略梯度定理的连续版本的详细证明、收敛结果以及对实用算法的全面讨论。我们比较了连续控制环境中最突出的算法，并提供了关于正则化好处的见解。所有代码均可在 https://github.com/Matt00n/PolicyGradientsJax 上获取。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
