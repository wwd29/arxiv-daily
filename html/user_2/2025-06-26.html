<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-06-26</h1>
<h3>Title: CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation</h3>
<ul>
<li><strong>Authors: </strong>Deepon Halder, Thanmay Jayakumar, Raj Dabre</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19952">https://arxiv.org/abs/2506.19952</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19952">https://arxiv.org/pdf/2506.19952</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19952]] CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation(https://arxiv.org/abs/2506.19952)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs), despite their ability to perform few-shot machine translation (MT), often lag behind dedicated MT systems trained on parallel corpora, which are crucial for high quality machine translation (MT). However, parallel corpora are often scarce or non-existent for low-resource languages. In this paper, we propose CycleDistill, a bootstrapping approach leveraging LLMs and few-shot translation to obtain high-quality MT systems. CycleDistill involves iteratively generating synthetic parallel corpora from monolingual corpora via zero- or few-shot MT, which is then used to fine-tune the model that was used for generating said data for MT. CycleDistill does not need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments focusing on three Indian languages, by relying solely on monolingual corpora, it can achieve high-quality machine translation, improving upon a few-shot baseline model by over 20-30 chrF points on average in the first iteration. We also study the effect of leveraging softmax activations during the distillation process and observe mild improvements in translation quality.</li>
<li><strong>摘要：</strong>大型语言模型（LLMS）尽管能够执行几次射击机器翻译（MT），但通常落后于专用的MT系统，该系统接受了并行语料库培训的，这对于高质量的机器翻译（MT）至关重要。但是，对于低资源语言，平行语料库通常很少或不存在。在本文中，我们提出了CycleDistill，这是利用LLM的自举方法，几乎​​没有射击翻译以获得高质量的MT系统。自行车赛涉及通过零或少量MT从单语库中迭代生成合成的平行语料库，然后将其用于微调用于生成MT上述数据的模型。 CycleDistill不需要1至4个几次示例以外的平行语料库，在我们的实验中，通过仅依靠单语语料库来重点关注三种印度语言，它可以实现高质量的机器翻译，从而在第一次迭代中平均在20-30个CHRF点上提高了几次基线模型。我们还研究了在蒸馏过程中利用软磁性激活的效果，并观察到翻译质量的温和改善。</li>
</ul>

<h3>Title: Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Travis Thompson, Seung-Hwan Lim, Paul Liu, Ruoying He, Dongkuan Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19967">https://arxiv.org/abs/2506.19967</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19967">https://arxiv.org/pdf/2506.19967</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19967]] Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs(https://arxiv.org/abs/2506.19967)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, retrieval-augmented generation, chain-of-thought</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have achieved impressive capabilities in language understanding and generation, yet they continue to underperform on knowledge-intensive reasoning tasks due to limited access to structured context and multi-hop information. Retrieval-Augmented Generation (RAG) partially mitigates this by grounding generation in retrieved context, but conventional RAG and GraphRAG methods often fail to capture relational structure across nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel framework that enhances LLM-based graph reasoning by applying inference-time compute scaling. Our method combines sequential scaling with deep chain-of-thought graph traversal, and parallel scaling with majority voting over sampled trajectories within an interleaved reasoning-execution loop. Experiments on the GRBench benchmark demonstrate that our approach significantly improves multi-hop question answering performance, achieving substantial gains over both traditional GraphRAG and prior graph traversal baselines. These findings suggest that inference-time scaling is a practical and architecture-agnostic solution for structured knowledge reasoning with LLMs</li>
<li><strong>摘要：</strong>大型语言模型（LLM）在语言理解和产生方面具有令人印象深刻的能力，但是由于访问结构化的上下文和多跳信息，它们在知识密集型推理任务上的表现不佳。检索增强的生成（RAG）通过在检索到上下文中的基础生成来部分缓解这种情况，但是常规的抹布和Gragrag方法通常无法捕获知识图中节点之间的关系结构。我们介绍了推理尺寸的GraphRag，这是一个新颖的框架，通过应用推理时间计算缩放来增强基于LLM的图形推理。我们的方法将顺序缩放与深度链的图形横向遍历结合在一起，并在交错的推理执行循环中对采样轨迹进行了多数投票。 Grbench基准测试的实验表明，我们的方法显着改善了多跳的问题回答性能，对传统的GraphRag和先前的图形遍历基线取得了可观的增长。这些发现表明，推理时间缩放是用于使用LLMS结构化知识推理的实用且构造的敏捷解决方案</li>
</ul>

<h3>Title: Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation</h3>
<ul>
<li><strong>Authors: </strong>Xinyi Ni, Haonan Jian, Qiuyang Wang, Vedanshi Chetan Shah, Pengyu Hong</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.19998">https://arxiv.org/abs/2506.19998</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.19998">https://arxiv.org/pdf/2506.19998</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.19998]] Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation(https://arxiv.org/abs/2506.19998)</code><input type="text"></li>
<li><strong>Keywords: </strong>agent</a></li>
<li><strong>Abstract: </strong>REST APIs play important roles in enriching the action space of web agents, yet most API-based agents rely on curated and uniform toolsets that do not reflect the complexity of real-world APIs. Building tool-using agents for arbitrary domains remains a major challenge, as it requires reading unstructured API documentation, testing APIs and inferring correct parameters. We propose Doc2Agent, a scalable pipeline to build agents that can call Python-based tools generated from API documentation. Doc2Agent generates executable tools from API documentations and iteratively refines them using a code agent. We evaluate our approach on real-world APIs, WebArena APIs, and research APIs, producing validated tools. We achieved a 55\% relative performance improvement with 90\% lower cost compared to direct API calling on WebArena benchmark. A domain-specific agent built for glycomaterial science further demonstrates the pipeline's adaptability to complex, knowledge-rich tasks. Doc2Agent offers a generalizable solution for building tool agents from unstructured API documentation at scale.</li>
<li><strong>摘要：</strong>REST API在丰富网络代理的动作空间中起着重要作用，但是大多数基于API的代理都依赖于不反映现实世界API的复杂性的精选和统一的工具集。构建任意域的工具使用代理仍然是一个重大挑战，因为它需要读取非结构化的API文档，测试API并推断正确的参数。我们提出了Doc2agent，这是一种可扩展的管道，用于构建可以调用API文档生成的基于Python的工具的代理。 Doc2agent从API文档生成可执行的工具，并使用代码代理迭代地完善它们。我们评估了对现实世界中的API，Webarena API和Research API的方法，并生产了经过验证的工具。与直接呼叫WebArena基准测试相比，我们实现了55％的相对性能提高，成本低90 \％。为糖材料科学构建的特定领域特定代理进一步证明了管道对复杂，知识丰富的任务的适应性。 DOC2Agent提供了可从非结构化API文档进行大规模构建工具代理的概括解决方案。</li>
</ul>

<h3>Title: A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs</h3>
<ul>
<li><strong>Authors: </strong>Kethmi Hirushini Hettige, Jiahao Ji, Cheng Long, Shili Xiang, Gao Cong, Jingyuan Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20073">https://arxiv.org/abs/2506.20073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20073">https://arxiv.org/pdf/2506.20073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20073]] A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs(https://arxiv.org/abs/2506.20073)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Spatio-temporal data mining plays a pivotal role in informed decision making across diverse domains. However, existing models are often restricted to narrow tasks, lacking the capacity for multi-task inference and complex long-form reasoning that require generation of in-depth, explanatory outputs. These limitations restrict their applicability to real-world, multi-faceted decision scenarios. In this work, we introduce STReason, a novel framework that integrates the reasoning strengths of large language models (LLMs) with the analytical capabilities of spatio-temporal models for multi-task inference and execution. Without requiring task-specific finetuning, STReason leverages in-context learning to decompose complex natural language queries into modular, interpretable programs, which are then systematically executed to generate both solutions and detailed rationales. To facilitate rigorous evaluation, we construct a new benchmark dataset and propose a unified evaluation framework with metrics specifically designed for long-form spatio-temporal reasoning. Experimental results show that STReason significantly outperforms advanced LLM baselines across all metrics, particularly excelling in complex, reasoning-intensive spatio-temporal scenarios. Human evaluations further validate STReason's credibility and practical utility, demonstrating its potential to reduce expert workload and broaden the applicability to real-world spatio-temporal tasks. We believe STReason provides a promising direction for developing more capable and generalizable spatio-temporal reasoning systems.</li>
<li><strong>摘要：</strong>时空数据挖掘在跨不同领域的知情决策中起关键作用。但是，现有模型通常仅限于狭窄的任务，缺乏需要多任务推理和复杂的长格式推理的能力，这些推理需要产生深入的解释性输出。这些限制限制了它们对现实世界中多方面决策方案的适用性。在这项工作中，我们介绍了肌遍历，这是一个新颖的框架，将大语言模型（LLMS）的推理优势与以多任务推理和执行的时空模型的分析能力相结合。不需要特定于任务的填充，春季杠杆杠杆学习将复杂的自然语言查询分解为模块化的，可解释的程序，然后系统地执行以生成解决方案和详细的理由。为了促进严格的评估，我们构建了一个新的基准数据集，并提出了一个统一的评估框架，其指标专门为长时间时空推理而设计。实验结果表明，在所有指标中，肌顿大大优于先进的LLM基准，尤其是在复杂的，强化的时空场景中出色。人类评估进一步验证了肌肌的信誉和实用性，证明了其减少专家工作量并扩大对现实时代时空任务的适用性的潜力。我们认为，肌延展为开发更有能力和可推广的时空推理系统提供了有希望的方向。</li>
</ul>

<h3>Title: Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder</h3>
<ul>
<li><strong>Authors: </strong>Yingji Zhang, Danilo S. Carvalho, André Freitas</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20083">https://arxiv.org/abs/2506.20083</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20083">https://arxiv.org/pdf/2506.20083</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20083]] Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder(https://arxiv.org/abs/2506.20083)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Integrating compositional and symbolic properties into current distributional semantic spaces can enhance the interpretability, controllability, compositionality, and generalisation capabilities of Transformer-based auto-regressive language models (LMs). In this survey, we offer a novel perspective on latent space geometry through the lens of compositional semantics, a direction we refer to as \textit{semantic representation learning}. This direction enables a bridge between symbolic and distributional semantics, helping to mitigate the gap between them. We review and compare three mainstream autoencoder architectures-Variational AutoEncoder (VAE), Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the distinctive latent geometries they induce in relation to semantic structure and interpretability.</li>
<li><strong>摘要：</strong>将组成和符号属性集成到当前的分布语义空间中可以增强基于变压器的自动回归语言模型（LMS）的解释性，可控性，组成性和泛化功能。在这项调查中，我们通过构图语义的镜头提供了关于潜在空间几何形状的新颖观点，我们称为\ textit {语义表示学习}。这个方向使符号和分布语义之间的桥梁有助于减轻它们之间的差距。我们审查并比较了三个主流自动编码器体系结构 - 变量自动编码器（VAE），矢量量化VAE（VQVAE）和稀疏的自动编码器（SAE） - 并检查它们与语义结构和解释性相关的独特潜在几何。</li>
</ul>

<h3>Title: ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset</h3>
<ul>
<li><strong>Authors: </strong>Yilin Wang, Peixuan Lei, Jie Song, Yuzhe Hao, Tao Chen, Yuxuan Zhang, Lei Jia, Yuanxiang Li, Zhongyu Wei</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20093">https://arxiv.org/abs/2506.20093</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20093">https://arxiv.org/pdf/2506.20093</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20093]] ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset(https://arxiv.org/abs/2506.20093)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Time-series data are critical in diverse applications, such as industrial monitoring, medical diagnostics, and climate research. However, effectively integrating these high-dimensional temporal signals with natural language for dynamic, interactive tasks remains a significant challenge. To address this, we introduce the Time-Series Question Answering (Time-Series QA) task and release EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset designed to capture complex interactions between time-series signals and natural language. Building on this resource, we propose the Instruct Time Transformer (ITFormer), a novel framework that bridges time-series encoders with frozen large language models (LLMs). ITFormer effectively extracts, aligns, and fuses temporal and textual features, achieving a strong improvement in QA accuracy over strong baselines with fewer than 1\% additional trainable parameters. By combining computational efficiency with robust cross-modal modeling, our work establishes a adaptable paradigm for integrating temporal data with natural language, paving the way for new research and applications in multi-modal AI. More details about the project, including datasets and code, are available at: this https URL</li>
<li><strong>摘要：</strong>时间序列数据在不同的应用程序中至关重要，例如工业监测，医学诊断和气候研究。但是，有效地将这些高维时间信号与自然语言集成到动态，交互式任务仍然是一个重大挑战。为了解决这个问题，我们介绍了时间序列问题回答（时间序列QA）任务，并发布Enginemt-QA，这是第一个大规模，多任务，暂时的QA数据集，旨在捕获时间序列信号和自然语言之间的复杂交互。在此资源的基础上，我们提出了指示时间变压器（ITFormer），这是一个新颖的框架，它桥接了时间序列，用冷冻的大型语言模型（LLMS）编码。 ITFormer有效地提取，对齐和融合了时间和文本特征，与较少额外的可训练参数的强基础相比，质量标准的准确性得到了强大的提高。通过将计算效率与强大的跨模式建模相结合，我们的工作建立了一个适应性的范式，可以将时间数据与自然语言整合在一起，为多模式AI中的新研究和应用铺平了道路。有关该项目的更多详细信息，包括数据集和代码，请访问：此HTTPS URL</li>
</ul>

<h3>Title: MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations</h3>
<ul>
<li><strong>Authors: </strong>Vardhan Dongre, Chi Gui, Shubham Garg, Hooshang Nayyeri, Gokhan Tur, Dilek Hakkani-Tür, Vikram S. Adve</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20100">https://arxiv.org/abs/2506.20100</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20100">https://arxiv.org/pdf/2506.20100</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20100]] MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations(https://arxiv.org/abs/2506.20100)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning and decision-making in consultative interaction settings. Designed for the agriculture domain, MIRAGE captures the full complexity of expert consultations by combining natural user queries, expert-authored responses, and image-based context, offering a high-fidelity benchmark for evaluating models on grounded reasoning, clarification strategies, and long-form generation in a real-world, knowledge-intensive domain. Grounded in over 35,000 real user-expert interactions and curated through a carefully designed multi-step pipeline, MIRAGE spans diverse crop health, pest diagnosis, and crop management scenarios. The benchmark includes more than 7,000 unique biological entities, covering plant species, pests, and diseases, making it one of the most taxonomically diverse benchmarks available for vision-language models, grounded in the real world. Unlike existing benchmarks that rely on well-specified user inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich scenarios with open-world settings, requiring models to infer latent knowledge gaps, handle rare entities, and either proactively guide the interaction or respond. Project Page: this https URL</li>
<li><strong>摘要：</strong>我们介绍了Mirage，这是一种新的基准，用于在协商互动环境中进行多模式专家级别的推理和决策。 Mirage专为农业领域而设计，通过结合自然用户查询，专家作者的响应和基于图像的环境，捕获了专家咨询的全部复杂性，为评估基础推理，澄清策略以及在现实世界中的知识强度，强度的领域中评估模型的高保真基准，以评估模型。基于35,000多个真正的用户专家交互，并通过精心设计的多步管道策划，幻影跨越了多样化的作物健康，害虫诊断和作物管理方案。基准包括7,000多个独特的生物实体，涵盖植物，害虫和疾病，使其成为现实世界中基于视觉语言模型的分类学最多样化的基准之一。与依赖于明确指定的用户输入和封闭式分类法的现有基准不同，Mirage具有指定性的，具有开放世界设置的上下文富裕场景，需要模型来推断潜在的知识差距，处理稀有实体并主动指导交互或响应。项目页面：此HTTPS URL</li>
</ul>

<h3>Title: A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection</h3>
<ul>
<li><strong>Authors: </strong>Songsoo Kim, Seungtae Lee, See Young Lee, Joonho Kim, Keechan Kan, Dukyong Yoon</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20112">https://arxiv.org/abs/2506.20112</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20112">https://arxiv.org/pdf/2506.20112</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20112]] A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection(https://arxiv.org/abs/2506.20112)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>Background: The positive predictive value (PPV) of large language model (LLM)-based proofreading for radiology reports is limited due to the low error prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV and reduces operational costs compared with baseline approaches. Materials and Methods: A retrospective analysis was performed on 1,000 consecutive radiology reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III database. Two external datasets (CheXpert and Open-i) were validation sets. Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor plus detector; and (3) extractor, detector, and false-positive verifier. Precision was measured by PPV and absolute true positive rate (aTPR). Efficiency was calculated from model inference charges and reviewer remuneration. Statistical significance was tested using cluster bootstrap, exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118, Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs. baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per 1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively. Human-reviewed reports decreased from 192 to 88. External validation supported Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR (0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and reduced operational costs, maintaining detection performance, providing an effective strategy for AI-assisted radiology report quality assurance.</li>
<li><strong>摘要：</strong>背景：大语言模型（LLM）基于放射学报告的校对的正预测值（PPV）受到较低的误差率的限制。目的：评估与基线方法相比，三通LLM框架是否增强了PPV并降低运营成本。材料和方法：对MIMIC-III数据库的1,000个连续放射学报告（每份250个：射线照相，超声检查，CT，MRI）进行了回顾性分析。两个外部数据集（CHExpert和Open-I）是验证集。测试了三个LLM框架：（1）单prompt检测器； （2）提取器加探测器； （3）提取器，检测器和假阳性验证者。通过PPV和绝对真实的正速率（ATPR）测量精度。效率是根据模型推理费用和审阅者报酬计算得出的。使用群集自举，精确的McNemar检验和Holm-Bonferroni校正测试统计显着性。结果：框架PPV从0.063（95％CI，0.036-0.101，框架1）提高到0.079（0.049-0.118，框架2），显着增加到0.159（0.090-0.252，框架3；框架3; p <.001 vs.sbaselines）。 ATPR保持稳定（0.012-0.014; p> =。84）。从9.72美元（框架1）和6.85美元（框架2）降至5.58美元（框架3），每1,000起报告的运营成本分别降至5.58美元（框架3），分别反映了42.6％和18.5％的降低。经过人工评审的报告从192下降到88。外部验证支持3的上级PPV（CHEXPERT 0.133，OPEN-I 0.105）和稳定的ATPR（0.007）。结论：三通LLM框架显着提高了PPV并降低了操作成本，维持检测性能，为AI辅助放射学报告质量保证提供了有效的策略。</li>
</ul>

<h3>Title: CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation</h3>
<ul>
<li><strong>Authors: </strong>Aashiq Muhamed</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20128">https://arxiv.org/abs/2506.20128</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20128">https://arxiv.org/pdf/2506.20128</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20128]] CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation(https://arxiv.org/abs/2506.20128)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm</a></li>
<li><strong>Abstract: </strong>RAG systems enhance LLMs by incorporating external knowledge, which is crucial for domains that demand factual accuracy and up-to-date information. However, evaluating the multifaceted quality of RAG outputs, spanning aspects such as contextual coherence, query relevance, factual correctness, and informational completeness, poses significant challenges. Existing evaluation methods often rely on simple lexical overlap metrics, which are inadequate for capturing these nuances, or involve complex multi-stage pipelines with intermediate steps like claim extraction or require finetuning specialized judge models, hindering practical efficiency. To address these limitations, we propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five metrics that utilizes a single, powerful, pretrained LLM as a zero-shot, end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance (QR), Information Density (ID), Answer Correctness (AC), and Information Recall (IR). We apply CCRS to evaluate six diverse RAG system configurations on the challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively discriminates between system performances, confirming, for instance, that the Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of CCRS metric properties, including score distributions, convergent/discriminant validity, tie rates, population statistics, and discriminative power. Compared to the complex RAGChecker framework, CCRS offers comparable or superior discriminative power for key aspects like recall and faithfulness, while being significantly more computationally efficient. CCRS thus provides a practical, comprehensive, and efficient framework for evaluating and iteratively improving RAG systems.</li>
<li><strong>摘要：</strong>抹布系统通过合并外部知识来增强LLM，这对于需要事实准确性和最新信息的领域至关重要。但是，评估抹布输出的多方面质量，涵盖上下文连贯性，查询相关性，事实正确性和信息完整性等方面，提出了重大挑战。现有的评估方法通常依赖于简单的词汇叠加指标，这些指标不足以捕获这些细微差别，或者涉及复杂的多阶段管道，具有中间步骤，例如主张提取或需要填充专业的法官模型，从而阻碍了实践效率。为了解决这些局限性，我们提出了CCR（上下文连贯性和相关性得分），这是一套由五个指标组成的新型套件，该指标利用一个单一的，强大的，预审预告片的LLM作为零枪，端到端的法官。 CCR评估：上下文连贯性（CC），问题相关性（QR），信息密度（ID），答案正确性（AC）和信息召回（IR）。我们应用CCR来评估具有挑战性的BioASQ数据集上的六种不同的抹布系统配置。我们的分析表明，CCR有效地区分了系统性能，例如确认Mistral-7b读取器的表现优于Llama变体。我们提供了CCRS度量属性的详细分析，包括得分分布，收敛/判别有效性，平局率，人口统计和判别能力。与复杂的Ragchecker框架相比，CCRS为召回和忠诚等关键方面提供了可比或优越的判别能力，同时在计算上更有效。因此，CCR提供了一个实用，全面和有效的框架，用于评估和迭代地改善破布系统。</li>
</ul>

<h3>Title: AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control</h3>
<ul>
<li><strong>Authors: </strong>Ruosen Li, Ziming Luo, Quan Zhang, Ruochen Li, Ben Zhou, Ali Payani, Xinya Du</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20160">https://arxiv.org/abs/2506.20160</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20160">https://arxiv.org/pdf/2506.20160</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20160]] AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control(https://arxiv.org/abs/2506.20160)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, chain-of-thought</a></li>
<li><strong>Abstract: </strong>Large reasoning models (LRMs) achieve impressive reasoning capabilities by generating lengthy chain-of-thoughts, but this "overthinking" incurs high latency and cost without commensurate accuracy gains. In this work, we introduce AALC, a lightweight, accuracy-aware length reward integrated into reinforcement learning that dynamically balances correctness and brevity during training. By incorporating validation accuracy into the reward and employing a smooth, dynamically scheduled length penalty, AALC delays length penalty until target performance is met. Through extensive experiments across standard and out-of-distribution math benchmarks, we show that our approach reduces response length by over 50% while maintaining or even improving the original accuracy. Furthermore, qualitative analysis reveals that our method curbs redundant reasoning patterns such as excessive subgoal setting and verification, leading to structurally refined outputs rather than naive truncation. We also identify that efficiency gains are accompanied by reduced interpretability: models trained with AALC omit some narrative framing and explanatory context. These findings highlight the potential of reward-based strategies to guide LRMs toward more efficient, generalizable reasoning paths.</li>
<li><strong>摘要：</strong>大型推理模型（LRMS）通过产生冗长的思想链来实现令人印象深刻的推理能力，但是这种“过度思考”会带来高潜伏期和成本，而没有相应的准确性提高。在这项工作中，我们介绍了AALC，这是一个轻巧，准确的长度奖励，并将其整合到强化学习中，以动态平衡训练期间的正确性和简洁性。通过将验证精度纳入奖励并采用平稳，动态计划的长度罚款，AALC延迟了长度罚款，直到达到目标性能。通过跨标准和分布外数学基准的大量实验，我们表明我们的方法在维持甚至提高原始准确性的同时，将响应长度降低了50％以上。此外，定性分析表明，我们的方法遏制了冗余的推理模式，例如过度的亚目标和验证，导致结构精制的输出，而不是天真的截断。我们还确定效率提高伴随着可解释性的降低：经过AALC训练的模型省略了一些叙事框架和解释性的环境。这些发现突出了基于奖励的策略的潜力，以指导LRMS采取更有效，可推广的推理路径。</li>
</ul>

<h3>Title: SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs</h3>
<ul>
<li><strong>Authors: </strong>Fengze Li, Yue Wang, Yangle Liu, Ming Huang, Dou Hong, Jieming Ma</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20167">https://arxiv.org/abs/2506.20167</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20167">https://arxiv.org/pdf/2506.20167</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20167]] SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs(https://arxiv.org/abs/2506.20167)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Multivariate time series forecasting requires models to simultaneously capture variable-wise structural dependencies and generalize across diverse tasks. While structural encoders are effective in modeling feature interactions, they lack the capacity to support semantic-level reasoning or task adaptation. Conversely, large language models (LLMs) possess strong generalization capabilities but remain incompatible with raw time series inputs. This gap limits the development of unified, transferable prediction systems. Therefore, we introduce SEED, a structural encoder for embedding-driven decoding, which integrates four stages: a token-aware encoder for patch extraction, a projection module that aligns patches with language model embeddings, a semantic reprogramming mechanism that maps patches to task-aware prototypes, and a frozen language model for prediction. This modular architecture decouples representation learning from inference, enabling efficient alignment between numerical patterns and semantic reasoning. Empirical results demonstrate that the proposed method achieves consistent improvements over strong baselines, and comparative studies on various datasets confirm SEED's role in addressing the structural-semantic modeling gap.</li>
<li><strong>摘要：</strong>多元时间序列预测需要模型同时捕获可变的结构依赖性并跨越各种任务。尽管结构编码器可有效地建模特征交互作用，但它们缺乏支持语义级别推理或任务适应的能力。相反，大型语言模型（LLMS）具有强大的概括功能，但仍与原始时间序列输入保持不相容。该差距限制了统一，可转移的预测系统的发展。因此，我们介绍了种子，这是一种用于嵌入驱动解码的结构编码器，该编码器集成了四个阶段：用于贴片提取的令牌意识到的编码器，一种将贴片与语言模型嵌入的投影模块，一种语义重编程机制，将贴片绘制为任务促进的原型，以绘制任务促进原型的原型，以及用于预测的模型。该模块化体系结构将表示形式从推理中学习，从而在数值模式和语义推理之间有效地对齐。经验结果表明，所提出的方法可以实现对强基础的一致改进，并且对各种数据集的比较研究证实了种子在解决结构语义建模间隙方面的作用。</li>
</ul>

<h3>Title: COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees</h3>
<ul>
<li><strong>Authors: </strong>Zhiyuan Wang, Jinhao Duan, Qingni Wang, Xiaofeng Zhu, Tianlong Chen, Xiaoshuang Shi, Kaidi Xu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20178">https://arxiv.org/abs/2506.20178</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20178">https://arxiv.org/pdf/2506.20178</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20178]] COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees(https://arxiv.org/abs/2506.20178)</code><input type="text"></li>
<li><strong>Keywords: </strong>hallucination</a></li>
<li><strong>Abstract: </strong>Uncertainty quantification (UQ) for foundation models is essential to identify and mitigate potential hallucinations in automatically generated text. However, heuristic UQ approaches lack formal guarantees for key metrics such as the false discovery rate (FDR) in selective prediction. Previous work adopts the split conformal prediction (SCP) framework to ensure desired coverage of admissible answers by constructing prediction sets, but these sets often contain incorrect candidates, limiting their practical utility. To address this, we propose COIN, an uncertainty-guarding selection framework that calibrates statistically valid thresholds to filter a single generated answer per question under user-specified FDR constraints. COIN estimates the empirical error rate on a calibration set and applies confidence interval methods such as Clopper-Pearson to establish a high-probability upper bound on the true error rate (i.e., FDR). This enables the selection of the largest uncertainty threshold that ensures FDR control on test data while significantly increasing sample retention. We demonstrate COIN's robustness in risk control, strong test-time power in retaining admissible answers, and predictive efficiency under limited calibration data across both general and multimodal text generation tasks. Furthermore, we show that employing alternative upper bound constructions and UQ strategies can further boost COIN's power performance, which underscores its extensibility and adaptability to diverse application scenarios.</li>
<li><strong>摘要：</strong>基础模型的不确定性量化（UQ）对于识别和减轻自动生成的文本中的潜在幻觉至关重要。但是，启发式UQ方法缺乏对关键指标的正式保证，例如选择性预测中的错误发现率（FDR）。以前的工作采用了分裂的保形预测（SCP）框架，以确保通过构建预测集的理想覆盖范围，但是这些集合通常包含不正确的候选人，从而限制了其实际实用性。为了解决这个问题，我们提出了硬币，这是一种不确定性的选择框架，该框架校准了统计上有效的阈值，以根据用户指定的FDR约束过滤每个问题的单个生成答案。硬币估计校准集中的经验错误率，并应用置信区间方法，例如Clopper-Pearson，以建立在真实错误率（即FDR）上的高概率上限。这使得选择最大的不确定性阈值，以确保对测试数据的FDR控制，同时显着增加样品保留。我们证明了硬币在风险控制方面的鲁棒性，在保留可允许的答案方面的强大测试时间功率以及在一般和多模式文本生成任务中有限的校准数据下的预测效率。此外，我们表明，采用替代性上限结构和UQ策略可以进一步提高Coin的功率性能，这强调了其可扩展性和对各种应用程序方案的适应性。</li>
</ul>

<h3>Title: How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?</h3>
<ul>
<li><strong>Authors: </strong>Mengqi Wang, Tiantian Feng, Shrikanth Narayanan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20199">https://arxiv.org/abs/2506.20199</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20199">https://arxiv.org/pdf/2506.20199</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20199]] How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?(https://arxiv.org/abs/2506.20199)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have enabled a wide variety of real-world applications in various domains. However, creating a high-performing application with high accuracy remains challenging, particularly for subjective tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this study investigates approaches to improving conversational emotion recognition (CER) by LLMs. Specifically, we explore how to retrieve high-quality examples in in-context learning (ICL) to enhance CER. We propose various strategies based on random and augmented example retrieval and also analyze the impact of conversational context on CER accuracy. Experiments were conducted on the three datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented example retrieval consistently outperforms other techniques under investigation across all datasets, highlighting the importance of retrieving coherent targeted examples and enhancing them through paraphrasing.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）已在各个领域中启用了各种各样的现实应用程序。但是，创建具有高精度的高性能应用程序仍然具有挑战性，特别是对于情感识别等主观任务。受SLT 2024 Genser挑战的启发，这项研究调查了LLMS改善对话情感识别（CER）的方法。具体而言，我们探讨了如何检索在文化学习（ICL）中以增强CER的高质量示例。我们提出了基于随机和增强示例检索的各种策略，并分析了会话环境对CER准确性的影响。实验是在包括Iemocap，Meld和Emorynlp在内的三个数据集上进行的。结果表明，增强示例检索一致性地胜过所有数据集中研究的其他技术，突出了检索相干目标示例的重要性并通过释义来增强它们。</li>
</ul>

<h3>Title: Enhancing Large Language Models through Structured Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Yubo Dong, Hehe Fan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20241">https://arxiv.org/abs/2506.20241</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20241">https://arxiv.org/pdf/2506.20241</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20241]] Enhancing Large Language Models through Structured Reasoning(https://arxiv.org/abs/2506.20241)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Recent Large Language Models (LLMs) have significantly advanced natural language processing and automated decision-making. However, these models still encounter difficulties when performing complex reasoning tasks involving logical deduction and systematic planning, primarily due to their reliance on implicit statistical relationships without structured knowledge this http URL by cognitive science and neurosymbolic AI, we introduce a novel approach to enhance LLMs through explicit structured reasoning. First, we convert unstructured data into structured formats by explicitly annotating reasoning steps. We then employ this structured dataset to train LLMs through Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning capabilities of LLMs using Group Relative Policy Optimization (GRPO), incorporating two innovative algorithms--MAX-Flow and Longest Common Subsequence (LCS)--which notably improve reasoning effectiveness and reduce computational complexity. Experimental results from fine-tuning a DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust performance across various scenarios, and improved compatibility with optimization techniques, validating the efficacy of structured reasoning integration in LLMs.</li>
<li><strong>摘要：</strong>最近的大型语言模型（LLMS）具有显着高级的自然语言处理和自动决策。但是，这些模型在执行涉及逻辑推论和系统计划的复杂推理任务时仍然遇到困难，这主要是由于它们对内隐统计关系的依赖而没有结构化的知识，而这种http url通过认知科学和神经肌关系AI，我们通过明确的结构化推理引入了一种新颖的方法来增强LLMS的新方法。首先，我们通过明确注释推理步骤将非结构化数据转换为结构化格式。然后，我们使用该结构化数据集通过监督的微调（SFT）来培训LLM。此外，我们使用小组相对策略优化（GRPO）增强了LLM的结构化推理能力，并结合了两种创新的算法 - 最大 - 流量和最长的常见子序列（LCS） - 尤其提高了推理效率并降低了计算复杂性。通过微调DeepSeek-R1-Distill-Qwen-1.5b模型进行的实验结果表明，在各种情况下进行了简洁的推理，稳健的性能以及改善了优化技术的兼容性，从而验证了LLMS中结构化推理的疗效。</li>
</ul>

<h3>Title: Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kai-Robin Lange, Tobias Schmidt, Matthias Reccius, Henrik Müller, Michael Roos, Carsten Jentsch</a></li>
<li><strong>Subjects: </strong>cs.CL, econ.GN</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20269">https://arxiv.org/abs/2506.20269</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20269">https://arxiv.org/pdf/2506.20269</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20269]] Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models(https://arxiv.org/abs/2506.20269)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>With rapidly evolving media narratives, it has become increasingly critical to not just extract narratives from a given corpus but rather investigate, how they develop over time. While popular narrative extraction methods such as Large Language Models do well in capturing typical narrative elements or even the complex structure of a narrative, applying them to an entire corpus comes with obstacles, such as a high financial or computational cost. We propose a combination of the language understanding capabilities of Large Language Models with the large scale applicability of topic models to dynamically model narrative shifts across time using the Narrative Policy Framework. We apply a topic model and a corresponding change point detection method to find changes that concern a specific topic of interest. Using this model, we filter our corpus for documents that are particularly representative of that change and feed them into a Large Language Model that interprets the change that happened in an automated fashion and distinguishes between content and narrative shifts. We employ our pipeline on a corpus of The Wall Street Journal news paper articles from 2009 to 2023. Our findings indicate that a Large Language Model can efficiently extract a narrative shift if one exists at a given point in time, but does not perform as well when having to decide whether a shift in content or a narrative shift took place.</li>
<li><strong>摘要：</strong>随着媒体迅速发展的叙事，不仅要从给定的语料库中提取叙事，而且还要调查它们如何随着时间的流逝而变得越来越重要。尽管大型语言模型等流行的叙事提取方法在捕获典型的叙事元素甚至叙事的复杂结构方面确实表现出色，但将它们应用于整个语料库都有障碍，例如高财务或计算成本。我们建议使用叙事策略框架，将大型语言模型的语言理解能力与主题模型的大规模适用性的大规模适用性结合在一起。我们应用主题模型和相应的变更点检测方法来查找有关特定主题的更改。使用此模型，我们将语料库过滤的文档，这些文档特别代表了这种变化，并将其馈入大型语言模型，该模型以自动化方式解释发生的变化，并区分内容和叙事变化。我们在2009年至2023年的《华尔街日报》新闻报道文章的语料库上采用了管道。我们的发现表明，如果一个人在给定的时间点存在，则大型语言模型可以有效地提取叙事转变，但是当必须决定是否发生内容或叙述性的转变时，它的表现不佳。</li>
</ul>

<h3>Title: Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content</h3>
<ul>
<li><strong>Authors: </strong>Rian Touchent, Nathan Godey, Eric de la Clergerie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20331">https://arxiv.org/abs/2506.20331</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20331">https://arxiv.org/pdf/2506.20331</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20331]] Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content(https://arxiv.org/abs/2506.20331)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>We introduce Biomed-Enriched, a biomedical text dataset constructed from PubMed via a two-stage annotation process. In the first stage, a large language model annotates 400K paragraphs from PubMed scientific articles, assigning scores for their type (review, study, clinical case, other), domain (clinical, biomedical, other), and educational quality. The educational quality score (rated 1 to 5) estimates how useful a paragraph is for college-level learning. These annotations are then used to fine-tune a small language model, which propagates the labels across the full PMC-OA corpus. The resulting metadata allows us to extract refined subsets, including 2M clinical case paragraphs with over 450K high-quality ones from articles with commercial-use licenses, and to construct several variants via quality filtering and domain upsampling. Clinical text is typically difficult to access due to privacy constraints, as hospital records cannot be publicly shared. Hence, our dataset provides an alternative large-scale, openly available collection of clinical cases from PubMed, making it a valuable resource for biomedical and clinical NLP. Preliminary continual-pretraining experiments with OLMo2 suggest these curated subsets enable targeted improvements, with clinical upsampling boosting performance by ~5% on MMLU ProfMed and educational quality filtering improving MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster convergence, reaching same performance with a third of training tokens, indicating potential for more efficient and effective biomedical pretraining strategies.</li>
<li><strong>摘要：</strong>我们介绍了生物医学文本数据集，该数据集是由PubMed构建的，该数据集是通过两阶段注释过程构建的。在第一阶段，大型语言模型注释了PubMed Scientific文章的400K段落，分配了其类型的分数（审查，研究，临床案例，其他），域（临床，生物医学，其他）和教育质量。教育质量得分（1至5）估计一段对大学级学习的有用程度。然后，这些注释用于微调一个小语言模型，该模型在整个PMC-OA语料库中传播标签。由此产生的元数据使我们能够提取精致的子集，包括来自具有商业使用许可证的文章的200万个临床案例段落，具有超过450k的高质量的段落，并通过质量过滤和域进行启动来构造多个变体。由于无法公开共享医院记录，因此通常由于隐私限制而难以访问临床文本。因此，我们的数据集提供了PubMed的替代性大规模，公开可用的临床病例集合，使其成为生物医学和临床NLP的宝贵资源。使用OLMO2进行初步的持续进化实验表明，这些策划的子集可实现有针对性的改进，而MMLU的临床提高性能提高了约5％的MMLU和教育质量过滤，从而提高了MEDQA和MEDMCQA的性能约为1％。这些技术的组合导致了更快的收敛性，与三分之一的训练令牌达到了相同的性能，这表明可能采取了更有效，有效的生物医学预训练策略。</li>
</ul>

<h3>Title: TAPS: Tool-Augmented Personalisation via Structured Tagging</h3>
<ul>
<li><strong>Authors: </strong>Ekaterina Taktasheva, Jeff Dalton</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20409">https://arxiv.org/abs/2506.20409</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20409">https://arxiv.org/pdf/2506.20409</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20409]] TAPS: Tool-Augmented Personalisation via Structured Tagging(https://arxiv.org/abs/2506.20409)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Recent advancements in tool-augmented large language models have enabled them to interact with external tools, enhancing their ability to perform complex user tasks. However, existing approaches overlook the role of personalisation in guiding tool use. This work investigates how user preferences can be effectively integrated into goal-oriented dialogue agents. Through extensive analysis, we identify key weaknesses in the ability of LLMs to personalise tool use. To this end, we introduce \name, a novel solution that enhances personalised tool use by leveraging a structured tagging tool and an uncertainty-based tool detector. TAPS significantly improves the ability of LLMs to incorporate user preferences, achieving the new state-of-the-art for open source models on the NLSI task.</li>
<li><strong>摘要：</strong>工具增强的大语言模型的最新进展使他们能够与外部工具进行交互，从而增强了执行复杂的用户任务的能力。但是，现有方法忽略了个性化在指导工具使用中的作用。这项工作调查了如何有效地将用户偏好集成到目标的对话代理中。通过广泛的分析，我们确定了LLMS个性化工具使用能力的关键弱点。为此，我们介绍了一种新颖的解决方案\名称，该解决方案通过利用结构化标记工具和基于不确定的工具检测器来增强个性化工具的使用。 TAPS显着提高了LLMS合并用户偏好的能力，从而实现了NLSI任务上开源模型的新最新设备。</li>
</ul>

<h3>Title: An Agentic System for Rare Disease Diagnosis with Traceable Reasoning</h3>
<ul>
<li><strong>Authors: </strong>Weike Zhao, Chaoyi Wu, Yanjie Fan, Xiaoman Zhang, Pengcheng Qiu, Yuze Sun, Xiao Zhou, Yanfeng Wang, Ya Zhang, Yongguo Yu, Kun Sun, Weidi Xie</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.CV, cs.MA</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20430">https://arxiv.org/abs/2506.20430</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20430">https://arxiv.org/pdf/2506.20430</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20430]] An Agentic System for Rare Disease Diagnosis with Traceable Reasoning(https://arxiv.org/abs/2506.20430)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Rare diseases collectively affect over 300 million individuals worldwide, yet timely and accurate diagnosis remains a pervasive challenge. This is largely due to their clinical heterogeneity, low individual prevalence, and the limited familiarity most clinicians have with rare conditions. Here, we introduce DeepRare, the first rare disease diagnosis agentic system powered by a large language model (LLM), capable of processing heterogeneous clinical inputs. The system generates ranked diagnostic hypotheses for rare diseases, each accompanied by a transparent chain of reasoning that links intermediate analytic steps to verifiable medical evidence. DeepRare comprises three key components: a central host with a long-term memory module; specialized agent servers responsible for domain-specific analytical tasks integrating over 40 specialized tools and web-scale, up-to-date medical knowledge sources, ensuring access to the most current clinical information. This modular and scalable design enables complex diagnostic reasoning while maintaining traceability and adaptability. We evaluate DeepRare on eight datasets. The system demonstrates exceptional diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013 diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15 methods, like traditional bioinformatics diagnostic tools, LLMs, and other agentic systems, achieving an average Recall@1 score of 57.18% and surpassing the second-best method (Reasoning LLM) by a substantial margin of 23.79 percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of reasoning chains by clinical experts achieves 95.40% agreements. Furthermore, the DeepRare system has been implemented as a user-friendly web application this http URL.</li>
<li><strong>摘要：</strong>罕见的疾病在全球范围内统一影响了超过3亿人，但及时，准确的诊断仍然是一个普遍的挑战。这在很大程度上是由于它们的临床异质性，个性较低的患病率以及大多数临床医生在极少数情况下的熟悉程度有限。在这里，我们介绍了DeepRare，这是第一个由大语言模型（LLM）提供动力的罕见疾病诊断系统，能够处理异质的临床输入。该系统对罕见疾病产生了排名的诊断假设，每种假设都伴随着透明的推理链，该推理将中间分析步骤与可验证的医学证据联系起来。 DeepRare包括三个关键组成部分：具有长期内存模块的中心主机；专门的代理服务器负责集成了40多个专用工具和Web规模的最新医学知识来源的特定领域分析任务，从而确保访问最新的临床信息。这种模块化的可扩展设计可实现复杂的诊断推理，同时保持可追溯性和适应性。我们在八个数据集上评估了DeepRare。该系统在2,919种疾病中表现出出色的诊断性能，可实现1013种疾病的100％精度。在基于HPO的评估中，DeepRare明显优于其他15种方法，例如传统的生物信息学诊断工具，LLMS和其他代理系统，平均召回@1得分为57.18％，超过了第二好的方法（推理LLM）的实质范围为23.79％。对于多模式输入方案，DeepRare在召回@1处的持续时间为70.60％，而Exomiser的53.20％在109例情况下达到了70.60％。临床专家对推理链的手动验证达到了95.40％的协议。此外，DeepRare系统已作为用户友好的Web应用程序实现。</li>
</ul>

<h3>Title: Probing AI Safety with Source Code</h3>
<ul>
<li><strong>Authors: </strong>Ujwal Narayan, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Karthik Narasimhan, Ameet Deshpande, Vishvak Murahari</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20471">https://arxiv.org/abs/2506.20471</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20471">https://arxiv.org/pdf/2506.20471</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20471]] Probing AI Safety with Source Code(https://arxiv.org/abs/2506.20471)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have become ubiquitous, interfacing with humans in numerous safety-critical applications. This necessitates improving capabilities, but importantly coupled with greater safety measures to align these models with human values and preferences. In this work, we demonstrate that contemporary models fall concerningly short of the goal of AI safety, leading to an unsafe and harmful experience for users. We introduce a prompting strategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT converts natural language inputs to simple code that represents the same intent. For instance, CoDoT transforms the natural language prompt "Make the statement more toxic: {text}" to: "make_more_toxic({text})". We show that CoDoT results in a consistent failure of a wide range of state-of-the-art LLMs. For example, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of the time, and toxicity increases 300% on average across seven modern LLMs. Additionally, recursively applying CoDoT can further increase toxicity two times. Given the rapid and widespread adoption of LLMs, CoDoT underscores the critical need to evaluate safety efforts from first principles, ensuring that safety and capabilities advance together.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）已无处不在，与人类在许多安全至关重要的应用中与人类接触。这需要提高能力，但重要的是，再加上更大的安全措施，以使这些模型与人类价值观和偏好保持一致。在这项工作中，我们证明了当代模型涉及AI安全的目标，从而导致对用户的不安全和有害体验。我们引入了一种名为“思想守则”（CODOT）的提示策略，以评估LLM的安全性。 CODOT将自然语言输入转换为表示相同意图的简单代码。例如，CODOT将自然语言提示“使语句更有毒：{text}”转换为：“ make_more_toxic（{text}）”。我们表明，CODOT会导致广泛的最先进的LLM的稳定失败。例如，GPT-4 Turbo的毒性增加了16.5倍，DeepSeek R1的时间为100％，而在七个现代LLM中的毒性平均增加了300％。另外，递归应用CODOT可以进一步增加毒性两次。鉴于LLM的快速和广泛采用，CODOT强调了评估第一原则的安全工作的关键需求，从而确保安全和能力共同提高。</li>
</ul>

<h3>Title: Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations</h3>
<ul>
<li><strong>Authors: </strong>Kaixiang Zhang, Justine Zhang, Cristian Danescu-Niculescu-Mizil</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20474">https://arxiv.org/abs/2506.20474</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20474">https://arxiv.org/pdf/2506.20474</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20474]] Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations(https://arxiv.org/abs/2506.20474)</code><input type="text"></li>
<li><strong>Keywords: </strong>chat</a></li>
<li><strong>Abstract: </strong>An intrinsic aspect of every conversation is the way talk-time is shared between multiple speakers. Conversations can be balanced, with each speaker claiming a similar amount of talk-time, or imbalanced when one talks disproportionately. Such overall distributions are the consequence of continuous negotiations between the speakers throughout the conversation: who should be talking at every point in time, and for how long? In this work we introduce a computational framework for quantifying both the conversation-level distribution of talk-time between speakers, as well as the lower-level dynamics that lead to it. We derive a typology of talk-time sharing dynamics structured by several intuitive axes of variation. By applying this framework to a large dataset of video-chats between strangers, we confirm that, perhaps unsurprisingly, different conversation-level distributions of talk-time are perceived differently by speakers, with balanced conversations being preferred over imbalanced ones, especially by those who end up talking less. Then we reveal that -- even when they lead to the same level of overall balance -- different types of talk-time sharing dynamics are perceived differently by the participants, highlighting the relevance of our newly introduced typology. Finally, we discuss how our framework offers new tools to designers of computer-mediated communication platforms, for both human-human and human-AI communication.</li>
<li><strong>摘要：</strong>每次对话的一个内在方面是多个演讲者之间的谈话时间的方式。对话可以保持平衡，每个讲话者都声称谈话时间类似，或者当人说话不成比例时会失去不平衡。这样的总体分布是在整个谈话中说话者之间连续谈判的结果：谁应该在每个时间点说话，以及多长时间？在这项工作中，我们介绍了一个计算框架，以量化说话者之间的谈话时间的对话级分布以及导致它的低级动态。我们得出了通过几个直观轴变异轴结构的谈话时间共享动力学的类型。通过将此框架应用于陌生人之间的大型视频聊天数据集，我们确认，毫不奇怪的是，扬声器对聊天时间的不同对话级别的分布有所不同，而平衡的对话比不平衡的对话尤其是那些最终少说话的对话。然后，我们揭示了 - 即使它们导致了相同的总体平衡水平，参与者对不同类型的聊天时间共享动态也有所不同，从而强调了我们新引入的类型学的相关性。最后，我们讨论了我们的框架如何为人类和人类通信的计算机介导的通信平台的设计师提供新的工具。</li>
</ul>

<h3>Title: GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching</h3>
<ul>
<li><strong>Authors: </strong>Guinan Su, Li Shen, Lu Yin, Shiwei Liu, Yanwu Yang, Jonas Geiping</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20480">https://arxiv.org/abs/2506.20480</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20480">https://arxiv.org/pdf/2506.20480</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20480]] GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching(https://arxiv.org/abs/2506.20480)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have shown remarkable capabilities in language understanding and generation. However, such impressive capability typically comes with a substantial model size, which presents significant challenges in deployment and inference. While structured pruning of model parameters offers a promising way to reduce computational costs at deployment time, current methods primarily focus on single model pruning. In this work, we develop a novel strategy to compress models by strategically combining or merging layers from finetuned model variants, which preserves the original model's abilities by aggregating capabilities accentuated in different finetunes. We pose the optimal tailoring of these LLMs as a zero-order optimization problem, adopting a search space that supports three different operations: (1) Layer removal, (2) Layer selection from different candidate models, and (3) Layer merging. Our experiments demonstrate that this approach leads to competitive model pruning, for example, for the Llama2-13B model families, our compressed models maintain approximately 97.3\% of the original performance while removing $\sim25\%$ of parameters, significantly outperforming previous state-of-the-art methods. The code is available at this https URL.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）在语言理解和产生方面表现出了显着的功能。但是，这种令人印象深刻的能力通常具有很大的模型规模，这在部署和推理中面临着重大挑战。虽然模型参数的结构化修剪提供了一种有希望的方法来减少部署时间的计算成本，但当前方法主要集中于单个模型修剪。在这项工作中，我们制定了一种新颖的策略来通过策略性地结合或合并鉴定模型变体的层来压缩模型，该模型变体通过汇总在不同的登录中强调的功能来保留原始模型的能力。我们将这些LLMS作为零级优化问题提出最佳剪裁，采用一个支持三种不同操作的搜索空间：（1）层删除，（2）从不同候选模型中选择层，以及（3）层合并。我们的实验表明，这种方法会导致竞争性模型修剪，例如，对于Llama2-13b模型家族，我们的压缩模​​型将维持原始性能的约97.3％，同时删除$ \ sim25 \％的参数参数，显着超出了先前的先前尚未实现的态度。该代码可在此HTTPS URL上找到。</li>
</ul>

<h3>Title: ReCode: Updating Code API Knowledge with Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Haoze Wu, Yunzhi Yao, Wenhao Yu, Huajun Chen, Ningyu Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IR, cs.LG, cs.SE</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20495">https://arxiv.org/abs/2506.20495</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20495">https://arxiv.org/pdf/2506.20495</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20495]] ReCode: Updating Code API Knowledge with Reinforcement Learning(https://arxiv.org/abs/2506.20495)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) exhibit remarkable code generation capabilities but falter when adapting to frequent updates in external library APIs. This critical limitation, stemming from reliance on outdated API knowledge from their training data, even with access to current documentation, impedes reliable code generation in dynamic environments. To tackle this issue, we propose ReCode (rule-based Reinforcement learning for Code Update), a novel framework that mimics human programmer adaptation to API changes. Specifically, we construct a dataset of approximately 2,000 data entries to train the LLMs to perform version migration based on updated information. Then, we introduce a modified string similarity metric for code evaluation as the reward for reinforcement learning. Our experiments demonstrate that ReCode substantially boosts LLMs' code generation performance in dynamic API scenarios, especially on the unseen CodeUpdateArena task. Crucially, compared to supervised fine-tuning, ReCode has less impact on LLMs' general code generation abilities. We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and DAPO), all achieving consistent improvements. Notably, after training, Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned model and the reasoning model with the same architecture. Code is available at this https URL.</li>
<li><strong>摘要：</strong>大型语言模型（LLMS）具有显着的代码生成功能，但在适应外部库API中的频繁更新时会曲折。这一关键限制是由于依赖过时的API知识从其培训数据中依靠，即使使用当前文档，也会阻碍可靠的代码生成在动态环境中。为了解决此问题，我们提出了RECODE（用于代码更新的基于规则的增强学习），这是一个模仿人类程序员适应API变化的新颖框架。具体来说，我们构建了一个大约2,000个数据条目的数据集，以训练LLMS以基于更新的信息执行版本迁移。然后，我们引入了一个修改后的字符串相似性指标，以评估代码评估，作为增强学习的奖励。我们的实验表明，在动态API方案中，尤其是在看不见的CodeUpdateArena任务中，重新编码LLMS的代码生成性能大大提高了代码的生成性能。至关重要的是，与受监督的微调相比，recode对LLMS的一般代码生成能力的影响较小。我们对各种LLM和增强学习算法（GRPO和DAPO）进行了RECODE，所有这些都取得了一致的改进。值得注意的是，经过训练，QWEN2.5-CODER-7B的表现优于32B参数代码指令模型的模型和具有相同体系结构的推理模型。代码可在此HTTPS URL上找到。</li>
</ul>

<h3>Title: OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling</h3>
<ul>
<li><strong>Authors: </strong>Zengzhi Wang, Fan Zhou, Xuefeng Li, Pengfei Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20512">https://arxiv.org/abs/2506.20512</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20512">https://arxiv.org/pdf/2506.20512</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20512]] OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling(https://arxiv.org/abs/2506.20512)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, chain-of-thought</a></li>
<li><strong>Abstract: </strong>Different base language model families, such as Llama and Qwen, exhibit divergent behaviors during post-training with reinforcement learning (RL), especially on reasoning-intensive tasks. What makes a base language model suitable for reinforcement learning? Gaining deeper insight into this question is essential for developing RL-scalable foundation models of the next generation. In this work, we investigate how mid-training strategies shape RL dynamics, focusing on two representative model families: Qwen and Llama. Our study reveals that (1) high-quality mathematical corpora, such as MegaMath-Web-Pro, significantly improve both base model and RL performance, while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further adding QA-style data, particularly long chain-of-thought (CoT) reasoning examples, enhances RL outcomes, and instruction data further unlocks this effect; (3) while long-CoT improves reasoning depth, it can also induce verbosity of model responses and unstability of RL training, underscoring the importance of data formatting; (4) scaling mid-training consistently leads to stronger downstream RL performance. Building on these insights, we introduce a two-stage mid-training strategy, Stable-then-Decay, in which base models are first trained on 200B tokens with a constant learning rate, followed by 20B tokens across three CoT-focused branches with learning rate decay. This yields OctoThinker, a family of models demonstrating strong RL compatibility and closing the performance gap with more RL-friendly model families, i.e., Qwen. We hope our work will help shape pre-training strategies for foundation models in the RL era. To support further research, we release our open-source models along with a curated math reasoning-intensive corpus of over 70 billion tokens (i.e., MegaMath-Web-Pro-Max).</li>
<li><strong>摘要：</strong>不同的基本语言模型家族，例如骆驼和QWEN，在加强学习后培训期间表现出不同的行为（RL），尤其是在推理密集型任务上。是什么使基本语言模型适合加固学习？深入了解这个问题对于开发下一代的RL尺度基础模型至关重要。在这项工作中，我们研究了中期训练策略如何塑造RL动态，重点是两个代表性的模型家族：Qwen和Llama。我们的研究表明，（1）高质量的数学语料库，例如Megamath-Web-Pro，显着改善了基本模型和RL性能，而现有替代方案（例如Finemath-4plus）未能做到这一点； （2）进一步添加QA风格的数据，尤其是长期的经过思考链（COT）推理示例，增强了RL结果，并进一步解锁了此效果； （3）虽然长时间提高了推理的深度，但它也可以引起模型响应的冗长和RL训练的不稳定，从而强调了数据格式的重要性； （4）扩展中期训练会始终导致更强的下游RL性能。在这些见解的基础上，我们引入了一种两阶段的中期训练策略，即稳定，然后是稳定的，其中首先在200B代币上以恒定的学习率进行了基本模型，然后在三个具有学习率衰减的COT的分支上进行了20B令牌。这产生了Octothinker，这是一个模型家族，表现出强大的RL兼容性，并使用更友好的RL友好模型系列（即Qwen）缩小了性能差距。我们希望我们的工作将有助于在RL时代制定基础模型的训练前策略。为了支持进一步的研究，我们发布了我们的开源模型以及超过700亿代币（即Megamath-Web-Pro-Max）的精选数学推理密集型语料库。</li>
</ul>

<h3>Title: When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs</h3>
<ul>
<li><strong>Authors: </strong>Ammar Khairi, Daniel D'souza, Ye Shen, Julia Kreutzer, Sara Hooker</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20544">https://arxiv.org/abs/2506.20544</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20544">https://arxiv.org/pdf/2506.20544</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20544]] When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs(https://arxiv.org/abs/2506.20544)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>Recent advancements in large language models (LLMs) have shifted focus toward scaling inference-time compute, improving performance without retraining the model. A common approach is to sample multiple outputs in parallel, and select one of these as the final output. However, work to date has focused on English and a handful of domains such as math and code. In contrast, we are most interested in techniques that generalize across open-ended tasks, formally verifiable tasks, and across languages. In this work, we study how to robustly scale inference-time compute for open-ended generative tasks in a multilingual, multi-task setting. Our findings show that both sampling strategy based on temperature variation and selection strategy must be adapted to account for diverse domains and varied language settings. We evaluate existing selection methods, revealing that strategies effective in English often fail to generalize across languages. We propose novel sampling and selection strategies specifically adapted for multilingual and multi-task inference scenarios, and show they yield notable gains across languages and tasks. In particular, our combined sampling and selection methods lead to an average +6.8 jump in win-rates for our 8B models on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At larger scale, Command-A (111B model) equipped with our methods, shows +9.0 improvement in win-rates on the same benchmark with just five samples against single-sample decoding, a substantial increase at minimal cost. Our results underscore the need for language- and task-aware approaches to inference-time compute, aiming to democratize performance improvements in underrepresented languages.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）的最新进步已将重点转向扩展推理时间计算，在不重新培训模型的情况下提高了性能。一种常见的方法是并行采样多个输出，然后选择其中一种作为最终输出。但是，迄今为止的工作集中在英语和少数几个域，例如数学和代码。相比之下，我们最感兴趣的是将开放式任务，正式可验证的任务以及跨语言概括的技术感兴趣。在这项工作中，我们研究了如何在多语言多任务设置中进行开放式生成任务的推理时间计算。我们的发现表明，必须调整基于温度变化和选择策略的两个采样策略，以说明各种域和各种语言设置。我们评估了现有的选择方法，表明在英语中有效的策略通常无法跨语言概括。我们提出了专门针对多语言和多任务推理情景的新颖采样和选择策略，并表明它们在跨语言和任务之间取得了显着的收益。特别是，我们在M-Arenahard-v2.0提示的8B模型中，平均+6.8的取得+6.8跃升，这是针对Gemini等专有模型的平均速度。在更大范围内，配备了我们方法的Command-A（111b型号）在同一基准测试上显示了+9.0的胜利率，只有五个样本针对单样本解码，而以最小的成本增加了大幅提高。我们的结果强调了对推理时间计算的语言和任务感知方法的需求，旨在使代表性不足的语言的绩效改善民主化。</li>
</ul>

<h3>Title: Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm</h3>
<ul>
<li><strong>Authors: </strong>Baixiang Huang, Zhen Tan, Haoran Wang, Zijie Liu, Dawei Li, Ali Payani, Huan Liu, Tianlong Chen, Kai Shu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20606">https://arxiv.org/abs/2506.20606</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20606">https://arxiv.org/pdf/2506.20606</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20606]] Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm(https://arxiv.org/abs/2506.20606)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Agents based on Large Language Models (LLMs) have demonstrated strong capabilities across a wide range of tasks. However, deploying LLM-based agents in high-stakes domains comes with significant safety and ethical risks. Unethical behavior by these agents can directly result in serious real-world consequences, including physical harm and financial loss. To efficiently steer the ethical behavior of agents, we frame agent behavior steering as a model editing task, which we term Behavior Editing. Model editing is an emerging area of research that enables precise and efficient modifications to LLMs while preserving their overall capabilities. To systematically study and evaluate this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in psychological moral theories. This benchmark supports both the evaluation and editing of agent behaviors across a variety of scenarios, with each tier introducing more complex and ambiguous scenarios. We first demonstrate that Behavior Editing can dynamically steer agents toward the target behavior within specific scenarios. Moreover, Behavior Editing enables not only scenario-specific local adjustments but also more extensive shifts in an agent's global moral alignment. We demonstrate that Behavior Editing can be used to promote ethical and benevolent behavior or, conversely, to induce harmful or malicious behavior. Through comprehensive evaluations on agents based on frontier LLMs, BehaviorBench shows the effectiveness of Behavior Editing across different models and scenarios. Our findings offer key insights into a new paradigm for steering agent behavior, highlighting both the promise and perils of Behavior Editing.</li>
<li><strong>摘要：</strong>基于大语言模型（LLM）的代理商在各种任务中都表现出强大的功能。但是，在高风险领域中部署基于LLM的代理具有重大的安全性和道德风险。这些代理商的不道德行为可以直接导致严重的现实后果，包括身体伤害和财务损失。为了有效地指导代理的道德行为，我们将代理行为转向作为模型编辑任务，我们将其称为行为编辑。模型编辑是一个新兴领域的研究领域，可以在保留其整体功能的同时对LLM进行精确有效的修改。为了系统地研究和评估这种方法，我们介绍了行为积木，这是一种以心理道德理论为基础的多层基准。该基准测试支持各种场景中代理行为的评估和编辑，每个层都引入了更复杂和模棱两可的场景。我们首先证明行为编辑可以在特定情况下动态地引导目标行为。此外，行为编辑不仅可以使场景特定的本地调整，而且还可以使代理商的全球道德一致性更广泛地转变。我们证明，行为编辑可用于促进道德和仁慈的行为，或者相反，可以诱导有害或恶意行为。通过对基于Frontier LLM的代理的全面评估，行为基础显示了跨不同模型和场景的行为编辑的有效性。我们的发现为转向剂行为的新范式提供了关键的见解，强调了行为编辑的承诺和危险。</li>
</ul>

<h3>Title: DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation</h3>
<ul>
<li><strong>Authors: </strong>Shansan Gong, Ruixiang Zhang, Huangjie Zheng, Jiatao Gu, Navdeep Jaitly, Lingpeng Kong, Yizhe Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20639">https://arxiv.org/abs/2506.20639</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20639">https://arxiv.org/pdf/2506.20639</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20639]] DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation(https://arxiv.org/abs/2506.20639)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Diffusion large language models (dLLMs) are compelling alternatives to autoregressive (AR) models because their denoising models operate over the entire sequence. The global planning and iterative refinement features of dLLMs are particularly useful for code generation. However, current training and inference mechanisms for dLLMs in coding are still under-explored. To demystify the decoding behavior of dLLMs and unlock their potential for coding, we systematically investigate their denoising processes and reinforcement learning (RL) methods. We train a 7B dLLM, \textbf{DiffuCoder}, on 130B tokens of code. Using this model as a testbed, we analyze its decoding behavior, revealing how it differs from that of AR models: (1) dLLMs can decide how causal their generation should be without relying on semi-AR decoding, and (2) increasing the sampling temperature diversifies not only token choices but also their generation order. This diversity creates a rich search space for RL rollouts. For RL training, to reduce the variance of token log-likelihood estimates and maintain training efficiency, we propose \textbf{coupled-GRPO}, a novel sampling scheme that constructs complementary mask noise for completions used in training. In our experiments, coupled-GRPO significantly improves DiffuCoder's performance on code generation benchmarks (+4.4\% on EvalPlus) and reduces reliance on AR causal during decoding. Our work provides deeper insight into the machinery of dLLM generation and offers an effective, diffusion-native RL training framework. this https URL.</li>
<li><strong>摘要：</strong>扩散大语言模型（DLLM）是自回归（AR）模型的引人注目的替代方案，因为它们的降解模型在整个序列中运行。 DLLM的全球计划和迭代精炼功能对于代码生成特别有用。但是，当前的DLLM在编码中的培训和推理机制仍未探索。为了揭开DLLM的解码行为并解锁其编码潜力，我们系统地研究了它们的降解过程和加强学习（RL）方法。我们在130b代码上训练7b dllm，\ textbf {diffucoder}。我们将该模型作为测试台，分析其解码行为，揭示其与AR模型的不同之处：（1）DLLM可以在不依赖半AR解码的情况下决定其产生的因果关系，以及（2）增加采样温度的多样性不仅会使标记选择，而且还会产生代序。这种多样性为RL推出创造了丰富的搜索空间。对于RL培训，为了减少令牌样品样式估计的差异并保持训练效率，我们建议\ textbf {coupled-grpo}，这是一种新型的采样方案，该方案构建了用于训练中使用的互补掩模噪声。在我们的实验中，耦合GRPO显着提高了Diffucoder在代码生成基准（+4.4 \％\％）上的性能，并降低了解码过程中对AR因果关系的依赖。我们的工作为DLLM生成机械提供了更深入的了解，并提供了一个有效的扩散的RL训练框架。此HTTPS URL。</li>
</ul>

<h3>Title: Memento: Note-Taking for Your Future Self</h3>
<ul>
<li><strong>Authors: </strong>Chao Wan, Albert Gong, Mihir Mishra, Carl-Leander Henneking, Claas Beger, Kilian Q. Weinberger</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20642">https://arxiv.org/abs/2506.20642</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20642">https://arxiv.org/pdf/2506.20642</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20642]] Memento: Note-Taking for Your Future Self(https://arxiv.org/abs/2506.20642)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt, chain-of-thought, agent</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) excel at reasoning-only tasks, but struggle when reasoning must be tightly coupled with retrieval, as in multi-hop question answering. To overcome these limitations, we introduce a prompting strategy that first decomposes a complex question into smaller steps, then dynamically constructs a database of facts using LLMs, and finally pieces these facts together to solve the question. We show how this three-stage strategy, which we call Memento, can boost the performance of existing prompting strategies across diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the performance of chain-of-thought (CoT) when all information is provided in context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1 percentage points, demonstrating its utility in agentic settings.</li>
<li><strong>摘要：</strong>大型语言模型（LLMS）在仅推理任务方面表现出色，但是在推理必须与检索紧密相结合时挣扎，就像在多跳的问题回答中一样。为了克服这些局限性，我们引入了一种提示策略，该策略首先将复杂的问题分解为较小的步骤，然后使用LLMS动态构建事实数据库，最后将这些事实拼凑在一起以解决问题。我们展示了我们称为Memento的这种三阶段策略如何提高各种环境中现有的提示策略的性能。在9步Phantomwiki基准上，当在上下文中提供所有信息时，纪念品将经营链（COT）的性能加倍。在2个Wikimultihopqa的开放域版本上，带有Memento的Cot-rag在Vanilla Cot-rag上提高了20个以上的F1百分点，而多跳抹布基线IRCOT（IRCOT）上升了13个以上的F1百分点。在具有挑战性的Musique数据集上，Memento将反应提高了3个以上的F1百分点，这表明了其在代理环境中的效用。</li>
</ul>

<h3>Title: Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs</h3>
<ul>
<li><strong>Authors: </strong>Sonia K. Murthy, Rosie Zhao, Jennifer Hu, Sham Kakade, Markus Wulfmeier, Peng Qian, Tomer Ullman</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2506.20666">https://arxiv.org/abs/2506.20666</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2506.20666">https://arxiv.org/pdf/2506.20666</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2506.20666]] Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs(https://arxiv.org/abs/2506.20666)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm</a></li>
<li><strong>Abstract: </strong>Navigating everyday social situations often requires juggling conflicting goals, such as conveying a harsh truth, maintaining trust, all while still being mindful of another person's feelings. These value trade-offs are an integral part of human decision-making and language use, however, current tools for interpreting such dynamic and multi-faceted notions of values in LLMs are limited. In cognitive science, so-called "cognitive models" provide formal accounts of these trade-offs in humans, by modeling the weighting of a speaker's competing utility functions in choosing an action or utterance. In this work, we use a leading cognitive model of polite speech to interpret the extent to which LLMs represent human-like trade-offs. We apply this lens to systematically evaluate value trade-offs in two encompassing model settings: degrees of reasoning "effort" in frontier black-box models, and RL post-training dynamics of open-source models. Our results highlight patterns of higher informational utility than social utility in reasoning models, and in open-source models shown to be stronger in mathematical reasoning. Our findings from LLMs' training dynamics suggest large shifts in utility values early on in training with persistent effects of the choice of base model and pretraining data, compared to feedback dataset or alignment method. We show that our method is responsive to diverse aspects of the rapidly evolving LLM landscape, with insights for forming hypotheses about other high-level behaviors, shaping training regimes for reasoning models, and better controlling trade-offs between values during model training.</li>
<li><strong>摘要：</strong>经常导航日常社交状况通常需要挑战矛盾的目标，例如传达一个苛刻的真理，保持信任，同时仍然在想到他人的感受。这些价值权衡是人类决策和语言使用的不可或缺的一部分，但是，当前用于解释LLM中这种动态和多方面的价值观概念的工具有限。在认知科学中，所谓的“认知模型”通过建模说话者的竞争效用功能在选择动作或话语时对人类的这些权衡进行正式说明。在这项工作中，我们使用礼貌语音的领先认知模型来解释LLM代表类似人类的权衡的程度。我们将这些镜头应用于在两个包含模型设置中的价值权衡中的系统评估：在Frontier Black-Box模型中推理的“努力”程度，以及开源模型的RL后训练动力学。我们的结果强调了在推理模型中比社会效用更高的信息效用模式，在开源模型中，在数学推理中表现更强。与反馈数据集或对齐方式相比，LLMS训练动力学的发现表明，在训练中，在训练中，基本模型和预审计数据的持续效果的持续影响，效用的效果持续影响。我们表明，我们的方法对快速发展的LLM景观的各个方面有反应，并提供了有关形成有关其他高级行为的假设的见解，在模型培训过程中塑造了推理模型的培训方案，并更好地控制价值观之间的权衡。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
