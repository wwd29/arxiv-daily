<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-01-03</h1>
<h2>language model</h2>
<h3>Title: LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models. (arXiv:2401.00907v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00907">http://arxiv.org/abs/2401.00907</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00907]] LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models(http://arxiv.org/abs/2401.00907)</code></li>
<li>Summary: <p>Fine-tuning Large Language Models (LLMs) adapts a trained model to specific
downstream tasks, significantly improving task-specific performance. Supervised
Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce
desired answers. However, LLMs trained with SFT sometimes make simple mistakes
and result in hallucinations on reasoning tasks such as question-answering.
Without external feedback, it is difficult for SFT to learn a good mapping
between the question and the desired answer, especially with a small dataset.
This paper introduces an alternative to SFT called Natural Language Feedback
for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they
will receive from an annotator. We find that requiring such reflection can
significantly improve the accuracy in in-domain question-answering tasks,
providing a promising direction for the application of natural language
feedback in the realm of SFT LLMs. Additional ablation studies show that the
portion of human-annotated data in the annotated datasets affects the
fine-tuning performance.
</p></li>
</ul>

<h3>Title: LLaMA Beyond English: An Empirical Study on Language Capability Transfer. (arXiv:2401.01055v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01055">http://arxiv.org/abs/2401.01055</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01055]] LLaMA Beyond English: An Empirical Study on Language Capability Transfer(http://arxiv.org/abs/2401.01055)</code></li>
<li>Summary: <p>In recent times, substantial advancements have been witnessed in large
language models (LLMs), exemplified by ChatGPT, showcasing remarkable
proficiency across a range of complex tasks. However, many mainstream LLMs
(e.g. LLaMA) are pretrained on English-dominant corpus, which limits their
performance in other non-English languages. In this paper, we focus on how to
effectively transfer the capabilities of language generation and following
instructions to a non-English language. To answer this question, we conduct an
extensive empirical investigation based on LLaMA, accumulating over 1440 GPU
hours. We analyze the impact of key factors such as vocabulary extension,
further pretraining, and instruction tuning on transfer. To accurately assess
the model's level of knowledge, we employ four widely used standardized testing
benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a
comprehensive evaluation of the model's response quality is conducted,
considering aspects such as accuracy, fluency, informativeness, logical
coherence, and harmlessness, based on LLM-Eval, a benchmarks consisting
instruction tasks from 17 diverse categories. Our evaluation results
demonstrate that comparable performance to state-of-the-art transfer models can
be achieved with less than 1% of the pretraining data, both in terms of
knowledge alignment and response quality. Furthermore, the experimental
outcomes across the thirteen low-resource languages also exhibit similar
trends. We anticipate that the conclusions revealed by the experiments will aid
the community in developing non-English LLMs.
</p></li>
</ul>

<h3>Title: Discovering Significant Topics from Legal Decisions with Selective Inference. (arXiv:2401.01068v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01068">http://arxiv.org/abs/2401.01068</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01068]] Discovering Significant Topics from Legal Decisions with Selective Inference(http://arxiv.org/abs/2401.01068)</code></li>
<li>Summary: <p>We propose and evaluate an automated pipeline for discovering significant
topics from legal decision texts by passing features synthesized with topic
models through penalised regressions and post-selection significance tests. The
method identifies case topics significantly correlated with outcomes,
topic-word distributions which can be manually-interpreted to gain insights
about significant topics, and case-topic weights which can be used to identify
representative cases for each topic. We demonstrate the method on a new dataset
of domain name disputes and a canonical dataset of European Court of Human
Rights violation cases. Topic models based on latent semantic analysis as well
as language model embeddings are evaluated. We show that topics derived by the
pipeline are consistent with legal doctrines in both areas and can be useful in
other related legal analysis tasks.
</p></li>
</ul>

<h3>Title: Quokka: An Open-source Large Language Model ChatBot for Material Science. (arXiv:2401.01089v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01089">http://arxiv.org/abs/2401.01089</a></li>
<li>Code URL: <a href="https://github.com/xianjun-yang/quokka">https://github.com/xianjun-yang/quokka</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01089]] Quokka: An Open-source Large Language Model ChatBot for Material Science(http://arxiv.org/abs/2401.01089)</code></li>
<li>Summary: <p>This paper presents the development of a specialized chatbot for materials
science, leveraging the Llama-2 language model, and continuing pre-training on
the expansive research articles in the materials science domain from the S2ORC
dataset. The methodology involves an initial pretraining phase on over one
million domain-specific papers, followed by an instruction-tuning process to
refine the chatbot's capabilities. The chatbot is designed to assist
researchers, educators, and students by providing instant, context-aware
responses to queries in the field of materials science. We make the four
trained checkpoints (7B, 13B, with or without chat ability) freely available to
the research community at https://github.com/Xianjun-Yang/Quokka.
</p></li>
</ul>

<h3>Title: Uncertainty Resolution in Misinformation Detection. (arXiv:2401.01197v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01197">http://arxiv.org/abs/2401.01197</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01197]] Uncertainty Resolution in Misinformation Detection(http://arxiv.org/abs/2401.01197)</code></li>
<li>Summary: <p>Misinformation poses a variety of risks, such as undermining public trust and
distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been
shown effective in mitigating misinformation, particularly in handling
statements where enough context is provided. However, they struggle to assess
ambiguous or context-deficient statements accurately. This work introduces a
new method to resolve uncertainty in such statements. We propose a framework to
categorize missing information and publish category labels for the LIAR-New
dataset, which is adaptable to cross-domain content with missing information.
We then leverage this framework to generate effective user queries for missing
context. Compared to baselines, our method improves the rate at which generated
questions are answerable by the user by 38 percentage points and classification
performance by over 10 percentage points macro F1. Thus, this approach may
provide a valuable component for future misinformation mitigation pipelines.
</p></li>
</ul>

<h3>Title: Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01218">http://arxiv.org/abs/2401.01218</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01218]] Zero-Shot Position Debiasing for Large Language Models(http://arxiv.org/abs/2401.01218)</code></li>
<li>Summary: <p>Fine-tuning has been demonstrated to be an effective method to improve the
domain performance of large language models (LLMs). However, LLMs might fit the
dataset bias and shortcuts for prediction, leading to poor generation
performance. Experimental result shows that LLMs are prone to exhibit position
bias, i.e., leveraging information positioned at the beginning or end, or
specific positional cues within the input. Existing works on mitigating
position bias require external bias knowledge or annotated non-biased samples,
which is unpractical in reality. In this work, we propose a zero-shot position
debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages
unsupervised responses from pre-trained LLMs for debiasing, thus without any
external knowledge or datasets. To improve the quality of unsupervised
responses, we propose a master-slave alignment (MSA) module to prune these
responses. Experiments on eight datasets and five tasks show that ZOE
consistently outperforms existing methods in mitigating four types of position
biases. Besides, ZOE achieves this by sacrificing only a small performance on
biased samples, which is simple and effective.
</p></li>
</ul>

<h3>Title: Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01262">http://arxiv.org/abs/2401.01262</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01262]] Fairness Certification for Natural Language Processing and Large Language Models(http://arxiv.org/abs/2401.01262)</code></li>
<li>Summary: <p>Natural Language Processing (NLP) plays an important role in our daily lives,
particularly due to the enormous progress of Large Language Models (LLM).
However, NLP has many fairness-critical use cases, e.g., as an expert system in
recruitment or as an LLM-based tutor in education. Since NLP is based on human
language, potentially harmful biases can diffuse into NLP systems and produce
unfair results, discriminate against minorities or generate legal issues.
Hence, it is important to develop a fairness certification for NLP approaches.
We follow a qualitative research approach towards a fairness certification for
NLP. In particular, we have reviewed a large body of literature on algorithmic
fairness, and we have conducted semi-structured expert interviews with a wide
range of experts from that area. We have systematically devised six fairness
criteria for NLP, which can be further refined into 18 sub-categories. Our
criteria offer a foundation for operationalizing and testing processes to
certify fairness, both from the perspective of the auditor and the audited
organization.
</p></li>
</ul>

<h3>Title: A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01286">http://arxiv.org/abs/2401.01286</a></li>
<li>Code URL: <a href="https://github.com/zjunlp/easyedit">https://github.com/zjunlp/easyedit</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01286]] A Comprehensive Study of Knowledge Editing for Large Language Models(http://arxiv.org/abs/2401.01286)</code></li>
<li>Summary: <p>Large Language Models (LLMs) have shown extraordinary capabilities in
understanding and generating text that closely mirrors human communication.
However, a primary limitation lies in the significant computational demands
during training, arising from their extensive parameterization. This challenge
is further intensified by the dynamic nature of the world, necessitating
frequent updates to LLMs to correct outdated information or integrate new
knowledge, thereby ensuring their continued relevance. Note that many
applications demand continual model adjustments post-training to address
deficiencies or undesirable behaviors. There is an increasing interest in
efficient, lightweight methods for on-the-fly model modifications. To this end,
recent years have seen a burgeoning in the techniques of knowledge editing for
LLMs, which aim to efficiently modify LLMs' behaviors within specific domains
while preserving overall performance across various inputs. In this paper, we
first define the knowledge editing problem and then provide a comprehensive
review of cutting-edge approaches. Drawing inspiration from educational and
cognitive research theories, we propose a unified categorization criterion that
classifies knowledge editing methods into three groups: resorting to external
knowledge, merging knowledge into the model, and editing intrinsic knowledge.
Furthermore, we introduce a new benchmark, KnowEdit, for a comprehensive
empirical evaluation of representative knowledge editing approaches.
Additionally, we provide an in-depth analysis of knowledge location, which can
provide a deeper understanding of the knowledge structures inherent within
LLMs. Finally, we discuss several potential applications of knowledge editing,
outlining its broad and impactful implications.
</p></li>
</ul>

<h3>Title: Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. (arXiv:2401.01301v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01301">http://arxiv.org/abs/2401.01301</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01301]] Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models(http://arxiv.org/abs/2401.01301)</code></li>
<li>Summary: <p>Large language models (LLMs) have the potential to transform the practice of
law, but this potential is threatened by the presence of legal hallucinations
-- responses from these models that are not consistent with legal facts. We
investigate the extent of these hallucinations using an original suite of legal
queries, comparing LLMs' responses to structured legal metadata and examining
their consistency. Our work makes four key contributions: (1) We develop a
typology of legal hallucinations, providing a conceptual framework for future
research in this area. (2) We find that legal hallucinations are alarmingly
prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with
Llama 2, when these models are asked specific, verifiable questions about
random federal court cases. (3) We illustrate that LLMs often fail to correct a
user's incorrect legal assumptions in a contra-factual question setup. (4) We
provide evidence that LLMs cannot always predict, or do not always know, when
they are producing legal hallucinations. Taken together, these findings caution
against the rapid and unsupervised integration of popular LLMs into legal
tasks. Even experienced lawyers must remain wary of legal hallucinations, and
the risks are highest for those who stand to benefit from LLMs the most -- pro
se litigants or those without access to traditional legal resources.
</p></li>
</ul>

<h3>Title: Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01335">http://arxiv.org/abs/2401.01335</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01335]] Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models(http://arxiv.org/abs/2401.01335)</code></li>
<li>Summary: <p>Harnessing the power of human-annotated data through Supervised Fine-Tuning
(SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we
delve into the prospect of growing a strong LLM out of a weak one without the
need for acquiring additional human-annotated data. We propose a new
fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a
supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism,
where the LLM refines its capability by playing against instances of itself.
More specifically, the LLM generates its own training data from its previous
iterations, refining its policy by discerning these self-generated responses
from those obtained from human-annotated data. Our method progressively
elevates the LLM from a nascent model to a formidable one, unlocking the full
potential of human-annotated demonstration data for SFT. Theoretically, we
prove that the global optimum to the training objective function of our method
is achieved only when the LLM policy aligns with the target data distribution.
Empirically, we evaluate our method on several benchmark datasets including the
HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our
results show that SPIN can significantly improve the LLM's performance across a
variety of benchmarks and even outperform models trained through direct
preference optimization (DPO) supplemented with extra GPT-4 preference data.
This sheds light on the promise of self-play, enabling the achievement of
human-level performance in LLMs without the need for expert opponents.
</p></li>
</ul>

<h3>Title: DocLLM: A layout-aware generative language model for multimodal document understanding. (arXiv:2401.00908v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00908">http://arxiv.org/abs/2401.00908</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00908]] DocLLM: A layout-aware generative language model for multimodal document understanding(http://arxiv.org/abs/2401.00908)</code></li>
<li>Summary: <p>Enterprise documents such as forms, invoices, receipts, reports, contracts,
and other similar records, often carry rich semantics at the intersection of
textual and spatial modalities. The visual cues offered by their complex
layouts play a crucial role in comprehending these documents effectively. In
this paper, we present DocLLM, a lightweight extension to traditional large
language models (LLMs) for reasoning over visual documents, taking into account
both textual semantics and spatial layout. Our model differs from existing
multimodal LLMs by avoiding expensive image encoders and focuses exclusively on
bounding box information to incorporate the spatial layout structure.
Specifically, the cross-alignment between text and spatial modalities is
captured by decomposing the attention mechanism in classical transformers to a
set of disentangled matrices. Furthermore, we devise a pre-training objective
that learns to infill text segments. This approach allows us to address
irregular layouts and heterogeneous content frequently encountered in visual
documents. The pre-trained model is fine-tuned using a large-scale instruction
dataset, covering four core document intelligence tasks. We demonstrate that
our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks,
and generalizes well to 4 out of 5 previously unseen datasets.
</p></li>
</ul>

<h3>Title: Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01053">http://arxiv.org/abs/2401.01053</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01053]] Cheetah: Natural Language Generation for 517 African Languages(http://arxiv.org/abs/2401.01053)</code></li>
<li>Summary: <p>Low-resource African languages pose unique challenges for natural language
processing (NLP) tasks, including natural language generation (NLG). In this
paper, we develop Cheetah, a massively multilingual NLG language model for
African languages. Cheetah supports 517 African languages and language
varieties, allowing us to address the scarcity of NLG resources and provide a
solution to foster linguistic diversity. We demonstrate the effectiveness of
Cheetah through comprehensive evaluations across seven generation downstream
tasks. In five of the seven tasks, Cheetah significantly outperforms other
models, showcasing its remarkable performance for generating coherent and
contextually appropriate text in a wide range of African languages. We
additionally conduct a detailed human evaluation to delve deeper into the
linguistic capabilities of Cheetah. The introduction of Cheetah has
far-reaching benefits for linguistic diversity. By leveraging pretrained models
and adapting them to specific languages, our approach facilitates the
development of practical NLG applications for African communities. The findings
of this study contribute to advancing NLP research in low-resource settings,
enabling greater accessibility and inclusion for African languages in a rapidly
expanding digital landscape. We will publicly release our models for research.
</p></li>
</ul>

<h3>Title: DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever. (arXiv:2401.01076v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01076">http://arxiv.org/abs/2401.01076</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01076]] DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever(http://arxiv.org/abs/2401.01076)</code></li>
<li>Summary: <p>Recently, substantial advancements in pre-trained vision-language models have
greatly enhanced the capabilities of multi-modal dialog systems. These models
have demonstrated significant improvements by fine-tuning on downstream tasks.
However, the existing pre-trained models primarily focus on effectively
capturing the alignment between vision and language modalities, often ignoring
the intricate nature of dialog context. In this paper, we propose a
parameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog
retrieval. Specifically, our approach introduces a multi-modal context prompt
generator to learn context features which are subsequently distilled into
prompts within the pre-trained vision-language model CLIP. Besides, we
introduce domain prompt to mitigate the disc repancy from the downstream dialog
data. To facilitate various types of retrieval, we also design multiple experts
to learn mappings from CLIP outputs to multi-modal representation space, with
each expert being responsible to one specific retrieval type. Extensive
experiments show that DialCLIP achieves state-of-the-art performance on two
widely recognized benchmark datasets (i.e., PhotoChat and MMDialog) by tuning a
mere 0.04% of the total parameters. These results highlight the efficacy and
efficiency of our proposed approach, underscoring its potential to advance the
field of multi-modal dialog retrieval.
</p></li>
</ul>

<h3>Title: A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01313">http://arxiv.org/abs/2401.01313</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01313]] A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models(http://arxiv.org/abs/2401.01313)</code></li>
<li>Summary: <p>As Large Language Models (LLMs) continue to advance in their ability to write
human-like text, a key challenge remains around their tendency to hallucinate
generating content that appears factual but is ungrounded. This issue of
hallucination is arguably the biggest hindrance to safely deploying these
powerful LLMs into real-world production systems that impact people's lives.
The journey toward widespread adoption of LLMs in practical settings heavily
relies on addressing and mitigating hallucinations. Unlike traditional AI
systems focused on limited tasks, LLMs have been exposed to vast amounts of
online text data during training. While this allows them to display impressive
language fluency, it also means they are capable of extrapolating information
from the biases in training data, misinterpreting ambiguous prompts, or
modifying the information to align superficially with the input. This becomes
hugely alarming when we rely on language generation capabilities for sensitive
applications, such as summarizing medical records, financial analysis reports,
etc. This paper presents a comprehensive survey of over 32 techniques developed
to mitigate hallucination in LLMs. Notable among these are Retrieval Augmented
Generation (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),
CoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we
introduce a detailed taxonomy categorizing these methods based on various
parameters, such as dataset utilization, common tasks, feedback mechanisms, and
retriever types. This classification helps distinguish the diverse approaches
specifically designed to tackle hallucination issues in LLMs. Additionally, we
analyze the challenges and limitations inherent in these techniques, providing
a solid foundation for future research in addressing hallucinations and related
phenomena within the realm of LLMs.
</p></li>
</ul>

<h2>gpt</h2>
<h3>Title: Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01078">http://arxiv.org/abs/2401.01078</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01078]] Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation(http://arxiv.org/abs/2401.01078)</code></li>
<li>Summary: <p>Poetry generation has been a challenging task in the field of Natural
Language Processing, as it requires the model to understand the nuances of
language, sentiment, and style. In this paper, we propose using Large Language
Models to generate Vietnamese poems from natural language prompts, thereby
facilitating an intuitive process with enhanced content control. Our most
efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation
score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese
poetry. Furthermore, we also explore the idea of paraphrasing poems into normal
text prompts and yield a relatively high score of 0.718 in the "luc bat" genre.
This experiment presents the potential for cross-Language poem-to-poem
translation with translated poems as the inputs while concurrently maintaining
complete control over the generated content.
</p></li>
</ul>

<h2>llm</h2>
<h3>Title: LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01325">http://arxiv.org/abs/2401.01325</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01325]] LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning(http://arxiv.org/abs/2401.01325)</code></li>
<li>Summary: <p>This work elicits LLMs' inherent ability to handle long contexts without
fine-tuning. The limited length of the training sequence during training may
limit the application of Large Language Models (LLMs) on long input sequences
for inference. In this work, we argue that existing LLMs themselves have
inherent capabilities for handling long contexts. Based on this argument, we
suggest extending LLMs' context window by themselves to fully utilize the
inherent ability.We propose Self-Extend to stimulate LLMs' long context
handling potential. The basic idea is to construct bi-level attention
information: the group level and the neighbor level. The two levels are
computed by the original model's self-attention, which means the proposed does
not require any training. With only four lines of code modification, the
proposed method can effortlessly extend existing LLMs' context window without
any fine-tuning. We conduct comprehensive experiments and the results show that
the proposed method can effectively extend existing LLMs' context window's
length.
</p></li>
</ul>

<h2>long context</h2>
<h2>lora</h2>
<h3>Title: Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems. (arXiv:2401.01192v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01192">http://arxiv.org/abs/2401.01192</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01192]] Deep-ELA: Deep Exploratory Landscape Analysis with Self-Supervised Pretrained Transformers for Single- and Multi-Objective Continuous Optimization Problems(http://arxiv.org/abs/2401.01192)</code></li>
<li>Summary: <p>In many recent works, the potential of Exploratory Landscape Analysis (ELA)
features to numerically characterize, in particular, single-objective
continuous optimization problems has been demonstrated. These numerical
features provide the input for all kinds of machine learning tasks on
continuous optimization problems, ranging, i.a., from High-level Property
Prediction to Automated Algorithm Selection and Automated Algorithm
Configuration. Without ELA features, analyzing and understanding the
characteristics of single-objective continuous optimization problems would be
impossible.
</p>
<p>Yet, despite their undisputed usefulness, ELA features suffer from several
drawbacks. These include, in particular, (1.) a strong correlation between
multiple features, as well as (2.) its very limited applicability to
multi-objective continuous optimization problems. As a remedy, recent works
proposed deep learning-based approaches as alternatives to ELA. In these works,
e.g., point-cloud transformers were used to characterize an optimization
problem's fitness landscape. However, these approaches require a large amount
of labeled training data.
</p>
<p>Within this work, we propose a hybrid approach, Deep-ELA, which combines (the
benefits of) deep learning and ELA features. Specifically, we pre-trained four
transformers on millions of randomly generated optimization problems to learn
deep representations of the landscapes of continuous single- and
multi-objective optimization problems. Our proposed framework can either be
used out-of-the-box for analyzing single- and multi-objective continuous
optimization problems, or subsequently fine-tuned to various tasks focussing on
algorithm behavior and problem understanding.
</p></li>
</ul>

<h2>hallucination</h2>
<h2>prompt</h2>
<h2>code</h2>
<h3>Title: Tensor Networks for Explainable Machine Learning in Cybersecurity. (arXiv:2401.00867v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00867">http://arxiv.org/abs/2401.00867</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00867]] Tensor Networks for Explainable Machine Learning in Cybersecurity(http://arxiv.org/abs/2401.00867)</code></li>
<li>Summary: <p>In this paper we show how tensor networks help in developing explainability
of machine learning algorithms. Specifically, we develop an unsupervised
clustering algorithm based on Matrix Product States (MPS) and apply it in the
context of a real use-case of adversary-generated threat intelligence. Our
investigation proves that MPS rival traditional deep learning models such as
autoencoders and GANs in terms of performance, while providing much richer
model interpretability. Our approach naturally facilitates the extraction of
feature-wise probabilities, Von Neumann Entropy, and mutual information,
offering a compelling narrative for classification of anomalies and fostering
an unprecedented level of transparency and interpretability, something
fundamental to understand the rationale behind artificial intelligence
decisions.
</p></li>
</ul>

<h3>Title: Automating Leukemia Diagnosis with Autoencoders: A Comparative Study. (arXiv:2401.00883v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00883">http://arxiv.org/abs/2401.00883</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00883]] Automating Leukemia Diagnosis with Autoencoders: A Comparative Study(http://arxiv.org/abs/2401.00883)</code></li>
<li>Summary: <p>Leukemia is one of the most common and death-threatening types of cancer that
threaten human life. Medical data from some of the patient's critical
parameters contain valuable information hidden among these data. On this
subject, deep learning can be used to extract this information. In this paper,
AutoEncoders have been used to develop valuable features to help the precision
of leukemia diagnosis. It has been attempted to get the best activation
function and optimizer to use in AutoEncoder and designed the best architecture
for this neural network. The proposed architecture is compared with this area's
classical machine learning models. Our proposed method performs better than
other machine learning in precision and f1-score metrics by more than 11%.
</p></li>
</ul>

<h3>Title: Unifying Structured Data as Graph for Data-to-Text Pre-Training. (arXiv:2401.01183v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01183">http://arxiv.org/abs/2401.01183</a></li>
<li>Code URL: <a href="https://github.com/alibabaresearch/damo-convai">https://github.com/alibabaresearch/damo-convai</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01183]] Unifying Structured Data as Graph for Data-to-Text Pre-Training(http://arxiv.org/abs/2401.01183)</code></li>
<li>Summary: <p>Data-to-text (D2T) generation aims to transform structured data into natural
language text. Data-to-text pre-training has proved to be powerful in enhancing
D2T generation and yields impressive performances. However, previous
pre-training methods either oversimplified structured data into a sequence
without considering input structures or designed training objectives tailored
for a specific data structure (e.g., table or knowledge graph). In this paper,
we unify different types of structured data (i.e., table, key-value data,
knowledge graph) into the graph format and cast different data-to-text
generation tasks as graph-to-text generation. To effectively exploit the
structural information of the input graph, we propose a structure-enhanced
pre-training method for D2T generation by designing a structure-enhanced
Transformer. Concretely, we devise a position matrix for the Transformer,
encoding relative positional information of connected nodes in the input graph.
In addition, we propose a new attention matrix to incorporate graph structures
into the original Transformer by taking the available explicit connectivity
structure into account. Extensive experiments on six benchmark datasets show
the effectiveness of our model. Our source codes are available at
https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/unid2t.
</p></li>
</ul>

<h3>Title: Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning. (arXiv:2401.01242v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01242">http://arxiv.org/abs/2401.01242</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01242]] Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning(http://arxiv.org/abs/2401.01242)</code></li>
<li>Summary: <p>Broadband infrastructure owners do not always know how their customers are
connected in the local networks, which are structured as rooted trees. A recent
study is able to infer the topology of a local network using discrete time
series data from the leaves of the tree (customers). In this study we propose a
contrastive approach for learning a binary event encoder from continuous time
series data. As a preliminary result, we show that our approach has some
potential in learning a valuable encoder.
</p></li>
</ul>

<h3>Title: An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01326">http://arxiv.org/abs/2401.01326</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01326]] An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction(http://arxiv.org/abs/2401.01326)</code></li>
<li>Summary: <p>In this paper, we propose a novel method for joint entity and relation
extraction from unstructured text by framing it as a conditional sequence
generation problem. In contrast to conventional generative information
extraction models that are left-to-right token-level generators, our approach
is \textit{span-based}. It generates a linearized graph where nodes represent
text spans and edges represent relation triplets. Our method employs a
transformer encoder-decoder architecture with pointing mechanism on a dynamic
vocabulary of spans and relation types. Our model can capture the structural
characteristics and boundaries of entities and relations through span
representations while simultaneously grounding the generated output in the
original text thanks to the pointing mechanism. Evaluation on benchmark
datasets validates the effectiveness of our approach, demonstrating competitive
results. Code is available at https://github.com/urchade/ATG.
</p></li>
</ul>

<h3>Title: A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models. (arXiv:2401.00873v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00873">http://arxiv.org/abs/2401.00873</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00873]] A Bayesian Unification of Self-Supervised Clustering and Energy-Based Models(http://arxiv.org/abs/2401.00873)</code></li>
<li>Summary: <p>Self-supervised learning is a popular and powerful method for utilizing large
amounts of unlabeled data, for which a wide variety of training objectives have
been proposed in the literature. In this study, we perform a Bayesian analysis
of state-of-the-art self-supervised learning objectives, elucidating the
underlying probabilistic graphical models in each class and presenting a
standardized methodology for their derivation from first principles. The
analysis also indicates a natural means of integrating self-supervised learning
with likelihood-based generative models. We instantiate this concept within the
realm of cluster-based self-supervised learning and energy models, introducing
a novel lower bound which is proven to reliably penalize the most important
failure modes. Furthermore, this newly proposed lower bound enables the
training of a standard backbone architecture without the necessity for
asymmetric elements such as stop gradients, momentum encoders, or specialized
clustering layers - typically introduced to avoid learning trivial solutions.
Our theoretical findings are substantiated through experiments on synthetic and
real-world data, including SVHN, CIFAR10, and CIFAR100, thus showing that our
objective function allows to outperform existing self-supervised learning
strategies in terms of clustering, generation and out-of-distribution detection
performance by a wide margin. We also demonstrate that GEDI can be integrated
into a neural-symbolic framework to mitigate the reasoning shortcut problem and
to learn higher quality symbolic representations thanks to the enhanced
classification performance.
</p></li>
</ul>

<h3>Title: Aircraft Landing Time Prediction with Deep Learning on Trajectory Images. (arXiv:2401.01083v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01083">http://arxiv.org/abs/2401.01083</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01083]] Aircraft Landing Time Prediction with Deep Learning on Trajectory Images(http://arxiv.org/abs/2401.01083)</code></li>
<li>Summary: <p>Aircraft landing time (ALT) prediction is crucial for air traffic management,
especially for arrival aircraft sequencing on the runway. In this study, a
trajectory image-based deep learning method is proposed to predict ALTs for the
aircraft entering the research airspace that covers the Terminal Maneuvering
Area (TMA). Specifically, the trajectories of all airborne arrival aircraft
within the temporal capture window are used to generate an image with the
target aircraft trajectory labeled as red and all background aircraft
trajectory labeled as blue. The trajectory images contain various information,
including the aircraft position, speed, heading, relative distances, and
arrival traffic flows. It enables us to use state-of-the-art deep convolution
neural networks for ALT modeling. We also use real-time runway usage obtained
from the trajectory data and the external information such as aircraft types
and weather conditions as additional inputs. Moreover, a convolution neural
network (CNN) based module is designed for automatic holding-related
featurizing, which takes the trajectory images, the leading aircraft holding
status, and their time and speed gap at the research airspace boundary as its
inputs. Its output is further fed into the final end-to-end ALT prediction. The
proposed ALT prediction approach is applied to Singapore Changi Airport (ICAO
Code: WSSS) using one-month Automatic Dependent Surveillance-Broadcast (ADS-B)
data from November 1 to November 30, 2022. Experimental results show that by
integrating the holding featurization, we can reduce the mean absolute error
(MAE) from 82.23 seconds to 43.96 seconds, and achieve an average accuracy of
96.1\%, with 79.4\% of the predictions errors being less than 60 seconds.
</p></li>
</ul>

<h3>Title: Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning. (arXiv:2401.01232v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01232">http://arxiv.org/abs/2401.01232</a></li>
<li>Code URL: <a href="https://github.com/riemanngraph/motifrgc">https://github.com/riemanngraph/motifrgc</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01232]] Motif-aware Riemannian Graph Neural Network with Generative-Contrastive Learning(http://arxiv.org/abs/2401.01232)</code></li>
<li>Summary: <p>Graphs are typical non-Euclidean data of complex structures. In recent years,
Riemannian graph representation learning has emerged as an exciting alternative
to Euclidean ones. However, Riemannian methods are still in an early stage:
most of them present a single curvature (radius) regardless of structural
complexity, suffer from numerical instability due to the
exponential/logarithmic map, and lack the ability to capture motif regularity.
In light of the issues above, we propose the problem of \emph{Motif-aware
Riemannian Graph Representation Learning}, seeking a numerically stable encoder
to capture motif regularity in a diverse-curvature manifold without labels. To
this end, we present a novel Motif-aware Riemannian model with
Generative-Contrastive learning (MotifRGC), which conducts a minmax game in
Riemannian manifold in a self-supervised manner. First, we propose a new type
of Riemannian GCN (D-GCN), in which we construct a diverse-curvature manifold
by a product layer with the diversified factor, and replace the
exponential/logarithmic map by a stable kernel layer. Second, we introduce a
motif-aware Riemannian generative-contrastive learning to capture motif
regularity in the constructed manifold and learn motif-aware node
representation without external labels. Empirical results show the superiority
of MofitRGC.
</p></li>
</ul>

<h2>chat</h2>
<h2>retrieval augmented generation</h2>
<h2>retrieval-augmented generation</h2>
<h2>rag</h2>
<h3>Title: Balanced Graph Structure Information for Brain Disease Detection. (arXiv:2401.00876v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00876">http://arxiv.org/abs/2401.00876</a></li>
<li>Code URL: <a href="https://github.com/falihgoz/bargrain">https://github.com/falihgoz/bargrain</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00876]] Balanced Graph Structure Information for Brain Disease Detection(http://arxiv.org/abs/2401.00876)</code></li>
<li>Summary: <p>Analyzing connections between brain regions of interest (ROI) is vital to
detect neurological disorders such as autism or schizophrenia. Recent
advancements employ graph neural networks (GNNs) to utilize graph structures in
brains, improving detection performances. Current methods use correlation
measures between ROI's blood-oxygen-level-dependent (BOLD) signals to generate
the graph structure. Other methods use the training samples to learn the
optimal graph structure through end-to-end learning. However, implementing
those methods independently leads to some issues with noisy data for the
correlation graphs and overfitting problems for the optimal graph. In this
work, we proposed Bargrain (balanced graph structure for brains), which models
two graph structures: filtered correlation matrix and optimal sample graph
using graph convolution networks (GCNs). This approach aims to get advantages
from both graphs and address the limitations of only relying on a single type
of structure. Based on our extensive experiment, Bargrain outperforms
state-of-the-art methods in classification tasks on brain disease datasets, as
measured by average F1 scores.
</p></li>
</ul>

<h3>Title: Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment. (arXiv:2401.00996v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00996">http://arxiv.org/abs/2401.00996</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00996]] Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment(http://arxiv.org/abs/2401.00996)</code></li>
<li>Summary: <p>The size of deep learning models in artificial intelligence (AI) software is
increasing rapidly, hindering the large-scale deployment on resource-restricted
devices (e.g., smartphones). To mitigate this issue, AI software compression
plays a crucial role, which aims to compress model size while keeping high
performance. However, the intrinsic defects in a big model may be inherited by
the compressed one. Such defects may be easily leveraged by adversaries, since
a compressed model is usually deployed in a large number of devices without
adequate protection. In this article, we aim to address the safe model
compression problem from the perspective of safety-performance co-optimization.
Specifically, inspired by the test-driven development (TDD) paradigm in
software engineering, we propose a test-driven sparse training framework called
SafeCompress. By simulating the attack mechanism as safety testing,
SafeCompress can automatically compress a big model to a small one following
the dynamic sparse training paradigm. Then, considering two kinds of
representative and heterogeneous attack mechanisms, i.e., black-box membership
inference attack and white-box membership inference attack, we develop two
concrete instances called BMIA-SafeCompress and WMIA-SafeCompress. Further, we
implement another instance called MMIA-SafeCompress by extending SafeCompress
to defend against the occasion when adversaries conduct black-box and white-box
membership inference attacks simultaneously. We conduct extensive experiments
on five datasets for both computer vision and natural language processing
tasks. The results show the effectiveness and generalizability of our
framework. We also discuss how to adapt SafeCompress to other attacks besides
membership inference attack, demonstrating the flexibility of SafeCompress.
</p></li>
</ul>

<h3>Title: Do Concept Bottleneck Models Obey Locality?. (arXiv:2401.01259v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01259">http://arxiv.org/abs/2401.01259</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01259]] Do Concept Bottleneck Models Obey Locality?(http://arxiv.org/abs/2401.01259)</code></li>
<li>Summary: <p>Concept-based learning improves a deep learning model's interpretability by
explaining its predictions via human-understandable concepts. Deep learning
models trained under this paradigm heavily rely on the assumption that neural
networks can learn to predict the presence or absence of a given concept
independently of other concepts. Recent work, however, strongly suggests that
this assumption may fail to hold in Concept Bottleneck Models (CBMs), a
quintessential family of concept-based interpretable architectures. In this
paper, we investigate whether CBMs correctly capture the degree of conditional
independence across concepts when such concepts are localised both spatially,
by having their values entirely defined by a fixed subset of features, and
semantically, by having their values correlated with only a fixed subset of
predefined concepts. To understand locality, we analyse how changes to features
outside of a concept's spatial or semantic locality impact concept predictions.
Our results suggest that even in well-defined scenarios where the presence of a
concept is localised to a fixed feature subspace, or whose semantics are
correlated to a small subset of other concepts, CBMs fail to learn this
locality. These results cast doubt upon the quality of concept representations
learnt by CBMs and strongly suggest that concept-based explanations may be
fragile to changes outside their localities.
</p></li>
</ul>

<h3>Title: Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01283">http://arxiv.org/abs/2401.01283</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01283]] Quality and Quantity of Machine Translation References for Automated Metrics(http://arxiv.org/abs/2401.01283)</code></li>
<li>Summary: <p>Automatic machine translation metrics often use human translations to
determine the quality system translations. Common wisdom in the field dictates
that the human references should be of very high quality. However, there are no
cost-benefit analyses that could be used to guide practitioners who plan to
collect references for machine translation evaluation. We find that
higher-quality references lead to better metric correlations with humans at the
segment-level. Having up to 7 references per segment and taking their average
helps all metrics. Interestingly, the references from vendors of different
qualities can be mixed together and improve metric success. Higher quality
references, however, cost more to create and we frame this as an optimization
problem: given a specific budget, what references should be collected to
maximize metric success. These findings can be used by evaluators of shared
tasks when references need to be created under a certain budget.
</p></li>
</ul>

<h3>Title: Boosting Transformer's Robustness and Efficacy in PPG Signal Artifact Detection with Self-Supervised Learning. (arXiv:2401.01013v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01013">http://arxiv.org/abs/2401.01013</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01013]] Boosting Transformer's Robustness and Efficacy in PPG Signal Artifact Detection with Self-Supervised Learning(http://arxiv.org/abs/2401.01013)</code></li>
<li>Summary: <p>Recent research at CHU Sainte Justine's Pediatric Critical Care Unit (PICU)
has revealed that traditional machine learning methods, such as semi-supervised
label propagation and K-nearest neighbors, outperform Transformer-based models
in artifact detection from PPG signals, mainly when data is limited. This study
addresses the underutilization of abundant unlabeled data by employing
self-supervised learning (SSL) to extract latent features from these data,
followed by fine-tuning on labeled data. Our experiments demonstrate that SSL
significantly enhances the Transformer model's ability to learn
representations, improving its robustness in artifact classification tasks.
Among various SSL techniques, including masking, contrastive learning, and DINO
(self-distillation with no labels)-contrastive learning exhibited the most
stable and superior performance in small PPG datasets. Further, we delve into
optimizing contrastive loss functions, which are crucial for contrastive SSL.
Inspired by InfoNCE, we introduce a novel contrastive loss function that
facilitates smoother training and better convergence, thereby enhancing
performance in artifact classification. In summary, this study establishes the
efficacy of SSL in leveraging unlabeled data, particularly in enhancing the
capabilities of the Transformer model. This approach holds promise for broader
applications in PICU environments, where annotated data is often limited.
</p></li>
</ul>

<h3>Title: Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions. (arXiv:2401.01077v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01077">http://arxiv.org/abs/2401.01077</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01077]] Constrained Online Two-stage Stochastic Optimization: Algorithm with (and without) Predictions(http://arxiv.org/abs/2401.01077)</code></li>
<li>Summary: <p>We consider an online two-stage stochastic optimization with long-term
constraints over a finite horizon of $T$ periods. At each period, we take the
first-stage action, observe a model parameter realization and then take the
second-stage action from a feasible set that depends both on the first-stage
decision and the model parameter. We aim to minimize the cumulative objective
value while guaranteeing that the long-term average second-stage decision
belongs to a set. We develop online algorithms for the online two-stage problem
from adversarial learning algorithms. Also, the regret bound of our algorithm
can be reduced to the regret bound of embedded adversarial learning algorithms.
Based on this framework, we obtain new results under various settings. When the
model parameters are drawn from unknown non-stationary distributions and we are
given machine-learned predictions of the distributions, we develop a new
algorithm from our framework with a regret $O(W_T+\sqrt{T})$, where $W_T$
measures the total inaccuracy of the machine-learned predictions. We then
develop another algorithm that works when no machine-learned predictions are
given and show the performances.
</p></li>
</ul>

<h3>Title: Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer. (arXiv:2401.01165v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01165">http://arxiv.org/abs/2401.01165</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01165]] Reinforcement Learning for SAR View Angle Inversion with Differentiable SAR Renderer(http://arxiv.org/abs/2401.01165)</code></li>
<li>Summary: <p>The electromagnetic inverse problem has long been a research hotspot. This
study aims to reverse radar view angles in synthetic aperture radar (SAR)
images given a target model. Nonetheless, the scarcity of SAR data, combined
with the intricate background interference and imaging mechanisms, limit the
applications of existing learning-based approaches. To address these
challenges, we propose an interactive deep reinforcement learning (DRL)
framework, where an electromagnetic simulator named differentiable SAR render
(DSR) is embedded to facilitate the interaction between the agent and the
environment, simulating a human-like process of angle prediction. Specifically,
DSR generates SAR images at arbitrary view angles in real-time. And the
differences in sequential and semantic aspects between the view
angle-corresponding images are leveraged to construct the state space in DRL,
which effectively suppress the complex background interference, enhance the
sensitivity to temporal variations, and improve the capability to capture
fine-grained information. Additionally, in order to maintain the stability and
convergence of our method, a series of reward mechanisms, such as memory
difference, smoothing and boundary penalty, are utilized to form the final
reward function. Extensive experiments performed on both simulated and real
datasets demonstrate the effectiveness and robustness of our proposed method.
When utilized in the cross-domain area, the proposed method greatly mitigates
inconsistency between simulated and real domains, outperforming reference
methods significantly.
</p></li>
</ul>

<h3>Title: $f$-Divergence Based Classification: Beyond the Use of Cross-Entropy. (arXiv:2401.01268v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01268">http://arxiv.org/abs/2401.01268</a></li>
<li>Code URL: <a href="https://github.com/tonellolab/discriminative-classification-fdiv">https://github.com/tonellolab/discriminative-classification-fdiv</a></li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01268]] $f$-Divergence Based Classification: Beyond the Use of Cross-Entropy(http://arxiv.org/abs/2401.01268)</code></li>
<li>Summary: <p>In deep learning, classification tasks are formalized as optimization
problems solved via the minimization of the cross-entropy. However, recent
advancements in the design of objective functions allow the $f$-divergence
measure to generalize the formulation of the optimization problem for
classification. With this goal in mind, we adopt a Bayesian perspective and
formulate the classification task as a maximum a posteriori probability
problem. We propose a class of objective functions based on the variational
representation of the $f$-divergence, from which we extract a list of five
posterior probability estimators leveraging well-known $f$-divergences. In
addition, driven by the challenge of improving the state-of-the-art approach,
we propose a bottom-up method that leads us to the formulation of a new
objective function (and posterior probability estimator) corresponding to a
novel $f$-divergence referred to as shifted log (SL). First, we theoretically
prove the convergence property of the posterior probability estimators. Then,
we numerically test the set of proposed objective functions in three
application scenarios: toy examples, image data sets, and signal
detection/decoding problems. The analyzed tasks demonstrate the effectiveness
of the proposed estimators and that the SL divergence achieves the highest
classification accuracy in almost all the scenarios.
</p></li>
</ul>

<h3>Title: Learning-based agricultural management in partially observable environments subject to climate variability. (arXiv:2401.01273v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01273">http://arxiv.org/abs/2401.01273</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01273]] Learning-based agricultural management in partially observable environments subject to climate variability(http://arxiv.org/abs/2401.01273)</code></li>
<li>Summary: <p>Agricultural management, with a particular focus on fertilization strategies,
holds a central role in shaping crop yield, economic profitability, and
environmental sustainability. While conventional guidelines offer valuable
insights, their efficacy diminishes when confronted with extreme weather
conditions, such as heatwaves and droughts. In this study, we introduce an
innovative framework that integrates Deep Reinforcement Learning (DRL) with
Recurrent Neural Networks (RNNs). Leveraging the Gym-DSSAT simulator, we train
an intelligent agent to master optimal nitrogen fertilization management.
Through a series of simulation experiments conducted on corn crops in Iowa, we
compare Partially Observable Markov Decision Process (POMDP) models with Markov
Decision Process (MDP) models. Our research underscores the advantages of
utilizing sequential observations in developing more efficient nitrogen input
policies. Additionally, we explore the impact of climate variability,
particularly during extreme weather events, on agricultural outcomes and
management. Our findings demonstrate the adaptability of fertilization policies
to varying climate conditions. Notably, a fixed policy exhibits resilience in
the face of minor climate fluctuations, leading to commendable corn yields,
cost-effectiveness, and environmental conservation. However, our study
illuminates the need for agent retraining to acquire new optimal policies under
extreme weather events. This research charts a promising course toward
adaptable fertilization strategies that can seamlessly align with dynamic
climate scenarios, ultimately contributing to the optimization of crop
management practices.
</p></li>
</ul>

<h2>multi-run</h2>
<h2>chain-of-thought</h2>
<h2>tree-of-thought</h2>
<h2>agent</h2>
<h3>Title: Towards Bridging the Gap between High-Level Reasoning and Execution on Robots. (arXiv:2401.00880v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.00880">http://arxiv.org/abs/2401.00880</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.00880]] Towards Bridging the Gap between High-Level Reasoning and Execution on Robots(http://arxiv.org/abs/2401.00880)</code></li>
<li>Summary: <p>When reasoning about actions, e.g., by means of task planning or agent
programming with Golog, the robot's actions are typically modeled on an
abstract level, where complex actions such as picking up an object are treated
as atomic primitives with deterministic effects and preconditions that only
depend on the current state. However, when executing such an action on a robot
it can no longer be seen as a primitive. Instead, action execution is a complex
task involving multiple steps with additional temporal preconditions and timing
constraints. Furthermore, the action may be noisy, e.g., producing erroneous
sensing results and not always having the desired effects. While these aspects
are typically ignored in reasoning tasks, they need to be dealt with during
execution. In this thesis, we propose several approaches towards closing this
gap.
</p></li>
</ul>

<h3>Title: CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation. (arXiv:2401.01275v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2401.01275">http://arxiv.org/abs/2401.01275</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2401.01275]] CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation(http://arxiv.org/abs/2401.01275)</code></li>
<li>Summary: <p>Recently, the advent of large language models (LLMs) has revolutionized
generative agents. Among them, Role-Playing Conversational Agents (RPCAs)
attract considerable attention due to their ability to emotionally engage
users. However, the absence of a comprehensive benchmark impedes progress in
this field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark
for comprehensive RPCA assessment, complemented by a tailored high-quality
dataset. The dataset comprises 1,785 multi-turn role-playing dialogues,
encompassing 23,020 examples and featuring 77 characters derived from Chinese
novels and scripts. It was carefully constructed, beginning with initial
dialogue extraction via GPT-4, followed by rigorous human-led quality control,
and enhanced with in-depth character profiles sourced from Baidu Baike.
CharacterEval employs a multifaceted evaluation approach, encompassing thirteen
targeted metrics on four dimensions. Comprehensive experiments on CharacterEval
demonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in
Chinese role-playing conversation. Source code, data source and reward model
will be publicly accessible at https://github.com/morecry/CharacterEval.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
