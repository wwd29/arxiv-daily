<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2024-11-04</h1>
<h3>Title: A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges</h3>
<ul>
<li><strong>Authors: </strong>Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajun Wang, Pranav Rajpurkar, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00024">https://arxiv.org/abs/2411.00024</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00024">https://arxiv.org/pdf/2411.00024</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00024]] A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges(https://arxiv.org/abs/2411.00024)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination, prompt</a></li>
<li><strong>Abstract: </strong>The integration of Large Language Models (LLMs) into medical applications has sparked widespread interest across the healthcare industry, from drug discovery and development to clinical decision support, assisting telemedicine, medical devices, and healthcare insurance applications. This perspective paper aims to discuss the inner workings of building LLM-powered medical AI applications and introduces a comprehensive framework for their development. We review existing literature and outline the unique challenges of applying LLMs in specialized medical contexts. Additionally, we introduce a three-step framework to organize medical LLM research activities: 1) Modeling: breaking down complex medical workflows into manageable steps for developing medical-specific models; 2) Optimization: optimizing the model performance with crafted prompts and integrating external knowledge and tools, and 3) System engineering: decomposing complex tasks into subtasks and leveraging human expertise for building medical AI applications. Furthermore, we offer a detailed use case playbook that describes various LLM-powered medical AI applications, such as optimizing clinical trial design, enhancing clinical decision support, and advancing medical imaging analysis. Finally, we discuss various challenges and considerations for building medical AI applications with LLMs, such as handling hallucination issues, data ownership and compliance, privacy, intellectual property considerations, compute cost, sustainability issues, and responsible AI requirements.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 与医疗应用的集成引起了整个医疗行业的广泛关注，从药物发现和开发到临床决策支持、协助远程医疗、医疗设备和医疗保险应用。这篇观点论文旨在讨论构建 LLM 驱动的医疗 AI 应用程序的内部工作原理，并介绍其开发的全面框架。我们回顾了现有文献，并概述了在专门的医疗环境中应用 LLM 的独特挑战。此外，我们引入了一个三步框架来组织医学 LLM 研究活动：1) 建模：将复杂的医疗工作流程分解为可管理的步骤，以开发特定于医疗的模型；2) 优化：通过精心设计的提示优化模型性能并集成外部知识和工具，3) 系统工程：将复杂任务分解为子任务并利用人类专业知识来构建医疗 AI 应用程序。此外，我们还提供了详细的用例手册，描述了各种 LLM 驱动的医疗 AI 应用程序，例如优化临床试验设计、增强临床决策支持和推进医学成像分析。最后，我们讨论了使用 LLM 构建医疗 AI 应用程序的各种挑战和注意事项，例如处理幻觉问题、数据所有权和合规性、隐私、知识产权考虑、计算成本、可持续性问题以及负责任的 AI 要求。</li>
</ul>

<h3>Title: Personalization of Large Language Models: A Survey</h3>
<ul>
<li><strong>Authors: </strong>Zhehao Zhang, Ryan A. Rossi, Branislav Kveton, Yijia Shao, Diyi Yang, Hamed Zamani, Franck Dernoncourt, Joe Barrow, Tong Yu, Sungchul Kim, Ruiyi Zhang, Jiuxiang Gu, Tyler Derr, Hongjie Chen, Junda Wu, Xiang Chen, Zichao Wang, Subrata Mitra, Nedim Lipka, Nesreen Ahmed, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00027">https://arxiv.org/abs/2411.00027</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00027">https://arxiv.org/pdf/2411.00027</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00027]] Personalization of Large Language Models: A Survey(https://arxiv.org/abs/2411.00027)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Personalization of Large Language Models (LLMs) has recently become increasingly important with a wide range of applications. Despite the importance and recent progress, most existing works on personalized LLMs have focused either entirely on (a) personalized text generation or (b) leveraging LLMs for personalization-related downstream applications, such as recommendation systems. In this work, we bridge the gap between these two separate main directions for the first time by introducing a taxonomy for personalized LLM usage and summarizing the key differences and challenges. We provide a formalization of the foundations of personalized LLMs that consolidates and expands notions of personalization of LLMs, defining and discussing novel facets of personalization, usage, and desiderata of personalized LLMs. We then unify the literature across these diverse fields and usage scenarios by proposing systematic taxonomies for the granularity of personalization, personalization techniques, datasets, evaluation methods, and applications of personalized LLMs. Finally, we highlight challenges and important open problems that remain to be addressed. By unifying and surveying recent research using the proposed taxonomies, we aim to provide a clear guide to the existing literature and different facets of personalization in LLMs, empowering both researchers and practitioners.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 的个性化最近变得越来越重要，应用范围越来越广。尽管个性化 LLM 非常重要且最近取得了进展，但现有的大多数关于个性化 LLM 的研究要么完全集中在 (a) 个性化文本生成，要么完全集中在 (b) 利用 LLM 进行个性化相关的下游应用，例如推荐系统。在这项工作中，我们首次通过引入个性化 LLM 使用的分类法并总结主要差异和挑战，弥合了这两个独立主要方向之间的差距。我们对个性化 LLM 的基础进行了形式化，巩固和扩展了 LLM 个性化的概念，定义和讨论了个性化、使用和个性化 LLM 需求的新方面。然后，我们通过提出个性化粒度、个性化技术、数据集、评估方法和个性化 LLM 的应用的系统分类法，统一了这些不同领域和使用场景的文献。最后，我们强调了尚待解决的挑战和重要开放问题。通过使用所提出的分类法统一和调查最近的研究，我们旨在为现有文献和法学硕士 (LLM) 个性化的不同方面提供清晰的指南，为研究人员和从业人员提供帮助。</li>
</ul>

<h3>Title: Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN</h3>
<ul>
<li><strong>Authors: </strong>Zhilun Zhou, Jingyang Fan, Yu Liu, Fengli Xu, Depeng Jin, Yong Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG, cs.SI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00028">https://arxiv.org/abs/2411.00028</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00028">https://arxiv.org/pdf/2411.00028</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00028]] Synergizing LLM Agents and Knowledge Graph for Socioeconomic Prediction in LBSN(https://arxiv.org/abs/2411.00028)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>The fast development of location-based social networks (LBSNs) has led to significant changes in society, resulting in popular studies of using LBSN data for socioeconomic prediction, e.g., regional population and commercial activity estimation. Existing studies design various graphs to model heterogeneous LBSN data, and further apply graph representation learning methods for socioeconomic prediction. However, these approaches heavily rely on heuristic ideas and expertise to extract task-relevant knowledge from diverse data, which may not be optimal for specific tasks. Additionally, they tend to overlook the inherent relationships between different indicators, limiting the prediction accuracy. Motivated by the remarkable abilities of large language models (LLMs) in commonsense reasoning, embedding, and multi-agent collaboration, in this work, we synergize LLM agents and knowledge graph for socioeconomic prediction. We first construct a location-based knowledge graph (LBKG) to integrate multi-sourced LBSN data. Then we leverage the reasoning power of LLM agent to identify relevant meta-paths in the LBKG for each type of socioeconomic prediction task, and design a semantic-guided attention module for knowledge fusion with meta-paths. Moreover, we introduce a cross-task communication mechanism to further enhance performance by enabling knowledge sharing across tasks at both LLM agent and KG levels. On the one hand, the LLM agents for different tasks collaborate to generate more diverse and comprehensive meta-paths. On the other hand, the embeddings from different tasks are adaptively merged for better socioeconomic prediction. Experiments on two datasets demonstrate the effectiveness of the synergistic design between LLM and KG, providing insights for information sharing across socioeconomic prediction tasks.</li>
<li><strong>摘要：</strong>基于位置的社交网络 (LBSN) 的快速发展导致了社会的重大变化，由此产生了使用 LBSN 数据进行社会经济预测（例如区域人口和商业活动估计）的热门研究。现有研究设计了各种图来建模异构 LBSN 数据，并进一步将图表示学习方法应用于社会经济预测。然而，这些方法严重依赖启发式思想和专业知识从多样化数据中提取与任务相关的知识，这可能不是特定任务的最佳选择。此外，它们往往忽视不同指标之间的内在关系，从而限制了预测准确性。受大型语言模型 (LLM) 在常识推理、嵌入和多智能体协作方面的卓越能力的启发，在本文中，我们将 LLM 智能体和知识图谱结合起来进行社会经济预测。我们首先构建一个基于位置的知识图谱 (LBKG) 来整合多源 LBSN 数据。然后，我们利用 LLM 代理的推理能力来识别 LBKG 中与每种类型的社会经济预测任务相关的元路径，并设计一个语义引导的注意模块来与元路径进行知识融合。此外，我们引入了一种跨任务通信机制，通过在 LLM 代理和 KG 级别实现跨任务知识共享来进一步提高性能。一方面，不同任务的 LLM 代理协作以生成更多样化和全面的元路径。另一方面，来自不同任务的嵌入被自适应地合并以实现更好的社会经济预测。在两个数据集上的实验证明了 LLM 和 KG 之间协同设计的有效性，为跨社会经济预测任务的信息共享提供了见解。</li>
</ul>

<h3>Title: Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot</h3>
<ul>
<li><strong>Authors: </strong>Herman Lassche (1 and 2), Michiel Overeem (1), Ayushi Rastogi (2) ((1) AFAS Software, (2) University Groningen)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00034">https://arxiv.org/abs/2411.00034</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00034">https://arxiv.org/pdf/2411.00034</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00034]] Is Our Chatbot Telling Lies? Assessing Correctness of an LLM-based Dutch Support Chatbot(https://arxiv.org/abs/2411.00034)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, chat</a></li>
<li><strong>Abstract: </strong>Companies support their customers using live chats and chatbots to gain their loyalty. AFAS is a Dutch company aiming to leverage the opportunity large language models (LLMs) offer to answer customer queries with minimal to no input from its customer support team. Adding to its complexity, it is unclear what makes a response correct, and that too in Dutch. Further, with minimal data available for training, the challenge is to identify whether an answer generated by a large language model is correct and do it on the fly. This study is the first to define the correctness of a response based on how the support team at AFAS makes decisions. It leverages literature on natural language generation and automated answer grading systems to automate the decision-making of the customer support team. We investigated questions requiring a binary response (e.g., Would it be possible to adjust tax rates manually?) or instructions (e.g., How would I adjust tax rate manually?) to test how close our automated approach reaches support rating. Our approach can identify wrong messages in 55\% of the cases. This work shows the viability of automatically assessing when our chatbot tell lies.</li>
<li><strong>摘要：</strong>公司使用实时聊天和聊天机器人为客户提供支持，以赢得他们的忠诚度。AFAS 是一家荷兰公司，旨在利用大型语言模型 (LLM) 提供的机会，在客户支持团队几乎不输入任何输入的情况下回答客户查询。更复杂的是，不清楚什么使响应正确，而且在荷兰语中也是如此。此外，由于可用于训练的数据很少，挑战在于确定大型语言模型生成的答案是否正确，并即时执行。这项研究首次根据 AFAS 支持团队的决策方式来定义响应的正确性。它利用自然语言生成和自动答案评分系统的文献来自动化客户支持团队的决策。我们调查了需要二元响应的问题（例如，是否可以手动调整税率？）或说明（例如，我如何手动调整税率？）以测试我们的自动化方法与支持评级的接近程度。我们的方法可以在 55% 的情况下识别错误消息。这项工作表明，自动评估我们的聊天机器人何时撒谎是可行的。</li>
</ul>

<h3>Title: Topic-Conversation Relevance (TCR) Dataset and Benchmarks</h3>
<ul>
<li><strong>Authors: </strong>Yaran Fan, Jamie Pool, Senja Filipi, Ross Cutler</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00038">https://arxiv.org/abs/2411.00038</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00038">https://arxiv.org/pdf/2411.00038</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00038]] Topic-Conversation Relevance (TCR) Dataset and Benchmarks(https://arxiv.org/abs/2411.00038)</code><input type="text"></li>
<li><strong>Keywords: </strong>gpt</a></li>
<li><strong>Abstract: </strong>Workplace meetings are vital to organizational collaboration, yet a large percentage of meetings are rated as ineffective. To help improve meeting effectiveness by understanding if the conversation is on topic, we create a comprehensive Topic-Conversation Relevance (TCR) dataset that covers a variety of domains and meeting styles. The TCR dataset includes 1,500 unique meetings, 22 million words in transcripts, and over 15,000 meeting topics, sourced from both newly collected Speech Interruption Meeting (SIM) data and existing public datasets. Along with the text data, we also open source scripts to generate synthetic meetings or create augmented meetings from the TCR dataset to enhance data diversity. For each data source, benchmarks are created using GPT-4 to evaluate the model accuracy in understanding transcription-topic relevance.</li>
<li><strong>摘要：</strong>工作场所会议对于组织协作至关重要，但很大一部分会议被评为无效。为了通过了解对话是否围绕主题来帮助提高会议效率，我们创建了一个全面的主题对话相关性 (TCR) 数据集，该数据集涵盖了各种领域和会议风格。TCR 数据集包括 1,500 次独特的会议、2200 万字的记录和超过 15,000 个会议主题，这些主题来自新收集的语音中断会议 (SIM) 数据和现有的公共数据集。除了文本数据外，我们还开源脚本以生成合成会议或从 TCR 数据集创建增强会议以增强数据多样性。对于每个数据源，我们都使用 GPT-4 创建基准，以评估模型在理解转录主题相关性方面的准确性。</li>
</ul>

<h3>Title: Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Yulong Wang, Chang Zuo, Yin Xuan, Hong Li, Ni Wei</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00039">https://arxiv.org/abs/2411.00039</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00039">https://arxiv.org/pdf/2411.00039</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00039]] Linear Chain Transformation: Expanding Optimization Dynamics for Fine-Tuning Large Language Models(https://arxiv.org/abs/2411.00039)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Fine-tuning large language models (LLMs) has become essential for adapting pretrained models to specific downstream tasks. In this paper, we propose Linear Chain Transformation (LinChain), a novel approach that introduces a sequence of linear transformations during fine-tuning to enrich optimization dynamics. By incorporating multiple linear transformations into the parameter update process, LinChain expands the effective rank of updates and enhances the model's ability to learn complex task-specific representations. We demonstrate that this method significantly improves the performance of LLM fine-tuning over state-of-the-art methods by providing more flexible optimization paths during training, while maintaining the inference efficiency of the resulting model. Our experiments on various benchmark tasks show that LinChain leads to better generalization, fewer learnable parameters, and improved task adaptation, making it a compelling strategy for LLM fine-tuning.</li>
<li><strong>摘要：</strong>对大型语言模型 (LLM) 进行微调已成为将预训练模型适应特定下游任务的关键。在本文中，我们提出了线性链变换 (LinChain)，这是一种在微调过程中引入一系列线性变换以丰富优化动态的新方法。通过将多个线性变换纳入参数更新过程，LinChain 扩展了更新的有效秩并增强了模型学习复杂任务特定表示的能力。我们证明，通过在训练期间提供更灵活的优化路径，该方法显著提高了 LLM 微调相对于最先进方法的性能，同时保持了结果模型的推理效率。我们在各种基准任务上进行的实验表明，LinChain 可以实现更好的泛化、更少的可学习参数和更好的任务适应性，使其成为 LLM 微调的有力策略。</li>
</ul>

<h3>Title: NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Parvez Zamil, Gollam Rabby, Md. Sadekur Rahman, Sören Auer</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DL, cs.IR</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00041">https://arxiv.org/abs/2411.00041</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00041">https://arxiv.org/pdf/2411.00041</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00041]] NeuroSym-BioCAT: Leveraging Neuro-Symbolic Methods for Biomedical Scholarly Document Categorization and Question Answering(https://arxiv.org/abs/2411.00041)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>The growing volume of biomedical scholarly document abstracts presents an increasing challenge in efficiently retrieving accurate and relevant information. To address this, we introduce a novel approach that integrates an optimized topic modelling framework, OVB-LDA, with the BI-POP CMA-ES optimization technique for enhanced scholarly document abstract categorization. Complementing this, we employ the distilled MiniLM model, fine-tuned on domain-specific data, for high-precision answer extraction. Our approach is evaluated across three configurations: scholarly document abstract retrieval, gold-standard scholarly documents abstract, and gold-standard snippets, consistently outperforming established methods such as RYGH and bio-answer finder. Notably, we demonstrate that extracting answers from scholarly documents abstracts alone can yield high accuracy, underscoring the sufficiency of abstracts for many biomedical queries. Despite its compact size, MiniLM exhibits competitive performance, challenging the prevailing notion that only large, resource-intensive models can handle such complex tasks. Our results, validated across various question types and evaluation batches, highlight the robustness and adaptability of our method in real-world biomedical applications. While our approach shows promise, we identify challenges in handling complex list-type questions and inconsistencies in evaluation metrics. Future work will focus on refining the topic model with more extensive domain-specific datasets, further optimizing MiniLM and utilizing large language models (LLM) to improve both precision and efficiency in biomedical question answering.</li>
<li><strong>摘要：</strong>生物医学学术文献摘要的数量不断增长，对有效检索准确和相关信息提出了越来越大的挑战。为了解决这个问题，我们引入了一种新方法，将优化的主题建模框架 OVB-LDA 与 BI-POP CMA-ES 优化技术相结合，以增强学术文献摘要分类。除此之外，我们还采用了经过精炼的 MiniLM 模型，该模型针对特定领域的数据进行了微调，以实现高精度答案提取。我们的方法在三种配置中进行评估：学术文献摘要检索、黄金标准学术文献摘要和黄金标准片段，其表现始终优于 RYGH 和生物答案查找器等成熟方法。值得注意的是，我们证明仅从学术文献摘要中提取答案就可以获得高精度，这强调了摘要对于许多生物医学查询的充分性。尽管 MiniLM 体积小巧，但它表现出了极具竞争力的性能，挑战了只有大型、资源密集型模型才能处理如此复杂任务的普遍观念。我们的结果已在各种问题类型和评估批次中得到验证，凸显了我们的方法在现实世界生物医学应用中的稳健性和适应性。虽然我们的方法很有前景，但我们发现在处理复杂的列表类型问题和评估指标不一致方面存在挑战。未来的工作将侧重于使用更广泛的领域特定数据集来完善主题模型，进一步优化 MiniLM 并利用大型语言模型 (LLM) 来提高生物医学问答的准确性和效率。</li>
</ul>

<h3>Title: Problem Categorization Can Help Large Language Models Solve Math Problems</h3>
<ul>
<li><strong>Authors: </strong>Amogh Akella</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00042">https://arxiv.org/abs/2411.00042</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00042">https://arxiv.org/pdf/2411.00042</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00042]] Problem Categorization Can Help Large Language Models Solve Math Problems(https://arxiv.org/abs/2411.00042)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination</a></li>
<li><strong>Abstract: </strong>In this paper, we explore how to optimize the usage of Large-Language Models to quickly and accurately solve mathematical problems. In particular, we show the effectiveness of using the classification of problems into different categories to facilitate problem-solving. Additionally, we optimize the classification of problems into categories by creating an accurate dataset. We believe that our technique for problem-solving works by helping mitigate hallucination in LLMs which is key to unlocking their ability to solve math problems.</li>
<li><strong>摘要：</strong>在本文中，我们探讨了如何优化大型语言模型的使用，以快速准确地解决数学问题。特别是，我们展示了将问题分类为不同类别以促进解决问题的有效性。此外，我们通过创建准确的数据集来优化问题分类。我们相信，我们的解决问题技术有助于减轻 LLM 的幻觉，这是释放他们解决数学问题能力的关键。</li>
</ul>

<h3>Title: MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset</h3>
<ul>
<li><strong>Authors: </strong>B. D. Lam, S. Ma, I. Kovalenko, P. Wang, O. Jafari, A. Li, S. Horng</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00044">https://arxiv.org/abs/2411.00044</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00044">https://arxiv.org/pdf/2411.00044</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00044]] MIMIC-IV-Ext-PE: Using a large language model to predict pulmonary embolism phenotype in the MIMIC-IV dataset(https://arxiv.org/abs/2411.00044)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Pulmonary embolism (PE) is a leading cause of preventable in-hospital mortality. Advances in diagnosis, risk stratification, and prevention can improve outcomes. There are few large publicly available datasets that contain PE labels for research. Using the MIMIC-IV database, we extracted all available radiology reports of computed tomography pulmonary angiography (CTPA) scans and two physicians manually labeled the results as PE positive (acute PE) or PE negative. We then applied a previously finetuned Bio_ClinicalBERT transformer language model, VTE-BERT, to extract labels automatically. We verified VTE-BERT's reliability by measuring its performance against manual adjudication. We also compared the performance of VTE-BERT to diagnosis codes. We found that VTE-BERT has a sensitivity of 92.4% and positive predictive value (PPV) of 87.8% on all 19,942 patients with CTPA radiology reports from the emergency room and/or hospital admission. In contrast, diagnosis codes have a sensitivity of 95.4% and PPV of 83.8% on the subset of 11,990 hospitalized patients with discharge diagnosis codes. We successfully add nearly 20,000 labels to CTPAs in a publicly available dataset and demonstrate the external validity of a semi-supervised language model in accelerating hematologic research.</li>
<li><strong>摘要：</strong>肺栓塞 (PE) 是可预防的院内死亡的主要原因。诊断、风险分层和预防方面的进步可以改善结果。包含 PE 标签以供研究的大型公开数据集很少。使用 MIMIC-IV 数据库，我们提取了所有可用的计算机断层肺血管造影 (CTPA) 扫描放射学报告，并由两名医生手动将结果标记为 PE 阳性（急性 PE）或 PE 阴性。然后，我们应用之前微调的 Bio_ClinicalBERT 转换器语言模型 VTE-BERT 来自动提取标签。我们通过测量 VTE-BERT 与人工裁决的性能来验证其可靠性。我们还将 VTE-BERT 的性能与诊断代码进行了比较。我们发现，对于所有 19,942 名来自急诊室和/或医院入院且具有 CTPA 放射学报告的患者，VTE-BERT 的灵敏度为 92.4%，阳性预测值 (PPV) 为 87.8%。相比之下，在 11,990 名具有出院诊断代码的住院患者子集上，诊断代码的敏感性为 95.4%，PPV 为 83.8%。我们成功地在公开可用的数据集中为 CTPA 添加了近 20,000 个标签，并证明了半监督语言模型在加速血液学研究方面的外部有效性。</li>
</ul>

<h3>Title: A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Elena Kardanova, Alina Ivanova, Ksenia Tarasova, Taras Pashchenko, Aleksei Tikhoniuk, Elen Yusupova, Anatoly Kasprzhak, Yaroslav Kuzminov, Ekaterina Kruchinskaia, Irina Brun (National Research University Higher School of Economics, Moscow, Russia)</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00045">https://arxiv.org/abs/2411.00045</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00045">https://arxiv.org/pdf/2411.00045</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00045]] A Novel Psychometrics-Based Approach to Developing Professional Competency Benchmark for Large Language Models(https://arxiv.org/abs/2411.00045)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm</a></li>
<li><strong>Abstract: </strong>The era of large language models (LLM) raises questions not only about how to train models, but also about how to evaluate them. Despite numerous existing benchmarks, insufficient attention is often given to creating assessments that test LLMs in a valid and reliable manner. To address this challenge, we accommodate the Evidence-centered design (ECD) methodology and propose a comprehensive approach to benchmark development based on rigorous psychometric principles. In this paper, we have made the first attempt to illustrate this approach by creating a new benchmark in the field of pedagogy and education, highlighting the limitations of existing benchmark development approach and taking into account the development of LLMs. We conclude that a new approach to benchmarking is required to match the growing complexity of AI applications in the educational context. We construct a novel benchmark guided by the Bloom's taxonomy and rigorously designed by a consortium of education experts trained in test development. Thus the current benchmark provides an academically robust and practical assessment tool tailored for LLMs, rather than human participants. Tested empirically on the GPT model in the Russian language, it evaluates model performance across varied task complexities, revealing critical gaps in current LLM capabilities. Our results indicate that while generative AI tools hold significant promise for education - potentially supporting tasks such as personalized tutoring, real-time feedback, and multilingual learning - their reliability as autonomous teachers' assistants right now remain rather limited, particularly in tasks requiring deeper cognitive engagement.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 时代不仅提出了如何训练模型的问题，还提出了如何评估模型的问题。尽管现有的基准众多，但人们往往没有足够重视创建以有效和可靠的方式测试 LLM 的评估。为了应对这一挑战，我们采用了以证据为中心的设计 (ECD) 方法，并提出了一种基于严格心理测量原则的全面基准开发方法。在本文中，我们首次尝试通过在教学法和教育领域创建一个新的基准来说明这种方法，强调现有基准开发方法的局限性并考虑到 LLM 的发展。我们得出结论，需要一种新的基准方法来匹配教育环境中日益复杂的人工智能应用。我们构建了一个由布鲁姆分类法指导的新基准，并由一组受过测试开发培训的教育专家严格设计。因此，当前的基准为 LLM 而非人类参与者提供了一种学术上稳健且实用的评估工具。它在俄语的 GPT 模型上进行了实证测试，评估了模型在不同任务复杂度下的表现，揭示了当前 LLM 能力的重大差距。我们的结果表明，虽然生成式 AI 工具对教育有着重大的前景——可能支持个性化辅导、实时反馈和多语言学习等任务——但它们作为自主教师助手的可靠性目前仍然相当有限，特别是在需要更深入的认知参与的任务中。</li>
</ul>

<h3>Title: CurateGPT: A flexible language-model assisted biocuration tool</h3>
<ul>
<li><strong>Authors: </strong>Harry Caufield, Carlo Kroll, Shawn T O'Neil, Justin T Reese, Marcin P Joachimiak, Harshad Hegde, Nomi L Harris, Madan Krishnamurthy, James A McLaughlin, Damian Smedley, Melissa A Haendel, Peter N Robinson, Christopher J Mungall</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB, q-bio.QM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00046">https://arxiv.org/abs/2411.00046</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00046">https://arxiv.org/pdf/2411.00046</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00046]] CurateGPT: A flexible language-model assisted biocuration tool(https://arxiv.org/abs/2411.00046)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, agent</a></li>
<li><strong>Abstract: </strong>Effective data-driven biomedical discovery requires data curation: a time-consuming process of finding, organizing, distilling, integrating, interpreting, annotating, and validating diverse information into a structured form suitable for databases and knowledge bases. Accurate and efficient curation of these digital assets is critical to ensuring that they are FAIR, trustworthy, and sustainable. Unfortunately, expert curators face significant time and resource constraints. The rapid pace of new information being published daily is exceeding their capacity for curation. Generative AI, exemplified by instruction-tuned large language models (LLMs), has opened up new possibilities for assisting human-driven curation. The design philosophy of agents combines the emerging abilities of generative AI with more precise methods. A curator's tasks can be aided by agents for performing reasoning, searching ontologies, and integrating knowledge across external sources, all efforts otherwise requiring extensive manual effort. Our LLM-driven annotation tool, CurateGPT, melds the power of generative AI together with trusted knowledge bases and literature sources. CurateGPT streamlines the curation process, enhancing collaboration and efficiency in common workflows. Compared to direct interaction with an LLM, CurateGPT's agents enable access to information beyond that in the LLM's training data and they provide direct links to the data supporting each claim. This helps curators, researchers, and engineers scale up curation efforts to keep pace with the ever-increasing volume of scientific data.</li>
<li><strong>摘要：</strong>有效的数据驱动的生物医学发现需要数据管理：这是一个耗时的过程，需要查找、组织、提炼、集成、解释、注释和验证各种信息，使其成为适合数据库和知识库的结构化形式。准确高效地管理这些数字资产对于确保其公平、可信和可持续至关重要。不幸的是，专家管理者面临着巨大的时间和资源限制。每天发布的新信息速度之快超出了他们的管理能力。以指令调整的大型语言模型 (LLM) 为代表的生成式人工智能为协助人类驱动的管理开辟了新的可能性。代理的设计理念将生成式人工智能的新兴能力与更精确的方法相结合。代理可以帮助管理者执行推理、搜索本体和跨外部来源集成知识的任务，否则所有这些工作都需要大量的手动工作。我们的 LLM 驱动的注释工具 CurateGPT 将生成式人工智能的强大功能与可信的知识库和文献来源融合在一起。 CurateGPT 简化了策展流程，增强了常见工作流程中的协作和效率。与直接与 LLM 交互相比，CurateGPT 的代理可以访问 LLM 训练数据以外的信息，并提供支持每项主张的数据的直接链接。这有助于策展人、研究人员和工程师扩大策展工作，以跟上不断增长的科学数据量。</li>
</ul>

<h3>Title: ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate</h3>
<ul>
<li><strong>Authors: </strong>Andrew Estornell, Jean-Francois Ton, Yuanshun Yao, Yang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00053">https://arxiv.org/abs/2411.00053</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00053">https://arxiv.org/pdf/2411.00053</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00053]] ACC-Debate: An Actor-Critic Approach to Multi-Agent Debate(https://arxiv.org/abs/2411.00053)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models, frequently referred to as multi-agent debate (MAD). While debate shows promise as a means of improving model efficacy, most works in this area treat debate as an emergent behavior, rather than a learned behavior. In doing so, current debate frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Debate, an Actor-Critic based learning framework to produce a two-agent team specialized in debate. We demonstrate that ACC-Debate outperforms SotA debate techniques on a wide array of benchmarks.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 已显示出作为各种语言任务通用工具的卓越能力。最近的研究表明，此类模型的有效性可以通过多个模型之间的迭代对话来提高，这通常称为多智能体辩论 (MAD)。虽然辩论有望成为提高模型有效性的一种手段，但该领域的大多数研究都将辩论视为一种突发行为，而不是一种学习行为。为此，当前的辩论框架依赖于协作行为，以便将其充分训练成现成的模型。为了解决这一限制，我们提出了 ACC-Debate，这是一个基于 Actor-Critic 的学习框架，用于组建一个专门从事辩论的双智能体团队。我们证明 ACC-Debate 在各种基准测试中都优于 SotA 辩论技术。</li>
</ul>

<h3>Title: Generating Diverse Negations from Affirmative Sentences</h3>
<ul>
<li><strong>Authors: </strong>Darian Rodriguez Vasquez, Afroditi Papadaki</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00056">https://arxiv.org/abs/2411.00056</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00056">https://arxiv.org/pdf/2411.00056</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00056]] Generating Diverse Negations from Affirmative Sentences(https://arxiv.org/abs/2411.00056)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>Despite the impressive performance of large language models across various tasks, they often struggle with reasoning under negated statements. Negations are important in real-world applications as they encode negative polarity in verb phrases, clauses, or other expressions. Nevertheless, they are underrepresented in current benchmarks, which mainly include basic negation forms and overlook more complex ones, resulting in insufficient data for training a language model. In this work, we propose NegVerse, a method that tackles the lack of negation datasets by producing a diverse range of negation types from affirmative sentences, including verbal, non-verbal, and affixal forms commonly found in English text. We provide new rules for masking parts of sentences where negations are most likely to occur, based on syntactic structure and use a frozen baseline LLM and prompt tuning to generate negated sentences. We also propose a filtering mechanism to identify negation cues and remove degenerate examples, producing a diverse range of meaningful perturbations. Our results show that NegVerse outperforms existing methods and generates negations with higher lexical similarity to the original sentences, better syntactic preservation and negation diversity. The code is available in this https URL</li>
<li><strong>摘要：</strong>尽管大型语言模型在各种任务中的表现令人印象深刻，但它们在否定语句下的推理方面往往存在困难。否定在实际应用中非常重要，因为它们在动词短语、从句或其他表达中编码了否定极性。然而，它们在当前的基准测试中代表性不足，这些基准测试主要包括基本否定形式而忽略了更复杂的否定形式，导致训练语言模型的数据不足。在这项工作中，我们提出了 NegVerse，这种方法通过从肯定句中生成各种否定类型来解决否定数据集的缺乏问题，包括英语文本中常见的动词、非动词和词缀形式。我们根据句法结构提供了新的规则来屏蔽最有可能出现否定的句子部分，并使用冻结的基线 LLM 和快速调整来生成否定句。我们还提出了一种过滤机制来识别否定线索并删除退化示例，从而产生各种有意义的扰动。我们的结果表明，NegVerse 的表现优于现有方法，并且生成的否定与原始句子的词汇相似度更高、句法保存性更好、否定多样性更强。代码可在此 https URL 中找到</li>
</ul>

<h3>Title: Evolving Alignment via Asymmetric Self-Play</h3>
<ul>
<li><strong>Authors: </strong>Ziyu Ye, Rishabh Agarwal, Tianqi Liu, Rishabh Joshi, Sarmishta Velury, Quoc V. Le, Qijun Tan, Yuan Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, physics.data-an, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00062">https://arxiv.org/abs/2411.00062</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00062">https://arxiv.org/pdf/2411.00062</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00062]] Evolving Alignment via Asymmetric Self-Play(https://arxiv.org/abs/2411.00062)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>Current RLHF frameworks for aligning large language models (LLMs) typically assume a fixed prompt distribution, which is sub-optimal and limits the scalability of alignment and generalizability of models. To address this, we introduce a general open-ended RLHF framework that casts alignment as an asymmetric game between two players: (i) a creator that generates increasingly informative prompt distributions using the reward model, and (ii) a solver that learns to produce more preferred responses on prompts produced by the creator. This framework of Evolving Alignment via Asymmetric Self-Play (eva), results in a simple and efficient approach that can utilize any existing RLHF algorithm for scalable alignment. eva outperforms state-of-the-art methods on widely-used benchmarks, without the need of any additional human crafted prompts. Specifically, eva improves the win rate of Gemma-2-9B-it on Arena-Hard from 51.6% to 60.1% with DPO, from 55.7% to 58.9% with SPPO, from 52.3% to 60.7% with SimPO, and from 54.8% to 60.3% with ORPO, surpassing its 27B version and matching claude-3-opus. This improvement is persistent even when new human crafted prompts are introduced. Finally, we show eva is effective and robust under various ablation settings.</li>
<li><strong>摘要：</strong>目前用于对齐大型语言模型 (LLM) 的 RLHF 框架通常假设固定的提示分布，这不是最优的，并且限制了对齐的可扩展性和模型的通用性。为了解决这个问题，我们引入了一个通用的开放式 RLHF 框架，将对齐视为两个玩家之间的不对称游戏：(i) 使用奖励模型生成越来越有用的提示分布的创建者，以及 (ii) 学习对创建者生成的提示产生更受欢迎的响应的求解器。通过非对称自我博弈 (eva) 实现对齐的这种框架产生了一种简单而有效的方法，可以利用任何现有的 RLHF 算法进行可扩展的对齐。eva 在广泛使用的基准上的表现优于最先进的方法，而无需任何额外的人工制作提示。具体来说，eva 将 Gemma-2-9B-it 在 Arena-Hard 上的胜率从 51.6% 提高到 60.1%（使用 DPO），从 55.7% 提高到 58.9%（使用 SPPO），从 52.3% 提高到 60.7%（使用 SimPO），从 54.8% 提高到 60.3%（使用 ORPO），超越了 27B 版本并与 claude-3-opus 相匹配。即使引入新的人工制作的提示，这种改进仍然持续存在。最后，我们展示了 eva 在各种消融设置下都是有效且稳健的。</li>
</ul>

<h3>Title: Interpretable Language Modeling via Induction-head Ngram Models</h3>
<ul>
<li><strong>Authors: </strong>Eunji Kim, Sriya Mantena, Weiwei Yang, Chandan Singh, Sungroh Yoon, Jianfeng Gao</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00066">https://arxiv.org/abs/2411.00066</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00066">https://arxiv.org/pdf/2411.00066</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00066]] Interpretable Language Modeling via Induction-head Ngram Models(https://arxiv.org/abs/2411.00066)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Recent large language models (LLMs) have excelled across a wide range of tasks, but their use in high-stakes and compute-limited settings has intensified the demand for interpretability and efficiency. We address this need by proposing Induction-head ngram models (Induction-Gram), a method that builds an efficient, interpretable LM by bolstering modern ngram models with a hand-engineered "induction head". This induction head uses a custom neural similarity metric to efficiently search the model's input context for potential next-word completions. This process enables Induction-Gram to provide ngram-level grounding for each generated token. Moreover, experiments show that this simple method significantly improves next-word prediction over baseline interpretable models (up to 26%p) and can be used to speed up LLM inference for large models through speculative decoding. We further study Induction-Gram in a natural-language neuroscience setting, where the goal is to predict the next fMRI response in a sequence. It again provides a significant improvement over interpretable models (20% relative increase in the correlation of predicted fMRI responses), potentially enabling deeper scientific investigation of language selectivity in the brain. The code is available at this https URL.</li>
<li><strong>摘要：</strong>最近的大型语言模型 (LLM) 在各种任务中都表现出色，但它们在高风险和计算受限环境中的使用加剧了对可解释性和效率的需求。我们通过提出归纳头 ngram 模型 (Induction-Gram) 来满足这一需求，这种方法通过用手工设计的“归纳头”支持现代 ngram 模型来构建高效、可解释的 LM。此归纳头使用自定义神经相似性度量来有效地搜索模型的输入上下文以查找潜在的下一个单词补全。此过程使 Induction-Gram 能够为每个生成的标记提供 ngram 级基础。此外，实验表明，这种简单的方法与基线可解释模型相比显著提高了下一个单词预测（高达 26%p），并且可用于通过推测解码来加速大型模型的 LLM 推理。我们在自然语言神经科学环境中进一步研究了 Induction-Gram，其目标是预测序列中的下一个 fMRI 反应。它再次提供了比可解释模型显著的改进（预测 fMRI 反应的相关性相对提高了 20%），有可能使对大脑语言选择性的科学研究更加深入。代码可在此 https URL 上找到。</li>
</ul>

<h3>Title: RSL-SQL: Robust Schema Linking in Text-to-SQL Generation</h3>
<ul>
<li><strong>Authors: </strong>Zhenbiao Cao, Yuanlei Zheng, Zhihao Fan, Xiaojin Zhang, Wei Chen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00073">https://arxiv.org/abs/2411.00073</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00073">https://arxiv.org/pdf/2411.00073</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00073]] RSL-SQL: Robust Schema Linking in Text-to-SQL Generation(https://arxiv.org/abs/2411.00073)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt</a></li>
<li><strong>Abstract: </strong>Text-to-SQL generation aims to translate natural language questions into SQL statements. In large language models (LLMs) based Text-to-SQL, schema linking is a widely adopted strategy to streamline the input for LLMs by selecting only relevant schema elements, therefore reducing noise and computational overhead. However, schema linking faces risks that requires caution, including the potential omission of necessary elements and disruption of database structural integrity. To address these challenges, we propose a novel framework called RSL-SQL that combines bidirectional schema linking, contextual information augmentation, binary selection strategy, and multi-turn self-correction. Our approach improves the recall of schema linking through forward and backward pruning and hedges the risk by voting between full schema and contextual information augmented simplified schema. Experiments on the BIRD and Spider benchmarks demonstrate that our approach achieves state-of-the-art execution accuracy among open-source solutions, with 67.2% on BIRD and 87.9% on Spider using GPT-4o. Furthermore, our approach outperforms a series of GPT-4 based Text-to-SQL systems when adopting DeepSeek (much cheaper) with same intact prompts. Extensive analysis and ablation studies confirm the effectiveness of each component in our framework. The codes are available at this https URL.</li>
<li><strong>摘要：</strong>文本到 SQL 生成旨在将自然语言问题转换为 SQL 语句。在基于大型语言模型 (LLM) 的文本到 SQL 中，模式链接是一种广泛采用的策略，通过仅选择相关的模式元素来简化 LLM 的输入，从而减少噪音和计算开销。然而，模式链接面临着需要谨慎的风险，包括可能遗漏必要元素和破坏数据库结构完整性。为了应对这些挑战，我们提出了一个名为 RSL-SQL 的新框架，它结合了双向模式链接、上下文信息增强、二元选择策略和多轮自校正。我们的方法通过前向和后向修剪提高了模式链接的召回率，并通过在完整模式和上下文信息增强的简化模式之间投票来规避风险。在 BIRD 和 Spider 基准上的实验表明，我们的方法在开源解决方案中实现了最先进的执行准确率，使用 GPT-4o 在 BIRD 上为 67.2%，在 Spider 上为 87.9%。此外，在采用 DeepSeek（便宜得多）且具有相同完整提示时，我们的方法优于一系列基于 GPT-4 的文本到 SQL 系统。广泛的分析和消融研究证实了我们框架中每个组件的有效性。代码可在此 https URL 上找到。</li>
</ul>

<h3>Title: JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking</h3>
<ul>
<li><strong>Authors: </strong>Tong Niu, Shafiq Joty, Ye Liu, Caiming Xiong, Yingbo Zhou, Semih Yavuz</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00142">https://arxiv.org/abs/2411.00142</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00142">https://arxiv.org/pdf/2411.00142</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00142]] JudgeRank: Leveraging Large Language Models for Reasoning-Intensive Reranking(https://arxiv.org/abs/2411.00142)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, retrieval-augmented generation, agent</a></li>
<li><strong>Abstract: </strong>Accurate document retrieval is crucial for the success of retrieval-augmented generation (RAG) applications, including open-domain question answering and code completion. While large language models (LLMs) have been employed as dense encoders or listwise rerankers in RAG systems, they often struggle with reasoning-intensive tasks because they lack nuanced analysis when judging document relevance. To address this limitation, we introduce JudgeRank, a novel agentic reranker that emulates human cognitive processes when assessing document relevance. Our approach consists of three key steps: (1) query analysis to identify the core problem, (2) document analysis to extract a query-aware summary, and (3) relevance judgment to provide a concise assessment of document relevance. We evaluate JudgeRank on the reasoning-intensive BRIGHT benchmark, demonstrating substantial performance improvements over first-stage retrieval methods and outperforming other popular reranking approaches. In addition, JudgeRank performs on par with fine-tuned state-of-the-art rerankers on the popular BEIR benchmark, validating its zero-shot generalization capability. Through comprehensive ablation studies, we demonstrate that JudgeRank's performance generalizes well across LLMs of various sizes while ensembling them yields even more accurate reranking than individual models.</li>
<li><strong>摘要：</strong>准确的文档检索对于检索增强生成 (RAG) 应用程序（包括开放域问答和代码补全）的成功至关重要。虽然大型语言模型 (LLM) 已被用作 RAG 系统中的密集编码器或列表重排器，但它们在执行推理密集型任务时往往举步维艰，因为它们在判断文档相关性时缺乏细致的分析。为了解决这一限制，我们引入了 JudgeRank，这是一种新型的代理重排器，可在评估文档相关性时模拟人类的认知过程。我们的方法包括三个关键步骤：(1) 查询分析以确定核心问题，(2) 文档分析以提取查询感知摘要，以及 (3) 相关性判断以提供对文档相关性的简明评估。我们在推理密集型 BRIGHT 基准上评估 JudgeRank，结果显示与第一阶段检索方法相比，其性能有显著提升，并且优于其他流行的重排方法。此外，JudgeRank 在流行的 BEIR 基准上的表现与经过微调的最先进的重新排序器相当，证明了其零样本泛化能力。通过全面的消融研究，我们证明了 JudgeRank 的性能在各种规模的 LLM 中都能很好地推广，而将它们组合在一起可以产生比单个模型更准确的重新排序。</li>
</ul>

<h3>Title: Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking</h3>
<ul>
<li><strong>Authors: </strong>Christopher Richardson, Roshan Sharma, Neeraj Gaur, Parisa Haghani, Anirudh Sundar, Bhuvana Ramabhadran</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00150">https://arxiv.org/abs/2411.00150</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00150">https://arxiv.org/pdf/2411.00150</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00150]] Schema Augmentation for Zero-Shot Domain Adaptation in Dialogue State Tracking(https://arxiv.org/abs/2411.00150)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, prompt</a></li>
<li><strong>Abstract: </strong>Zero-shot domain adaptation for dialogue state tracking (DST) remains a challenging problem in task-oriented dialogue (TOD) systems, where models must generalize to target domains unseen at training time. Current large language model approaches for zero-shot domain adaptation rely on prompting to introduce knowledge pertaining to the target domains. However, their efficacy strongly depends on prompt engineering, as well as the zero-shot ability of the underlying language model. In this work, we devise a novel data augmentation approach, Schema Augmentation, that improves the zero-shot domain adaptation of language models through fine-tuning. Schema Augmentation is a simple but effective technique that enhances generalization by introducing variations of slot names within the schema provided in the prompt. Experiments on MultiWOZ and SpokenWOZ showed that the proposed approach resulted in a substantial improvement over the baseline, in some experiments achieving over a twofold accuracy gain over unseen domains while maintaining equal or superior performance over all domains.</li>
<li><strong>摘要：</strong>对话状态跟踪 (DST) 的零样本域自适应仍然是面向任务的对话 (TOD) 系统中的一项挑战性问题，其中模型必须推广到训练时未见过的目标域。当前用于零样本域自适应的大型语言模型方法依赖于提示来引入与目标域相关的知识。然而，它们的有效性在很大程度上取决于提示工程，以及底层语言模型的零样本能力。在这项工作中，我们设计了一种新颖的数据增强方法，即模式增强，它通过微调来改善语言模型的零样本域自适应。模式增强是一种简单但有效的技术，它通过在提示中提供的模式中引入槽名的变体来增强泛化。在 MultiWOZ 和 SpokenWOZ 上的实验表明，所提出的方法比基线有了显着的改进，在一些实验中，在未见过的域上实现了两倍以上的准确率提升，同时在所有域上保持相同或更优异的性能。</li>
</ul>

<h3>Title: Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Haritz Puerto, Martin Gubri, Sangdoo Yun, Seong Joon Oh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00154">https://arxiv.org/abs/2411.00154</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00154">https://arxiv.org/pdf/2411.00154</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00154]] Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models(https://arxiv.org/abs/2411.00154)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Membership inference attacks (MIA) attempt to verify the membership of a given data sample in the training set for a model. MIA has become relevant in recent years, following the rapid development of large language models (LLM). Many are concerned about the usage of copyrighted materials for training them and call for methods for detecting such usage. However, recent research has largely concluded that current MIA methods do not work on LLMs. Even when they seem to work, it is usually because of the ill-designed experimental setup where other shortcut features enable "cheating." In this work, we argue that MIA still works on LLMs, but only when multiple documents are presented for testing. We construct new benchmarks that measure the MIA performances at a continuous scale of data samples, from sentences (n-grams) to a collection of documents (multiple chunks of tokens). To validate the efficacy of current MIA approaches at greater scales, we adapt a recent work on Dataset Inference (DI) for the task of binary membership detection that aggregates paragraph-level MIA features to enable MIA at document and collection of documents level. This baseline achieves the first successful MIA on pre-trained and fine-tuned LLMs.</li>
<li><strong>摘要：</strong>成员推理攻击 (MIA) 试图验证给定数据样本在模型训练集中的成员身份。近年来，随着大型语言模型 (LLM) 的快速发展，MIA 变得越来越重要。许多人担心使用受版权保护的材料进行训练，并呼吁制定检测此类使用的方法。然而，最近的研究在很大程度上得出结论，当前的 MIA 方法不适用于 LLM。即使它们似乎有效，通常也是因为实验设置设计不当，其他快捷功能可以实现“作弊”。在这项工作中，我们认为 MIA 仍然适用于 LLM，但只有在提供多个文档进行测试时才有效。我们构建了新的基准，以衡量 MIA 在连续数据样本规模上的表现，从句子（n-gram）到文档集合（多个标记块）。为了验证当前 MIA 方法在更大规模上的有效性，我们调整了最近关于数据集推理 (DI) 的工作，用于二元成员检测任务，该工作聚合了段落级 MIA 特征，以在文档和文档集合级别启用 MIA。该基线在预训练和微调的 LLM 上实现了首次成功的 MIA。</li>
</ul>

<h3>Title: Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning</h3>
<ul>
<li><strong>Authors: </strong>John Wu, David Wu, Jimeng Sun</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00173">https://arxiv.org/abs/2411.00173</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00173">https://arxiv.org/pdf/2411.00173</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00173]] Beyond Label Attention: Transparency in Language Models for Automated Medical Coding via Dictionary Learning(https://arxiv.org/abs/2411.00173)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Medical coding, the translation of unstructured clinical text into standardized medical codes, is a crucial but time-consuming healthcare practice. Though large language models (LLM) could automate the coding process and improve the efficiency of such tasks, interpretability remains paramount for maintaining patient trust. Current efforts in interpretability of medical coding applications rely heavily on label attention mechanisms, which often leads to the highlighting of extraneous tokens irrelevant to the ICD code. To facilitate accurate interpretability in medical language models, this paper leverages dictionary learning that can efficiently extract sparsely activated representations from dense language model embeddings in superposition. Compared with common label attention mechanisms, our model goes beyond token-level representations by building an interpretable dictionary which enhances the mechanistic-based explanations for each ICD code prediction, even when the highlighted tokens are medically irrelevant. We show that dictionary features can steer model behavior, elucidate the hidden meanings of upwards of 90% of medically irrelevant tokens, and are human interpretable.</li>
<li><strong>摘要：</strong>医学编码是将非结构化的临床文本翻译成标准化的医学代码，是一种至关重要但耗时的医疗保健实践。尽管大型语言模型 (LLM) 可以自动化编码过程并提高此类任务的效率，但可解释性对于维护患者信任仍然至关重要。当前医学编码应用程序可解释性方面的努力在很大程度上依赖于标签注意机制，这通常会导致突出显示与 ICD 代码无关的无关标记。为了促进医学语言模型的准确可解释性，本文利用词典学习，可以有效地从叠加的密集语言模型嵌入中提取稀疏激活的表示。与常见的标签注意机制相比，我们的模型通过构建可解释的词典超越了标记级表示，该词典增强了每个 ICD 代码预测的基于机制的解释，即使突出显示的标记与医学无关。我们表明，词典特征可以引导模型行为，阐明 90% 以上与医学无关的标记的隐藏含义，并且可以被人类解释。</li>
</ul>

<h3>Title: RESTOR: Knowledge Recovery through Machine Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Keivan Rezaei, Khyathi Chandu, Soheil Feizi, Yejin Choi, Faeze Brahman, Abhilasha Ravichander</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00204">https://arxiv.org/abs/2411.00204</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00204">https://arxiv.org/pdf/2411.00204</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00204]] RESTOR: Knowledge Recovery through Machine Unlearning(https://arxiv.org/abs/2411.00204)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Large language models trained on web-scale corpora can memorize undesirable datapoints such as incorrect facts, copyrighted content or sensitive data. Recently, many machine unlearning methods have been proposed that aim to 'erase' these datapoints from trained models -- that is, revert model behavior to be similar to a model that had never been trained on these datapoints. However, evaluating the success of unlearning algorithms remains challenging. In this work, we propose the RESTOR framework for machine unlearning based on the following dimensions: (1) a task setting that focuses on real-world factual knowledge, (2) a variety of corruption scenarios that emulate different kinds of datapoints that might need to be unlearned, and (3) evaluation metrics that emphasize not just forgetting undesirable knowledge, but also recovering the model's original state before encountering these datapoints, or restorative unlearning. RESTOR helps uncover several novel insights about popular unlearning algorithms, and the mechanisms through which they operate -- for instance, identifying that some algorithms merely emphasize forgetting the knowledge to be unlearned, and that localizing unlearning targets can enhance unlearning performance. Code/data is available at this http URL.</li>
<li><strong>摘要：</strong>在网络规模语料库上训练的大型语言模型可能会记住不良数据点，例如不正确的事实、受版权保护的内容或敏感数据。最近，提出了许多机器反学习方法，旨在从训练过的模型中“抹去”这些数据点，也就是说，将模型行为恢复为与从未在这些数据点上训练过的模型相似。然而，评估反学习算法的成功仍然具有挑战性。在这项工作中，我们根据以下维度提出了机器反学习的 RESTOR 框架：(1) 专注于现实世界事实知识的任务设置，(2) 模拟可能需要反学习的不同类型数据点的各种损坏场景，以及 (3) 评估指标不仅强调忘记不良知识，还强调在遇到这些数据点之前恢复模型的原始状态，或恢复性反学习。 RESTOR 有助于揭示关于流行的反学习算法及其运作机制的一些新见解 - 例如，确定一些算法仅仅强调忘记要反学习的知识，而定位反学习目标可以提高反学习性能。代码/数据可在此 http URL 上找到。</li>
</ul>

<h3>Title: A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making</h3>
<ul>
<li><strong>Authors: </strong>Yubin Kim, Chanwoo Park, Hyewon Jeong, Cristina Grau-Vilchez, Yik Siu Chan, Xuhai Xu, Daniel McDuff, Hyeonhoon Lee, Marzyeh Ghassemi, Cynthia Breazeal, Hae Won Park</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00248">https://arxiv.org/abs/2411.00248</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00248">https://arxiv.org/pdf/2411.00248</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00248]] A Demonstration of Adaptive Collaboration of Large Language Models for Medical Decision-Making(https://arxiv.org/abs/2411.00248)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Medical Decision-Making (MDM) is a multi-faceted process that requires clinicians to assess complex multi-modal patient data patient, often collaboratively. Large Language Models (LLMs) promise to streamline this process by synthesizing vast medical knowledge and multi-modal health data. However, single-agent are often ill-suited for nuanced medical contexts requiring adaptable, collaborative problem-solving. Our MDAgents addresses this need by dynamically assigning collaboration structures to LLMs based on task complexity, mimicking real-world clinical collaboration and decision-making. This framework improves diagnostic accuracy and supports adaptive responses in complex, real-world medical scenarios, making it a valuable tool for clinicians in various healthcare settings, and at the same time, being more efficient in terms of computing cost than static multi-agent decision making methods.</li>
<li><strong>摘要：</strong>医疗决策 (MDM) 是一个多方面的过程，需要临床医生评估复杂的多模式患者数据，通常是协作式的。大型语言模型 (LLM) 有望通过综合大量医学知识和多模式健康数据来简化这一过程。然而，单智能体通常不适合需要适应性强、协作解决问题的细致入微的医疗环境。我们的 MDAgents 通过根据任务复杂性动态地为 LLM 分配协作结构来满足这一需求，模拟现实世界的临床协作和决策。该框架提高了诊断准确性，并支持复杂的现实世界医疗场景中的自适应响应，使其成为各种医疗环境中临床医生的宝贵工具，同时在计算成本方面比静态多智能体决策方法更高效。</li>
</ul>

<h3>Title: LLM-Ref: Enhancing Reference Handling in Technical Writing with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Kazi Ahmed Asif Fuad, Lizhong Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00294">https://arxiv.org/abs/2411.00294</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00294">https://arxiv.org/pdf/2411.00294</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00294]] LLM-Ref: Enhancing Reference Handling in Technical Writing with Large Language Models(https://arxiv.org/abs/2411.00294)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, retrieval-augmented generation</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) excel in data synthesis but can be inaccurate in domain-specific tasks, which retrieval-augmented generation (RAG) systems address by leveraging user-provided data. However, RAGs require optimization in both retrieval and generation stages, which can affect output quality. In this paper, we present LLM-Ref, a writing assistant tool that aids researchers in writing articles from multiple source documents with enhanced reference synthesis and handling capabilities. Unlike traditional RAG systems that use chunking and indexing, our tool retrieves and generates content directly from text paragraphs. This method facilitates direct reference extraction from the generated outputs, a feature unique to our tool. Additionally, our tool employs iterative response generation, effectively managing lengthy contexts within the language model's constraints. Compared to baseline RAG-based systems, our approach achieves a $3.25\times$ to $6.26\times$ increase in Ragas score, a comprehensive metric that provides a holistic view of a RAG system's ability to produce accurate, relevant, and contextually appropriate responses. This improvement shows our method enhances the accuracy and contextual relevance of writing assistance tools.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 在数据合成方面表现出色，但在特定领域任务中可能不准确，检索增强生成 (RAG) 系统通过利用用户提供的数据来解决这一问题。但是，RAG 需要在检索和生成阶段进行优化，这会影响输出质量。在本文中，我们介绍了 LLM-Ref，这是一种写作辅助工具，可帮助研究人员从多个源文档撰写文章，并具有增强的参考合成和处理功能。与使用分块和索引的传统 RAG 系统不同，我们的工具直接从文本段落中检索和生成内容。此方法有助于从生成的输出中直接提取参考，这是我们工具独有的功能。此外，我们的工具采用迭代响应生成，可在语言模型的约束范围内有效管理冗长的上下文。与基于 RAG 的基准系统相比，我们的方法将 Ragas 得分提高了 $3.25\times$ 到 $6.26\times$，这是一个全面的指标，可以全面反映 RAG 系统生成准确、相关且符合语境的响应的能力。这一改进表明我们的方法提高了写作辅助工具的准确性和语境相关性。</li>
</ul>

<h3>Title: Rationale-Guided Retrieval Augmented Generation for Medical Question Answering</h3>
<ul>
<li><strong>Authors: </strong>Jiwoong Sohn, Yein Park, Chanwoong Yoon, Sihyeon Park, Hyeon Hwang, Mujeen Sung, Hyunjae Kim, Jaewoo Kang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00300">https://arxiv.org/abs/2411.00300</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00300">https://arxiv.org/pdf/2411.00300</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00300]] Rationale-Guided Retrieval Augmented Generation for Medical Question Answering(https://arxiv.org/abs/2411.00300)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination, retrieval augmented generation, retrieval-augmented generation</a></li>
<li><strong>Abstract: </strong>Large language models (LLM) hold significant potential for applications in biomedicine, but they struggle with hallucinations and outdated knowledge. While retrieval-augmented generation (RAG) is generally employed to address these issues, it also has its own set of challenges: (1) LLMs are vulnerable to irrelevant or incorrect context, (2) medical queries are often not well-targeted for helpful information, and (3) retrievers are prone to bias toward the specific source corpus they were trained on. In this study, we present RAG$^2$ (RAtionale-Guided RAG), a new framework for enhancing the reliability of RAG in biomedical contexts. RAG$^2$ incorporates three key innovations: a small filtering model trained on perplexity-based labels of rationales, which selectively augments informative snippets of documents while filtering out distractors; LLM-generated rationales as queries to improve the utility of retrieved snippets; a structure designed to retrieve snippets evenly from a comprehensive set of four biomedical corpora, effectively mitigating retriever bias. Our experiments demonstrate that RAG$^2$ improves the state-of-the-art LLMs of varying sizes, with improvements of up to 6.1\%, and it outperforms the previous best medical RAG model by up to 5.6\% across three medical question-answering benchmarks. Our code is available at this https URL.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 在生物医学领域具有巨大的应用潜力，但它们在处理幻觉和过时知识方面存在困难。虽然检索增强生成 (RAG) 通常用于解决这些问题，但它也有自己的一系列挑战：(1) LLM 容易受到不相关或不正确上下文的影响，(2) 医学查询通常不能很好地针对有用的信息，以及 (3) 检索器容易对它们所训练的特定源语料库产生偏见。在本研究中，我们提出了 RAG$^2$（RAtionale-Guided RAG），这是一个用于增强 RAG 在生物医学环境中的可靠性的新框架。RAG$^2$ 包含三个关键创新：一个在基于困惑度的理由标签上训练的小型过滤模型，它可以选择性地增强文档的信息片段，同时过滤掉干扰项；LLM 生成的理由作为查询，以提高检索到的片段的效用；该结构旨在从四个生物医学语料库的综合集合中均匀检索片段，从而有效减轻检索者的偏见。我们的实验表明，RAG2 可以改进不同规模的最先进的 LLM，改进幅度高达 6.1%，并且在三个医学问答基准上比之前最好的医学 RAG 模型高出 5.6%。我们的代码可在此 https URL 上找到。</li>
</ul>

<h3>Title: GRS-QA -- Graph Reasoning-Structured Question Answering Dataset</h3>
<ul>
<li><strong>Authors: </strong>Anish Pahilajani, Devasha Trivedi, Jincen Shuai, Khin S. Yone, Samyak Rajesh Jain, Namyong Park, Ryan A. Rossi, Nesreen K. Ahmed, Franck Dernoncourt, Yu Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00369">https://arxiv.org/abs/2411.00369</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00369">https://arxiv.org/pdf/2411.00369</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00369]] GRS-QA -- Graph Reasoning-Structured Question Answering Dataset(https://arxiv.org/abs/2411.00369)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Large Language Models (LLMs) have excelled in multi-hop question-answering (M-QA) due to their advanced reasoning abilities. However, the impact of the inherent reasoning structures on LLM M-QA performance remains unclear, largely due to the absence of QA datasets that provide fine-grained reasoning structures. To address this gap, we introduce the Graph Reasoning-Structured Question Answering Dataset (GRS-QA), which includes both semantic contexts and reasoning structures for QA pairs. Unlike existing M-QA datasets, where different reasoning structures are entangled together, GRS-QA explicitly captures intricate reasoning pathways by constructing reasoning graphs, where nodes represent textual contexts and edges denote logical flows. These reasoning graphs of different structures enable a fine-grained evaluation of LLM reasoning capabilities across various reasoning structures. Our empirical analysis reveals that LLMs perform differently when handling questions with varying reasoning structures. This finding facilitates the exploration of textual structures as compared with semantics.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 凭借其先进的推理能力在多跳问答 (M-QA) 中表现出色。然而，固有推理结构对 LLM M-QA 性能的影响仍不清楚，这主要是由于缺乏提供细粒度推理结构的 QA 数据集。为了解决这一差距，我们引入了图推理结构化问答数据集 (GRS-QA)，其中包括 QA 对的语义上下文和推理结构。与现有的 M-QA 数据集中不同的推理结构纠缠在一起不同，GRS-QA 通过构建推理图明确捕获复杂的推理路径，其中节点表示文本上下文，边表示逻辑流。这些不同结构的推理图能够对各种推理结构的 LLM 推理能力进行细粒度评估。我们的实证分析表明，LLM 在处理具有不同推理结构的问题时表现不同。与语义相比，这一发现有助于探索文本结构。</li>
</ul>

<h3>Title: STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing</h3>
<ul>
<li><strong>Authors: </strong>Jiaru Zou, Qing Wang, Pratyush Thakur, Nickvash Kani</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00387">https://arxiv.org/abs/2411.00387</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00387">https://arxiv.org/pdf/2411.00387</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00387]] STEM-POM: Evaluating Language Models Math-Symbol Reasoning in Document Parsing(https://arxiv.org/abs/2411.00387)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Advances in large language models (LLMs) have spurred research into enhancing their reasoning capabilities, particularly in math-rich STEM documents. While LLMs can generate equations or solve math-related queries, their ability to fully understand and interpret abstract mathematical symbols in long, math-rich documents remains limited. In this paper, we introduce STEM-PoM, a comprehensive benchmark dataset designed to evaluate LLMs' reasoning abilities on math symbols within contextual scientific text. The dataset, sourced from real-world ArXiv documents, contains over 2K math symbols classified as main attributes of variables, constants, operators, and unit descriptors, with additional sub-attributes including scalar/vector/matrix for variables and local/global/discipline-specific labels for both constants and operators. Our extensive experiments show that state-of-the-art LLMs achieve an average of 20-60% accuracy under in-context learning and 50-60% accuracy with fine-tuning, revealing a significant gap in their mathematical reasoning capabilities. STEM-PoM fuels future research of developing advanced Math-AI models that can robustly handle math symbols.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 的进步推动了人们对增强其推理能力的研究，特别是在富含数学的 STEM 文档中。虽然 LLM 可以生成方程式或解决与数学相关的查询，但它们完全理解和解释长篇富含数学的文档中的抽象数学符号的能力仍然有限。在本文中，我们介绍了 STEM-PoM，这是一个全面的基准数据集，旨在评估 LLM 对上下文科学文本中数学符号的推理能力。该数据集来源于现实世界的 ArXiv 文档，包含超过 2K 个数学符号，这些符号被归类为变量、常量、运算符和单位描述符的主要属性，其他子属性包括变量的标量/向量/矩阵以及常量和运算符的本地/全局/学科特定标签。我们进行了广泛的实验，表明最先进的 LLM 在上下文学习下的平均准确率为 20-60%，在微调下的平均准确率为 50-60%，这表明它们的数学推理能力存在显著差距。 STEM-PoM 推动了未来开发能够稳健处理数学符号的高级数学人工智能模型的研究。</li>
</ul>

<h3>Title: Enhancing Authorship Attribution through Embedding Fusion: A Novel Approach with Masked and Encoder-Decoder Language Models</h3>
<ul>
<li><strong>Authors: </strong>Arjun Ramesh Kaushik, Sunil Rufus R P, Nalini Ratha</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00411">https://arxiv.org/abs/2411.00411</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00411">https://arxiv.org/pdf/2411.00411</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00411]] Enhancing Authorship Attribution through Embedding Fusion: A Novel Approach with Masked and Encoder-Decoder Language Models(https://arxiv.org/abs/2411.00411)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>The increasing prevalence of AI-generated content alongside human-written text underscores the need for reliable discrimination methods. To address this challenge, we propose a novel framework with textual embeddings from Pre-trained Language Models (PLMs) to distinguish AI-generated and human-authored text. Our approach utilizes Embedding Fusion to integrate semantic information from multiple Language Models, harnessing their complementary strengths to enhance performance. Through extensive evaluation across publicly available diverse datasets, our proposed approach demonstrates strong performance, achieving classification accuracy greater than 96% and a Matthews Correlation Coefficient (MCC) greater than 0.93. This evaluation is conducted on a balanced dataset of texts generated from five well-known Large Language Models (LLMs), highlighting the effectiveness and robustness of our novel methodology.</li>
<li><strong>摘要：</strong>人工智能生成的内容与人类撰写的文本日益流行，这凸显了对可靠区分方法的需求。为了应对这一挑战，我们提出了一个新颖的框架，该框架使用来自预训练语言模型 (PLM) 的文本嵌入来区分人工智能生成的文本和人类撰写的文本。我们的方法利用嵌入融合来集成来自多个语言模型的语义信息，利用它们的互补优势来提高性能。通过对公开可用的各种数据集进行广泛的评估，我们提出的方法表现出强大的性能，实现了超过 96% 的分类准确率和大于 0.93 的马修斯相关系数 (MCC)。该评估是在五个知名大型语言模型 (LLM) 生成的文本的平衡数据集上进行的，突显了我们新方法的有效性和稳健性。</li>
</ul>

<h3>Title: Self-Evolved Reward Learning for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Chenghua Huang, Zhizhen Fan, Lu Wang, Fangkai Yang, Pu Zhao, Zeqi Lin, Qingwei Lin, Dongmei Zhang, Saravan Rajmohan, Qi Zhang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00418">https://arxiv.org/abs/2411.00418</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00418">https://arxiv.org/pdf/2411.00418</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00418]] Self-Evolved Reward Learning for LLMs(https://arxiv.org/abs/2411.00418)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, chat</a></li>
<li><strong>Abstract: </strong>Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for aligning language models with human preferences, playing a pivotal role in the success of conversational models like GPT-4, ChatGPT, and Llama 2. A core challenge in employing RLHF lies in training a reliable reward model (RM), which relies on high-quality labels typically provided by human experts or advanced AI system. These methods can be costly and may introduce biases that affect the language model's responses. As language models improve, human input may become less effective in further enhancing their performance. In this paper, we propose Self-Evolved Reward Learning (SER), a novel approach where the RM generates additional training data to iteratively improve itself. We conducted extensive experiments on multiple datasets such as HH-RLHF and UltraFeedback, using models like Mistral and Llama 3, and compare SER against various baselines. Our results demonstrate that even with limited human-annotated data, learning from self-feedback can robustly enhance RM performance, thereby boosting the capabilities of large language models (LLMs).</li>
<li><strong>摘要：</strong>基于人类反馈的强化学习 (RLHF) 是将语言模型与人类偏好相结合的关键技术，在 GPT-4、ChatGPT 和 Llama 2 等对话模型的成功中发挥着关键作用。采用 RLHF 的核心挑战在于训练可靠的奖励模型 (RM)，该模型依赖于通常由人类专家或高级 AI 系统提供的高质量标签。这些方法成本高昂，可能会引入影响语言模型响应的偏差。随着语言模型的改进，人类输入在进一步提高其性能方面可能会变得不那么有效。在本文中，我们提出了自我进化的奖励学习 (SER)，这是一种新颖的方法，其中 RM 生成额外的训练数据以迭代改进自身。我们使用 Mistral 和 Llama 3 等模型对 HH-RLHF 和 UltraFeedback 等多个数据集进行了广泛的实验，并将 SER 与各种基线进行了比较。我们的结果表明，即使人工注释的数据有限，通过自我反馈学习也可以有力地提高 RM 性能，从而提升大型语言模型 (LLM) 的能力。</li>
</ul>

<h3>Title: DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems</h3>
<ul>
<li><strong>Authors: </strong>Aman Gupta, Anirudh Ravichandran, Ziji Zhang, Swair Shah, Anurag Beniwal, Narayanan Sadagopan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00427">https://arxiv.org/abs/2411.00427</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00427">https://arxiv.org/pdf/2411.00427</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00427]] DARD: A Multi-Agent Approach for Task-Oriented Dialog Systems(https://arxiv.org/abs/2411.00427)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Task-oriented dialogue systems are essential for applications ranging from customer service to personal assistants and are widely used across various industries. However, developing effective multi-domain systems remains a significant challenge due to the complexity of handling diverse user intents, entity types, and domain-specific knowledge across several domains. In this work, we propose DARD (Domain Assigned Response Delegation), a multi-agent conversational system capable of successfully handling multi-domain dialogs. DARD leverages domain-specific agents, orchestrated by a central dialog manager agent. Our extensive experiments compare and utilize various agent modeling approaches, combining the strengths of smaller fine-tuned models (Flan-T5-large & Mistral-7B) with their larger counterparts, Large Language Models (LLMs) (Claude Sonnet 3.0). We provide insights into the strengths and limitations of each approach, highlighting the benefits of our multi-agent framework in terms of flexibility and composability. We evaluate DARD using the well-established MultiWOZ benchmark, achieving state-of-the-art performance by improving the dialogue inform rate by 6.6% and the success rate by 4.1% over the best-performing existing approaches. Additionally, we discuss various annotator discrepancies and issues within the MultiWOZ dataset and its evaluation system.</li>
<li><strong>摘要：</strong>面向任务的对话系统对于从客户服务到个人助理等各种应用都至关重要，并且广泛应用于各个行业。然而，由于处理跨多个领域的各种用户意图、实体类型和领域特定知识的复杂性，开发有效的多领域系统仍然是一项重大挑战。在这项工作中，我们提出了 DARD（域分配响应委托），这是一种能够成功处理多域对话的多代理对话系统。DARD 利用由中央对话管理器代理协调的领域特定代理。我们进行了广泛的实验，比较并利用了各种代理建模方法，将较小的微调模型（Flan-T5-large 和 Mistral-7B）与其较大的对应模型大型语言模型 (LLM)（Claude Sonnet 3.0）的优势相结合。我们深入了解了每种方法的优势和局限性，突出了我们的多代理框架在灵活性和可组合性方面的优势。我们使用成熟的 MultiWOZ 基准对 DARD 进行评估，与现有最佳方法相比，对话信息率提高了 6.6%，成功率提高了 4.1%，实现了最佳性能。此外，我们还讨论了 MultiWOZ 数据集及其评估系统中的各种注释器差异和问题。</li>
</ul>

<h3>Title: E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation</h3>
<ul>
<li><strong>Authors: </strong>Yun Jiang, Zilong Xie, Wei Zhang, Yun Fang, Shuai Pan</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00437">https://arxiv.org/abs/2411.00437</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00437">https://arxiv.org/pdf/2411.00437</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00437]] E2E-AFG: An End-to-End Model with Adaptive Filtering for Retrieval-Augmented Generation(https://arxiv.org/abs/2411.00437)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, retrieval-augmented generation</a></li>
<li><strong>Abstract: </strong>Retrieval-augmented generation methods often neglect the quality of content retrieved from external knowledge bases, resulting in irrelevant information or potential misinformation that negatively affects the generation results of large language models. In this paper, we propose an end-to-end model with adaptive filtering for retrieval-augmented generation (E2E-AFG), which integrates answer existence judgment and text generation into a single end-to-end framework. This enables the model to focus more effectively on relevant content while reducing the influence of irrelevant information and generating accurate answers. We evaluate E2E-AFG on six representative knowledge-intensive language datasets, and the results show that it consistently outperforms baseline models across all tasks, demonstrating the effectiveness and robustness of the proposed approach.</li>
<li><strong>摘要：</strong>检索增强生成方法往往忽视从外部知识库中检索内容的质量，从而导致不相关信息或潜在的错误信息，对大型语言模型的生成结果产生负面影响。在本文中，我们提出了一种具有自适应过滤的端到端检索增强生成模型（E2E-AFG），将答案存在性判断和文本生成集成到一个端到端框架中。这使模型能够更有效地关注相关内容，同时减少不相关信息的影响并生成准确的答案。我们在六个具有代表性的知识密集型语言数据集上评估了 E2E-AFG，结果表明它在所有任务中始终优于基线模型，证明了所提方法的有效性和鲁棒性。</li>
</ul>

<h3>Title: Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Do Xuan Long, Duong Ngoc Yen, Anh Tuan Luu, Kenji Kawaguchi, Min-Yen Kan, Nancy F. Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00492">https://arxiv.org/abs/2411.00492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00492">https://arxiv.org/pdf/2411.00492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00492]] Multi-expert Prompting Improves Reliability, Safety, and Usefulness of Large Language Models(https://arxiv.org/abs/2411.00492)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, gpt, llm, prompt, chat</a></li>
<li><strong>Abstract: </strong>We present Multi-expert Prompting, a novel enhancement of ExpertPrompting (Xu et al., 2023), designed to improve the large language model (LLM) generation. Specifically, it guides an LLM to fulfill an input instruction by simulating multiple experts, aggregating their responses, and selecting the best among individual and aggregated responses. This process is performed in a single chain of thoughts through our seven carefully designed subtasks derived from the Nominal Group Technique (Ven and Delbecq, 1974), a well-established decision-making framework. Our evaluations demonstrate that Multi-expert Prompting significantly outperforms ExpertPrompting and comparable baselines in enhancing the truthfulness, factuality, informativeness, and usefulness of responses while reducing toxicity and hurtfulness. It further achieves state-of-the-art truthfulness by outperforming the best baseline by 8.69% with ChatGPT. Multi-expert Prompting is efficient, explainable, and highly adaptable to diverse scenarios, eliminating the need for manual prompt construction.</li>
<li><strong>摘要：</strong>我们提出了多专家提示，这是 ExpertPrompting（Xu 等人，2023 年）的一种新增强，旨在改进大型语言模型 (LLM) 的生成。具体来说，它通过模拟多位专家、汇总他们的回答并在单个和汇总的回答中选择最佳回答来指导 LLM 完成输入指令。这个过程通过我们精心设计的七个子任务以单一思路执行，这些子任务源自完善的决策框架 Nominal Group Technique（Ven 和 Delbecq，1974 年）。我们的评估表明，多专家提示在提高回答的真实性、事实性、信息性和实用性的同时，显著优于 ExpertPrompting 和可比基线，同时降低了毒性和伤害性。它通过 ChatGPT 比最佳基线高出 8.69%，进一步实现了最先进的真实性。多专家提示高效、可解释、高度适应多样化场景，无需手动构建提示。</li>
</ul>

<h3>Title: ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models</h3>
<ul>
<li><strong>Authors: </strong>Anbang Wang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00533">https://arxiv.org/abs/2411.00533</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00533">https://arxiv.org/pdf/2411.00533</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00533]] ReverseNER: A Self-Generated Example-Driven Framework for Zero-Shot Named Entity Recognition with Large Language Models(https://arxiv.org/abs/2411.00533)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>This paper presents ReverseNER, a framework aimed at overcoming the limitations of large language models (LLMs) in zero-shot Named Entity Recognition (NER) tasks, particularly in cases where certain entity types have ambiguous boundaries. ReverseNER tackles this challenge by constructing a reliable example library with the reversed process of NER. Rather than beginning with sentences, this method uses an LLM to generate entities based on their definitions and then expands them into full sentences. During sentence generation, the LLM is guided to replicate the structure of a specific 'feature sentence', extracted from the task sentences by clustering. This results in well-annotated sentences with clearly labeled entities, while preserving semantic and structural similarity to the task sentences. Once the example library is constructed, the method selects the most semantically similar example labels for each task sentence to support the LLM's inference. We also propose an entity-level self-consistency scoring mechanism to improve NER performance with LLMs. Experiments show that ReverseNER significantly outperforms traditional zero-shot NER with LLMs and surpasses several few-shot methods, marking a notable improvement in NER for domains with limited labeled data.</li>
<li><strong>摘要：</strong>本文介绍了 ReverseNER，这是一个旨在克服大型语言模型 (LLM) 在零样本命名实体识别 (NER) 任务中的局限性的框架，特别是在某些实体类型具有模糊边界的情况下。ReverseNER 通过使用 NER 的逆过程构建可靠的示例库来解决这一挑战。此方法不是从句子开始，而是使用 LLM 根据实体的定义生成实体，然后将其扩展为完整的句子。在句子生成过程中，引导 LLM 复制通过聚类从任务句子中提取的特定“特征句子”的结构。这样可以得到注释良好的句子，其中的实体标记清晰，同时保留与任务句子的语义和结构相似性。构建示例库后，该方法会为每个任务句子选择语义最相似的示例标签，以支持 LLM 的推理。我们还提出了一种实体级自洽评分机制，以提高 LLM 的 NER 性能。实验表明，ReverseNER 的表现明显优于使用 LLM 的传统零样本 NER，并且超越了几种少样本方法，标志着在标记数据有限的领域 NER 取得了显着的进步。</li>
</ul>

<h3>Title: Adapting Language Models via Token Translation</h3>
<ul>
<li><strong>Authors: </strong>Zhili Feng, Tanya Marwah, Lester Mackey, David Alvarez-Melis, Nicolo Fusi</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00593">https://arxiv.org/abs/2411.00593</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00593">https://arxiv.org/pdf/2411.00593</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00593]] Adapting Language Models via Token Translation(https://arxiv.org/abs/2411.00593)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Modern large language models use a fixed tokenizer to effectively compress text drawn from a source domain. However, applying the same tokenizer to a new target domain often leads to inferior compression, more costly inference, and reduced semantic alignment. To address this deficiency, we introduce Sparse Sinkhorn Token Translation (S2T2). S2T2 trains a tailored tokenizer for the target domain and learns to translate between target and source tokens, enabling more effective reuse of the pre-trained next-source-token predictor. In our experiments with finetuned English language models, S2T2 improves both the perplexity and the compression of out-of-domain protein sequences, outperforming direct finetuning with either the source or target tokenizer. In addition, we find that token translations learned for smaller, less expensive models can be directly transferred to larger, more powerful models to reap the benefits of S2T2 at lower cost.</li>
<li><strong>摘要：</strong>现代大型语言模型使用固定的标记器来有效压缩从源域中提取的文本。但是，将相同的标记器应用于新的目标域通常会导致压缩效果较差、推理成本更高以及语义对齐降低。为了解决这一不足，我们引入了稀疏 Sinkhorn 标记翻译 (S2T2)。S2T2 为目标域训练定制的标记器，并学习在目标标记和源标记之间进行转换，从而能够更有效地重用预先训练的下一个源标记预测器。在我们对微调的英语语言模型的实验中，S2T2 改善了域外蛋白质序列的困惑度和压缩率，优于使用源或目标标记器的直接微调。此外，我们发现，为较小、较便宜的模型学习的标记翻译可以直接转移到更大、更强大的模型，从而以更低的成本获得 S2T2 的好处。</li>
</ul>

<h3>Title: Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction</h3>
<ul>
<li><strong>Authors: </strong>Houjing Wei, Hakaze Cho, Yuting Shi, Naoya Inoue</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00646">https://arxiv.org/abs/2411.00646</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00646">https://arxiv.org/pdf/2411.00646</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00646]] Phase Diagram of Vision Large Language Models Inference: A Perspective from Interaction across Image and Instruction(https://arxiv.org/abs/2411.00646)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Vision Large Language Models (VLLMs) usually take input as a concatenation of image token embeddings and text token embeddings and conduct causal modeling. However, their internal behaviors remain underexplored, raising the question of interaction among two types of tokens. To investigate such multimodal interaction during model inference, in this paper, we measure the contextualization among the hidden state vectors of tokens from different modalities. Our experiments uncover a four-phase inference dynamics of VLLMs against the depth of Transformer-based LMs, including (I) Alignment: In very early layers, contextualization emerges between modalities, suggesting a feature space alignment. (II) Intra-modal Encoding: In early layers, intra-modal contextualization is enhanced while inter-modal interaction is suppressed, suggesting a local encoding within modalities. (III) Inter-modal Encoding: In later layers, contextualization across modalities is enhanced, suggesting a deeper fusion across modalities. (IV) Output Preparation: In very late layers, contextualization is reduced globally, and hidden states are aligned towards the unembedding space.</li>
<li><strong>摘要：</strong>视觉大型语言模型 (VLLM) 通常将输入作为图像标记嵌入和文本标记嵌入的串联并进行因果建模。然而，它们的内部行为仍未得到充分探索，这引发了两类标记之间相互作用的问题。为了研究模型推理过程中的这种多模态交互，本文测量了来自不同模态的标记的隐藏状态向量之间的语境化。我们的实验揭示了 VLLM 相对于基于 Transformer 的 LM 深度的四阶段推理动态，包括 (I) 对齐：在非常早期的层中，模态之间出现了语境化，表明特征空间对齐。(II) 模态内编码：在早期层中，模态内语境化得到增强，而模态间交互受到抑制，表明模态内的局部编码。(III) 模态间编码：在后面的层中，跨模态的语境化得到增强，表明跨模态的更深层次融合。 （IV）输出准备：在非常靠后的层中，上下文化全局减少，并且隐藏状态与非嵌入空间对齐。</li>
</ul>

<h3>Title: Zipfian Whitening</h3>
<ul>
<li><strong>Authors: </strong>Sho Yokoi, Han Bao, Hiroto Kurita, Hidetoshi Shimodaira</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.LG, stat.ML</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00680">https://arxiv.org/abs/2411.00680</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00680">https://arxiv.org/pdf/2411.00680</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00680]] Zipfian Whitening(https://arxiv.org/abs/2411.00680)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>The word embedding space in neural models is skewed, and correcting this can improve task performance. We point out that most approaches for modeling, correcting, and measuring the symmetry of an embedding space implicitly assume that the word frequencies are uniform; in reality, word frequencies follow a highly non-uniform distribution, known as Zipf's law. Surprisingly, simply performing PCA whitening weighted by the empirical word frequency that follows Zipf's law significantly improves task performance, surpassing established baselines. From a theoretical perspective, both our approach and existing methods can be clearly categorized: word representations are distributed according to an exponential family with either uniform or Zipfian base measures. By adopting the latter approach, we can naturally emphasize informative low-frequency words in terms of their vector norm, which becomes evident from the information-geometric perspective, and in terms of the loss functions for imbalanced classification. Additionally, our theory corroborates that popular natural language processing methods, such as skip-gram negative sampling, WhiteningBERT, and headless language models, work well just because their word embeddings encode the empirical word frequency into the underlying probabilistic model.</li>
<li><strong>摘要：</strong>神经模型中的词嵌入空间是倾斜的，纠正这个问题可以提高任务性能。我们指出，大多数用于建模、纠正和测量嵌入空间对称性的方法都隐含地假设词频是均匀的；实际上，词频遵循高度不均匀的分布，称为齐普夫定律。令人惊讶的是，只需执行遵循齐普夫定律的经验词频加权的 PCA 白化就可以显著提高任务性能，超越既定基线。从理论角度来看，我们的方法和现有方法都可以清楚地分类：词表示根据指数族分布，具有均匀或齐普夫基度量。通过采用后一种方法，我们可以自然地强调信息丰富的低频词的向量范数，这从信息几何角度和不平衡分类的损失函数来看是显而易见的。此外，我们的理论证实，流行的自然语言处理方法（例如 skip-gram negative采样、WhiteningBERT 和无头语言模型）之所以效果良好，只是因为它们的词嵌入将经验词频编码到底层概率模型中。</li>
</ul>

<h3>Title: Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models</h3>
<ul>
<li><strong>Authors: </strong>Minki Kang, Sung Ju Hwang, Gibbeum Lee, Jaewoong Cho</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00686">https://arxiv.org/abs/2411.00686</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00686">https://arxiv.org/pdf/2411.00686</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00686]] Latent Paraphrasing: Perturbation on Layers Improves Knowledge Injection in Language Models(https://arxiv.org/abs/2411.00686)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>As Large Language Models (LLMs) are increasingly deployed in specialized domains with continuously evolving knowledge, the need for timely and precise knowledge injection has become essential. Fine-tuning with paraphrased data is a common approach to enhance knowledge injection, yet it faces two significant challenges: high computational costs due to repetitive external model usage and limited sample diversity. To this end, we introduce LaPael, a latent-level paraphrasing method that applies input-dependent noise to early LLM layers. This approach enables diverse and semantically consistent augmentations directly within the model. Furthermore, it eliminates the recurring costs of paraphrase generation for each knowledge update. Our extensive experiments on question-answering benchmarks demonstrate that LaPael improves knowledge injection over standard fine-tuning and existing noise-based approaches. Additionally, combining LaPael with data-level paraphrasing further enhances performance.</li>
<li><strong>摘要：</strong>随着大型语言模型 (LLM) 越来越多地部署在知识不断发展的专业领域，及时和精确的知识注入变得至关重要。使用释义数据进行微调是增强知识注入的常用方法，但它面临两个重大挑战：由于重复使用外部模型而导致的计算成本高，以及样本多样性有限。为此，我们引入了 LaPael，这是一种潜在级释义方法，它将输入相关的噪声应用于早期的 LLM 层。这种方法可以直接在模型内实现多样化和语义一致的增强。此外，它消除了每次知识更新时释义生成的重复成本。我们在问答基准上进行的大量实验表明，与标准微调和现有的基于噪声的方法相比，LaPael 改进了知识注入。此外，将 LaPael 与数据级释义相结合可以进一步提高性能。</li>
</ul>

<h3>Title: Towards Multi-Source Retrieval-Augmented Generation via Synergizing Reasoning and Preference-Driven Retrieval</h3>
<ul>
<li><strong>Authors: </strong>Qingfei Zhao, Ruobing Wang, Xin Wang, Daren Zha, Nan Mu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00689">https://arxiv.org/abs/2411.00689</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00689">https://arxiv.org/pdf/2411.00689</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00689]] Towards Multi-Source Retrieval-Augmented Generation via Synergizing Reasoning and Preference-Driven Retrieval(https://arxiv.org/abs/2411.00689)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, hallucination, retrieval-augmented generation</a></li>
<li><strong>Abstract: </strong>Retrieval-Augmented Generation (RAG) has emerged as a reliable external knowledge augmentation technique to mitigate hallucination issues and parameterized knowledge limitations in Large Language Models (LLMs). Existing Adaptive RAG (ARAG) systems struggle to effectively explore multiple retrieval sources due to their inability to select the right source at the right time. To address this, we propose a multi-source ARAG framework, termed MSPR, which synergizes reasoning and preference-driven retrieval to adaptive decide "when and what to retrieve" and "which retrieval source to use". To better adapt to retrieval sources of differing characteristics, we also employ retrieval action adjustment and answer feedback strategy. They enable our framework to fully explore the high-quality primary source while supplementing it with secondary sources at the right time. Extensive and multi-dimensional experiments conducted on three datasets demonstrate the superiority and effectiveness of MSPR.</li>
<li><strong>摘要：</strong>检索增强生成 (RAG) 已成为一种可靠的外部知识增强技术，可缓解大型语言模型 (LLM) 中的幻觉问题和参数化知识限制。现有的自适应 RAG (ARAG) 系统难以有效地探索多个检索源，因为它们无法在正确的时间选择正确的源。为了解决这个问题，我们提出了一个多源 ARAG 框架，称为 MSPR，它协同推理和偏好驱动的检索来自适应地决定“何时和检索什么”以及“使用哪个检索源”。为了更好地适应不同特征的检索源，我们还采用了检索动作调整和答案反馈策略。它们使我们的框架能够充分探索高质量的主要来源，同时在正确的时间用次要来源进行补充。在三个数据集上进行的广泛和多维实验证明了 MSPR 的优越性和有效性。</li>
</ul>

<h3>Title: Leveraging Large Language Models for Code-Mixed Data Augmentation in Sentiment Analysis</h3>
<ul>
<li><strong>Authors: </strong>Linda Zeng</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00691">https://arxiv.org/abs/2411.00691</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00691">https://arxiv.org/pdf/2411.00691</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00691]] Leveraging Large Language Models for Code-Mixed Data Augmentation in Sentiment Analysis(https://arxiv.org/abs/2411.00691)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, prompt</a></li>
<li><strong>Abstract: </strong>Code-mixing (CM), where speakers blend languages within a single expression, is prevalent in multilingual societies but poses challenges for natural language processing due to its complexity and limited data. We propose using a large language model to generate synthetic CM data, which is then used to enhance the performance of task-specific models for CM sentiment analysis. Our results show that in Spanish-English, synthetic data improved the F1 score by 9.32%, outperforming previous augmentation techniques. However, in Malayalam-English, synthetic data only helped when the baseline was low; with strong natural data, additional synthetic data offered little benefit. Human evaluation confirmed that this approach is a simple, cost-effective way to generate natural-sounding CM sentences, particularly beneficial for low baselines. Our findings suggest that few-shot prompting of large language models is a promising method for CM data augmentation and has significant impact on improving sentiment analysis, an important element in the development of social influence systems.</li>
<li><strong>摘要：</strong>混合语码 (CM) 是指说话者在单一表达中混合多种语言，这种现象在多语言社会中十分普遍，但由于其复杂性和数据有限，对自然语言处理提出了挑战。我们建议使用大型语言模型来生成合成 CM 数据，然后使用这些数据来增强 CM 情绪分析任务特定模型的性能。我们的结果表明，在西班牙语-英语中，合成数据将 F1 得分提高了 9.32%，优于之前的增强技术。然而，在马拉雅拉姆语-英语中，合成数据仅在基线较低时才有帮助；有了强大的自然数据，额外的合成数据几乎没有什么好处。人工评估证实，这种方法是一种简单、经济高效的生成自然 CM 句子的方法，尤其适用于低基线。我们的研究结果表明，对大型语言模型进行少量提示是一种很有前途的 CM 数据增强方法，对改进情绪分析有重大影响，情绪分析是社会影响系统开发的一个重要元素。</li>
</ul>

<h3>Title: SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task</h3>
<ul>
<li><strong>Authors: </strong>Hamees Sayed, Advait Joglekar, Srinivasan Umesh</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00727">https://arxiv.org/abs/2411.00727</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00727">https://arxiv.org/pdf/2411.00727</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00727]] SPRING Lab IITM's submission to Low Resource Indic Language Translation Shared Task(https://arxiv.org/abs/2411.00727)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>We develop a robust translation model for four low-resource Indic languages: Khasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive pipeline from data collection and preprocessing to training and evaluation, leveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To address the scarcity of bilingual data, we use back-translation techniques on monolingual datasets for Mizo and Khasi, significantly expanding our training corpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and Manipuri, achieving improved performance over the baseline. For Khasi, which is not supported by the NLLB model, we introduce special tokens and train the model on our Khasi corpus. Our training involves masked language modelling, followed by fine-tuning for English-to-Indic and Indic-to-English translations.</li>
<li><strong>摘要：</strong>我们为四种资源匮乏的印度语开发了一个强大的翻译模型：卡西语、米佐语、曼尼普尔语和阿萨姆语。我们的方法包括从数据收集和预处理到训练和评估的全面流程，利用来自 WMT 任务数据集、BPCC、PMIndia 和 OpenLanguageData 的数据。为了解决双语数据稀缺的问题，我们在米佐语和卡西语的单语数据集上使用反向翻译技术，大大扩展了我们的训练语料库。我们针对阿萨姆语、米佐语和曼尼普尔语对预训练的 NLLB 3.3B 模型进行了微调，实现了比基线更高的性能。对于 NLLB 模型不支持的卡西语，我们引入了特殊标记并在我们的卡西语语料库上训练模型。我们的训练涉及掩码语言建模，然后对英语到印度语和印度语到英语的翻译进行微调。</li>
</ul>

<h3>Title: MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction</h3>
<ul>
<li><strong>Authors: </strong>Carl Edwards, Ziqing Lu, Ehsan Hajiramezanali, Tommaso Biancalani, Heng Ji, Gabriele Scalia</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, q-bio.BM</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00737">https://arxiv.org/abs/2411.00737</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00737">https://arxiv.org/pdf/2411.00737</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00737]] MolCap-Arena: A Comprehensive Captioning Benchmark on Language-Enhanced Molecular Property Prediction(https://arxiv.org/abs/2411.00737)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, prompt</a></li>
<li><strong>Abstract: </strong>Bridging biomolecular modeling with natural language information, particularly through large language models (LLMs), has recently emerged as a promising interdisciplinary research area. LLMs, having been trained on large corpora of scientific documents, demonstrate significant potential in understanding and reasoning about biomolecules by providing enriched contextual and domain knowledge. However, the extent to which LLM-driven insights can improve performance on complex predictive tasks (e.g., toxicity) remains unclear. Further, the extent to which relevant knowledge can be extracted from LLMs also remains unknown. In this study, we present Molecule Caption Arena: the first comprehensive benchmark of LLM-augmented molecular property prediction. We evaluate over twenty LLMs, including both general-purpose and domain-specific molecule captioners, across diverse prediction tasks. To this goal, we introduce a novel, battle-based rating system. Our findings confirm the ability of LLM-extracted knowledge to enhance state-of-the-art molecular representations, with notable model-, prompt-, and dataset-specific variations. Code, resources, and data are available at this http URL.</li>
<li><strong>摘要：</strong>将生物分子建模与自然语言信息结合起来，特别是通过大型语言模型 (LLM)，最近已成为一个有前途的跨学科研究领域。LLM 经过大量科学文献的训练，通过提供丰富的上下文和领域知识，在理解和推理生物分子方面表现出巨大的潜力。然而，LLM 驱动的洞察力能在多大程度上提高复杂预测任务（例如毒性）的性能仍不清楚。此外，从 LLM 中提取相关知识的程度也仍然未知。在本研究中，我们提出了分子标题竞技场：LLM 增强分子特性预测的第一个综合基准。我们在不同的预测任务中评估了二十多个 LLM，包括通用和领域特定的分子字幕。为了实现这个目标，我们引入了一个新颖的基于战斗的评级系统。我们的研究结果证实了 LLM 提取的知识能够增强最先进的分子表征，具有显着的模型、提示和数据集特定变化。代码、资源和数据可在此 http URL 上获取。</li>
</ul>

<h3>Title: Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling</h3>
<ul>
<li><strong>Authors: </strong>Yiwen Ding, Zhiheng Xi, Wei He, Zhuoyuan Li, Yitao Zhai, Xiaowei Shi, Xunliang Cai, Tao Gui, Qi Zhang, Xuanjing Huang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2411.00750">https://arxiv.org/abs/2411.00750</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2411.00750">https://arxiv.org/pdf/2411.00750</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2411.00750]] Mitigating Tail Narrowing in LLM Self-Improvement via Socratic-Guided Sampling(https://arxiv.org/abs/2411.00750)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Self-improvement methods enable large language models (LLMs) to generate solutions themselves and iteratively train on filtered, high-quality rationales. This process proves effective and reduces the reliance on human supervision in LLMs' reasoning, but the performance soon plateaus. We delve into the process and find that models tend to over-sample on easy queries and under-sample on queries they have yet to master. As iterations proceed, this imbalance in sampling is exacerbated, leading to a long-tail distribution where solutions to difficult queries almost diminish. This phenomenon limits the performance gain of self-improving models. A straightforward solution is brute-force sampling to balance the distribution, which significantly raises computational costs. In this paper, we introduce Guided Self-Improvement (GSI), a strategy aimed at improving the efficiency of sampling challenging heavy-tailed data. It leverages Socratic-style guidance signals to help LLM reasoning with complex queries, reducing the exploration effort and minimizing computational overhead. Experiments on four models across diverse mathematical tasks show that GSI strikes a balance between performance and efficiency, while also being effective on held-out tasks.</li>
<li><strong>摘要：</strong>自我改进方法使大型语言模型 (LLM) 能够自行生成解决方案，并针对经过筛选的高质量原理进行迭代训练。这一过程被证明是有效的，减少了 LLM 推理对人工监督的依赖，但性能很快就会停滞不前。我们深入研究了这一过程，发现模型倾向于对简单查询进行过度采样，而对尚未掌握的查询进行欠采样。随着迭代的进行，这种采样不平衡会加剧，导致长尾分布，其中困难查询的解决方案几乎消失。这种现象限制了自我改进模型的性能提升。一种直接的解决方案是强力采样以平衡分布，这会大大增加计算成本。在本文中，我们介绍了引导式自我改进 (GSI)，这是一种旨在提高具有挑战性的重尾数据采样效率的策略。它利用苏格拉底式指导信号帮助 LLM 推理复杂查询，减少探索工作量并最大限度地减少计算开销。对四种模型在不同数学任务上的实验表明，GSI 在性能和效率之间取得了平衡，同时在保留任务上也有效。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
