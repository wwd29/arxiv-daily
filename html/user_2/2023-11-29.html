<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h2>language model</h2>
<h3>Title: Enhancing Sentiment Analysis Results through Outlier Detection Optimization. (arXiv:2311.16185v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16185">http://arxiv.org/abs/2311.16185</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16185]] Enhancing Sentiment Analysis Results through Outlier Detection Optimization(http://arxiv.org/abs/2311.16185)</code></li>
<li>Summary: <p>When dealing with text data containing subjective labels like speaker
emotions, inaccuracies or discrepancies among labelers are not uncommon. Such
discrepancies can significantly affect the performance of machine learning
algorithms. This study investigates the potential of identifying and addressing
outliers in text data with subjective labels, aiming to enhance classification
outcomes. We utilized the Deep SVDD algorithm, a one-class classification
method, to detect outliers in nine text-based emotion and sentiment analysis
datasets. By employing both a small-sized language model (DistilBERT base model
with 66 million parameters) and non-deep learning machine learning algorithms
(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our
findings suggest that the removal of outliers can lead to enhanced results in
most cases. Additionally, as outliers in such datasets are not necessarily
unlearnable, we experienced utilizing a large language model -- DeBERTa v3
large with 131 million parameters, which can capture very complex patterns in
data. We continued to observe performance enhancements across multiple
datasets.
</p></li>
</ul>

<h3>Title: Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models. (arXiv:2311.16338v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16338">http://arxiv.org/abs/2311.16338</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16338]] Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models(http://arxiv.org/abs/2311.16338)</code></li>
<li>Summary: <p>Instruction-following language models demand robust methodologies for
information retrieval to augment instructions for question-answering
applications. A primary challenge is the resolution of coreferences in the
context of chunking strategies for long documents. The critical barrier to
experimentation of handling coreferences is a lack of open source datasets,
specifically in question-answering tasks that require coreference resolution.
In this work we present our Coreference Resolution in Question-Answering
(CRaQAn) dataset, an open-source dataset that caters to the nuanced information
retrieval requirements of coreference resolution in question-answering tasks by
providing over 250 question-answer pairs containing coreferences. To develop
this dataset, we developed a novel approach for creating high-quality datasets
using an instruction-following model (GPT-4) and a Recursive Criticism and
Improvement Loop.
</p></li>
</ul>

<h3>Title: Applications of Large Language Models in Data Processing: Innovative Approaches to Segmenting and Renewing Information. (arXiv:2311.16267v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16267">http://arxiv.org/abs/2311.16267</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16267]] Applications of Large Language Models in Data Processing: Innovative Approaches to Segmenting and Renewing Information(http://arxiv.org/abs/2311.16267)</code></li>
<li>Summary: <p>Our paper investigates effective methods for code generation in
"specific-domain" applications, including the use of Large Language Models
(LLMs) for data segmentation and renewal, as well as stimulating deeper
thinking in LLMs through prompt adjustments. Using a real company product as an
example, we provide user manuals, API documentation, and other data. The ideas
discussed in this paper help segment and then convert this data into semantic
vectors to better reflect their true positioning. Subsequently, user
requirements are transformed into vectors to retrieve the most relevant
content, achieving about 70% accuracy in simple to medium-complexity tasks
through various prompt techniques. This paper is the first to enhance
specific-domain code generation effectiveness from this perspective.
Additionally, we experiment with generating more scripts from a limited number
using llama2-based fine-tuning to test its effectiveness in professional domain
code generation. This is a challenging and promising field, and once achieved,
it will not only lead to breakthroughs in LLM development across multiple
industries but also enable LLMs to understand and learn any new knowledge
effectively.
</p></li>
</ul>

<h3>Title: Influence Scores at Scale for Efficient Language Data Sampling. (arXiv:2311.16298v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16298">http://arxiv.org/abs/2311.16298</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16298]] Influence Scores at Scale for Efficient Language Data Sampling(http://arxiv.org/abs/2311.16298)</code></li>
<li>Summary: <p>Modern ML systems ingest data aggregated from diverse sources, such as
synthetic, human-annotated, and live customer traffic. Understanding
\textit{which} examples are important to the performance of a learning
algorithm is crucial for efficient model training. Recently, a growing body of
literature has given rise to various "influence scores," which use training
artifacts such as model confidence or checkpointed gradients to identify
important subsets of data. However, these methods have primarily been developed
in computer vision settings, and it remains unclear how well they generalize to
language-based tasks using pretrained models.
</p>
<p>In this paper, we explore the applicability of influence scores in language
classification tasks. We evaluate a diverse subset of these scores on the SNLI
dataset by quantifying accuracy changes in response to pruning training data
through random and influence-score-based sampling. We then stress-test one of
the scores -- "variance of gradients" (VoG) from Agarwal et al. (2022) -- in an
NLU model stack that was exposed to dynamic user speech patterns in a voice
assistant type of setting. Our experiments demonstrate that in many cases,
encoder-based language models can be finetuned on roughly 50% of the original
data without degradation in performance metrics. Along the way, we summarize
lessons learned from applying out-of-the-box implementations of influence
scores, quantify the effects of noisy and class-imbalanced data, and offer
recommendations on score-based sampling for better accuracy and training
efficiency.
</p></li>
</ul>

<h3>Title: CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models. (arXiv:2311.16421v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16421">http://arxiv.org/abs/2311.16421</a></li>
<li>Code URL: https://github.com/astrodrew/cdeval</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16421]] CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models(http://arxiv.org/abs/2311.16421)</code></li>
<li>Summary: <p>As the scaling of Large Language Models (LLMs) has dramatically enhanced
their capabilities, there has been a growing focus on the alignment problem to
ensure their responsible and ethical use. While existing alignment efforts
predominantly concentrate on universal values such as the HHH principle, the
aspect of culture, which is inherently pluralistic and diverse, has not
received adequate attention. This work introduces a new benchmark, CDEval,
aimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by
incorporating both GPT-4's automated generation and human verification,
covering six cultural dimensions across seven domains. Our comprehensive
experiments provide intriguing insights into the culture of mainstream LLMs,
highlighting both consistencies and variations across different dimensions and
domains. The findings underscore the importance of integrating cultural
considerations in LLM development, particularly for applications in diverse
cultural settings. Through CDEval, we aim to broaden the horizon of LLM
alignment research by including cultural dimensions, thus providing a more
holistic framework for the future development and evaluation of LLMs. This
benchmark serves as a valuable resource for cultural studies in LLMs, paving
the way for more culturally aware and sensitive models.
</p></li>
</ul>

<h3>Title: StyleCap: Automatic Speaking-Style Captioning from Speech Based on Speech and Language Self-supervised Learning Models. (arXiv:2311.16509v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16509">http://arxiv.org/abs/2311.16509</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16509]] StyleCap: Automatic Speaking-Style Captioning from Speech Based on Speech and Language Self-supervised Learning Models(http://arxiv.org/abs/2311.16509)</code></li>
<li>Summary: <p>We propose StyleCap, a method to generate natural language descriptions of
speaking styles appearing in speech. Although most of conventional techniques
for para-/non-linguistic information recognition focus on the category
classification or the intensity estimation of pre-defined labels, they cannot
provide the reasoning of the recognition result in an interpretable manner. As
a first step towards an end-to-end method for generating speaking-style prompts
from speech, i.e., automatic speaking-style captioning, StyleCap uses paired
data of speech and natural language descriptions to train neural networks that
predict prefix vectors fed into a large language model (LLM)-based text decoder
from a speech representation vector. We explore an appropriate text decoder and
speech feature representation suitable for this new task. The experimental
results demonstrate that our StyleCap leveraging richer LLMs for the text
decoder, speech self-supervised learning (SSL) features, and sentence
rephrasing augmentation improves the accuracy and diversity of generated
speaking-style captions. Samples of speaking-style captions generated by our
StyleCap are publicly available.
</p></li>
</ul>

<h3>Title: MedGen: A Python Natural Language Processing Toolkit for Medical Text Processing. (arXiv:2311.16588v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16588">http://arxiv.org/abs/2311.16588</a></li>
<li>Code URL: https://github.com/yale-lily/medgen</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16588]] MedGen: A Python Natural Language Processing Toolkit for Medical Text Processing(http://arxiv.org/abs/2311.16588)</code></li>
<li>Summary: <p>This study introduces MedGen, a comprehensive natural language processing
(NLP) toolkit designed for medical text processing. MedGen is tailored for
biomedical researchers and healthcare professionals with an easy-to-use,
all-in-one solution that requires minimal programming expertise. It includes
(1) Generative Functions: For the first time, MedGen includes four advanced
generative functions: question answering, text summarization, text
simplification, and machine translation; (2) Basic NLP Functions: MedGen
integrates 12 essential NLP functions such as word tokenization and sentence
segmentation; and (3) Query and Search Capabilities: MedGen provides
user-friendly query and search functions on text corpora. We fine-tuned 32
domain-specific language models, evaluated them thoroughly on 24 established
benchmarks and conducted manual reviews with clinicians. Additionally, we
expanded our toolkit by introducing query and search functions, while also
standardizing and integrating functions from third-party libraries. The
toolkit, its models, and associated data are publicly available via
https://github.com/Yale-LILY/MedGen.
</p></li>
</ul>

<h2>gpt</h2>
<h3>Title: MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. (arXiv:2311.16502v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16502">http://arxiv.org/abs/2311.16502</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16502]] MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI(http://arxiv.org/abs/2311.16502)</code></li>
<li>Summary: <p>We introduce MMMU: a new benchmark designed to evaluate multimodal models on
massive multi-discipline tasks demanding college-level subject knowledge and
deliberate reasoning. MMMU includes 11.5K meticulously collected multimodal
questions from college exams, quizzes, and textbooks, covering six core
disciplines: Art &amp; Design, Business, Science, Health &amp; Medicine, Humanities &amp;
Social Science, and Tech &amp; Engineering. These questions span 30 subjects and
183 subfields, comprising 30 highly heterogeneous image types, such as charts,
diagrams, maps, tables, music sheets, and chemical structures. Unlike existing
benchmarks, MMMU focuses on advanced perception and reasoning with
domain-specific knowledge, challenging models to perform tasks akin to those
faced by experts. Our evaluation of 14 open-source LMMs and the proprietary
GPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the
advanced GPT-4V only achieves a 56% accuracy, indicating significant room for
improvement. We believe MMMU will stimulate the community to build
next-generation multimodal foundation models towards expert artificial general
intelligence.
</p></li>
</ul>

<h3>Title: Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine. (arXiv:2311.16452v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16452">http://arxiv.org/abs/2311.16452</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16452]] Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine(http://arxiv.org/abs/2311.16452)</code></li>
<li>Summary: <p>Generalist foundation models such as GPT-4 have displayed surprising
capabilities in a wide variety of domains and tasks. Yet, there is a prevalent
assumption that they cannot match specialist capabilities of fine-tuned models.
For example, most explorations to date on medical competency benchmarks have
leveraged domain-specific training, as exemplified by efforts on BioGPT and
Med-PaLM. We build on a prior study of GPT-4's capabilities on medical
challenge benchmarks in the absence of special training. Rather than using
simple prompting to highlight the model's out-of-the-box capabilities, we
perform a systematic exploration of prompt engineering. We find that prompting
innovation can unlock deeper specialist capabilities and show that GPT-4 easily
tops prior leading results for medical benchmarks. The prompting methods we
explore are general purpose, and make no specific use of domain expertise,
removing the need for expert-curated content. Our experimental design carefully
controls for overfitting during the prompt engineering process. We introduce
Medprompt, based on a composition of several prompting strategies. With
Medprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark
datasets in the MultiMedQA suite. The method outperforms leading specialist
models such as Med-PaLM 2 by a significant margin with an order of magnitude
fewer calls to the model. Steering GPT-4 with Medprompt achieves a 27%
reduction in error rate on the MedQA dataset over the best methods to date
achieved with specialist models and surpasses a score of 90% for the first
time. Beyond medical problems, we show the power of Medprompt to generalize to
other domains and provide evidence for the broad applicability of the approach
via studies of the strategy on exams in electrical engineering, machine
learning, philosophy, accounting, law, nursing, and clinical psychology.
</p></li>
</ul>

<h3>Title: Scaling Political Texts with ChatGPT. (arXiv:2311.16639v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16639">http://arxiv.org/abs/2311.16639</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16639]] Scaling Political Texts with ChatGPT(http://arxiv.org/abs/2311.16639)</code></li>
<li>Summary: <p>We use GPT-4 to obtain position estimates of political texts in continuous
spaces. We develop and validate a new approach by positioning British party
manifestos on the economic, social, and immigration policy dimensions and
tweets by members of the US Congress on the left-right ideological spectrum.
For the party manifestos, the correlation between the positions produced by
GPT-4 and experts is 93% or higher, a performance similar to or better than
that obtained with crowdsourced position estimates. For individual tweets, the
positions obtained with GPT-4 achieve a correlation of 91% with crowdsourced
position estimates. For senators of the 117th US Congress, the positions
obtained with GPT-4 achieve a correlation of 97% with estimates based on roll
call votes and of 96% with those based on campaign funding. Correlations are
also substantial within party, indicating that position estimates produced with
GPT-4 capture within-party differences between senators. Overall, using GPT-4
for ideological scaling is fast, cost-efficient, and reliable. This approach
provides a viable alternative to scaling by both expert raters and
crowdsourcing.
</p></li>
</ul>

<h2>llm</h2>
<h3>Title: Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce. (arXiv:2311.16171v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16171">http://arxiv.org/abs/2311.16171</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16171]] Multi-Agent Learning of Efficient Fulfilment and Routing Strategies in E-Commerce(http://arxiv.org/abs/2311.16171)</code></li>
<li>Summary: <p>This paper presents an integrated algorithmic framework for minimising
product delivery costs in e-commerce (known as the cost-to-serve or C2S). One
of the major challenges in e-commerce is the large volume of spatio-temporally
diverse orders from multiple customers, each of which has to be fulfilled from
one of several warehouses using a fleet of vehicles. This results in two levels
of decision-making: (i) selection of a fulfillment node for each order
(including the option of deferral to a future time), and then (ii) routing of
vehicles (each of which can carry multiple orders originating from the same
warehouse). We propose an approach that combines graph neural networks and
reinforcement learning to train the node selection and vehicle routing agents.
We include real-world constraints such as warehouse inventory capacity, vehicle
characteristics such as travel times, service times, carrying capacity, and
customer constraints including time windows for delivery. The complexity of
this problem arises from the fact that outcomes (rewards) are driven both by
the fulfillment node mapping as well as the routing algorithms, and are
spatio-temporally distributed. Our experiments show that this algorithmic
pipeline outperforms pure heuristic policies.
</p></li>
</ul>

<h3>Title: Conditions for Length Generalization in Learning Reasoning Skills. (arXiv:2311.16173v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16173">http://arxiv.org/abs/2311.16173</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16173]] Conditions for Length Generalization in Learning Reasoning Skills(http://arxiv.org/abs/2311.16173)</code></li>
<li>Summary: <p>Reasoning is a fundamental capability of AI agents. Recently, large language
models (LLMs) have shown remarkable abilities to perform reasoning tasks.
However, numerous evaluations of the reasoning capabilities of LLMs have also
showed some limitations. An outstanding limitation is length generalization,
meaning that when trained on reasoning problems of smaller lengths or sizes,
the resulting models struggle with problems of larger sizes or lengths. This
potentially indicates some theoretical limitations of generalization in
learning reasoning skills. These evaluations and their observations motivated
us to perform a theoretical study of the length generalization problem. This
work focused on reasoning tasks that can be formulated as Markov dynamic
processes (MDPs) and/or directed acyclic graphs (DAGs). It identifies and
proves conditions that decide whether the length generalization problem can be
solved or not for a reasoning task in a particular representation. Experiments
are also conducted to verify the theoretical results.
</p></li>
</ul>

<h3>Title: Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and Asynchronous Dequantization. (arXiv:2311.16442v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16442">http://arxiv.org/abs/2311.16442</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16442]] Enabling Fast 2-bit LLM on GPUs: Memory Alignment, Sparse Outlier, and Asynchronous Dequantization(http://arxiv.org/abs/2311.16442)</code></li>
<li>Summary: <p>Large language models (LLMs) have demonstrated impressive abilities in
various domains while the inference cost is expensive. The state-of-the-art
methods use 2-bit quantization for mainstream LLMs. However, challenges still
exist: (1) Nonnegligible accuracy loss for 2-bit quantization. Weights are
quantized by groups, while the ranges of weights are large in some groups,
resulting in large quantization errors and nonnegligible accuracy loss (e.g.
&gt;3% for Llama2-7b with 2-bit quantization in GPTQ and Greenbit). (2) Limited
accuracy improvement by adding 4-bit weights. Increasing 10% extra average bit
more 4-bit weights only leads to &lt;0.5% accuracy improvement on a quantized
Llama2-7b. (3) Time-consuming dequantization operations on GPUs. The
dequantization operations lead to &gt;50% execution time, hindering the potential
of reducing LLM inference cost. To tackle these challenges, we propose the
following techniques: (1) We only quantize a small fraction of groups with the
larger range using 4-bit with memory alignment consideration on GPUs. (2) We
point out that the distribution of the sparse outliers with larger weights is
different in 2-bit and 4-bit groups, and only a small fraction of outliers
require 16-bit quantization. Such design leads to &gt;0.5% accuracy improvement
with &lt;3% average increased bit for Llama2-7b. (3) We design the asynchronous
dequantization on GPUs, leading to up to 3.92X speedup. We conduct extensive
experiments on different model families and model sizes. We achieve 2.85-bit
for each weight and the end-to-end speedup for Llama2-7b is 1.74X over the
original model, and we reduce both runtime cost and hardware cost by up to
2.70X and 2.81X with less GPU requirements.
</p></li>
</ul>

<h2>long context</h2>
<h2>lora</h2>
<h3>Title: An Exploration of Left-Corner Transformations. (arXiv:2311.16258v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16258">http://arxiv.org/abs/2311.16258</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16258]] An Exploration of Left-Corner Transformations(http://arxiv.org/abs/2311.16258)</code></li>
<li>Summary: <p>The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to
remove left recursion from context-free grammars, which is an important step
towards making the grammar parsable top-down with simple techniques. This paper
generalizes prior left-corner transformations to support semiring-weighted
production rules and to provide finer-grained control over which left corners
may be moved. Our generalized left-corner transformation (GLCT) arose from
unifying the left-corner transformation and speculation transformation (Eisner
and Blatz, 2007), originally for logic programming. Our new transformation and
speculation define equivalent weighted languages. Yet, their derivation trees
are structurally different in an important way: GLCT replaces left recursion
with right recursion, and speculation does not. We also provide several
technical results regarding the formal relationships between the outputs of
GLCT, speculation, and the original grammar. Lastly, we empirically investigate
the efficiency of GLCT for left-recursion elimination from grammars of nine
languages.
</p></li>
</ul>

<h3>Title: Model-free Test Time Adaptation for Out-Of-Distribution Detection. (arXiv:2311.16420v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16420">http://arxiv.org/abs/2311.16420</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16420]] Model-free Test Time Adaptation for Out-Of-Distribution Detection(http://arxiv.org/abs/2311.16420)</code></li>
<li>Summary: <p>Out-of-distribution (OOD) detection is essential for the reliability of ML
models. Most existing methods for OOD detection learn a fixed decision
criterion from a given in-distribution dataset and apply it universally to
decide if a data point is OOD. Recent work~\cite{fang2022is} shows that given
only in-distribution data, it is impossible to reliably detect OOD data without
extra assumptions. Motivated by the theoretical result and recent exploration
of test-time adaptation methods, we propose a Non-Parametric Test Time
\textbf{Ada}ptation framework for \textbf{O}ut-Of-\textbf{D}istribution
\textbf{D}etection (\abbr). Unlike conventional methods, \abbr utilizes online
test samples for model adaptation during testing, enhancing adaptability to
changing data distributions. The framework incorporates detected OOD instances
into decision-making, reducing false positive rates, particularly when ID and
OOD distributions overlap significantly. We demonstrate the effectiveness of
\abbr through comprehensive experiments on multiple OOD detection benchmarks,
extensive empirical studies show that \abbr significantly improves the
performance of OOD detection over state-of-the-art methods. Specifically, \abbr
reduces the false positive rate (FPR95) by $23.23\%$ on the CIFAR-10 benchmarks
and $38\%$ on the ImageNet-1k benchmarks compared to the advanced methods.
Lastly, we theoretically verify the effectiveness of \abbr.
</p></li>
</ul>

<h2>hallucination</h2>
<h2>prompt</h2>
<h3>Title: Graph Prompt Learning: A Comprehensive Survey and Beyond. (arXiv:2311.16534v1 [cs.AI])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16534">http://arxiv.org/abs/2311.16534</a></li>
<li>Code URL: https://github.com/wxxshirley/awesome-graph-prompt</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16534]] Graph Prompt Learning: A Comprehensive Survey and Beyond(http://arxiv.org/abs/2311.16534)</code></li>
<li>Summary: <p>Artificial General Intelligence (AGI) has revolutionized numerous fields, yet
its integration with graph data, a cornerstone in our interconnected world,
remains nascent. This paper presents a pioneering survey on the emerging domain
of graph prompts in AGI, addressing key challenges and opportunities in
harnessing graph data for AGI applications. Despite substantial advancements in
AGI across natural language processing and computer vision, the application to
graph data is relatively underexplored. This survey critically evaluates the
current landscape of AGI in handling graph data, highlighting the distinct
challenges in cross-modality, cross-domain, and cross-task applications
specific to graphs. Our work is the first to propose a unified framework for
understanding graph prompt learning, offering clarity on prompt tokens, token
structures, and insertion patterns in the graph domain. We delve into the
intrinsic properties of graph prompts, exploring their flexibility,
expressiveness, and interplay with existing graph models. A comprehensive
taxonomy categorizes over 100 works in this field, aligning them with
pre-training tasks across node-level, edge-level, and graph-level objectives.
Additionally, we present, ProG, a Python library, and an accompanying website,
to support and advance research in graph prompting. The survey culminates in a
discussion of current challenges and future directions, offering a roadmap for
research in graph prompting within AGI. Through this comprehensive analysis, we
aim to catalyze further exploration and practical applications of AGI in graph
data, underlining its potential to reshape AGI fields and beyond. ProG and the
website can be accessed by
\url{https://github.com/WxxShirley/Awesome-Graph-Prompt}, and
\url{https://github.com/sheldonresearch/ProG}, respectively.
</p></li>
</ul>

<h3>Title: Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in Multi-Modal Fake News Detection. (arXiv:2311.16496v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16496">http://arxiv.org/abs/2311.16496</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16496]] Leveraging Out-of-Domain Data for Domain-Specific Prompt Tuning in Multi-Modal Fake News Detection(http://arxiv.org/abs/2311.16496)</code></li>
<li>Summary: <p>The spread of fake news using out-of-context images has become widespread and
is a challenging task in this era of information overload. Since annotating
huge amounts of such data requires significant time of domain experts, it is
imperative to develop methods which can work in limited annotated data
scenarios. In this work, we explore whether out-of-domain data can help to
improve out-of-context misinformation detection (termed here as multi-modal
fake news detection) of a desired domain, eg. politics, healthcare, etc.
Towards this goal, we propose a novel framework termed DPOD (Domain-specific
Prompt-tuning using Out-of-Domain data). First, to compute generalizable
features, we modify the Vision-Language Model, CLIP to extract features that
helps to align the representations of the images and corresponding text
captions of both the in-domain and out-of-domain data in a label-aware manner.
Further, we propose a domain-specific prompt learning technique which leverages
the training samples of all the available domains based on the the extent they
can be useful to the desired domain. Extensive experiments on a large-scale
benchmark dataset, namely NewsClippings demonstrate that the proposed framework
achieves state of-the-art performance, significantly surpassing the existing
approaches for this challenging task.
</p></li>
</ul>

<h2>code</h2>
<h3>Title: Reward Shaping for Improved Learning in Real-time Strategy Game Play. (arXiv:2311.16339v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16339">http://arxiv.org/abs/2311.16339</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16339]] Reward Shaping for Improved Learning in Real-time Strategy Game Play(http://arxiv.org/abs/2311.16339)</code></li>
<li>Summary: <p>We investigate the effect of reward shaping in improving the performance of
reinforcement learning in the context of the real-time strategy,
capture-the-flag game. The game is characterized by sparse rewards that are
associated with infrequently occurring events such as grabbing or capturing the
flag, or tagging the opposing player. We show that appropriately designed
reward shaping functions applied to different game events can significantly
improve the player's performance and training times of the player's learning
algorithm. We have validated our reward shaping functions within a simulated
environment for playing a marine capture-the-flag game between two players. Our
experimental results demonstrate that reward shaping can be used as an
effective means to understand the importance of different sub-tasks during
game-play towards winning the game, to encode a secondary objective functions
such as energy efficiency into a player's game-playing behavior, and, to
improve learning generalizable policies that can perform well against different
skill levels of the opponent.
</p></li>
</ul>

<h3>Title: Manifold Preserving Guided Diffusion. (arXiv:2311.16424v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16424">http://arxiv.org/abs/2311.16424</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16424]] Manifold Preserving Guided Diffusion(http://arxiv.org/abs/2311.16424)</code></li>
<li>Summary: <p>Despite the recent advancements, conditional image generation still faces
challenges of cost, generalizability, and the need for task-specific training.
In this paper, we propose Manifold Preserving Guided Diffusion (MPGD), a
training-free conditional generation framework that leverages pretrained
diffusion models and off-the-shelf neural networks with minimal additional
inference cost for a broad range of tasks. Specifically, we leverage the
manifold hypothesis to refine the guided diffusion steps and introduce a
shortcut algorithm in the process. We then propose two methods for on-manifold
training-free guidance using pre-trained autoencoders and demonstrate that our
shortcut inherently preserves the manifolds when applied to latent diffusion
models. Our experiments show that MPGD is efficient and effective for solving a
variety of conditional generation applications in low-compute settings, and can
consistently offer up to 3.8x speed-ups with the same number of diffusion steps
while maintaining high sample quality compared to the baselines.
</p></li>
</ul>

<h3>Title: MultiModal-Learning for Predicting Molecular Properties: A Framework Based on Image and Graph Structures. (arXiv:2311.16666v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16666">http://arxiv.org/abs/2311.16666</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16666]] MultiModal-Learning for Predicting Molecular Properties: A Framework Based on Image and Graph Structures(http://arxiv.org/abs/2311.16666)</code></li>
<li>Summary: <p>The quest for accurate prediction of drug molecule properties poses a
fundamental challenge in the realm of Artificial Intelligence Drug Discovery
(AIDD). An effective representation of drug molecules emerges as a pivotal
component in this pursuit. Contemporary leading-edge research predominantly
resorts to self-supervised learning (SSL) techniques to extract meaningful
structural representations from large-scale, unlabeled molecular data,
subsequently fine-tuning these representations for an array of downstream
tasks. However, an inherent shortcoming of these studies lies in their singular
reliance on one modality of molecular information, such as molecule image or
SMILES representations, thus neglecting the potential complementarity of
various molecular modalities. In response to this limitation, we propose MolIG,
a novel MultiModaL molecular pre-training framework for predicting molecular
properties based on Image and Graph structures. MolIG model innovatively
leverages the coherence and correlation between molecule graph and molecule
image to execute self-supervised tasks, effectively amalgamating the strengths
of both molecular representation forms. This holistic approach allows for the
capture of pivotal molecular structural characteristics and high-level semantic
information. Upon completion of pre-training, Graph Neural Network (GNN)
Encoder is used for the prediction of downstream tasks. In comparison to
advanced baseline models, MolIG exhibits enhanced performance in downstream
tasks pertaining to molecular property prediction within benchmark groups such
as MoleculeNet Benchmark Group and ADMET Benchmark Group.
</p></li>
</ul>

<h3>Title: Reducing Gender Bias in Machine Translation through Counterfactual Data Generation. (arXiv:2311.16362v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16362">http://arxiv.org/abs/2311.16362</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16362]] Reducing Gender Bias in Machine Translation through Counterfactual Data Generation(http://arxiv.org/abs/2311.16362)</code></li>
<li>Summary: <p>Recent advances in neural methods have led to substantial improvement in the
quality of Neural Machine Translation (NMT) systems. However, these systems
frequently produce translations with inaccurate gender (Stanovsky et al.,
2019), which can be traced to bias in training data. Saunders and Byrne (2020)
tackle this problem with a handcrafted dataset containing balanced gendered
profession words. By using this data to fine-tune an existing NMT model, they
show that gender bias can be significantly mitigated, albeit at the expense of
translation quality due to catastrophic forgetting. They recover some of the
lost quality with modified training objectives or additional models at
inference. We find, however, that simply supplementing the handcrafted dataset
with a random sample from the base model training corpus is enough to
significantly reduce the catastrophic forgetting. We also propose a novel
domain-adaptation technique that leverages in-domain data created with the
counterfactual data generation techniques proposed by Zmigrod et al. (2019) to
further improve accuracy on the WinoMT challenge test set without significant
loss in translation quality. We show its effectiveness in NMT systems from
English into three morphologically rich languages French, Spanish, and Italian.
The relevant dataset and code will be available at Github.
</p></li>
</ul>

<h3>Title: Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification. (arXiv:2311.16650v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16650">http://arxiv.org/abs/2311.16650</a></li>
<li>Code URL: https://github.com/jyansir/text2tree</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16650]] Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification(http://arxiv.org/abs/2311.16650)</code></li>
<li>Summary: <p>Deep learning approaches exhibit promising performances on various text
tasks. However, they are still struggling on medical text classification since
samples are often extremely imbalanced and scarce. Different from existing
mainstream approaches that focus on supplementary semantics with external
medical information, this paper aims to rethink the data challenges in medical
texts and present a novel framework-agnostic algorithm called Text2Tree that
only utilizes internal label hierarchy in training deep learning models. We
embed the ICD code tree structure of labels into cascade attention modules for
learning hierarchy-aware label representations. Two new learning schemes,
Similarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are
devised to boost text classification by reusing and distinguishing samples of
other labels following the label representation hierarchy, respectively.
Experiments on authoritative public datasets and real-world medical records
show that our approach stably achieves superior performances over classical and
advanced imbalanced classification methods.
</p></li>
</ul>

<h3>Title: A Distribution-Based Threshold for Determining Sentence Similarity. (arXiv:2311.16675v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16675">http://arxiv.org/abs/2311.16675</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16675]] A Distribution-Based Threshold for Determining Sentence Similarity(http://arxiv.org/abs/2311.16675)</code></li>
<li>Summary: <p>We hereby present a solution to a semantic textual similarity (STS) problem
in which it is necessary to match two sentences containing, as the only
distinguishing factor, highly specific information (such as names, addresses,
identification codes), and from which we need to derive a definition for when
they are similar and when they are not. The solution revolves around the use of
a neural network, based on the siamese architecture, to create the
distributions of the distances between similar and dissimilar pairs of
sentences. The goal of these distributions is to find a discriminating factor,
that we call "threshold", which represents a well-defined quantity that can be
used to distinguish vector distances of similar pairs from vector distances of
dissimilar pairs in new predictions and later analyses. In addition, we
developed a way to score the predictions by combining attributes from both the
distributions' features and the way the distance function works. Finally, we
generalize the results showing that they can be transferred to a wider range of
domains by applying the system discussed to a well-known and widely used
benchmark dataset for STS problems.
</p></li>
</ul>

<h3>Title: Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained Sentiment Analysis. (arXiv:2311.16678v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16678">http://arxiv.org/abs/2311.16678</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16678]] Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained Sentiment Analysis(http://arxiv.org/abs/2311.16678)</code></li>
<li>Summary: <p>Product reviews often contain a large number of implicit aspects and
object-attribute co-existence cases. Unfortunately, many existing studies in
Aspect-Based Sentiment Analysis (ABSA) have overlooked this issue, which can
make it difficult to extract opinions comprehensively and fairly. In this
paper, we propose a new task called Entity-Aspect-Opinion-Sentiment Quadruple
Extraction (EASQE), which aims to hierarchically decompose aspect terms into
entities and aspects to avoid information loss, non-exclusive annotations, and
opinion misunderstandings in ABSA tasks. To facilitate research in this new
task, we have constructed four datasets (Res14-EASQE, Res15-EASQE, Res16-EASQE,
and Lap14-EASQE) based on the SemEval Restaurant and Laptop datasets. We have
also proposed a novel two-stage sequence-tagging based Trigger-Opinion
framework as the baseline for the EASQE task. Empirical evaluations show that
our Trigger-Opinion framework can generate satisfactory EASQE results and can
also be applied to other ABSA tasks, significantly outperforming
state-of-the-art methods. We have made the four datasets and source code of
Trigger-Opinion publicly available to facilitate further research in this area.
</p></li>
</ul>

<h3>Title: Radiology-Aware Model-Based Evaluation Metric for Report Generation. (arXiv:2311.16764v1 [cs.CL])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16764">http://arxiv.org/abs/2311.16764</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16764]] Radiology-Aware Model-Based Evaluation Metric for Report Generation(http://arxiv.org/abs/2311.16764)</code></li>
<li>Summary: <p>We propose a new automated evaluation metric for machine-generated radiology
reports using the successful COMET architecture adapted for the radiology
domain. We train and publish four medically-oriented model checkpoints,
including one trained on RadGraph, a radiology knowledge graph. Our results
show that our metric correlates moderately to high with established metrics
such as BERTscore, BLEU, and CheXbert scores. Furthermore, we demonstrate that
one of our checkpoints exhibits a high correlation with human judgment, as
assessed using the publicly available annotations of six board-certified
radiologists, using a set of 200 reports. We also performed our own analysis
gathering annotations with two radiologists on a collection of 100 reports. The
results indicate the potential effectiveness of our method as a
radiology-specific evaluation metric. The code, data, and model checkpoints to
reproduce our findings will be publicly available.
</p></li>
</ul>

<h3>Title: Ultra-short-term multi-step wind speed prediction for wind farms based on adaptive noise reduction technology and temporal convolutional network. (arXiv:2311.16198v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16198">http://arxiv.org/abs/2311.16198</a></li>
<li>Code URL: https://github.com/jethrojames/wind-speed-forecast-tcn_gru</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16198]] Ultra-short-term multi-step wind speed prediction for wind farms based on adaptive noise reduction technology and temporal convolutional network(http://arxiv.org/abs/2311.16198)</code></li>
<li>Summary: <p>As an important clean and renewable kind of energy, wind power plays an
important role in coping with energy crisis and environmental pollution.
However, the volatility and intermittency of wind speed restrict the
development of wind power. To improve the utilization of wind power, this study
proposes a new wind speed prediction model based on data noise reduction
technology, temporal convolutional network (TCN), and gated recurrent unit
(GRU). Firstly, an adaptive data noise reduction algorithm P-SSA is proposed
based on singular spectrum analysis (SSA) and Pearson correlation coefficient.
The original wind speed is decomposed into multiple subsequences by SSA and
then reconstructed. When the Pearson correlation coefficient between the
reconstructed sequence and the original sequence is greater than 0.99, other
noise subsequences are deleted to complete the data denoising. Then, the
receptive field of the samples is expanded through the causal convolution and
dilated convolution of TCN, and the characteristics of wind speed change are
extracted. Then, the time feature information of the sequence is extracted by
GRU, and then the wind speed is predicted to form the wind speed sequence
prediction model of P-SSA-TCN-GRU. The proposed model was validated on three
wind farms in Shandong Province. The experimental results show that the
prediction performance of the proposed model is better than that of the
traditional model and other models based on TCN, and the wind speed prediction
of wind farms with high precision and strong stability is realized. The wind
speed predictions of this model have the potential to become the data that
support the operation and management of wind farms. The code is available at
link.
</p></li>
</ul>

<h3>Title: Target-Free Compound Activity Prediction via Few-Shot Learning. (arXiv:2311.16328v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16328">http://arxiv.org/abs/2311.16328</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16328]] Target-Free Compound Activity Prediction via Few-Shot Learning(http://arxiv.org/abs/2311.16328)</code></li>
<li>Summary: <p>Predicting the activities of compounds against protein-based or phenotypic
assays using only a few known compounds and their activities is a common task
in target-free drug discovery. Existing few-shot learning approaches are
limited to predicting binary labels (active/inactive). However, in real-world
drug discovery, degrees of compound activity are highly relevant. We study
Few-Shot Compound Activity Prediction (FS-CAP) and design a novel neural
architecture to meta-learn continuous compound activities across large
bioactivity datasets. Our model aggregates encodings generated from the known
compounds and their activities to capture assay information. We also introduce
a separate encoder for the unknown compound. We show that FS-CAP surpasses
traditional similarity-based techniques as well as other state of the art
few-shot learning methods on a variety of target-free drug discovery settings
and datasets.
</p></li>
</ul>

<h3>Title: Cross Entropy in Deep Learning of Classifiers Is Unnecessary -- ISBE Error is All You Need. (arXiv:2311.16357v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16357">http://arxiv.org/abs/2311.16357</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16357]] Cross Entropy in Deep Learning of Classifiers Is Unnecessary -- ISBE Error is All You Need(http://arxiv.org/abs/2311.16357)</code></li>
<li>Summary: <p>In deep learning classifiers, the cost function usually takes the form of a
combination of SoftMax and CrossEntropy functions. The SoftMax unit transforms
the scores predicted by the model network into assessments of the degree
(probabilities) of an object's membership to a given class. On the other hand,
CrossEntropy measures the divergence of this prediction from the distribution
of target scores. This work introduces the ISBE functionality, justifying the
thesis about the redundancy of cross entropy computation in deep learning of
classifiers. Not only can we omit the calculation of entropy, but also, during
back-propagation, there is no need to direct the error to the normalization
unit for its backward transformation. Instead, the error is sent directly to
the model's network. Using examples of perceptron and convolutional networks as
classifiers of images from the MNIST collection, it is observed for ISBE that
results are not degraded with SoftMax only, but also with other activation
functions such as Sigmoid, Tanh, or their hard variants HardSigmoid and
HardTanh. Moreover, up to three percent of time is saved within the total time
of forward and backward stages. The article is addressed mainly to programmers
and students interested in deep model learning. For example, it illustrates in
code snippets possible ways to implement ISBE units, but also formally proves
that the softmax trick only applies to the class of softmax functions with
relocations.
</p></li>
</ul>

<h3>Title: Contrastive encoder pre-training-based clustered federated learning for heterogeneous data. (arXiv:2311.16535v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16535">http://arxiv.org/abs/2311.16535</a></li>
<li>Code URL: null</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16535]] Contrastive encoder pre-training-based clustered federated learning for heterogeneous data(http://arxiv.org/abs/2311.16535)</code></li>
<li>Summary: <p>Federated learning (FL) is a promising approach that enables distributed
clients to collaboratively train a global model while preserving their data
privacy. However, FL often suffers from data heterogeneity problems, which can
significantly affect its performance. To address this, clustered federated
learning (CFL) has been proposed to construct personalized models for different
client clusters. One effective client clustering strategy is to allow clients
to choose their own local models from a model pool based on their performance.
However, without pre-trained model parameters, such a strategy is prone to
clustering failure, in which all clients choose the same model. Unfortunately,
collecting a large amount of labeled data for pre-training can be costly and
impractical in distributed environments. To overcome this challenge, we
leverage self-supervised contrastive learning to exploit unlabeled data for the
pre-training of FL systems. Together, self-supervised pre-training and client
clustering can be crucial components for tackling the data heterogeneity issues
of FL. Leveraging these two crucial strategies, we propose contrastive
pre-training-based clustered federated learning (CP-CFL) to improve the model
convergence and overall performance of FL systems. In this work, we demonstrate
the effectiveness of CP-CFL through extensive experiments in heterogeneous FL
settings, and present various interesting observations.
</p></li>
</ul>

<h3>Title: Scalable Label Distribution Learning for Multi-Label Classification. (arXiv:2311.16556v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16556">http://arxiv.org/abs/2311.16556</a></li>
<li>Code URL: https://github.com/ailearn-ml/sldl</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16556]] Scalable Label Distribution Learning for Multi-Label Classification(http://arxiv.org/abs/2311.16556)</code></li>
<li>Summary: <p>Multi-label classification (MLC) refers to the problem of tagging a given
instance with a set of relevant labels. Most existing MLC methods are based on
the assumption that the correlation of two labels in each label pair is
symmetric, which is violated in many real-world scenarios. Moreover, most
existing methods design learning processes associated with the number of
labels, which makes their computational complexity a bottleneck when scaling up
to large-scale output space. To tackle these issues, we propose a novel MLC
learning method named Scalable Label Distribution Learning (SLDL) for
multi-label classification which can describe different labels as distributions
in a latent space, where the label correlation is asymmetric and the dimension
is independent of the number of labels. Specifically, SLDL first converts
labels into continuous distributions within a low-dimensional latent space and
leverages the asymmetric metric to establish the correlation between different
labels. Then, it learns the mapping from the feature space to the latent space,
resulting in the computational complexity is no longer related to the number of
labels. Finally, SLDL leverages a nearest-neighbor-based strategy to decode the
latent representations and obtain the final predictions. Our extensive
experiments illustrate that SLDL can achieve very competitive classification
performances with little computational consumption.
</p></li>
</ul>

<h3>Title: PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network. (arXiv:2311.16670v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16670">http://arxiv.org/abs/2311.16670</a></li>
<li>Code URL: https://github.com/graphpku/pygho</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16670]] PyTorch Geometric High Order: A Unified Library for High Order Graph Neural Network(http://arxiv.org/abs/2311.16670)</code></li>
<li>Summary: <p>We introduce PyTorch Geometric High Order (PyGHO), a library for High Order
Graph Neural Networks (HOGNNs) that extends PyTorch Geometric (PyG). Unlike
ordinary Message Passing Neural Networks (MPNNs) that exchange messages between
nodes, HOGNNs, encompassing subgraph GNNs and k-WL GNNs, encode node tuples, a
method previously lacking a standardized framework and often requiring complex
coding. PyGHO's main objective is to provide an unified and user-friendly
interface for various HOGNNs. It accomplishes this through streamlined data
structures for node tuples, comprehensive data processing utilities, and a
flexible suite of operators for high-order GNN methodologies. In this work, we
present a detailed in-depth of PyGHO and compare HOGNNs implemented with PyGHO
with their official implementation on real-world tasks. PyGHO achieves up to
$50\%$ acceleration and reduces the code needed for implementation by an order
of magnitude. Our library is available at
\url{https://github.com/GraphPKU/PygHO}.
</p></li>
</ul>

<h2>chat</h2>
<h3>Title: ChatTraffc: Text-to-Traffic Generation via Diffusion Model. (arXiv:2311.16203v1 [cs.LG])</h3>
<ul>
<li>Paper URL: <a href="http://arxiv.org/abs/2311.16203">http://arxiv.org/abs/2311.16203</a></li>
<li>Code URL: https://github.com/ChyaZhang/ChatTraffic</li>
<li>Copy Paste: <code><input type="checkbox">[[2311.16203]] ChatTraffc: Text-to-Traffic Generation via Diffusion Model(http://arxiv.org/abs/2311.16203)</code></li>
<li>Summary: <p>Traffic prediction is one of the most significant foundations in Intelligent
Transportation Systems (ITS). Traditional traffic prediction methods rely only
on historical traffic data to predict traffic trends and face two main
challenges. 1) insensitivity to unusual events. 2) poor performance in
long-term prediction. In this work, we explore how generative models combined
with text describing the traffic system can be applied for traffic generation
and name the task Text-to-Traffic Generation (TTG). The key challenge of the
TTG task is how to associate text with the spatial structure of the road
network and traffic data for generating traffic situations. To this end, we
propose ChatTraffic, the first diffusion model for text-to-traffic generation.
To guarantee the consistency between synthetic and real data, we augment a
diffusion model with the Graph Convolutional Network (GCN) to extract spatial
correlations of traffic data. In addition, we construct a large dataset
containing text-traffic pairs for the TTG task. We benchmarked our model
qualitatively and quantitatively on the released dataset. The experimental
results indicate that ChatTraffic can generate realistic traffic situations
from the text. Our code and dataset are available at
https://github.com/ChyaZhang/ChatTraffic.
</p></li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="https://cdn.staticfile.org/clipboard.js/2.0.4/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
