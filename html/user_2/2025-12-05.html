<link rel="stylesheet" href="../../css/markdown.css" />
<article class="markdown-body">
<h1>2025-12-05</h1>
<h3>Title: On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral</h3>
<ul>
<li><strong>Authors: </strong>Wenlong Deng, Yushu Li, Boying Gong, Yi Ren, Christos Thrampoulidis, Xiaoxiao Li</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04220">https://arxiv.org/abs/2512.04220</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04220">https://arxiv.org/pdf/2512.04220</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04220]] On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral(https://arxiv.org/abs/2512.04220)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory's likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.</li>
<li><strong>摘要：</strong>工具集成 (TI) 强化学习 (RL) 使大型语言模型 (LLM) 能够通过与搜索引擎和检索器等外部工具交互来执行多步骤推理。以最近的 Search-R1 为代表的组相对策略优化 (GRPO) 提供了快速收敛和无价值的公式，使其对这种设置很有吸引力，但始终遭受训练崩溃的困扰。我们将惰性似然位移（LLD）（正确和错误响应的可能性的系统性降低或停滞）确定为导致这种失败的核心机制。 LLD 出现较早，并引发自我强化的 LLD 死亡螺旋，其中可能性下降导致低置信度响应、梯度增大，最终导致崩溃。我们在 Search-R1 式的搜索集成问答任务模型中凭经验描述了这一过程，揭示了一致的三阶段轨迹：早期停滞、稳定衰退和加速崩溃。为了解决这个问题，我们为 GRPO 提出了一种轻量级的保留似然正则化 LLDS，它仅在轨迹的似然降低时激活，并且仅对负责的标记进行正则化。这种细粒度的结构可以减轻 LLD，同时对优化的干扰最小。在七个开放域和多跳 QA 基准测试中，我们的方法稳定了训练，防止梯度爆炸，并产生了显着的性能改进，包括 Qwen2.5-3B 上 +37.8% 的增益和 Qwen2.5-7B 上 +32.0% 的增益。我们的结果将 LLD 确定为基于 GRPO 的 TIRL 的基本瓶颈，并为工具集成的 LLM 的稳定、可扩展培训提供了一条实用途径。</li>
</ul>

<h3>Title: SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats</h3>
<ul>
<li><strong>Authors: </strong>Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04292">https://arxiv.org/abs/2512.04292</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04292">https://arxiv.org/pdf/2512.04292</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04292]] SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats(https://arxiv.org/abs/2512.04292)</code><input type="text"></li>
<li><strong>Keywords: </strong>gpt, chat, agent</a></li>
<li><strong>Abstract: </strong>Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.</li>
<li><strong>摘要：</strong>由于多行标题、合并单元格和单元注释会破坏原始分块，因此对真实电子表格进行准确的问答仍然很困难，而严格的 SQL 视图在缺乏一致架构的文件上会失败。我们提出了 SQuARE，一种具有工作表级、复杂性感知路由的混合检索框架。它根据标头深度和合并密度计算连续分数，然后通过保留结构的块检索或基于自动构建的关系表示的 SQL 来路由查询。当置信度较低时，轻量级代理会监督两条路径上的检索、细化或结果组合。此设计维护标头层次结构、时间标签和单位，确保返回的值忠实于原始单元格并且易于验证。经过对多表头企业资产负债表、高度合并的世界银行工作簿和多样化公共数据集的评估，SQuARE 在检索精度和端到端答案准确性方面始终超越单策略基线和 ChatGPT-4o，同时保持延迟可预测。通过将检索与模型选择分离，该系统与新兴的表格基础模型兼容，并为更强大的表格理解提供了一座实用的桥梁。</li>
</ul>

<h3>Title: DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle</h3>
<ul>
<li><strong>Authors: </strong>Fangyu Lei, Jinxiang Meng, Yiming Huang, Junjie Zhao, Yitong Zhang, Jianwen Luo, Xin Zou, Ruiyi Yang, Wenbo Shi, Yan Gao, Shizhu He, Zuo Wang, Qian Liu, Yang Wang, Ke Wang, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04324">https://arxiv.org/abs/2512.04324</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04324">https://arxiv.org/pdf/2512.04324</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04324]] DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle(https://arxiv.org/abs/2512.04324)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm, agent</a></li>
<li><strong>Abstract: </strong>Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks that mirrors these complex workflows. Data engineering (DE) tasks require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving requirements. Data analysis (DA) tasks pose open-ended business problems that demand strategic planning, exploratory analysis through iterative coding, interpretation of intermediate results, and the synthesis of actionable recommendations. Engineering tasks are scored through execution-based, multi-metric evaluation. Open-ended tasks are assessed by a reliable, experimentally validated LLM-judge, which is guided by hierarchical, meticulously crafted rubrics. Our experiments reveal that even state-of-the-art agents falter on DAComp. Performance on DE tasks is particularly low, with success rates under 20%, exposing a critical bottleneck in holistic pipeline orchestration, not merely code generation. Scores on DA tasks also average below 40%, highlighting profound deficiencies in open-ended reasoning and demonstrating that engineering and analysis are distinct capabilities. By clearly diagnosing these limitations, DAComp provides a rigorous and realistic testbed to drive the development of truly capable autonomous data agents for enterprise settings. Our data and code are available at this https URL</li>
<li><strong>摘要：</strong>现实世界的企业数据智能工作流程包括将原始数据源转化为可分析的表格的数据工程，以及将这些表格转化为面向决策的见解的数据分析。我们引入了 DAComp，这是一个包含 210 项任务的基准，反映了这些复杂的工作流程。数据工程 (DE) 任务需要对工业模式进行存储库级工程，包括从头开始设计和构建多阶段 SQL 管道，以及根据不断变化的需求改进现有系统。数据分析 (DA) 任务提出了开放式业务问题，需要战略规划、通过迭代编码进行探索性分析、解释中间结果以及综合可行的建议。工程任务通过基于执行的多指标评估进行评分。开放式任务由可靠的、经过实验验证的法学硕士评审进行评估，该评审以分层的、精心设计的评估标准为指导。我们的实验表明，即使是最先进的代理在 DAComp 上也会出现问题。 DE 任务的性能特别低，成功率低于 20%，暴露了整体管道编排的关键瓶颈，而不仅仅是代码生成。 DA 任务的平均得分也低于 40%，凸显了开放式推理的严重缺陷，并表明工程和分析是截然不同的能力。通过清楚地诊断这些限制，DAComp 提供了严格且现实的测试平台，以推动为企业环境开发真正强大的自主数据代理。我们的数据和代码可在此 https URL 获取</li>
</ul>

<h3>Title: ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation</h3>
<ul>
<li><strong>Authors: </strong>Yiming Xu, Yuan Yuan, Vijay Viswanathan, Graham Neubig</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04350">https://arxiv.org/abs/2512.04350</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04350">https://arxiv.org/pdf/2512.04350</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04350]] ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation(https://arxiv.org/abs/2512.04350)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong contextual reasoning, yet prior work mainly uses them as auxiliary modules to refine embeddings or adjust cluster boundaries. We propose ClusterFusion, a hybrid framework that instead treats the LLM as the clustering core, guided by lightweight embedding methods. The framework proceeds in three stages: embedding-guided subset partition, LLM-driven topic summarization, and LLM-based topic assignment. This design enables direct incorporation of domain knowledge and user preferences, fully leveraging the contextual adaptability of LLMs. Experiments on three public benchmarks and two new domain-specific datasets demonstrate that ClusterFusion not only achieves state-of-the-art performance on standard tasks but also delivers substantial gains in specialized domains. To support future work, we release our newly constructed dataset and results on all benchmarks.</li>
<li><strong>摘要：</strong>文本聚类是自然语言处理中的一项基本任务，但具有预先训练嵌入的传统聚类算法通常在特定领域的上下文中陷入困境，而无需进行昂贵的微调。大型语言模型（LLM）提供了强大的上下文推理，但之前的工作主要将它们用作辅助模块来细化嵌入或调整集群边界。我们提出了 ClusterFusion，这是一种混合框架，它将 LLM 作为聚类核心，并以轻量级嵌入方法为指导。该框架分三个阶段进行：嵌入引导的子集划分、LLM 驱动的主题摘要和基于 LLM 的主题分配。这种设计可以直接整合领域知识和用户偏好，充分利用法学硕士的情境适应性。在三个公共基准和两个新的特定领域数据集上进行的实验表明，ClusterFusion 不仅在标准任务上实现了最先进的性能，而且还在专业领域中提供了巨大的收益。为了支持未来的工作，我们发布了新构建的数据集和所有基准的结果。</li>
</ul>

<h3>Title: LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving</h3>
<ul>
<li><strong>Authors: </strong>Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.FL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04374">https://arxiv.org/abs/2512.04374</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04374">https://arxiv.org/pdf/2512.04374</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04374]] LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving(https://arxiv.org/abs/2512.04374)</code><input type="text"></li>
<li><strong>Keywords: </strong>agent</a></li>
<li><strong>Abstract: </strong>Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.</li>
<li><strong>摘要：</strong>我们的工作提出了一种基于强化学习（RL）的新颖框架，以优化冲突驱动子句学习（CDCL）过程中的启发式选择，提高布尔可满足性（SAT）求解的效率。所提出的系统 LangSAT 通过将英语描述转换为连接范式 (CNF) 表达式并使用 RL 增强型 CDCL SAT 求解器来求解，从而弥合了自然语言输入和命题逻辑之间的差距。与需要 CNF 作为输入的现有 SAT 解题平台不同，LangSAT 允许用户输入标准的英语描述，使 SAT 解题更容易使用。该框架由两个关键组件组成：Lang2Logic（将英语句子翻译为 CNF 表达式）和 SmartSAT（基于 RL 的 SAT 求解器）。 SmartSAT 将子句变量关系编码为结构化图表示，并提取特定于 SAT 问题的全局特征。此实现为 RL 代理提供了更深入的上下文信息，使 SAT 问题能够更有效地解决。 Lang2Logic 在各种自然语言输入上进行了评估，可处理最多 450 个单词的描述。生成的 CNF 由 SmartSAT 求解，该算法在求解时间方面表现出与传统 CDCL 启发式算法相当的性能。组合的 LangSAT 框架为跨推理、形式验证和调试的 SAT 解决任务提供了更易于访问和扩展的解决方案。</li>
</ul>

<h3>Title: RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning</h3>
<ul>
<li><strong>Authors: </strong>Guoshenghui Zhao, Huawei Lin, Weijie Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04457">https://arxiv.org/abs/2512.04457</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04457">https://arxiv.org/pdf/2512.04457</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04457]] RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning(https://arxiv.org/abs/2512.04457)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and parameter-efficient unlearning framework. It first estimates per-sample influence through a fast estimation module, then maps these scores into adaptive update weights that guide selective parameter updates -- forgetting harmful behavior while retaining general knowledge. On Mistral-7B and Llama-3-8B across Dolly-15k and Alpaca-57k, RapidUn achieves up to 100 times higher efficiency than full retraining and consistently outperforms Fisher, GA, and LoReUn on both in-distribution and out-of-distribution forgetting. These results establish influence-guided parameter reweighting as a scalable and interpretable paradigm for LLM unlearning.</li>
<li><strong>摘要：</strong>消除大型语言模型 (LLM) 中特定数据的影响仍然具有挑战性，因为再训练成本高昂，而且现有的近似忘却方法通常不稳定。当遗忘集较小或不平衡时，挑战会加剧。我们介绍 RapidUn，一个影响力驱动且参数高效的忘却框架。它首先通过快速估计模块估计每个样本的影响，然后将这些分数映射到自适应更新权重，以指导选择性参数更新——在保留一般知识的同时忘记有害行为。在 Dolly-15k 和 Alpaca-57k 的 Mistral-7B 和 Llama-3-8B 上，RapidUn 的效率比完全再训练高出 100 倍，并且在分布内和分布外遗忘方面始终优于 Fisher、GA 和 LoReUn。这些结果将影响引导的参数重新加权作为法学硕士遗忘的可扩展和可解释的范例。</li>
</ul>

<h3>Title: MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection</h3>
<ul>
<li><strong>Authors: </strong>Yuanshuo Zhang, Aohua Li, Bo Chen, Jingbo Sun, Xiaobing Zhao</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04492">https://arxiv.org/abs/2512.04492</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04492">https://arxiv.org/pdf/2512.04492</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04492]] MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection(https://arxiv.org/abs/2512.04492)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm</a></li>
<li><strong>Abstract: </strong>LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve compound entities or events that must be explicitly linked to stance labels, and rhetorical devices such as irony often obscure the author's actual intent. To address these challenges, we propose MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection. MSME consists of three stages: (1) Knowledge Preparation, where relevant background knowledge is retrieved and stance labels are clarified; (2) Expert Reasoning, involving three specialized modules-Knowledge Expert distills salient facts and reasons from a knowledge perspective, Label Expert refines stance labels and reasons accordingly, and Pragmatic Expert detects rhetorical cues such as irony to infer intent from a pragmatic angle; (3) Decision Aggregation, where a Meta-Judge integrates all expert analyses to produce the final stance prediction. Experiments on three public datasets show that MSME achieves state-of-the-art performance across the board.</li>
<li><strong>摘要：</strong>基于法学硕士的方法最近在零样本姿态检测方面取得了令人印象深刻的成果。然而，他们仍然在复杂的现实场景中挣扎，其中立场理解需要动态背景知识，目标定义涉及必须与立场标签明确链接的复合实体或事件，而反讽等修辞手段常常掩盖作者的实际意图。为了应对这些挑战，我们提出了 MSME，这是一种用于零镜头姿态检测的多阶段、多专家框架。 MSME由三个阶段组成：（1）知识准备，检索相关背景知识并澄清立场标签； （2）专家推理，涉及三个专业模块——知识专家从知识角度提炼显着事实和理由，标签专家相应提炼立场标签和理由，语用专家检测反讽等修辞线索，从语用角度推断意图； (3) 决策聚合，元法官整合所有专家分析以产生最终立场预测。对三个公共数据集的实验表明，MSME 全面实现了最先进的性能。</li>
</ul>

<h3>Title: UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction</h3>
<ul>
<li><strong>Authors: </strong>Tianmai M. Zhang, Zhaoyi Sun, Sihang Zeng, Chenxi Li, Neil F. Abernethy, Barbara D. Lam, Fei Xia, Meliha Yetisgen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04518">https://arxiv.org/abs/2512.04518</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04518">https://arxiv.org/pdf/2512.04518</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04518]] UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction(https://arxiv.org/abs/2512.04518)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm, chain-of-thought</a></li>
<li><strong>Abstract: </strong>The ChemoTimelines shared task benchmarks methods for constructing timelines of systemic anticancer treatment from electronic health records of cancer patients. This paper describes our methods, results, and findings for subtask 2 -- generating patient chemotherapy timelines from raw clinical notes. We evaluated strategies involving chain-of-thought thinking, supervised fine-tuning, direct preference optimization, and dictionary-based lookup to improve timeline extraction. All of our approaches followed a two-step workflow, wherein an LLM first extracted chemotherapy events from individual clinical notes, and then an algorithm normalized and aggregated events into patient-level timelines. Each specific method differed in how the associated LLM was utilized and trained. Multiple approaches yielded competitive performances on the test set leaderboard, with fine-tuned Qwen3-14B achieving the best official score of 0.678. Our results and analyses could provide useful insights for future attempts on this task as well as the design of similar tasks.</li>
<li><strong>摘要：</strong>ChemoTimelines 共享了根据癌症患者的电子健康记录构建全身抗癌治疗时间表的任务基准方法。本文描述了我们的子任务 2 的方法、结果和发现——根据原始临床记录生成患者化疗时间表。我们评估了涉及思想链思维、监督微调、直接偏好优化和基于字典的查找的策略，以改进时间线提取。我们所有的方法都遵循两步工作流程，其中法学硕士首先从个人临床记录中提取化疗事件，然后算法将事件标准化并汇总到患者级别的时间线中。每种具体方法的不同之处在于如何利用和培训相关的法学硕士。多种方法在测试集排行榜上取得了具有竞争力的表现，经过微调的 Qwen3-14B 取得了 0.678 的最佳官方分数。我们的结果和分析可以为未来对该任务的尝试以及类似任务的设计提供有用的见解。</li>
</ul>

<h3>Title: EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion</h3>
<ul>
<li><strong>Authors: </strong>Pengfei Cao, Zeao Ji, Daojian Zeng, Jun Zhao, Kang Liu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04545">https://arxiv.org/abs/2512.04545</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04545">https://arxiv.org/pdf/2512.04545</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04545]] EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion(https://arxiv.org/abs/2512.04545)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch. However, existing methods suffer from two limitations. First, they depend on structured triplets that are misaligned with the free-text nature of LLM pretraining and fail to capture the nuanced relationships among facts. Second, they typically support one-time knowledge updates, with relatively limited research on the problem of sequential or lifelong editing. To address these gaps, we propose a new task, Lifelong Free-text Knowledge Editing (LF-Edit), which enables models to incorporate updates expressed in natural language and supports continual editing over time. Despite its promise, LF-Edit faces the dual challenge of integrating new knowledge while mitigating the forgetting of prior information. To foster research on this new task, we construct a large-scale benchmark, Multi-Rank Lifelong Free-text Editing Benchmark (MRLF-Bench), containing 16,835 free-text edit requests. We further design a cognitively inspired multi-rank evaluation framework encompassing four levels: memorization, understanding, constrained comprehension, and reasoning. To tackle the challenges inherent in LF-Edit, we introduce a novel approach named EvoEdit that enhances knowledge injection through Latent Perturbation Augmentation and preserves prior information via Knowledge-driven Parameter Fusion. Experimental results demonstrate that EvoEdit substantially outperforms existing knowledge editing methods on the proposed LF-Edit task.</li>
<li><strong>摘要：</strong>在部署后调整大型语言模型 (LLM) 的过时知识仍然是一项重大挑战。这种困难刺激了知识编辑的发展，它寻求准确有效地修改模型的内部（参数）知识，而无需从头开始重新训练。然而，现有方法存在两个局限性。首先，它们依赖于结构化的三元组，而这些三元组与法学硕士预训练的自由文本性质不一致，并且无法捕捉事实之间的微妙关系。其次，它们通常支持一次性知识更新，而对顺序或终身编辑问题的研究相对有限。为了解决这些差距，我们提出了一项新任务：终身自由文本知识编辑（LF-Edit），它使模型能够合并以自然语言表达的更新，并支持随着时间的推移持续编辑。尽管有这样的承诺，LF-Edit 仍面临着整合新知识和减少先前信息遗忘的双重挑战。为了促进对这项新任务的研究，我们构建了一个大规模基准，多等级终身自由文本编辑基准（MRLF-Bench），包含 16,835 个自由文本编辑请求。我们进一步设计了一个认知启发的多等级评估框架，涵盖四个层次：记忆、理解、约束理解和推理。为了解决 LF-Edit 固有的挑战，我们引入了一种名为 EvoEdit 的新颖方法，该方法通过潜在扰动增强增强知识注入，并通过知识驱动的参数融合保留先验信息。实验结果表明，EvoEdit 在所提出的 LF-Edit 任务上明显优于现有的知识编辑方法。</li>
</ul>

<h3>Title: AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees</h3>
<ul>
<li><strong>Authors: </strong>Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04550">https://arxiv.org/abs/2512.04550</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04550">https://arxiv.org/pdf/2512.04550</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04550]] AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees(https://arxiv.org/abs/2512.04550)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, long context</a></li>
<li><strong>Abstract: </strong>The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.</li>
<li><strong>摘要：</strong>自注意力的二次复杂性限制了大型语言模型（LLM）处理长上下文的能力，而这对于许多高级应用程序来说是必不可少的能力。上下文压缩旨在缓解这种计算瓶颈，同时保留关键语义信息。然而，现有的方法往往存在不足：显式方法可能会损害局部细节，而隐式方法可能会遭受位置偏差、信息退化或无法捕获远程语义依赖性的问题。我们提出了 AdmTree，这是一种用于自适应、分层上下文压缩的新颖框架，其核心重点是在保持效率的同时保持高语义保真度。 AdmTree 根据信息密度动态分段输入，利用 gist token 将可变长度分段总结为语义二叉树的叶子。这种结构与轻量级聚合机制和冻结骨干 LLM（从而最大限度地减少新的可训练参数）一起，实现了上下文的高效分层抽象。通过保留细粒度细节以及全局语义一致性、减轻位置偏差并动态适应内容，AdmTree 稳健地保留了长上下文的语义信息。</li>
</ul>

<h3>Title: ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning</h3>
<ul>
<li><strong>Authors: </strong>Pritam Kadasi, Abhishek Upperwal, Mayank SIngh</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04555">https://arxiv.org/abs/2512.04555</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04555">https://arxiv.org/pdf/2512.04555</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04555]] ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning(https://arxiv.org/abs/2512.04555)</code><input type="text"></li>
<li><strong>Keywords: </strong>llm</a></li>
<li><strong>Abstract: </strong>We propose ADAPT, a meta-learning algorithm that \emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1\%$, $5\%$, and $10\%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.</li>
<li><strong>摘要：</strong>我们提出了 ADAPT，一种元学习算法，可以在显式令牌预算下学习任务采样比例，以进行多任务指令调整。 \adapt{} 不是手动固定任务权重，而是保持任务的连续分布，并通过平滑的最坏情况验证目标的元梯度进行更新，从而引入自适应课程，将更多令牌分配给有用的任务，同时避免崩溃。我们在三个 $\sim$1B 参数开放权重 LLM（Gemma-3-1B、LLaMA-3.2-1B、Qwen-0.6B）上实例化 ADAPT，在可用监督令牌的预算为 $1\%$、$5\%$ 和 $10\%$ 下对 20 种自然指令任务类型进行训练，并与具有均匀和大小比例混合的强监督微调基线进行比较。我们对 11 个域外基准进行评估，涵盖推理、阅读理解、代码生成和指令跟踪，我们发现 ADAPT 相对于最佳静态混合匹配或略微提高了平均下游性能，同时使用更少的有效训练令牌并将预算重新分配给更困难的、基准对齐的任务。</li>
</ul>

<h3>Title: LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence</h3>
<ul>
<li><strong>Authors: </strong>Wenjin Liu, Haoran Luo, Xin Feng, Xiang Ji, Lijuan Zhou, Rui Mao, Jiapu Wang, Shirui Pan, Erik Cambria</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04578">https://arxiv.org/abs/2512.04578</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04578">https://arxiv.org/pdf/2512.04578</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04578]] LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence(https://arxiv.org/abs/2512.04578)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Legal general intelligence (GI) refers to artificial intelligence (AI) that encompasses legal understanding, reasoning, and decision-making, simulating the expertise of legal experts across domains. However, existing benchmarks are result-oriented and fail to systematically evaluate the legal intelligence of large language models (LLMs), hindering the development of legal GI. To address this, we propose LexGenius, an expert-level Chinese legal benchmark for evaluating legal GI in LLMs. It follows a Dimension-Task-Ability framework, covering seven dimensions, eleven tasks, and twenty abilities. We use the recent legal cases and exam questions to create multiple-choice questions with a combination of manual and LLM reviews to reduce data leakage risks, ensuring accuracy and reliability through multiple rounds of checks. We evaluate 12 state-of-the-art LLMs using LexGenius and conduct an in-depth analysis. We find significant disparities across legal intelligence abilities for LLMs, with even the best LLMs lagging behind human legal professionals. We believe LexGenius can assess the legal intelligence abilities of LLMs and enhance legal GI development. Our project is available at this https URL.</li>
<li><strong>摘要：</strong>法律通用智能（GI）是指涵盖法律理解、推理和决策的人工智能（AI），模拟跨领域法律专家的专业知识。然而，现有基准以结果为导向，未能系统地评估大语言模型（LLM）的法律智能，阻碍了法律地理标志的发展。为了解决这个问题，我们提出了 LexGenius，这是一个专家级的中国法律基准，用于评估法学硕士的合法地理标志。它遵循维度-任务-能力框架，涵盖七个维度、十一个任务和二十个能力。我们利用近期的法律案例和考试题目，通过人工审核和LLM审核相结合的方式制作选择题，以降低数据泄露风险，通过多轮检查确保准确性和可靠性。我们使用 LexGenius 评估 12 个最先进的法学硕士并进行深入分析。我们发现法学硕士的法律情报能力存在显着差异，即使是最好的法学硕士也落后于人类法律专业人士。我们相信LexGenius可以评估法学硕士的法律情报能力并促进法律地理标志的发展。我们的项目可以通过此 https URL 获取。</li>
</ul>

<h3>Title: OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models</h3>
<ul>
<li><strong>Authors: </strong>Zhuoyue Wan, Wentao Hu, Chen Jason Zhang, Yuanfeng Song, Shuaimin Li, Ruiqiang Xiao, Xiao-Yong Wei, Raymond Chi-Wing Wong</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.DB</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04738">https://arxiv.org/abs/2512.04738</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04738">https://arxiv.org/pdf/2512.04738</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04738]] OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models(https://arxiv.org/abs/2512.04738)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.</li>
<li><strong>摘要：</strong>连接自然语言和结构化查询语言是数据库社区中长期存在的挑战。虽然语言模型的最新进展在这个方向上显示出了希望，但现有的解决方案通常依赖于大规模闭源模型，这些模型存在推理成本高、透明度有限以及缺乏轻量级部署适应性的问题。在本文中，我们提出了 OsmT，这是一种开源标签感知语言模型，专门用于桥接自然语言和 Overpass 查询语言 (OverpassQL)，这是一种用于访问大规模 OpenStreetMap (OSM) 数据的结构化查询语言。为了提高生成查询的准确性和结构有效性，我们引入了标签检索增强（TRA）机制，该机制将上下文相关的标签知识合并到生成过程中。该机制旨在捕获 OSM 数据库中存在的层次结构和关系依赖关系，解决地理空间查询制定中固有的拓扑复杂性。此外，我们定义了一个反向任务 OverpassQL-to-Text，它将结构化查询转换为自然语言解释，以支持查询解释并提高用户可访问性。我们根据强大的基线在公共基准上评估 OsmT，并观察查询生成和解释方面的持续改进。尽管使用的参数明显减少，但我们的模型实现了有竞争力的准确性，证明了开源预训练语言模型在模式丰富的地理空间环境中桥接自然语言和结构化查询语言方面的有效性。</li>
</ul>

<h3>Title: SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs</h3>
<ul>
<li><strong>Authors: </strong>Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04746">https://arxiv.org/abs/2512.04746</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04746">https://arxiv.org/pdf/2512.04746</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04746]] SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs(https://arxiv.org/abs/2512.04746)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at this https URL.</li>
<li><strong>摘要：</strong>极低位量化对于有效部署大型语言模型 (LLM) 至关重要，但它通常会导致 2 位甚至 4 位（例如 MXFP4）的性能严重下降。我们提出了 SignRoundV2，这是一种训练后量化框架，即使没有混合精度也非常有效。 SignRoundV2 引入了 (1) 一种快速灵敏度度量，它将梯度信息与量化引起的偏差相结合，以指导逐层比特分配；(2) 量化尺度的轻量级预调整搜索，以改进极低比特量化。这些组件使 SignRoundV2 能够缩小与全精度模型的差距。大量实验表明，我们的方法对于法学硕士来说保持了有竞争力的准确性，实现了生产级性能，在 4-5 位时方差约为 1%，即使在 2 位时也能获得很好的结果。此 https URL 提供了该实现。</li>
</ul>

<h3>Title: Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time</h3>
<ul>
<li><strong>Authors: </strong>Xinyue Kang, Diwei Shi, Li Chen</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04748">https://arxiv.org/abs/2512.04748</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04748">https://arxiv.org/pdf/2512.04748</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04748]] Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time(https://arxiv.org/abs/2512.04748)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>It is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model's pre-existing this http URL address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM's parameters entirely frozen. By optimizing the TTSV on test data to minimize the model's output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach's effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.</li>
<li><strong>摘要：</strong>针对特定任务或新发行版有效释放大型语言模型 (LLM) 的强大推理潜力是一项关键挑战。现有的测试时适应方法通常需要调整模型参数，这不仅计算量大，而且还存在降低模型预先存在的此 http URL 地址的风险，为此，我们引入了一个轻量级组件，测试时引导向量 (TTSV)，它被添加到输入之前，同时保持 LLM 的参数完全冻结。通过优化测试数据上的 TTSV 以最小化模型的输出熵，我们引导模型走向更高置信度的内部状态，激活其与当前任务最相关的固有能力。 TTSV 既轻量又高效，可优化，使其成为真正的即插即用增强功能。大量的实验验证了我们的方法在基本模型和推理增强模型上的有效性。例如，在 MATH500 任务中，TTSV 在 Qwen2.5-Math-7B 模型上实现了 45.88% 的相对性能增益，在 Qwen3-4B 模型上实现了 16.22% 的相对性能增益。此外，我们的方法表现出强大的泛化能力，其引导向量被证明在不同任务之间具有高度可转移性。</li>
</ul>

<h3>Title: EtCon: Edit-then-Consolidate for Reliable Knowledge Editing</h3>
<ul>
<li><strong>Authors: </strong>Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04753">https://arxiv.org/abs/2512.04753</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04753">https://arxiv.org/pdf/2512.04753</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04753]] EtCon: Edit-then-Consolidate for Reliable Knowledge Editing(https://arxiv.org/abs/2512.04753)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing evaluations and their real-world effectiveness in lifelong learning scenarios, which greatly limits their practical applicability. This work's empirical analysis reveals two recurring issues associated with this gap: (1) Most traditional methods lead the edited model to overfit to the new fact, thereby degrading pre-trained capabilities; (2) There is a critical absence of a knowledge consolidation stage, leaving new facts insufficiently integrated into LLMs' inference-time behavior under autoregressive generation, thereby leading to a mismatch between parametric knowledge and actual generation behavior. To this end, we propose Edit-then-Consolidate, a novel knowledge editing paradigm that aims to bridge the gap between theoretical knowledge editing methods and their real-world applicability. Specifically, (1) our framework mitigates overfitting via Targeted Proximal Supervised Fine-Tuning (TPSFT) that localizes the edit via a trust-region objective to limit policy drift; (2) Then, a consolidation stage using Group Relative Policy Optimization (GRPO) aligns the edited knowledge with CoT-based inference policy by optimizing trajectory-level behavior under comprehensive reward signals. Extensive experiments demonstrate our framework consistently improves editing reliability and generalization under real-world evaluations, while better preserving locality and pre-trained capabilities.</li>
<li><strong>摘要：</strong>知识编辑旨在更新大型语言模型（LLM）中的特定事实，而无需完全重新训练。之前的努力试图调整法学硕士的知识层，事实证明对于进行选择性编辑是有效的。然而，它们在受控、教师强制评估中的表现与它们在终身学习场景中的现实有效性之间存在显着差距，这极大地限制了它们的实际适用性。这项工作的实证分析揭示了与这一差距相关的两个反复出现的问题：（1）大多数传统方法导致编辑后的模型过度适应新事实，从而降低了预训练的能力； （2）严重缺乏知识巩固阶段，导致新事实未能充分融入法学硕士在自回归生成下的推理时间行为中，从而导致参数知识与实际生成行为之间的不匹配。为此，我们提出了“编辑然后合并”，一种新颖的知识编辑范式，旨在弥合理论知识编辑方法与其现实世界适用性之间的差距。具体来说，（1）我们的框架通过有针对性的近端监督微调（TPSFT）缓解过度拟合，该微调通过信任区域目标本地化编辑以限制策略漂移； (2) 然后，使用组相对策略优化 (GRPO) 的巩固阶段通过优化综合奖励信号下的轨迹级行为，将编辑的知识与基于 CoT 的推理策略对齐。大量的实验表明，我们的框架在现实世界的评估下持续提高了编辑的可靠性和泛化性，同时更好地保留了局部性和预先训练的功能。</li>
</ul>

<h3>Title: Challenging the Abilities of Large Language Models in Italian: a Community Initiative</h3>
<ul>
<li><strong>Authors: </strong>Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Begoña Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potertì, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04759">https://arxiv.org/abs/2512.04759</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04759">https://arxiv.org/pdf/2512.04759</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04759]] Challenging the Abilities of Large Language Models in Italian: a Community Initiative(https://arxiv.org/abs/2512.04759)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. "Challenging the Abilities of LAnguage Models in ITAlian" (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource -- the most comprehensive and diverse benchmark for Italian to date -- and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 的快速进步改变了自然语言处理，并扩大了其在研究和社会中的影响。然而，对这些模型的系统评估，特别是对于英语以外的语言，仍然有限。 “挑战意大利语语言模型的能力”（CALAMITA）是一项大规模的意大利语协作基准测试计划，由意大利计算语言学协会负责协调。与专注于排行榜的现有工作不同，CALAMITA 强调方法论：它联合了来自学术界、工业界和公共部门的 80 多名贡献者来设计、记录和评估各种任务，涵盖语言能力、常识推理、事实一致性、公平性、摘要、翻译和代码生成。通过这个过程，我们不仅组装了超过 20 个任务和近 100 个子任务的基准，而且还建立了支持异构数据集和指标的集中式评估管道。我们报告了四个开放权重法学硕士的结果，强调了跨能力的系统优势和劣势，以及特定任务评估中的挑战。除了定量结果之外，CALAMITA 还揭示了方法论教训：细粒度、任务代表性指标的必要性、协调管道的重要性以及广泛社区参与的好处和局限性。 CALAMITA 被认为是一个滚动基准，能够持续集成新任务和模型。这使其既成为一种资源（迄今为止最全面、最多样化的意大利语基准），又成为可持续、社区驱动的评估框架。我们认为，这种组合为其他语言和社区寻求包容性和严格的法学硕士评估实践提供了蓝图。</li>
</ul>

<h3>Title: AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages</h3>
<ul>
<li><strong>Authors: </strong>Pooja Singh, Sandeep Kumar</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04765">https://arxiv.org/abs/2512.04765</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04765">https://arxiv.org/pdf/2512.04765</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04765]] AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages(https://arxiv.org/abs/2512.04765)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Large language models and multilingual machine translation (MT) systems increasingly drive access to information, yet many languages of the tribal communities remain effectively invisible in these technologies. This invisibility exacerbates existing structural inequities in education, governance, and digital participation. We present AdiBhashaa, a community-driven initiative that constructs the first open parallel corpora and baseline MT systems for four major Indian tribal languages-Bhili, Mundari, Gondi, and Santali. This work combines participatory data creation with native speakers, human-in-the-loop validation, and systematic evaluation of both encoder-decoder MT models and large language models. In addition to reporting technical findings, we articulate how AdiBhashaa illustrates a possible model for more equitable AI research: it centers local expertise, builds capacity among early-career researchers from marginalized communities, and foregrounds human validation in the development of language technologies.</li>
<li><strong>摘要：</strong>大型语言模型和多语言机器翻译 (MT) 系统日益推动信息获取，但部落社区的许多语言在这些技术中实际上仍然不可见。这种不可见性加剧了教育、治理和数字参与方面现有的结构性不平等。我们推出了 AdiBhashaa，这是一项社区驱动的计划，为四种主要印度部落语言（Bhili、Mundari、Gondi 和 Santali）构建了第一个开放并行语料库和基线机器翻译系统。这项工作将参与式数据创建与母语人士、人机交互验证以及编码器-解码器机器翻译模型和大型语言模型的系统评估结合起来。除了报告技术发现之外，我们还阐明了 AdiBhashaa 如何阐明更公平的人工智能研究的可能模型：它以当地专业知识为中心，培养来自边缘化社区的早期职业研究人员的能力，并在语言技术的开发中突出人类验证。</li>
</ul>

<h3>Title: DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors</h3>
<ul>
<li><strong>Authors: </strong>Gianluca Barmina, Nathalie Carmen Hau Norman, Peter Schneider-Kamp, Lukas Galke</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04799">https://arxiv.org/abs/2512.04799</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04799">https://arxiv.org/pdf/2512.04799</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04799]] DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors(https://arxiv.org/abs/2512.04799)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>We present an enhanced benchmark for evaluating linguistic acceptability in Danish. We first analyze the most common errors found in written Danish. Based on this analysis, we introduce a set of fourteen corruption functions that generate incorrect sentences by systematically introducing errors into existing correct Danish sentences. To ensure the accuracy of these corruptions, we assess their validity using both manual and automatic methods. The results are then used as a benchmark for evaluating Large Language Models on a linguistic acceptability judgement task. Our findings demonstrate that this extension is both broader and more comprehensive than the current state of the art. By incorporating a greater variety of corruption types, our benchmark provides a more rigorous assessment of linguistic acceptability, increasing task difficulty, as evidenced by the lower performance of LLMs on our benchmark compared to existing ones. Our results also suggest that our benchmark has a higher discriminatory power which allows to better distinguish well-performing models from low-performing ones.</li>
<li><strong>摘要：</strong>我们提出了评估丹麦语语言可接受性的增强基准。我们首先分析书面丹麦语中最常见的错误。基于此分析，我们引入了一组 14 个损坏函数，这些函数通过系统地将错误引入现有的正确丹麦语句子来生成不正确的句子。为了确保这些损坏的准确性，我们使用手动和自动方法评估其有效性。然后将结果用作评估大型语言模型在语言可接受性判断任务上的基准。我们的研究结果表明，这种扩展比当前的技术水平更广泛、更全面。通过纳入更多种类的腐败类型，我们的基准提供了对语言可接受性的更严格的评估，增加了任务难度，与现有的相比，法学硕士在我们的基准上的表现较低就证明了这一点。我们的结果还表明，我们的基准具有更高的区分能力，可以更好地区分表现良好的模型和表现不佳的模型。</li>
</ul>

<h3>Title: DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution</h3>
<ul>
<li><strong>Authors: </strong>L. D. M. S. Sai Teja, N. Siva Gopala Krishna, Ufaq Khan, Muhammad Haris Khan, Partha Pakray, Atul Mishra</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04838">https://arxiv.org/abs/2512.04838</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04838">https://arxiv.org/pdf/2512.04838</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04838]] DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution(https://arxiv.org/abs/2512.04838)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>In the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-versa, a problem with critical implications for authenticity, trust, and human oversight. We introduce a novel framework, called Info-Mask for mixed authorship detection that integrates stylometric cues, perplexity-driven signals, and structured boundary modeling to accurately segment collaborative human-AI content. To evaluate the robustness of our system against adversarial perturbations, we construct and release an adversarial benchmark dataset Mixed-text Adversarial setting for Segmentation (MAS), designed to probe the limits of existing detectors. Beyond segmentation accuracy, we introduce Human-Interpretable Attribution (HIA overlays that highlight how stylometric features inform boundary predictions, and we conduct a small-scale human study assessing their usefulness. Across multiple architectures, Info-Mask significantly improves span-level robustness under adversarial conditions, establishing new baselines while revealing remaining challenges. Our findings highlight both the promise and limitations of adversarially robust, interpretable mixed-authorship detection, with implications for trust and oversight in human-AI co-authorship.</li>
<li><strong>摘要：</strong>在先进的大语言模型 (LLM) 时代，人类和人工智能生成的文本之间的界限变得越来越模糊。我们解决了分割混合作者文本的挑战，即识别文本中作者身份从人类转移到人工智能的转变点，反之亦然，这个问题对真实性、信任和人类监督具有重要影响。我们引入了一种名为 Info-Mask 的新颖框架，用于混合作者身份检测，该框架集成了风格提示、困惑驱动信号和结构化边界建模，以准确分割人类与人工智能的协作内容。为了评估我们的系统对抗对抗性扰动的鲁棒性，我们构建并发布了一个对抗性基准数据集混合文本对抗性分割设置（MAS），旨在探测现有检测器的极限。除了分割准确性之外，我们还引入了人类可解释的归因（HIA 叠加，强调了风格特征如何影响边界预测，并且我们进行了一项小规模的人类研究来评估其有用性。在多种架构中，Info-Mask 显着提高了对抗条件下的跨度鲁棒性，建立了新的基线，同时揭示了剩余的挑战。我们的研究结果强调了对抗性鲁棒、可解释的混合作者检测的前景和局限性，这对人类人工智能的信任和监督具有影响共同作者。</li>
</ul>

<h3>Title: Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates</h3>
<ul>
<li><strong>Authors: </strong>Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04844">https://arxiv.org/abs/2512.04844</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04844">https://arxiv.org/pdf/2512.04844</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04844]] Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates(https://arxiv.org/abs/2512.04844)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.</li>
<li><strong>摘要：</strong>扩大指导大语言模型（LLM）的语言多样性对于全球可访问性至关重要，但往往因依赖昂贵的专业目标语言标记数据和适应过程中的灾难性遗忘而受到阻碍。我们在现实的、低资源的约束下应对这一挑战：仅使用未标记的目标语言数据来调整指导法学硕士。我们引入了源屏蔽更新（SSU），这是一种主动保留源知识的选择性参数更新策略。 SSU 使用一小组源数据和参数重要性评分方法来识别对于维持源能力至关重要的参数。然后，它应用逐列冻结策略来在适应之前保护这些参数。跨五种类型不同的语言以及 7B 和 13B 模型的实验表明，SSU 成功地减轻了灾难性遗忘。它将单语言源任务的性能下降平均降低至 3.4% (7B) 和 2.8% (13B)，与完全微调的 20.3% 和 22.3% 形成鲜明对比。 SSU 还通过全面微调实现了极具竞争力的目标语言性能，在 7B 模型的所有基准测试和大多数 13B 模型的基准测试中均优于它。</li>
</ul>

<h3>Title: SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs</h3>
<ul>
<li><strong>Authors: </strong>Hao Wang, Jialun Zhong, Changcheng Wang, Zhujun Nie, Zheng Li, Shunyu Yao, Yanzeng Li, Xinchi Li</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04868">https://arxiv.org/abs/2512.04868</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04868">https://arxiv.org/pdf/2512.04868</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04868]] SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs(https://arxiv.org/abs/2512.04868)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework's capacity for robust and scalable conversational reasoning.</li>
<li><strong>摘要：</strong>基于知识的会话问答（KBCQA）在解决共指、建模上下文依赖性和执行复杂的逻辑推理方面面临着持续的挑战。现有的方法，无论是端到端语义解析还是基于代理的逐步推理，通常都会遇到结构不准确和计算成本过高的问题，特别是在处理大型知识图谱上的复杂查询时。为了解决这些限制，我们引入了 SEAL，这是一种基于自我进化代理学习的新颖的两阶段语义解析框架。在第一阶段，大型语言模型 (LLM) 提取最小的 S 表达式核心，以捕获输入查询的基本语义。然后通过代理校准模块对该核心进行细化，该模块纠正语法不一致并将实体和关系与底层知识图精确对齐。第二阶段采用基于模板的补全，以问题类型预测和占位符实例化为指导，构建完全可执行的 S 表达式。这种分解不仅简化了逻辑形式的生成，而且显着提高了结构保真度和链接效率。至关重要的是，SEAL 结合了一种自我进化机制，将本地和全局内存与反射模块集成在一起，从而能够根据对话历史和执行反馈进行持续适应，而无需明确的重新训练。 SPICE 基准测试的大量实验表明，SEAL 实现了最先进的性能，特别是在多跳推理、比较和聚合任务中。结果验证了结构准确性和计算效率的显着提升，强调了该框架稳健且可扩展的对话推理的能力。</li>
</ul>

<h3>Title: LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics</h3>
<ul>
<li><strong>Authors: </strong>Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04957">https://arxiv.org/abs/2512.04957</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04957">https://arxiv.org/pdf/2512.04957</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04957]] LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics(https://arxiv.org/abs/2512.04957)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm</a></li>
<li><strong>Abstract: </strong>Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.</li>
<li><strong>摘要：</strong>大型语言模型 (LLM) 在各种语言相关任务中表现出巨大的潜力，但它们是否能够捕获更深层次的语言属性，例如来自原始文本的句法结构、语音提示和韵律模式，目前尚不清楚。为了分析法学硕士是否可以有效地学习这些特征并将其应用于重要的自然语言相关任务，我们引入了一个源自古腾堡计划的新颖的多语言流派分类数据集，古腾堡计划是一个大型数字图书馆，提供对数千部公共领域文学作品的免费访问，每个二进制任务包含数千个句子（诗歌与小说；戏剧与诗歌；戏剧与小说），有六种语言（英语、法语、德语、意大利语、西班牙语和葡萄牙语）。我们用三个显式语言特征集（句法树结构、隐喻计数和语音度量）来增强每个特征集，以评估它们对分类性能的影响。实验表明，尽管 LLM 分类器可以从原始文本或显式提供的特征中学习潜在的语言结构，但不同的特征在任务中的贡献并不均匀，这强调了在模型训练期间纳入更复杂的语言信号的重要性。</li>
</ul>

<h3>Title: Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction</h3>
<ul>
<li><strong>Authors: </strong>Nex-AGI Team: Yuxuan Cai, Lu Chen, Qiaoling Chen, Yuyang Ding, Liwen Fan, Wenjie Fu, Yufei Gao, Honglin Guo, Pinxue Guo, Zhenhua Han, Zhengfu He, Hanglei Hu, Kai Hu, Shengjia Hua, Tianyu Huai, Baodai Huang, Li Ji, Zhen Jiang, Zhikai Lei, Bufan Li, Jiahang Lin, Lizhi Lin, Jinxiu Liu, Shichun Liu, Ziming Liu, Yuchen Ni, Pengfang Qian, Yujiong Shen, Qingyun Shi, Wentao Shu, Peng Sun, Yiran Suo, Tian Tang, Boyu Tian, Guoteng Wang, Junzhe Wang, Peixin Wang, Zhiheng Xi, Hang Yan, Jie Yang, Zhixiong Yang, Tianchu Yao, Guangze Ye, Qianxi Yu, Shuo Zhang, Xinyue Zhang, Yiqi Zhang, Jiarong Zhao, Miao Zheng, Rui Zheng, Enyu Zhou, Jiazheng Zhou, Maosen Zhou, Yuhao Zhou, Tao Gui, Yining Zheng, Xinchi Chen, Jie Zhou, Siyuan Feng, Qin Chen, Liang He, Qi Zhang, Xuanjing Huang, Xipeng Qiu</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.04987">https://arxiv.org/abs/2512.04987</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.04987">https://arxiv.org/pdf/2512.04987</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.04987]] Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction(https://arxiv.org/abs/2512.04987)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, agent</a></li>
<li><strong>Abstract: </strong>The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms -- from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity and complexity of interactive environments. Our method realizes this scaling by addressing three orthogonal dimensions: (1) Complexity: NexAU, a flexible agent framework that supports building complex agent hierarchies via simple configurations; (2) Diversity: NexA4A automatically generates diverse agent hierarchies from natural language to cover infinite domains; and (3) Fidelity: NexGAP bridges the simulation-reality gap by integrating dynamic real-world environment for grounded trajectories synthesis. We train Nex-N1 upon the diverse and complex interactive environments established by our infrastructure. Empirical results on benchmarks such as SWE-bench and tau2 demonstrate that Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance against frontier proprietary models on complex agentic tasks. We open-source the Nex ecosystem and model weights to facilitate further research.</li>
<li><strong>摘要：</strong>大型语言模型（LLM）从被动响应者到自主代理的演变需要学习范式的根本转变——从静态模仿到激励驱动的决策。然而，由于缺乏能够构建高质量交互信号以进行有效政策学习的可扩展基础设施，这种转变受到严重阻碍。为了解决这个问题，我们引入了一种综合方法，旨在系统地扩展交互式环境的多样性和复杂性。我们的方法通过解决三个正交维度来实现这种扩展：（1）复杂性：NexAU，一个灵活的代理框架，支持通过简单的配置构建复杂的代理层次结构； (2) 多样性：NexA4A 自动从自然语言生成多样化的代理层次结构，以覆盖无限领域； (3) 保真度：NexGAP 通过集成动态现实环境进行接地轨迹合成，弥合了模拟与现实之间的差距。我们在我们的基础设施建立的多样​​化且复杂的交互环境中训练 Nex-N1。 SWE-bench 和 tau2 等基准测试的实证结果表明，Nex-N1 始终优于 SOTA 开源模型，并在复杂代理任务上实现了与前沿专有模型相比的竞争性能。我们开源 Nex 生态系统和模型权重，以促进进一步的研究。</li>
</ul>

<h3>Title: Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking</h3>
<ul>
<li><strong>Authors: </strong>Francielle Vargas, Daniel Pedronette</a></li>
<li><strong>Subjects: </strong>cs.CL</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.05012">https://arxiv.org/abs/2512.05012</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.05012">https://arxiv.org/pdf/2512.05012</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.05012]] Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking(https://arxiv.org/abs/2512.05012)</code><input type="text"></li>
<li><strong>Keywords: </strong>hallucination</a></li>
<li><strong>Abstract: </strong>This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.</li>
<li><strong>摘要：</strong>该扩展摘要介绍了自解释对比证据重排序（CER），这是一种新颖的方法，它通过对比学习微调嵌入并为每个检索到的段落生成标记级归因原理，从而围绕事实证据重组检索。使用基于主观性的标准自动选择硬否定，迫使模型更接近事实依据，同时将主观或误导性的解释推开。因此，该方法创建了一个与证据推理明确一致的嵌入空间。我们根据临床试验报告评估了我们的方法，初步实验结果表明，CER 提高了检索准确性，减轻了 RAG 系统中出现幻觉的可能性，并提供透明、基于证据的检索，从而提高了可靠性，尤其是在安全关键领域。</li>
</ul>

<h3>Title: Arbitrage: Efficient Reasoning via Advantage-Aware Speculation</h3>
<ul>
<li><strong>Authors: </strong>Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.LG</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.05033">https://arxiv.org/abs/2512.05033</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.05033">https://arxiv.org/pdf/2512.05033</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.05033]] Arbitrage: Efficient Reasoning via Advantage-Aware Speculation(https://arxiv.org/abs/2512.05033)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model</a></li>
<li><strong>Abstract: </strong>Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.</li>
<li><strong>摘要：</strong>现代大型语言模型通过长思想链实现了令人印象深刻的推理能力，但在推理过程中会产生大量的计算成本，这激励了技术提高性能成本比。在这些技术中，推测解码通过采用快速但不准确的草稿模型来自回归地提出令牌，然后由功能更强大的目标模型并行验证令牌，从而加速推理。然而，由于语义等效步骤中令牌不匹配导致不必要的拒绝，传统令牌级推测解码在推理任务中陷入困境。尽管最近的工作已经转向步骤级语义验证，通过接受或拒绝整个推理步骤来提高效率，但现有的步骤级方法仍然重新生成许多被拒绝的步骤，几乎没有改进，浪费了宝贵的目标计算。为了应对这一挑战，我们提出了套利，这是一种新颖的阶梯级投机生成框架，可根据草稿模型和目标模型之间的相对优势动态地路由生成。套利没有应用固定的接受阈值，而是使用经过训练的轻量级路由器来预测目标模型何时可能产生有意义的更好步骤。这种路由近似于理想的套利预言机，它始终选择更高质量的步骤，实现接近最优的效率与准确性权衡。在多个数学推理基准中，Arbitrage 始终超越先前的步骤级推测解码基线，在匹配的精度下将推理延迟减少高达 $\sim2\times$。</li>
</ul>

<h3>Title: Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning</h3>
<ul>
<li><strong>Authors: </strong>Purbesh Mitra, Sennur Ulukus</a></li>
<li><strong>Subjects: </strong>cs.CL, cs.AI, cs.IT, cs.LG, eess.SP</a></li>
<li><strong>Abstract URL: </strong><a href="https://arxiv.org/abs/2512.05105">https://arxiv.org/abs/2512.05105</a></li>
<li><strong>Pdf URL: </strong><a href="https://arxiv.org/pdf/2512.05105">https://arxiv.org/pdf/2512.05105</a></li>
<li><strong>Copy Paste: </strong><code><input type="checkbox">[[2512.05105]] Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning(https://arxiv.org/abs/2512.05105)</code><input type="text"></li>
<li><strong>Keywords: </strong>language model, llm, long context, prompt, chain-of-thought</a></li>
<li><strong>Abstract: </strong>Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at this https URL, and the model, curated dataset is available at this https URL.</li>
<li><strong>摘要：</strong>大语言模型 (LLM) 中的长上下文推理已证明通过思想链 (CoT) 推理可以增强其认知能力。训练此类模型通常是通过强化学习和可验证奖励（RLVR）来完成基于推理的问题，例如数学和编程。然而，RLVR 受到一些瓶颈的限制，例如缺乏密集的奖励、样本效率不足等。因此，在训练后阶段需要大量的计算资源。为了克服这些限制，在这项工作中，我们提出了 \textbf{语义软引导（SSB）}，一种自蒸馏技术，其中相同的基础语言模型扮演教师和学生的角色，但在训练时接收关于其结果正确性的不同语义上下文。首先用数学问题提示该模型，然后生成多个卷展栏。从它们中，过滤出正确和最常见的错误响应，然后将其提供给上下文中的模型，以生成更可靠的分步解释以及经过验证的最终答案。该管道会根据原始问题答案数据自动生成配对的师生训练集，无需任何人工干预。这个生成过程还会产生一系列 logits，这是学生模型在训练阶段仅从简单问题中尝试匹配的内容。在我们的实验中，Qwen2.5-3B-Instruct 通过参数高效的微调在 GSM8K 数据集上进行。然后我们在 MATH500 和 AIME2024 基准测试中测试了其准确性。我们的实验表明，与常用的 RLVR 算法——组相对策略优化 (GRPO) 相比，准确率分别提高了 10.6% 和 10%。我们的代码可从此 https URL 获取，模型、精选数据集可在此 https URL 获取。</li>
</ul>

<button id="copy">Copy All</button>
</article>
<script src="../../javascript/clipboard.min.js"></script>
<script src="../../javascript/clipboard.js"></script>
